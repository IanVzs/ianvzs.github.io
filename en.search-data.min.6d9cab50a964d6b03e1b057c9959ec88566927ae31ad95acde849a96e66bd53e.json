[{"id":0,"href":"/docs/programmer/","title":"程序员笔记","section":"Docs","content":" 简介 # 包含基本知识、编程语言、后端、前端、网络等，还有一些交叉领域。\n"},{"id":1,"href":"/docs/programmer/gui/example/table-of-contents/with-toc/","title":"With ToC","section":"Table of Contents","content":" Caput vino delphine in tamen vias # Cognita laeva illo fracta # Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\nTe at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit Natus quaerere # Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\nPhrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\nLimitibus misere sit # Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua # Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta # Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"},{"id":2,"href":"/docs/programmer/gui/example/table-of-contents/without-toc/","title":"Without ToC","section":"Table of Contents","content":" At me ipso nepotibus nunc celebratior genus # Tanto oblite # Lorem markdownum pectora novis patenti igne sua opus aurae feras materiaque illic demersit imago et aristas questaque posset. Vomit quoque suo inhaesuro clara. Esse cumque, per referri triste. Ut exponit solisque communis in tendens vincetis agisque iamque huic bene ante vetat omina Thebae rates. Aeacus servat admonitu concidit, ad resimas vultus et rugas vultu dignamque Siphnon.\nQuam iugulum regia simulacra, plus meruit humo pecorumque haesit, ab discedunt dixit: ritu pharetramque. Exul Laurenti orantem modo, per densum missisque labor manibus non colla unum, obiectat. Tu pervia collo, fessus quae Cretenque Myconon crate! Tegumenque quae invisi sudore per vocari quaque plus ventis fluidos. Nodo perque, fugisse pectora sorores.\nSumme promissa supple vadit lenius # Quibus largis latebris aethera versato est, ait sentiat faciemque. Aequata alis nec Caeneus exululat inclite corpus est, ire tibi ostendens et tibi. Rigent et vires dique possent lumina; eadem dixit poma funeribus paret et felix reddebant ventis utile lignum.\nRemansit notam Stygia feroxque Et dabit materna Vipereas Phrygiaeque umbram sollicito cruore conlucere suus Quarum Elis corniger Nec ieiunia dixit Vertitur mos ortu ramosam contudit dumque; placabat ac lumen. Coniunx Amoris spatium poenamque cavernis Thebae Pleiadasque ponunt, rapiare cum quae parum nimium rima.\nQuidem resupinus inducto solebat una facinus quae # Credulitas iniqua praepetibus paruit prospexit, voce poena, sub rupit sinuatur, quin suum ventorumque arcadiae priori. Soporiferam erat formamque, fecit, invergens, nymphae mutat fessas ait finge.\nBaculum mandataque ne addere capiti violentior Altera duas quam hoc ille tenues inquit Sicula sidereus latrantis domoque ratae polluit comites Possit oro clausura namque se nunc iuvenisque Faciem posuit Quodque cum ponunt novercae nata vestrae aratra Ite extrema Phrygiis, patre dentibus, tonso perculit, enim blanda, manibus fide quos caput armis, posse! Nocendo fas Alcyonae lacertis structa ferarum manus fulmen dubius, saxa caelum effuge extremis fixum tumor adfecit bella, potentes? Dum nec insidiosa tempora tegit spirarunt. Per lupi pars foliis, porreximus humum negant sunt subposuere Sidone steterant auro. Memoraverit sine: ferrum idem Orion caelum heres gerebat fixis?\n"},{"id":3,"href":"/docs/programmer/gui/example/","title":"Blog 构建","section":"图形用户界面-GUI","content":" Blog 构建 # #blog #hugo\nHugo特殊Markdown语法简介(Introduction) # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret Est simul fameque tauri qua ad # Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol # Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo; Trepident sitimque # Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"},{"id":4,"href":"/docs/programmer/ml/stable-diffusion/","title":"AI画图","section":"机器学习","content":" 起手式 # 正 # best quality, (mature:1.3),perfect face, beautiful face,western, sharp focus, solo,beautiful woman,sexy,shiny skin,Navy blouse, beige shorts, soft light,cinematic lighting, sunny, dusk, outdoor,depth of field,shidudou,red_dress, 反 # (worst quality, low quality:2), NSFW, monochrome, zombie, overexposure, watermark, text, bad anatomy, bad hand,((extra hands)),extra fingers, too many fingers, fused fingers, bad arm, distorted arm, extra arms, fused arms, extra legs, missing leg,disembodied leg,extra nipples, detached arm, liquid hand, inverted hand, disembodied limb, oversized head, extra body, extra navel, (hair between eyes),sketch, duplicate, ugly, huge eyes, text, logo, worst face, (bad and mutated hands:1.3), (blurry:2.0), horror, geometry, bad_prompt, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), (deformed fingers:1.2), (long fingers:1.2), bad hand, extra legs, easynegative monochrome, (impassive:1.4), featureless, colorless, characterless, teen, young, grotesque, 3d max, desaturated, paintings, sketches, (worst quality:1.7), (low quality:1.7), (normal quality:1.7), lowres, normal quality, skin spots, acnes, skin blemishes, age spot,close-up,badhanv4, 安装问题解决 # 运行.sh脚本自动创建的venv环境在../venv中，有时候bash webui.sh用不对虚拟环境时可以手动用python执行\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git cd stable-diffusion-webui git checkout 22bcc7be428c94e9408f589966c2040187245d81 bash webui.sh --skip-torch-cuda-test --no-half --precision full --use-cpu all --listen 由于以上checkout了，所以很多库版本跟不上了。虽然它会创建新的虚拟环境，但是我的torch安装的最新版本。所以遇到了下面问题，现在罗列解决办法如下：\n采用运行也可\nsource venv/bin/activate python webui.py --skip-torch-cuda-test --no-half --precision full --use-cpu all --listen TypeError: AsyncConnectionPool.init() got an unexpected keyword argument \u0026lsquo;socket_options\u0026rsquo;\npip install --upgrade httpx ModuleNotFoundError: No module named \u0026rsquo;torchvision.transforms.functional_tensor'\nvim /home/ian/Desktop/stable-diffusion-webui/venv/lib/python3.10/site-packages/basicsr/data/degradations.py 修改from torchvision.transforms.functional_tensor import rgb_to_grayscale为from torchvision.transforms._functional_tensor import rgb_to_grayscale\n角色控制 - ContralNet # ControlNet 1.1包括14个模型（11个生产就绪模型和3个实验性模型）：\n插件地址： 本地：extensions/sd-webui-controlnet 下载地址：git clone https://github.com/Mikubill/sd-webui-controlnet 插件模型地址： 本地：models/ControlNet 下载地址：git clone https://huggingface.co/lllyasviel/ControlNet-v1-1 模型名称 模型描述 模型和配置文件 control_v11p_sd15_canny 使用 Canny 边缘检测算法的模型 control_v11p_sd15_canny.pth / control_v11p_sd15_canny.yaml control_v11p_sd15_mlsd 使用最小长度分割线检测算法 (MLSD) 的模型 control_v11p_sd15_mlsd.pth / control_v11p_sd15_mlsd.yaml control_v11f1p_sd15_depth 生成深度信息的模型 control_v11f1p_sd15_depth.pth / control_v11f1p_sd15_depth.yaml control_v11p_sd15_normalbae 应用法线估计和自编码器 (BAE) 的模型 control_v11p_sd15_normalbae.pth / control_v11p_sd15_normalbae.yaml control_v11p_sd15_seg 用于图像分割的模型 control_v11p_sd15_seg.pth / control_v11p_sd15_seg.yaml control_v11p_sd15_inpaint 用于图像修复的模型 control_v11p_sd15_inpaint.pth / control_v11p_sd15_inpaint.yaml control_v11p_sd15_lineart 用于线稿生成的模型 control_v11p_sd15_lineart.pth / control_v11p_sd15_lineart.yaml control_v11p_sd15s2_lineart_anime 用于动漫线稿生成的模型 control_v11p_sd15s2_lineart_anime.pth / control_v11p_sd15s2_lineart_anime.yaml control_v11p_sd15_openpose 用于人体姿势估计的模型 control_v11p_sd15_openpose.pth / control_v11p_sd15_openpose.yaml control_v11p_sd15_scribble 用于涂鸦生成的模型 control_v11p_sd15_scribble.pth / control_v11p_sd15_scribble.yaml control_v11p_sd15_softedge 用于软边缘生成的模型 control_v11p_sd15_softedge.pth / control_v11p_sd15_softedge.yaml control_v11e_sd15_shuffle 使用深度估计和卷积神经网络的模型进行图像重排 control_v11e_sd15_shuffle.pth / control_v11e_sd15_shuffle.yaml control_v11e_sd15_ip2p 使用图像修复和卷积神经网络的模型进行图像到图像的转换 control_v11e_sd15_ip2p.pth / control_v11e_sd15_ip2p.yaml control_v11f1e_sd15_tile 使用深度估计和图像瓦片生成的模型 control_v11f1e_sd15_tile.pth / control_v11f1e_sd15_tile.yaml 超分算法插件 # .pth文件放到 models/ESRGAN/ 目录下\n无/None：单纯的放大，不做任何优化处理。 Lanczos：使用加权平均插值方法，利用原始图像自身的像素信息，增加图像的细节，从而提高图像的分辨率。传统的纯数学算法，效果一般。 Nearest：使用简单的插值方法，基于最近邻像素的值进行插值，从而增加图像的细节和提高分辨率。传统的纯数学算法，效果一般，还不如 Lanczos 的效果好。 LDSR：基于深度学习，通过使用轻量级的网络结构和残差学习，实现较高的超分性能和计算效率。适用于各种需要快速且准确地提高图像分辨率的应用场景，如实时视频处理、移动设备图像处理等。 ESRGAN：全称Enhanced Super-Resolution Generative Adversarial Networks （增强超分生成对抗网络），基于深度学习的超分辨率算法。增加了很多看上去很真实的纹理，但是有时可能会过度拟合，出现不好的效果。 4x-UltraSharp：基于ESRGAN做了优化，比较适合处理真人。 ESRGAN_4x：Real ESRGAN，完全使用纯合成数据来尽量贴近真实数据进行训练。腾讯贡献。 R-ESRGAN 4x+：基于Real ESRGAN的优化模型，适合放大真实风格的图片，常用。 R-ESRGAN 4x+ Anime6B：基于Real ESRGAN的优化模型，适合放大动漫风格的图片，常用。 ScuNET GAN：基于深度学习，使用生成对抗网络（GAN）进行训练。主要用在提高图像的视觉效果和感知质量，例如在图像增强、视频处理等。 ScuNET PSNR：基于深度学习，使用均方误差（PSNR）进行训练。主要用在提高图像的客观质量和准确性，例如在医学图像分析、监控视频处理等。 SwinIR_4x：使用Swin Transformer思想，基于自注意力机制的Transformer结构，适合各种图像的超分，比较通用。 视频转视频 # TemporalKit 帧换帧\n定脸输出 # sd-webui-roop\n检测nsfw太严格 # turn off stable diffusion webui (close terminal) open the folder where you have stable diffusion webui installed go to extensions/sd-webui-roop/scripts make and save a copy of the cimage.py file in case something goes wrong open cimage.py in any text editor and delete lines 8, 7, 6, 2. The final code should look like this: import tempfile def convert_to_sd(img): shapes = [] # --略-- return [any(shapes), tempfile.NamedTemporaryFile(delete=False, suffix=\u0026#34;.png\u0026#34;)] "},{"id":5,"href":"/posts/japanese/","title":"Japanese Learning","section":"Blog","content":" より、ほど # 2月は　1月より　ずっど　寒いです。 1がつは　2月ほど　さむくないです（寒くない）。 ーーーー比较 前，肯定，后否定。 1月より　2月ほうが　寒いです。 家族で誰が　一番歌が上手ですか。 ーーーより被比者　ほが选定者、更加者 ーーーで：划分范围　いちばん：最高 1月と　2月と　とどちらが　寒いですか。 ...2月のほうが寒いです。 ーー二选一句型。...と..と　答句：のほうがーー更～冷。 ほうが　いいです　一类形/二类形 ほうが　いいです いる：犬がいる　有狗 N-\u0026gt;N 窗那儿有的人 # 变化 # いー＞く　+なる（なります)　だー＞に　+する（します） 成为…变成… 使成/变为… # 前者，无主观后者有主观要变 二类形/名 に　なります　\u0026hellip;に　します 变成某种N ーーー性质状态发生变化 后者因主语意志、动作引起　電気を消し（けし）で、暗（くら）くします。　もう春になったから、暖かくなる。　（あたたかい）　夜（よる）に　なりました。部屋が暗くなりました。　名词に　します。要什么 息子は　医者に　なります。　話を　簡単（かんたん）に　します。 今年（ことし）七歳に　なりました。 欲しい　なりました\nだー＞な # この会社で歌が一番上手な人はだれですか。 ーー森さんだ+と思（おも）います 并列 # 一类形 て 一类形(いー＞く) 二类形 で 二类形 名1 で 名2 动て+います\n词语细分 # 音（おと）：物体发出 声（こえ）：人、动物意志物发出 できるだけ　軽い（かるい）します。ーー尽量……\n假定 # +れば： # 現実を直視なければ．人間変わらないんだ。　直視ければ　んだ＝！！ \u0026hellip;れば、\u0026hellip;ほど　\u0026hellip;れば、\u0026hellip;だけ　越\u0026hellip;越\u0026hellip; 前者 .^. 表程度 后者 .^. 表两件事物 食べれば食べるほど美味しいですよ。　〜　、〜\n意愿邀请 # \u0026hellip;たい　ゲエム(game)をしたいです。 勉強しくないです。 \u0026hellip;ましょう/ませんが　もう遅(おそ)いですから、寝(ね)ましょう。 \u0026hellip;ましょうか　暑いですから、クーラーを(くーらーを)つけましょうか。 あっ、雨(あめ)が降っていますね。傘を貸(か)しましょうが。 お見合い(おみあい)故郷へ帰りました。 回家相亲（有个老家的词，打不出来哦 実家(じっか)貌似促音的听不出来……）\n词性转换 # V-\u0026gt;N:..+こと # ..ことが　できます　ケーキを作ることが　できますか。 ...は..ことです　仕事(しこと)は日本語を教(おし)えることです。 ..前に ご飯を食べる前に手(て)を洗(あら)っとください。食事（しょくじ） N-\u0026gt;N:\u0026hellip;+ところ　# あの　窓（まど）のところに　いる人は誰ですか。 ..那儿（人也可+） "},{"id":6,"href":"/posts/some-notes-can-make-things-easier-and-more-enjoyable/","title":"杂笔记","section":"Blog","content":" Swift： # [Swift教程] # \u0026gt;https://github.com/ipader/SwiftGuide; Swift 开源项目精选: # \u0026gt;https://github.com/ipader/SwiftGuide/blob/master/Featured.md SwiftGuide: # \u0026gt;https://github.com/ipader/SwiftGuide/blob/master/Featured-Articles.md Swift，以上。\nPelican： # 高亮显示Markdown: # void main() { printf(\u0026quot;高亮？\u0026quot;); // 另起一行 首行缩进，书写即可 } 标题： # 在编辑文字的时候，在前面加上“#”号，可以将之后一行文字作为标题大字体显示，编辑中瞎按，手误敲出来的字符，结果却很有用呢。或许其他字符也有作用，不过这已经满足日常编辑所需，不做过多探究了。充实内容，往往是首要的。\n利用Disqus添加评论系统： # 在此网站注册一个帐号，在设置中找见shortname，应该为自己设置。 然后在Pelicanconf.py这个配置文件中添加\n:::iidentifier\nDISQUS_SITENAME = “yours shortname”\n贴图片： # 在国内找了一个Z4A图床，感觉不错。 注册完毕，上传好图片应用链接自动生成，直接诶复制粘贴即可。HTML、BBCode、Markdown的，另外分为完整图片，中等图片，缩略图三种不同尺寸的链接。感觉良心。另外，点击图片后跳转图床，可以查看原图片文件，更是舒心赏心悦目～ 免费使用，极力推荐。只不过图片不能加入缩进后的“代码栏”。\n数学公式： $ $e^{i\\pi} + 1 = 0$ $ $之间无空格\n$$e^{i\\pi} + 1 = 0$$\n失败……插入插件失败。之后有需要时再查找原因。 (不过这个图床已经废了。……默哀)\nLinux 嵌入式C編程 # Git 协助开发提交代码之类 参考流程（复制于 \u0026gt;https://github.com/numbbbbb/the-swift-programming-language-in-chinese） 有些朋友可能不太清楚如何帮忙翻译，我这里写一个简单的流程，大家可以参考一下： 首先fork我的项目 把fork过去的项目也就是你的项目clone到你的本地 在命令行运行git branch develop来创建一个新分支 运行git checkout develop来切换到新分支 运行git remote add upstream https://github.com/numbbbbb/the-swift-programming-language-in-chinese.git 把我的库添加为远端库 运行git remote update更新 运行git fetch upstream gh-pages拉取我的库的更新到本地 运行git rebase upstream/gh-pages将我的更新合并到你的分支 这是一个初始化流程，只需要做一遍就行，之后请一直在develop分支进行修改。 如果修改过程中我的库有了更新，请重复6、7、8步。 修改之后，首先push到你的库，然后登录GitHub，在你的库的首页可以看到一个pull request```按钮，点击它，填写一些说明信息，然后提交即可。\n关于Pelican这个文章写的完完全全了： # \u0026gt;http://www.wengweitao.com/shi-yong-pelican-github-pagesda-jian-ge-ren-bo-ke.html Vim # Vim中添加多行注释or删除： # 使用Ctrl+v进入VISUAL BLOCK状态 然后上下移动光标选择行数，输入I，改为INSERT(paste)状态，键入内容按下Esc结束，即可。 删除则为选中之后直接按删除功能键如：d、c皆可，即可删除所选一列\nBlog # Pelican # Pelican Static Site Generator, Powered by Python：Pelican是python语言写的静态网站生成器。因为之前一直弄不好Jekyll 犯不着掉在这一颗树上，所以搜到了此同类软件。\n网上的那些教程不知道为什么鲜有一次效仿成功的，都是各种问题。真心他们没有遇见过吗？因此我也不自己贴这个教程了，除非那一天弄懂了那些问题所在，否则不过张贴一些网上现有的示例而已，而且还是不能保证完全正确的示例，没有任何价值。\nDate: 2016-06-18 Title:The 2st Blog Tags: 2st,pelicanのはじて初体験 Slug: test2 就像这样\n接下来将本地的更到Gite: 2016-06-18tHub，至此就算告一段落。未能解决的问题还有很多，换言之其实就是问题们还没着手去解决。\n例如，回车符怎么敲现在都不知道，一篇文章只能这么一条龙一直打下去。真是囧…。另外没法添加链接，旁边那个邮件的地址都还是别人的——这个主题的开发者。如果搞清这两处，估计就能不再去研究别的功能了，毕竟只是一个博客，能更看的过去就好。哈。\n另外，将用到的命令在此备份 make html———— make serve————\noutput文件夹内： git init———— git add .———— git commit -m \u0026lsquo;first commit\u0026rsquo; ———— git remote add origin git@github.com:IanVzs/IanVzs.github.io.git———— git push -u origin master\n此外刚刚发现编辑时首行空格开始则将此段红色高亮显示 就像这样 就像这样并不会… 只不过在刚开始。 不过应该是汉字缩进，并且上一行没有内容，会有高亮显示。貌似是为了方便写程序？或许程序可以用这样的方式来插入，而不需要用那个专用的高亮语句:::*er什么的。\n然而事实并不像以上那么顺利……上传依然错误频出 所以接下来是成功代码依次再排列 git init\ngit add -A git remote remove origin git remote add origin https://github.com/IanVzs/IanVzs.github.io.git git add -A git push --set-upstream origin master -f git init git add -A git remote remove origin git remote add origin https://github.com/IanVzs/IanVzs.github.io.git git add -A git push --set-upstream origin master -f 并且之前写在此处的更新文章也一直没法更新出来，所以将第二篇拆分了，分两个文件来上传，否则只看那个成功update 实在有不信任感觉，现在如果这篇文章还是无法更新，那真的是…… 如果能的话，看来一篇文章还有字数限制？ 应该没 按理，更新后的文件也不是一个文件了，我也换了文件名都不能更新其内容是在令人不解。\n现在呢，就感觉顺手多了，只需要 git init git add . git git commit -m “hia” git push \u0026ndash;set-upstream -f 即可。\n现在，创建完新的 之后，官网有了详细的说明：\necho \u0026#34;# ianvzs.github.io\u0026#34; \u0026gt;\u0026gt; README.md git init git add README.md git commit -m \u0026#34;first commit\u0026#34; git remote add origin https://github.com/IanVzs/ianvzs.github.io.git git push -u origin master 简单明了。\nhexo # 而之后因为其主题我选的不好，然后又觊觎nodejs，所以将blog使用hexo来写了。以下是使用教程了—— title: Hello World\nWelcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start # Create a new post # $ hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server # $ hexo server More info: Server\nGenerate static files # $ hexo generate More info: Generating\nDeploy to remote sites # $ hexo deploy More info: Deployment\n修改配置 # blog根目录下_config.yml, 以及themes下_config.yml\n连接github: # deploy: type: git repo: https://github.com/*******/**.git branch: master npm install hexo-deploy-git --save themes # hueman主题的图片配置地址为: /themes/hueman/source/css/images 可在themes/hueman/_config.yml中进行修改各项图片配置 Git # git 版本切换 # 将项目克隆之后，可通过\n$ git tag // 查看tag \u0026gt; v1 \u0026gt; v2 \u0026gt; v3 $ git show v1 //根据tag 查看版本号 \u0026gt; tag v1 \u0026gt; Tagger: user \u0026gt; Data: Fri May 23 17:47:00 2018 +0800 \u0026gt; \u0026#39;为了部落\u0026#39; \u0026gt; commit 5b123b31h4bvb31 \u0026gt; Aurhor user \u0026gt; 等 $ git reset --hard 5b123b31h4bvb31 // 根据版本号回退版本 部署到服务器 # 在部署到服务器的时候，发现有‘node’: No such file or directory的错误，解决办法是创建软连接：\nln -s /usr/bin/nodejs /usr/bin/node 另外，直接拷过去的blog项目没法用hexo直接运行… 解决办法是：\n// 并没有解决啊！！！！ (⊙﹏⊙)，╮(╯-╰)╭其实是npm在服务器apt安装的版本太低了… 在官网下了最新版，然后再次通过新版npm安装hexo就可以直接用了。\n2021-04-21 # emmmmm如今重新再次翻看，觉得o(∩∩)o\u0026hellip;哈哈。 这次找了个不错的模板，比之前用的没有分页强多了，而且还有了搜索功能。简直完美符合平时查阅的需求。\n"},{"id":7,"href":"/posts/make-things-easy-and-enjoyable/","title":"Make things easy and enjoy","section":"Blog","content":" 命令行的简便生活 💦🤣 # 后传: [[小命令]]\nVirtualBox: linux 没有权限访问共享文件夹的问题 # 错误原因及解决办法\n这个自动mount的文件夹linux_share的所有者为root，所属的组是vboxsf，并且只有这两个用户有访问权限。Virtualbox的共享文件夹一般都挂载在/media下面，用ll查看会发现文件夹的所有者是root，所有组是vboxsf，所以文件管理去无法访问是正常的，解决方法是把你自己加入到vboxsf组里面。\n# 把自己添加到这个vboxsf组里面: sudo usermod -a -G vboxsf {USERNAME} 需要重启机器才能生效\nDelete Git Submodule # 逆初始化模块，其中{MOD_NAME}为模块目录，执行后可发现模块目录被清空 git submodule deinit {MOD_NAME} 删除.gitmodules中记录的模块信息（\u0026ndash;cached选项清除.git/modules中的缓存） git rm --cached {MOD_NAME} apt 安装前查看库里版本 # sudo apt-cache madison kdenlive 4K显示器软件不适配导致的字太小问题 # 在路径: /usr/share/applications下 将对应的.desktop文件使用文本编辑器打开,将Exec修改为:\nExec=env QT_DEVICE_PIXEL_RATIO=2 /opt/resolve/bin/resolve 主要是增加env QT_DEVICE_PIXEL_RATIO=2, 上述例中所示为达芬奇的配置. (不过很可惜它并不能和我的AMD 5700g+Ubuntu22.04+不知哪儿来的驱动一起工作. 虽然确实变好了.)\n切换用户默认终端程序 # 赢在起跑线: useradd -s /bin/bash ian 力挽狂澜: usermod -s /bin/bash ian 奋起反抗: chsh + 按提示操作 Github Personal access tokens # github 干掉了https账号密码pull push 之后 https pull push 专用 url\n4k码字 # 更改语言 # export LC_ALL=C # 改了确实大多数成英文了，不过树莓派汉化太狠了，console-setup里还有若干是中文就很蠢... unset LC_ALL # 改回原始 更改tty1字体大小 # sudo dpkg-reconfigure console-setup 操作粘贴板/剪贴板/剪切板 # xsel\n将输出存储到粘贴板 # echo \u0026#34;ashsaihs\u0026#34; | xsel -i -b 输出粘贴板信息 # xsel -o -b 由xsel --help可得-i -o分别代表标准输入输出(input output) -b代表: -b, \u0026ndash;clipboard Operate on the CLIPBOARD selection\n美化 # themes # Orchis Flatabulous XFCE Flatabulous\n图标 # sudo add-apt-repository ppa:numix/ppa sudo apt install numix-icon-theme-circle 文件编码格式嗅探 # pip install chardet python f = open(\u0026#34;file.path\u0026#34;, \u0026#34;rb\u0026#34;) bdata = f.read() f.close() result = chardet.detect(bdata) debian增加docker用户组,优化每次sudo问题 # 摘抄自这里\n检查是否已有docker用户组 cat /etc/group | grep docker 1无则创建 sudo groupadd docker 添加指定用户到docker用户组 sudo usermod -aG docker {用户名} 使用1检查2是否成功 重启docker sudo systemctl restart docker 给.sock添加权限 sudo chmod a+rw /var/run/docker.sock 检查是否成功 su {用户名} docker ps -a 使用各种跳板之后的远程文件传输 # sz \u0026amp;\u0026amp; rz # 安装 # # mac安装 brew install zssh # linux安装 sudo apt-get install zssh 取代ssh连接 # zssh username@xxx.xxx.x.x 使用 # cd destination_dir #进入到目的地目录 输入crtl+@组合键(mac是command+@)切换到zssh -- 2022-06-08 发现mac也是`control`+@ 即(`shift+2`和键盘布局有关) cd orgin_dir #进入源目录 sz example.txt #上传文件 exit #退出zssh sz 在服务器上准备要下载文件 sz abcde.py 输入crtl+@组合键(mac是command+@)切换到zssh cd destination_dir #进入到下载目录 rz #接收下载文件 在执行上传下载过程，开始时在界面上体现不太明显，需要耐心等待一下\n诗句 # sudo apt install fortunes-zh # 显示 fortune 代码量统计 # $ cloc . 6605 text files. 5869 unique files. 1049 files ignored. github.com/AlDanial/cloc v 1.86 T=6.47 s (862.2 files/s, 137709.8 lines/s) -------------------------------------------------------------------------------- Language files blank comment code -------------------------------------------------------------------------------- JavaScript 4200 69941 83775 452071 HTML 169 42890 164 69664 JSON 306 62 0 51362 Markdown 363 17792 0 49232 CSS 135 1670 901 14540 Stylus 131 1401 1112 6947 XML 8 3004 1289 5010 TypeScript 92 881 2953 4684 SVG 6 0 1 4299 EJS 105 49 15 1921 YAML 55 71 117 1564 Bourne Shell 1 163 112 791 DTD 1 179 177 514 make 5 42 8 114 Nix 1 1 0 19 Bourne Again Shell 1 5 13 7 zsh 1 4 13 7 DOS Batch 1 0 0 5 CoffeeScript 1 1 0 0 -------------------------------------------------------------------------------- SUM: 5582 138156 90650 662751 -------------------------------------------------------------------------------- xfce添加屏幕分辨率 # Virtual1: 使用vmware虚拟出来的显示器名称 具体执行时替换之\nxrandr --newmode \u0026#34;1920x1080_60.00\u0026#34; 173.00 1920 2048 2248 2576 1080 1083 1088 1120 -hsync +vsync xrandr --addmode Virtual1 \u0026#34;1920x1080_60.00\u0026#34; xrandr --output Virtual1 --mode \u0026#34;1920x1080_60.00\u0026#34; 给用户添加sudo权限 # echo: 使用vim添加这行比较保险\nchmod u+w /etc/sudoers echo \u0026#39;{username} ALL=(ALL) ALL\u0026#39; \u0026gt; /etc/sudoers chmod u-w /etc/sudoers ======= 查看端口占用 # netstat -ntulp | grep 80 find 文件查找 # 今天(2018年12月12日，17点08分)在众多文件里找一个文件的时候… 想到find命令。不过之前没有怎么了解过，所以… 我居然用了tree | grep filename.filetype来找东西。 结果路径太深——就最多确认了此文件的存在性。 随后，才知道find要加-name参数。 emm\u0026hellip;不过对于find多功能来说也说得过去。 随后便有了以下这个命令:\nfind . -name \u0026#34;cifar.py\u0026#34; -exec vim {} \\; 没错~，查找之后并编辑——😄 除此之外，当然可能用于 rm、grep等去替换vim进行操作。 其中，{}自然时代表匹配文件的路径。 如果不止一个那么…就： vim为例，会关闭一个窗口再打开另一个😓 另外，配合grep查找文本内容的时候，需要在最后面加-print否则只有匹配文本，不显示文件路径。\nWindows 转换磁盘分区格式 # 方法/步骤 # 1 1.U盘引导，进入PE系统\n2 用pe进去，找到运行输入cmd\n3 输入”Diskpart”(不用输入引号，下同)，并按回车，进入操作界面\n4 输入：”list disk”，查看磁盘信息。一般会出现两个选项，一个是你的硬盘，一个是U盘，要注意区分。\n5 输入：”select disk 0”，选择disk 0为当前操作的磁盘（也就是电脑的 硬盘）\n6 输入：”Clean”，清空当前磁盘分区\n7 输入：”convert mbr”，转换为MBR分区。\n8 OK，搞定，可以安装WIN7了\nWindows远程桌面 # mstsc # WIn自带应用，不过用的时候得关闭防火墙就很伤 Windows 输入法故障 # ctfmon.exe win+R 执行此，重启输入法 Win 安装Ubuntu # #在powerShell中管理员运行 Enable-WindowsOptionalFeature -Online -FeatureName Microsoft- Windows-Subsystem-Linux\nWindows 自启动项目录 # C:\\Users\\Administrator\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\n在此目录下添加入快捷方式则在系统启动之后自动加载，但会有一些延时，不同于直接定义的自启动项，算是优先级最落后的项目吧\nWindows 查看电池使用情况 # powercfg /BatteryReport # 适用于Win8+ Python Pip # pip install -r *.txt # 从*.txt 文件读取需要安装的插件列表 win Ubuntu 时间不一致 # timedatectl set-local-rtc true #采用本地时间 推荐 Ubuntu 升级系统 # sudo update-manager -c -d #会检测是否有系统更新， #如果都更新完毕， #则提醒有新版本系统是否更新 Windows 更新系统错误 # dism++ 你值得拥有\n另外： 无法连接到更新服务。我们将稍后再试，你也可以立即进行检查。如果问题仍然存在，请确保你已连接到 Internet。\n可能是 本地组策略中的windows更新的“指定Intranet Microsoft更新服务位置”被更改过\n解决办法为\ngpedit.msc 打开“本地组策略编辑器”展开“计算机配置”—“管理模版”—“Windows组件”—“Windows 更新”（专业版称为Windows Update） \u0026ldquo;指定Intranet Microsoft更新服务位置”，点击“未配置\u0026rdquo; Ubuntu 桌面显示问题 # 卸载 ibus 输入法，会出现桌面显示不完全的情况，任务栏显示，启动栏消失，键盘快捷键无法使用。解决办法是重新安装 Unity 之后启动Unity 就会重新打开桌面环境…其实是又重新安装了 ibus 嗯………\nVim 设置Tab空格数 # :set tabstop=4 #添加至用户vim配置文件： .vimrc 下即可 正则表达式 # 作为短小精悍的东西嘞，今天在限制密码类型和长度的时候尝尽了甜头。但在分类时…不好分，应该单独写一个笔记的，但短小精悍嘛，所以就放在命令行这里了。\nimport re # 好吧，其实无所谓的，因为下面并没有用到Python正则模块 a = QtCore.QRegExp(\u0026quot;[A-Za-z]{0,5}[1-9][0-9]{0,5}\u0026quot;) a = QtCore.QRegExp(\u0026quot;[a-zA-Z0-9]{0,12}$\u0026quot;) a = QtCore.QRegExp(\u0026quot;[a-zA-Z0-9]+$\u0026quot;) a = QtCore.QRegExp(\u0026quot;[a-zA-Z0-9\\,\\.\\\\\\!\\?\\#\\$\\%\\^\\\u0026amp;\\*\\(\\)\\)_\\_\\=\\`\\+]+$\u0026quot;) 这里的[]中内容是输入范围，{}中的则是长度限制，而+就是不限长度 与*类似。 $ 是结尾标志。 over。\n闲的没事找事记： # 安装了一个美国版的windows 10 pro N 结果字体缺失，系统默认编码方式是Ascii不是utf……导致程序中的输出中文都出现问题。结果在这些不构成生产力的份儿上浪费时间，真是闲的没事找事… Vim # 查看编码格式 `:set fenc` 设置文件格式`:set fileformat=unix`或者`:set fileformat=dos` ——针对于换行符 set tabstop=4、set expandtab前者是一个tab的长度，后者是tab换为空格…\nGoodApps # Nitrux、Flatabulous-master： # 主题，图标 用来美化很漂亮，图例样式可以参看这两者的Github。\nGoldenDict： # 一款词典，其可以添加网络翻译源，还可以自行下载本地翻译文件，本地内容我下载的含有：日汉、汉日、英牛津，朗道，还有本本草纲目……没错，确实还有科普类的翻译源。各种奇异翻译本都有。\nXware： # 一款迅雷的替代，网络远程下载，完全能当一个没有广告的迅雷来使。 只不过需要账户密码，还有，在安装完毕之后，需要预先设置一番，将Xware托管改为用户态upstar，或者简单的自动启动。否则会显示ETM 没有链接，不能使用。另外将挂载，实际作用是下载保存位置，也设置一下。这么长时间了，英文路径应该养成习惯……\nMyPaint： # 画图工具，很好使。\nChrome: # 这个浏览器不用说，这里介绍的是关于它修改hosts文件之后可能仍然无法使用谷歌搜索的问题。\n1.因为，默认的是http，故显示已被重定向啊，啥的。只要在地址栏前输入https就可以正常访问了。 2.当然，这样的话无法使用网页里的按钮“使用谷歌搜索”，所以需要修改其默认。可以在Chrome://net-internals/ 中，找见HSTS选项卡，Domain中输入想要默认强制使用https的网址。（PS：因为我的使用google自动跳转谷歌香港，所以这里用google.com还是不行的，得加上.hk的后缀。） 3.以上修改方法应该只能设置一个默认网址呢，不过一个google搜索就够了…… 嗯，我要求比较低。 至于其他浏览器，大概是默认https的，因为可以直接访问嘛。 自然还有很好的别的稍微专业的工具，这个会在之后持续更新出来，用学习笔记的形式（而且，等我学会在文章里添加链接啊，图片啊之后）。以上入门级、常用级的也会持续更新的～ 下载链接我以及之后都不会贴出来，嗯，毕竟没有永远保存的，链接经常失效。自行搜索总是好的，还能顺便了解一下这块软件的使用方法，以及类似替代软件的出现。\nNethack： # 終端運行的一款地牢遊戲，相當高的自由度和隨機程度，除卻一切怪物和地圖都是用符號來代替，戰鬥過程就是用文字信息來描述，在創造和思索方面簡直一流。以後有空閒肯定要玩一玩～\nVirbox ： # sudo mount /dev/cdrom // ^^^目標地^^^ //掛載光盤 sudo mount -t vboxsf //^^Name^^ ^^^目標地^^^ //掛載虛擬機共享文件 下面是其他软件的学习笔记：（等待更新——） # Linux： # 嗯，这是个软件…详见《Linuxのノート》\nPelican : # 静态网页编辑生成工具。 keywords：Python、markdown\nBlender： # 開源建模，動畫軟件。\n快捷鍵記錄： # N、T\t//編輯欄呼出、隱藏 T\t//側重物體，N側重編輯窗口 B\t//選擇 Tab\t//模式切換 Ctrl+U\t//用戶界面保存 Z\t//物體顯示樣式切換 線框、透視 H\t//刪除 G\t//移動 musicbox： # Linux 命令行下的 網易雲音樂 。夠精簡夠豐富，實爲經驗驚豔。\n基於Python： # \u0026gt;https://github.com/darknessomi/musicbox xSwipe： # 多指触控软件。通过将触控板手势映射成快捷键，可以支持甚至五指操作，还有侧边功能。在github中搜索xSwipe即可，其中有详细安装说明。之后可以在.conf文件中查看和修改映射快捷键。另最后如果不能运行，可能需要注销重启电脑方可。 运行 perl xSwipe.pl即可执行。\nOpenCV： # 开源计算机视觉库。 简单记录一下编译过程：(其實沒啥用的，自己爬官網找安裝教程去，基本沒用。)\n1. 解决依赖，编译工具 # sudo apt-get install build-essential sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev` 2. github 下载源程序 # git clone https://github.com/opencv/opencv.git 3. Building OpenCV from Source Using CMake, Using the Command Line # cd ~/opencv mkdir release cd release cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local .. 4. # make sudo make install all from \u0026gt;http://docs.opencv.org/2.4/doc/tutorials/introduction/linux_install/linux_install.html // (或許安裝過程就這句有用 23333) Thanks for your teaching. Simplenote: # 一款笔记软件，支持markdown编辑，很轻量、只能记录文字有点儿伤。不过有Linux版就很爽。而且同步速度、启动速度都很迅速。界面简单到不行。手机一次不幸刷机之后，有道云笔记懒得装，之后就用此软件吧… scp # server copy? 这个简写不晓得，不过确实是适用于远程连接传输文件的…\nscp ian@123.123.41.3(😀):/home/ian/nihou.txt ./files scp ./files ian@123.123.41.3(😀):/home/ian/nihou.txt 删除Win系统服务 # sc delete serverName Termux # 类似于WIN端的Subsystem——其实更像Ubuntu下的虚拟终端。 不过这东西功能强大，除了将安卓里的Linux发挥出来。还有Termux API来调用手机的底层接口。\nssh与手机连接 # 其实应该放在ssh的操作里面？ emm，还是就这儿吧。\n*pc # **电脑生成密匙,无视密码设置全部回车\nssh-keygen -t rsa **电脑开启sshd服务,用于手机的ssh连接到电脑拷贝id_rsa.pub内容\nsystemctl start sshd 然而我用的是win子系统所以：sshd re-exec requires execution with an absolute path\nphone # **手机连接拷贝\n$HOME/.ssh/authorized_keys -\u0026gt; 不管用什么复制，然后放到这个路径就好。 **查看手机的用户名\nwhoami **开启服务\nsshd -p 9000 *pc # 连接到手机\nssh u0_222@192.168.1.14 -p 9000 Over, 其余问题查看文件权限？ 不过还是自建文件.ssh出错率为0吧。\n2018年12月4日11点27分,当我反过来操作的时候… 嗯，果然在权限这里出问题了… 另外，电脑端开启sshd的时候用的绝对地址… 因为是Syb？\nchmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys 😓 快捷键(有用的音量键？) # 显示扩展功能按键\n方法一:\n从左向右滑动,显示隐藏式导航栏,长按左下角的KEYBOARD. 方法二:\n使用Termux快捷键:音量++Q键 常用快捷键\nCtrl键是终端用户常用的按键 – 但大多数触摸键盘都没有这个按键。为此，Termux使用音量减小按钮来模拟Ctrl键。在触摸键盘上按音量减小+ L发送与在硬件键盘上按Ctrl + L相同的输入。 Ctrl+A -\u0026gt; 将光标移动到行首 Ctrl+C -\u0026gt; 中止当前进程 Ctrl+D -\u0026gt; 注销终端会话 Ctrl+E -\u0026gt; 将光标移动到行尾 Ctrl+K -\u0026gt; 从光标删除到行尾 Ctrl+L -\u0026gt; 清除终端 Ctrl+Z -\u0026gt; 挂起（发送SIGTSTP到）当前进程 音量加键也可以作为产生特定输入的特殊键.\n音量加+E -\u0026gt; Esc键 音量加+T -\u0026gt; Tab键 音量加+1 -\u0026gt; F1（和音量增加+ 2→F2等） 音量加+0 -\u0026gt; F10 音量加+B -\u0026gt; Alt + B，使用readline时返回一个单词 音量加+F -\u0026gt; Alt + F，使用readline时转发一个单词 音量加+X -\u0026gt; Alt+X 音量加+W -\u0026gt; 向上箭头键 音量加+A -\u0026gt; 向左箭头键 音量加+S -\u0026gt; 向下箭头键 音量加+D -\u0026gt; 向右箭头键 音量加+L -\u0026gt; | （管道字符） 音量加+H -\u0026gt; 〜（波浪号字符） 音量加+U -\u0026gt; _ (下划线字符) 音量加+P -\u0026gt; 上一页 音量加+N -\u0026gt; 下一页 音量加+. -\u0026gt; Ctrl + \\（SIGQUIT） 音量加+V -\u0026gt; 显示音量控制 音量加+Q -\u0026gt; 显示额外的按键视图 Rdfind # 替代方案 # Rdfind是命令行的, DuplicatePhotoFinder1.6.3是有UI的, 可以展示出内容, 不过很傻, 不能多选一次删除, 只能一个一个删除\u0026hellip;.. 所以我做了一个托管鼠标点击器. 如下\n使用Rdfind 进行重复文件查询, 然后删了, 节省磁盘空间.\n不过我准备自己做一个, 更方便删减图片, 所以以后应该会用自己做的, 这个就留下参考吧.\n查询重复 # drfind /Image/`, 结果报表存于当前目录`results.txt\n终端输出 # rdfind -dryrun true /Image\n删除空文件和重复文件 # rdfind -deleteduplicates true -ignoreempty false /Image\n删除重复文件 # rdfind -deleteduplicates true /Image\n鼠标自动点击 # 选择点, 不到1s一点, 终端无法立即实时中断, 估计要用上Listener不过现在这样也可以啦.\nimport time from datetime import date, datetime from pynput import mouse from pynput.mouse import Button, Controller mouse = Controller() sign_start = False print(\u0026#34;请将鼠标移动到指定位置, 输入`r`开始.\u0026#34;) str_input = None position_loop = None while 1: str_input = str_input or input() if str_input == \u0026#39;r\u0026#39;: position_loop = position_loop or mouse.position mouse.position = position_loop # mouse.move(position_loop[0], position_loop[-1]) mouse.press(Button.left) time.sleep(0.2) mouse.release(Button.left) print(f\u0026#34;{datetime.now()} - clicked - {position_loop}.\u0026#34;) time.sleep(0.4) else: print(\u0026#34;输入错误, 程序结束.\u0026#34;) break "},{"id":8,"href":"/posts/daily-notes/","title":"Daily Notes","section":"Blog","content":" 2021年09月26日 测试一下是不是能挂视频呢：\n2021年09月09日 今天重新弄了blog,增加了Makefile可以更加无闹化的操作了 真是个好东西 不过hexo deploy放在里面一直出问题，重新执行一遍又好了不清楚啥原因。。。分不同的make子项试试\n同时也换了背景，一会儿打个release去.\n缅怀\n2018年12月12日 今儿开始，以后信笔记就写在上面了——本来笔记就没顺序，而考虑翻看的时候总是翻页太麻烦，emm 虽说越来越习惯grep但 …有时候还是要看网页的嘛。而新笔记的翻看率总是高过旧笔记，所以就用这个顺序~😄\nEeont size=4\u0026gt;原因：\n今天决定每天都写每日的学习总结，以此来激励。否则每天下来总觉得毫无收获，颇有空虚寂寞冷的感觉，也有当天学习的不真实感。此文章做做总概，目录的作用，详细的学习笔记就写在详细的文章下面。\n因为，暑假要学习日语，所以日常生活中能用日记就尽量用了。对于培养日语语感和结构的记忆及习惯，很有作用。 日语\n16-07-14 用于比较的句型：より　ほど 变化、使变化的句式。 16-07-16 昨天用的Winodos所以没发写了。 重新记了初上的18课内容。 16-07-18 B站上的每晚一句感觉不错。因为是长句嘛，能够更加详细了解句子逻辑和词语使用规律 16-07-19 復習 Pelican\n16-07-14 换了一个更加清明的主题，能够能好的搜索，并且显示格式也很顺眼。而且能够自动形成Tags等的文章链接。基本上满足我的写作还有以后用来搜索的需求了。而且也很简约漂亮。 明天再学习一些嵌入式以及Linux的内容～ 16-07-19 插入图片：图床 评论系统：Disqus 数学公式：latex\nLinux\n16-07-16 SSH rsync VNC 等命令的学习和使用。为此，倒是专门安装了一个Ubuntu的Servery版本的虚拟机。 16-07-17 disk LVM 16-07-18 复习了一些网络部分。 16-07-18 Vi \u0026amp;\u0026amp; Vim 果然在了解了一些按鍵的作用之後感覺無愧‘於編輯器之神’的稱號。輸入法不小心點成繁體了，懶得改回簡體————或許有‘懶’的比賽我能進三甲。 16-07-26 這兩三天看了看 嵌入式的ARM系列板開發，當然主要看了看Linux 移植一類。只不過說是教程也不過是流程吧。通篇下來基本上用的最多的語句即使 把這個這樣，那個這樣一下。具體爲什麼全然わかりませんね！ 不過也沒關係，留下來自己回頭再看看就行了。後面再看一下Qt程序的移植就可以完美收官了，在嵌入式的領域。 16-08-03 看完了——只不過很可惜沒有實驗板，所以不能進行實驗。開學之後在學校吧。當然，學習斷線了一些時候，嗯嗯…… 16-08-11 musicbox Nethack ————A Game\n還沒玩，或者說還沒看說明手冊先瞎玩一氣。雖說有一塌糊塗，不過我有預感，這確實是一款很好的自由地牢遊戲。 Blender ーー建模 動畫軟件\n16-08-03 重溫一下Blender，在快捷鍵上略做一些記錄，否則每次都忘…… :::ideer的上一行不能为空，缩进一下，然后写就可以了。 :::ideer的上一行不能为空，缩进一下，然后写就可以了。 藝術\n16-08-11 這幾天在看《藝術概論》《什麼是藝術》《電影理論基礎》，因爲是下到Reader上了，倒也沒有開機來寫總結。之後有什麼總結之類就再另開一個文章專門記錄個人所感所得。 16-8-29\n终结 往后作为假期学习记录不定时更\n17-04-08 好东西自然要重新启动，只不过配起来有些麻烦，前些日子的.md文件也丢光了，所以一直懒得再写。实在不应该……\n18-05-15 居然在公司工作时间来将博客来更了… emm 也没办法 调试时间太长，一边等结果一边儿就把博客重整了一遍。 但还有一些文章不好意思放上来，之后整理一下放呗.顺便一说，我之前18年其实也重整过一次…不过伴随着我的Ubuntu系统saybye 甚至丢失了我U盘里面保存的一些聊天记录！！！！！！！ 😔 故人西辞黄鹤楼 白云空载轻悠悠 不识人间好颜色 江边黄花两对愁 去年17年佳作~~~lul\n18-06-21 今天又重整了俺封装的MySQL Connecter的python库，完善了之前的查找功能和删除功能。 不过话说之前写的插入功能就是好用hhhh。 嗯~ o(￣▽￣)o 有空干脆再用python去写一个mysql的表设计程序算了~ 就类似powerDesigner在MySQL这边儿的作用，顺便也好想写一个能代替Navicat的小工具… 反正都是大家都是调用sql语句。(⊙﹏⊙) 其实发展发展我这个小库就能做了。有时间再说呗(没时间~，~)\n"},{"id":9,"href":"/docs/programmer/gui/example/table-of-contents/","title":"Table of Contents","section":"Blog 构建","content":" Ubi loqui # Mentem genus facietque salire tempus bracchia # Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice # Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); Placabilis coactis nega ingemuit ignoscat nimia non # Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; } Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":10,"href":"/docs/programmer/langs/","title":"编程语言","section":"程序员笔记","content":" C # Python # _index Note of Python Python Gui Vn.Py笔记-交易平台客户端 OpenCV Paddle pyinstaller-python打包 PyPi PyTest stable-diffusion Py小工具和功能性方法 paramiko 使用 - ssh\u0026amp;sftp 机器学习常用库基本用法 问题 [[docs/programmer/langs/java/noteOfjava### 爪洼调用Python]] Golang # Rust # Java # [[noteOfjava#Java语法]] [[noteOfjava#Maven 项目标准目录结构]] "},{"id":11,"href":"/docs/programmer/cloudnative/redis/","title":"中间件","section":"云原生","content":" Redis笔记目录 # 这个记录的很好: 佐的Notion笔记\n基础理论 # 概况 数据结构 Redis数据结构2 Redis高性能IO模型 持久化机制 缓存淘汰/删 阻塞点与异步机制 原子操作、管道、事务 内存碎片 面临问题 # 缓冲区溢出 缓存雪崩、击穿、穿透、预热、污染 读取过期数据 数据倾斜 脑裂 面试问题 高级篇 # 主从架构-主从同步 主从哨兵架构 切片集群-Redis Cluster Redis Cluster 通信开销 切片集群-Codis 数据结构选择 未来篇 # Redis 6.0 新特性 非易失内存-NVM 实战篇 # Redis延迟排查思路 Redis实时监控工具一览 redis info命令详解 RDB快照分析 Redis 分布式锁 Redis 分布式锁-Redission "},{"id":12,"href":"/docs/programmer/cloudnative/","title":"云原生","section":"程序员笔记","content":" Redis # _index The basics of Redis Advanced knowledge of Redis k8s # _index k8s常用命令和配置文件解析 [k8s 技术分享](docs/programmer/cloudnative/k8s/k8s 技术分享.md) [k8s 配套说明](docs/programmer/cloudnative/k8s/k8s 配套说明.md) [Argo 使用记录](docs/programmer/cloudnative/k8s/Argo 使用记录.md) elk在k8s上的部署使用示例 Git Docker # Note of Docker Note of Podman Tips of problems Docker # Note of Docker 后端框架 # Django建站 "},{"id":13,"href":"/docs/programmer/gui/","title":"图形用户界面-GUI","section":"程序员笔记","content":" 桌面应用开发 # Qt PyQt(PySide) Hugo特殊Markdown语法说明 "},{"id":14,"href":"/docs/programmer/database/","title":"Database","section":"程序员笔记","content":" [图数据库: dgraph](dgraph - Graph DB.md) Note of db data - MongoDB Note of db data - MySQL URL连接 # URL特殊字符转义 # 在构建数据库连接字符串时，URL中的某些字符具有特殊含义，如果它们出现在用户名或密码中，则需要被转义。以下是需要转义的字符及其对应的URL编码：\n空格：%20 !：%21 \u0026quot;：%22 #：%23 $：%24 %：%25 \u0026amp;：%26 '：%27 (：%28 )：%29 *：%2A +：%2B ,：%2C /：%2F :：%3A ;：%3B \u0026lt;：%3C =：%3D \u0026gt;：%3E ?：%3F @：%40 [：%5B \\：%5C ]：%5D ^：%5E _：%5F `（空格）：%60 {：%7B |：%7C }：%7D ~：%7E 示例 # 假设密码是 hihi#wav12391176393，其中包含特殊字符 #，我们需要将其转义。\nfrom urllib.parse import quote_plus password = \u0026#34;hihi#wav12391176393\u0026#34; encoded_password = quote_plus(password) URL = f\u0026#39;mysql://root:{encoded_password}@127.0.0.1:3306/installer\u0026#39; "},{"id":15,"href":"/docs/programmer/hardware/","title":"硬件","section":"程序员笔记","content":" 硬件篇 # 这里虽说是\u0026quot;硬件篇\u0026quot;其实并不是仅有硬件该怎么配，而包括了在这些硬件上，软件应该如何部署。 当然，也会有一些硬件的使用经验。\n便携屏幕 "},{"id":16,"href":"/docs/programmer/langs/python/python%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/","title":"Python包管理","section":"Python","content":" [[Rye 简单使用指南]] # Rye 是一个由 Flask 作者 Armin Ronacher 开发的 Python 版本和依赖管理工具，类似于 Pyenv + Poetry 的组合。\n安装 Rye # curl --proto \u0026#39;=https\u0026#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh # 安装cargo cargo install --git https://github.com/mitsuhiko/rye rye # 安装rye cargo的 .bashrc 相关:\n略略略略略略 . \u0026#34;$HOME/.cargo/env\u0026#34; 基本命令 # 初始化新项目 # rye init my_project cd my_project 指定 Python 版本 # rye pin 3.9.10 # 指定使用 Python 3.9.10 添加依赖 # rye add flask==2.3.2 rye add black --dev # 添加开发依赖 同步依赖 # rye sync 运行项目 # rye run python main.py 常用工具 # rye fmt # 格式化代码 rye lint # 代码检查 rye test # 运行测试 优势特点 # 内置 Python 版本管理，自动下载所需 Python 版本 使用标准的 pyproject.toml 文件 无需激活虚拟环境，自动感知项目环境 内置常用开发工具 (fmt/lint/test) 示例项目结构 # my_project/ ├── .python-version ├── pyproject.toml ├── src/ │ └── ... └── tests/ └── ... 提示：Rye 适合小型到中型项目，对于大型项目可能需要评估是否满足需求。\n这篇笔记包含了 Rye 的基本使用方法和主要特性，你可以将其保存为 [[Rye 简单使用指南]] 或其他你喜欢的标题。需要更详细的内容可以随时补充。\n"},{"id":17,"href":"/docs/programmer/cloudnative/redis/redis%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","title":"Redis集群部署","section":"中间件","content":" [!note] 以下是为 Redis 7.2.4（最新版本-我替换成了latest）编写的完整 docker-compose.yml 文件，包含 6 个节点 (3 主 + 3 从) 的完整配置：\n安装 # version: \u0026#39;3.8\u0026#39; services: redis-7000: image: redis:latest container_name: redis-7000 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7000.conf:/usr/local/etc/redis/redis.conf - ./data/7000:/data networks: - redis-cluster-net ports: - \u0026#34;7000:7000\u0026#34; - \u0026#34;17000:17000\u0026#34; redis-7001: image: redis:latest container_name: redis-7001 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7001.conf:/usr/local/etc/redis/redis.conf - ./data/7001:/data networks: - redis-cluster-net ports: - \u0026#34;7001:7001\u0026#34; - \u0026#34;17001:17001\u0026#34; redis-7002: image: redis:latest container_name: redis-7002 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7002.conf:/usr/local/etc/redis/redis.conf - ./data/7002:/data networks: - redis-cluster-net ports: - \u0026#34;7002:7002\u0026#34; - \u0026#34;17002:17002\u0026#34; redis-7003: image: redis:latest container_name: redis-7003 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7003.conf:/usr/local/etc/redis/redis.conf - ./data/7003:/data networks: - redis-cluster-net ports: - \u0026#34;7003:7003\u0026#34; - \u0026#34;17003:17003\u0026#34; redis-7004: image: redis:latest container_name: redis-7004 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7004.conf:/usr/local/etc/redis/redis.conf - ./data/7004:/data networks: - redis-cluster-net ports: - \u0026#34;7004:7004\u0026#34; - \u0026#34;17004:17004\u0026#34; redis-7005: image: redis:latest container_name: redis-7005 command: redis-server /usr/local/etc/redis/redis.conf volumes: - ./config/redis-7005.conf:/usr/local/etc/redis/redis.conf - ./data/7005:/data networks: - redis-cluster-net ports: - \u0026#34;7005:7005\u0026#34; - \u0026#34;17005:17005\u0026#34; networks: redis-cluster-net: driver: bridge 配套操作步骤 # 创建目录和配置文件 mkdir -p redis-cluster/{config,data/{7000,7001,7002,7003,7004,7005}} cd redis-cluster 生成所有配置文件（一键生成脚本） for port in {7000..7005}; do cat \u0026gt; config/redis-${port}.conf \u0026lt;\u0026lt;EOF port ${port} cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yes dir /data # 重要：替换为你的宿主机IP（非容器IP） cluster-announce-ip 192.168.1.100 cluster-announce-port ${port} cluster-announce-bus-port 1${port} EOF done 启动所有容器 podman-compose up -d 初始化集群 podman exec -it redis-7000 redis-cli --cluster create \\ $(for port in {7000..7005}; do echo -n \u0026#34;$(hostname -I | awk \u0026#39;{print $1}\u0026#39;):${port} \u0026#34;; done) \\ --cluster-replicas 1 关键配置说明 # cluster-announce-ip 参数\n必须设置为 宿主机的真实 IP（不能是 127.0.0.1 或容器 IP） 如果使用局域网访问，例如 192.168.1.100 如果使用公网访问，设置为公网 IP 端口映射规则\n客户端端口：7000-7005 集群总线端口：17000-17005（必须开放） 安全建议（生产环境必做）\n# 在配置文件中添加以下内容 requirepass your_strong_password masterauth your_strong_password 验证集群状态 # # 查看集群信息 podman exec -it redis-7000 redis-cli -p 7000 cluster info # 查看节点拓扑 podman exec -it redis-7000 redis-cli -p 7000 cluster nodes 常见问题解决 # 节点无法加入集群\n检查 cluster-announce-ip 是否能被其他节点访问 检查防火墙是否开放 7000-7005 和 17000-17005 端口 客户端连接超时\n确保客户端使用 宿主机的 IP 而不是容器 IP 检查 Redis 配置文件中的 port 和 cluster-announce-port 是否一致 使用 # Python # from loguru import logger from redis.cluster import RedisCluster, ClusterNode def test_redis_cluster(): # 使用 ClusterNode 对象，并确保端口为 int 类型 # 可以只使用一个node也可以传入多个防止单个故障无法连接(单个连接成功后会自动发现其它) startup_nodes = [ ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7000), ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7001), ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7002), ] try: rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True) except Exception as e: logger.error(f\u0026#34;连接 Redis 集群失败: {e}\u0026#34;) return # 测试写入和读取数据 try: rc.set(\u0026#34;test-key\u0026#34;, \u0026#34;hello redis cluster\u0026#34;) value = rc.get(\u0026#34;test-key\u0026#34;) logger.info(f\u0026#34;test-key: {value}\u0026#34;) except Exception as e: logger.error(f\u0026#34;操作 Redis 集群失败: {e}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: test_redis_cluster() 异步IO # import asyncio from loguru import logger from redis.asyncio.cluster import RedisCluster, ClusterNode async def test_redis_cluster(): # 定义集群启动节点，使用 ClusterNode 对象，确保端口为 int 类型 startup_nodes = [ ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7000), ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7001), ClusterNode(host=\u0026#34;192.168.105.156\u0026#34;, port=7002), ] try: # 创建 Redis 集群客户端 rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True) except Exception as e: logger.error(f\u0026#34;连接 Redis 集群失败: {e}\u0026#34;) return try: # 异步写入数据 await rc.set(\u0026#34;test-key\u0026#34;, \u0026#34;hello redis cluster\u0026#34;) # 异步读取数据 value = await rc.get(\u0026#34;test-key\u0026#34;) logger.info(f\u0026#34;test-key: {value}\u0026#34;) except Exception as e: logger.error(f\u0026#34;操作 Redis 集群失败: {e}\u0026#34;) finally: # 使用 aclose() 方法关闭客户端连接 await rc.aclose() if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(test_redis_cluster()) "},{"id":18,"href":"/docs/programmer/net/crawler/selenium-grid/","title":"Selenium Grid","section":"Net","content":" [!note] 一个用于分布式测试的工具，它允许你在多个机器上并行运行测试。通过 Selenium Grid，你可以同时在多个浏览器和操作系统上执行测试，从而加快测试速度并提高测试覆盖率。\n主要特点： # 并行执行：可以在多个节点上同时运行测试，显著减少测试时间。 跨浏览器测试：支持在不同的浏览器（如 Chrome、Firefox、Edge 等）上运行测试。 跨平台测试：支持在不同的操作系统（如 Windows、macOS、Linux 等）上运行测试。 集中管理：通过一个中心节点（Hub）来管理多个测试节点（Node），方便配置和监控。 基本架构： # Hub：中心节点，负责接收测试请求并将其分发到合适的节点。 Node：测试节点，负责执行实际的测试任务。每个节点可以配置不同的浏览器和操作系统。 示例： # 假设你有一个测试套件需要在 Chrome、Firefox 和 Edge 上运行，你可以配置一个 Selenium Grid，其中包含三个节点，每个节点分别运行不同的浏览器。然后，你可以通过 Hub 将测试分发到这些节点上并行执行。\npodman-compose部署 # version: \u0026#39;3\u0026#39; services: selenium-hub: image: selenium/hub:latest ports: - \u0026#34;4442:4442\u0026#34; - \u0026#34;4443:4443\u0026#34; - \u0026#34;4444:4444\u0026#34; environment: - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 security_opt: - no-new-privileges:true selenium-node-chrome: image: selenium/node-chrome:latest shm_size: 1g dns: - 8.8.8.8 environment: - SE_EVENT_BUS_HOST=selenium-hub - SE_EVENT_BUS_PUBLISH_PORT=4442 - SE_EVENT_BUS_SUBSCRIBE_PORT=4443 depends_on: - selenium-hub security_opt: - no-new-privileges:true Python代码 # from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support.wait import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from settings import RemoteBrowserAPIHost # hub 部署host class Browser: def __init__(self, headless=True, account_info=None): self.headless = headless self.input_element = None self.account_info = account_info logger.debug(f\u0026#34;其它模式使用远程浏览器\u0026#34;) op = webdriver.ChromeOptions() self.browser = webdriver.Remote(command_executor=RemoteBrowserAPIHost + \u0026#34;/wd/hub\u0026#34;, options=op) self.session_id = self.browser.session_id RDS.update_browser_heartbeat(self.session_id) logger.info(f\u0026#34;浏览器 连接成功!\u0026#34;) "},{"id":19,"href":"/docs/programmer/basetc/obsidian/","title":"Obsidian笔记软件","section":"基础工具和配置","content":"使用obsidian进行笔记编写或许是个好主意.\n"},{"id":20,"href":"/docs/programmer/ml/%E5%9B%BE%E7%89%87%E8%83%8C%E6%99%AF%E6%B6%88%E9%99%A4/","title":"图片背景消除","section":"机器学习","content":" 一、工具 rembg # https://github.com/danielgatis/rembg\nrembg i -m birefnet-massive 20241126-140049.jpg 49-max.png 默认使用u2net模型， 使用-m 可以指定模型运行\n二、模型 # Model Name Download Link Source Link Description 描述 u2net Download Source A pre-trained model for general use cases. 用于通用用途的预训练模型。 u2netp Download Source A lightweight version of u2net model. u2net模型的轻量版。 u2net_human_seg Download Source A pre-trained model for human segmentation. 用于人类分割的预训练模型。 u2net_cloth_seg Download Source A pre-trained model for clothes parsing. 用于服装解析的预训练模型（上衣、下衣、全身）。 silueta Download Source A reduced size version of u2net (43MB). u2net的精简版（43MB）。 isnet-general-use Download Source A new pre-trained model for general use cases. 新的通用预训练模型。 isnet-anime Download Source High-accuracy segmentation for anime characters. 高精度的动漫角色分割模型。 sam Download Encoder Source A pre-trained model for any use cases. 用于任何用途的预训练模型。 birefnet-general Download Source A pre-trained model for general use cases. 用于通用用途的预训练模型。 birefnet-general-lite Download Source A light pre-trained model for general use cases. 轻量级的通用预训练模型。 birefnet-portrait Download Source A pre-trained model for human portraits. 用于人像的预训练模型。 birefnet-dis Download Source A pre-trained model for dichotomous image segmentation. 用于二分图像分割的预训练模型。 birefnet-hrsod Download Source A pre-trained model for high-resolution salient object detection. 用于高分辨率显著目标检测的预训练模型。 birefnet-cod Download Source A pre-trained model for concealed object detection. 用于隐蔽物体检测的预训练模型。 birefnet-massive Download Source A pre-trained model with a massive dataset. 使用大规模数据集的预训练模型。 birefnet-massive # 效果最好， 最吃配置 大概用12G内存\n"},{"id":21,"href":"/docs/programmer/cloudnative/elk/%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F/","title":"日志收集系统: loki+promtail+Grafana","section":"云原生","content":"todo\n"},{"id":22,"href":"/docs/programmer/langs/golang/%E6%8A%8Agolang%E5%BD%93%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80%E7%94%A8/","title":"把Golang当脚本语言用","section":"Golang","content":" 支持 # Go 软件包：\ngithub.com/fatih/color[8] 是用于输出对应编码颜色的包。\ngithub.com/schollz/progressbar[9] 是用于为执行时间过久的任务创建进度条的包。\ngithub.com/jimlawless/whereami[10] 是用于捕获源代码的文件名、行号、函数等信息的包，这对于改正错误信息十分有用！\ngithub.com/spf13/cobra[11] 是用于更轻松地创建带有输入选项和相关文档的复杂脚本的包。\n"},{"id":23,"href":"/docs/programmer/basetc/%E7%BB%88%E7%AB%AF%E6%B5%8F%E8%A7%88%E5%99%A8/","title":"终端浏览器","section":"基础工具和配置","content":" 在终端中使用浏览器 # 一、lynx # 安装 # sudo apt install lynx 使用 # lynx https://github.com 二、carbonyl # 使用 # docker run --rm -ti docker.io/fathyb/carbonyl https://youtube.com 垃圾， 太模糊了，图片模糊就算了， 字也跟着模糊， 反正基本处于不能用的状态\n"},{"id":24,"href":"/docs/programmer/gui/ffmpeg/","title":"ffmpeg 使用","section":"图形用户界面-GUI","content":" 命令 # [[小命令#13. ffmpeg 提取视频中音频]] [[小命令#21. 压缩视频]] 1. 修改图片分辨率 # ffmpeg -i input.jpg -vf scale=iw/2:ih/2 output.jpg # 集体操作 for file in *.png; do ffmpeg -i \u0026#34;$file\u0026#34; -vf scale=iw/2:ih/2 \u0026#34;${file%.png}-2.png\u0026#34;; done 2. 压缩图片 # 1 - 9 越大越狠\nffmpeg -i input.jpg -compression_level 9 output.jpg # 集体压缩 for file in *.png; do ffmpeg -i \u0026#34;$file\u0026#34; -compression_level 9 \u0026#34;${file%.png}-2.png\u0026#34;; done "},{"id":25,"href":"/docs/programmer/platforms/%E9%80%86%E5%90%91/","title":"逆向三板斧","section":"平台","content":"突然想起它: [[noteOfjava]]\n三板斧 - apktool # https://apktool.org/docs/install/#linux\njava -jar apktool.jar d -f -o outputDir yourApp.apk // 或 ./apktool d -f -o outputDir yourApp.apk 文件目录说明:\n目录/文件名 用途 内容 original 保存 Apktool 无法直接处理的原始文件 AndroidManifest.xml 和签名信息目录 META-INF res 包含应用程序的资源文件 drawable (图片资源), layout (布局文件), values (字符串等), menu (菜单定义), xml (其他 XML 资源) smali 包含反编译后的字节码文件 .smali 文件，每个对应一个 Java 类的方法 assets 存放原始文件资源，不经编译处理 音频、视频、HTML、字体等文件 lib 存放 native 库（.so 文件） 不同平台架构的 .so 文件 AndroidManifest.xml 应用的清单文件，定义应用名称、包名、版本、权限等 XML 格式的配置信息 apktool.yml Apktool 的配置文件，存储解码和重建参数 框架版本、资源位置、编码设置等 注意事项： 修改资源或代码后，使用 Apktool 重新打包 APK。 确保遵守法律法规和使用协议。 Smali 是一种用于 Android 应用程序的DEX（Dalvik Executable）文件的汇编语言。它是DEX代码的反汇编表示，类似于Java的字节码。Smali 语法具有特定的结构和规则，以下是一些基本概念和语法：\nSmali语言 # 基本结构 # 一个 Smali 文件通常包含以下部分：\n头部信息：包括文件版本、创建日期等。 类定义：以 .class 开头，后跟类名和父类名。 字段定义：以 .field 开头，定义类的字段。 方法定义：以 .method 开头，定义类的方法。 指令：方法内部的操作码，执行具体的操作。 类定义 # .class public Lcom/example/MyClass; .super Ljava/lang/Object; .source \u0026#34;MyClass.java\u0026#34; .class：定义一个类，public 表示访问权限，Lcom/example/MyClass; 是类的全限定名。 .super：指定父类，这里是 Ljava/lang/Object;，表示继承自 Object 类。 .source：指定源文件的名称。 字段定义 # .field private static myField:I .field：定义一个字段，private static 表示访问权限和静态属性，myField 是字段名，:I 表示字段类型为 int。 方法定义 # .method public static main([Ljava/lang/String;)V .method：定义一个方法，public static 表示访问权限和静态方法，main 是方法名，[Ljava/lang/String; 表示参数类型为字符串数组，V 表示返回类型为 void。 指令 # 在方法内部，你会找到一系列的指令，它们用于执行操作：\naload_0 // 将局部变量0的引用推送到操作数栈 invoke-static {p0}, Lcom/example/MyClass;-\u0026gt;myMethod(Ljava/lang/String;)V // 调用一个静态方法 const/4 v0, 0x1 // 将整数1推送到局部变量v0 return-void // 从当前方法返回void aload_0：加载引用类型局部变量到操作数栈。 invoke-static：调用一个静态方法，{p0} 是参数，Lcom/example/MyClass;-\u0026gt;myMethod(Ljava/lang/String;)V 是方法的全限定名和描述符。 const/4：将一个小的整数值推送到局部变量。 return-void：从方法返回。 注释 # Smali 文件中也可以包含注释，使用 # 开头的行是注释。\n# This is a comment 数据类型 # Smali 使用特定的符号来表示数据类型：\nV：void Z：boolean B：byte S：short C：char I：int J：long F：float D：double Lfully/qualified/Class;：对象类型 这只是 Smali 语法的一个简要概述。由于 Smali 是一种低级语言，它包含许多复杂的指令和结构，理解它需要时间和实践。\nhttps证书 # Android # mount -o remount,rw /system mv /sdcard/c8750f0d.0 /system/etc/security/cacerts/ chmod 644 /system/etc/security/cacerts/* chcon u:object_r:system_file:s0 /system/etc/security/cacerts/* mount -o remount,ro /system the perms \u0026amp; selinux context labels, so everything is as readable as before # Delete the temp cert directory \u0026amp; this script itself\n"},{"id":26,"href":"/docs/programmer/langs/python/%E8%A7%84%E8%8C%83/","title":"Python编码规范","section":"Python","content":" 函数返回值定义 # 多个返回值 - Tuple # async def function_name(package_name: str) -\u0026gt; Tuple[ParamsPushLvl2Pool, bool]: pass 支持传入多类型 - Union # ex: Union[ExpiryT, None] = None, 迭代 # def _yield_offer_info(_session, from_days_ago: int) -\u0026gt; Iterator[Offer]: "},{"id":27,"href":"/docs/programmer/database/note-of-db-data-mariadb/","title":"数据库-MariaDB篇","section":"Database","content":" MariaDB数据库 📊 # 一、安装 # Docker Run # You need to specify one of MARIADB_ROOT_PASSWORD, MARIADB_ROOT_PASSWORD_HASH, MARIADB_ALLOW_EMPTY_ROOT_PASSWORD and MARIADB_RANDOM_ROOT_PASSWORD\ndocker run -p 3306:3306 --name mariadb11 -e MARIADB_ROOT_PASSWORD=mrp1234 mariadb:11 "},{"id":28,"href":"/docs/programmer/langs/golang/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"常用命令","section":"Golang","content":" build # 编译个后端服务，解决有些包依赖问题\ngo build -ldflags \u0026#39;-w -s\u0026#39; -tags netgo -insta llsuffix netgo -o xxxxx 清理 # 清理GOPATH: go clean -modcache # 设置大磁盘的新路径 export GOPATH=/mnt/data/go/gopath "},{"id":29,"href":"/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%A1%8C%E4%B8%BA%E8%87%AA%E5%8A%A8%E7%BC%96%E6%8E%92%E5%92%8C%E4%BB%BB%E5%8A%A1/","title":"机器人行为自动编排和任务","section":"机器学习","content":" 一、分层 # 人机交互型的从人到机器逐层看是\n接受端： 语音识别 \u0026amp; 图像识别 \u0026amp; 压力感知 语义理解： 语言大模型/语义提取模型， 前者专业，后者专精 状态感知：图像识别 \u0026amp; 其他传感器 行为编排： 语言大模型/图数据编排/行为树 动作执行 二、最小系统流程 # 使用者发出命令，接收端接受进行语义理解，获知使用者目的 -\u0026gt; 参数一 当获知目的之后，先对当前状态进行分析（所处环境和当前执行任务状态） -\u0026gt; 参数二 将获取到的两参数都传于任务编排模型后，基于当前状态和命令创建后续流程 最后按步骤执行任务即可 三、所需技术 # 语音识别： 本地部署模型可选用阿里Paraformer，地址：https://github.com/modelscope/FunASR/wiki/paraformer， 我这里也有个demo项目: https://github.com/IanVzs/asr 基本和wiki里示例一样 如果需要tts的话可以用: https://github.com/kuangdd/ttskit， 可以在执行动作的时候“说”出来调试用 或者调讯飞服务接口，地址：https://www.xfyun.cn/doc/asr/voicedictation/API.html#%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B 以上两个都涵盖了流式和语音文件识别两种方式，准确率都相当高可以满足几乎任何场合使用 图像识别： 目标识别可用yolo，或者用飞桨相关模型，不过这两个只能获取到二维信息，要对物体进行准确定位还需要搭配“双目深度估计算法”才可以组装出来三维信息 当然也可以用多模态大模型替换yolo，但是速度会变慢，其获取到的还是二维数据，可以对视野里的物体进行广泛的识别但是无法做到精准定位：https://community.modelscope.cn/669e26f4962e585a2565ab42.html 压力感知或其他传感器： 嵌入式内容， 具体情况具体实现 大模型prompt工程和微调： prompt可以满足大多数场景需求，可见： https://www.promptingguide.ai/zh 微调Lora技术 有需要再看，具体得根据大模型选型，去看相对应大模型的具体微调文档 汉语类的可选ChatGLM, QWen这些 Mixtral-8x7b 这种混合模型或许更适合你的使用场景 四、优化点 # 在跑通最小系统的单线程流程之后， 就可以就任务中断、处理干扰、大模型效果优化进行对点的提升。 所用方案大体上也就是：\n同步改异步：将最小系统流程中的步骤由1-\u0026gt;2-\u0026gt;3-\u0026gt;4修改为互相独立的1, 2, 3, 4每个任务都基于事件变化进行触发，如拿红球，突然视野中红球全部变为绿球，因外界状态改变就应自主触发第三步编排任务对当前的抓取动作进行中断。 多任务融合： 续接1中红绿球所描述的，对抓取红球和取消抓取动作这两个任务进行融合 或者说原本视野只有一个红球，突然变成两个，就需要对抓取一个红球的任务编排和抓取两个红球的任务编排进行融合 对大语言模型进行“驯化”，固化大模型输出内容格式，链式思考提升准确度： 大语言模型经常性胡言乱语或逻辑不准，很正常，需要反复了解把控 需要对大模型动作做风控 总之，以上工作所涉领域很多，每个领域所要求都偏高，要实现只能是搭积木。这样就使得这个工作更加偏向工程一些，并不怎么偏研究类。语音识别能力现在已经相当高尽管拿来用，不用投入无用时间。 图像这块儿所投入的精力会比较多，尤其是在具体定位某个物体上。\n要用传感器的话，那嵌入式相关知识也得掌握。\n大模型的作用在这里无非就是比专业的小模型更为通用，可以处理更多意料之外的状况，但是相对应的，还得专门写一个针对它的乱输出的风控。\n另一个耗时点就是在任务编排上，需要你自己整理出一些通用、独立不耦合的子任务，交由大模型去搭积木，这就是你和大模型去磨合的过程，会很烦。\n"},{"id":30,"href":"/docs/programmer/net/tools/ngrok/","title":"ngrok - 一个免费内网穿透api工具","section":"Net","content":" ngrok - 一个免费内网穿透api工具 # 官网: https://dashboard.ngrok.com/get-started/setup/linux\n步骤说明 # 一共三步, 安装、配置、发布就是这么简单:\ncurl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\ | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc \u0026gt;/dev/null \\ \u0026amp;\u0026amp; echo \u0026#34;deb https://ngrok-agent.s3.amazonaws.com buster main\u0026#34; \\ | sudo tee /etc/apt/sources.list.d/ngrok.list \\ \u0026amp;\u0026amp; sudo apt update \\ \u0026amp;\u0026amp; sudo apt install ngrok ngrok config add-authtoken {authtoken} \u0026gt; Authtoken saved to configuration file: {home}/.config/ngrok/ngrok.yml # 发布应用 ngrok http http://localhost:8080 成功输出: # ngrok (Ctrl+C to quit) Try our new Traffic Inspector: https://ngrok.com/r/ti Session Status online Account ian (Plan: Free) Version 3.13.0 Region Asia Pacific (ap) Web Interface http://127.0.0.1:4040 Forwarding https://ccf7-138-59-113-191.ngrok-free.app -\u0026gt; http://localhost:8011 Connections ttl opn rt1 rt5 p50 p90 0 0 0.00 0.00 0.00 0.00\n使用 # 访问 https://ccf7-138-59-113-191.ngrok-free.app 就可以用啦.\n"},{"id":31,"href":"/docs/programmer/basetc/curl/","title":"curl","section":"基础工具和配置","content":" 常用命令 # 文件上传 curl -F \u0026#34;file=@./1.jpg\u0026#34; -X POST \u0026#34;http://localhost:8080/upload\u0026#34; # 上传多个 curl -F \u0026#34;upload=@./1.jpg\u0026#34; -F \u0026#34;upload=@./2.jpg\u0026#34; -X POST \u0026#34;http://localhost:8080/uploadMul 代理IP curl -x {proxyserver}.com -U \u0026#34;{username}-zone-custom-region-ru-session-31fa4be5f7fa2389-sessTime-3:{passwd}\u0026#34; https://jsonip.com/ Post Json curl -X POST -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;value1\u0026#34;,\u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;}\u0026#39; http://example.com/api/resource 参数 # 参数 作用 示例 -k https时忽略证书验证 curl -k \u0026hellip; "},{"id":32,"href":"/docs/programmer/net/crawler/mitmproxy/","title":"mitmproxy","section":"Net","content":" 安装 # 代码示例 # #!/bin/env python import asyncio import sys from mitmproxy import options from mitmproxy.tools import dump class RequestLogger: def request(self, flow): print(flow.request.url) def response(self, flow): print(f\u0026#34;rsp; {flow.response.headers}\u0026#34;) async def start_proxy(host, port): opts = options.Options(listen_host=host, listen_port=port) master = dump.DumpMaster( opts, with_termlog=False, with_dumper=False, ) master.addons.add(RequestLogger()) await master.run() return master if __name__ == \u0026#39;__main__\u0026#39;: host=sys.argv[1] port=int(sys.argv[2]) asyncio.run(start_proxy(host, port)) "},{"id":33,"href":"/docs/programmer/basetc/%E6%96%87%E6%9C%AC%E4%B8%89%E5%89%91%E5%AE%A2/","title":"文本三剑客","section":"基础工具和配置","content":" grep # 一、或和过滤 # grep \u0026#34;abc\\|123\u0026#34; test.log` | grep -v \u0026#34;xyz\u0026#34; 二、排除某(些)文件(夹) # 1. 排除文件: # --exclude=\n2. 排除文件类型: # grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude=*.{log,} {}中貌似必须有,， 也就是说必须传入为列表， 不然不生效， 倒和Python的tuple类型有些相像。\n3. 排除文件夹: # --exclude-dir=\n个: grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude-dir=log 些: grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude-dir={log,__pycache__} sed # awk # 只能使用 单引号 双引号不行的呦( \u0026quot;{print $1}\u0026quot; ✗ )\nawk \u0026#39;{print $1}\u0026#39; # 第一列 一、awk算数 # [[小命令#18. awk算数]]\ngrep 400586 sched.log.2024-05-28 | grep 条 | awk \u0026#39;{print $8}\u0026#39; | awk -F\u0026#39;条,\u0026#39; \u0026#39;{sum += $1} END {print sum}\u0026#39; awk -F'条,' '{sum += $1} END {print sum}' 用条进行分割取$1第一个进行sum求和计算 awk '{print $8}' 这里注意使用单引号 250\n原日志数据为:\n2024-05-28 18:15:51 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 1条, 0 is: 400586 + 2024-05-28 05:24:52 + MY 2024-05-28 18:49:20 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 3条, 0 is: 400586 + 2024-05-28 03:02:38 + MY 2024-05-28 18:59:50 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 4条, 0 is: 400586 + 2024-05-28 04:12:04 + MY 二、查看文本列 # awk -F \u0026#39;,\u0026#39; \u0026#39;{print $NF}\u0026#39; , 分隔符 $NF 末尾 同理也可 $1 $1, $3 表示1列+3列,并不含2列 三、统计每秒多少条日志 # cut -d \u0026lsquo;.\u0026rsquo; 很重要, 因为uniq -c 会把带符号的相同数据作为分开统计就很迷惑 tr -d \u0026lsquo;,\u0026rsquo; 也可以用\ngrep \u0026#34;status_code: 200\u0026#34; max_power_pro_max.log | awk \u0026#39;{print $1, $2}\u0026#39; | cut -d \u0026#39;.\u0026#39; -f 1 | uniq -c | awk \u0026#39;{print $2, $3, $4 \u0026#34;: \u0026#34; $1 \u0026#34; logs\u0026#34;}\u0026#39; cut 命令笔记 # cut 命令用于从每行文本中提取文本列。\n基本用法： cut OPTION... [FILE]... 选项： -d CHAR：指定字段分隔符，默认是制表符。 -f FIELDS：指定要提取的字段，可以是单个数字或一系列数字（例如，1,3,5）。 示例： 提取文件 data.txt 中的第一和第三列（假设字段由逗号分隔）： cut -d \u0026#39;,\u0026#39; -f 1,3 data.txt 提取 IP 地址的第一个部分：\necho \u0026#34;192.168.1.1\u0026#34; | cut -d \u0026#39;.\u0026#39; -f 1 tr 命令笔记 # tr 命令用于转换或删除文本流中的字符。\n基本用法： tr [OPTION]... SET1 [SET2] 选项： -d：删除 SET1 中指定的所有字符。 -s：压缩连续的 SET1 中的字符为一个字符。 示例： 删除文本中的所有逗号： echo \u0026#34;1,2,3,4,5\u0026#34; | tr -d \u0026#39;,\u0026#39; 将文本中的小写字母转换为大写：\necho \u0026#34;hello world\u0026#34; | tr \u0026#39;a-z\u0026#39; \u0026#39;A-Z\u0026#39; 四、sort + uniq # uniq 命令的工作原理是只聚合相邻的重复行。 所以如果要统计总频次的话就需要先使用sort进行排序\n示例 # apple banana apple cat fruits.txt | uniq -c 1 apple 1 banana 1 apple cat fruits.txt | sort | uniq -c 2 apple 1 banana "},{"id":34,"href":"/docs/programmer/basetc/tmux/","title":"Tmux使用笔记","section":"基础工具和配置","content":" tmux # 从posts中迁移来\n丰富纯文字终端窗口，可以创建终端副本(反正也是我取得名字)—\u0026ndash;类似于win的多桌面。也可以分割终端(界面类似vim分割)l\u0026ndash;这便是类似于win的多窗口了。 (官方翻译: \u0026lsquo;窗格\u0026rsquo;？)\n进入: tmux 退出: exit 类似于vim命令模式： ctrl+b以下简写为CL_B。 创建多桌面: CL_B + c 查看全部窗口，类似win+Tab: CL_B + s 使用窗口号切换桌面: CL_B + NUM 关闭当前窗口: CL_B + \u0026amp;,emm直接exit\u0026hellip; 创建多窗口: CL_B + \u0026quot; (垂直上下)、CL_B + % (水平左右) 调整窗口位置、大小 CL_B + space (默认布局轮换) 显示窗口编号: CL_B + q 暂时最大化当前窗格: CL_B + z 切换到下一个窗格: CL_B + o 对换窗格位置: CL_B + CL_O(ctrl + o) 设置 # 启用鼠标触控板 # set -g mouse on 复制终端展示内容 # 复制 # set-window-option -g mode-keys vi #可以设置为vi或emacs set-window-option -g utf8 on #开启窗口的UTF-8支持 CL_B + [ Space空格开始选择(可使用?,/vi工具辅助定位, 在有些终端中不大好使) Enter回车确认选择(在有些终端中不大好使) CB_B + ] 可粘贴 必须保证以上全在Tmux中进行哈 再次记录 # 按下三个按键进入文本复制模式: CTRL + b + [ 按下两个按键进入文本开始复制的起始位置: CTRL + 空格 上下左右键或者Page up/down选择要复制的文本, 选中了要复制的文本后，按ALT + w，将文本保存到tmux的buffer中 按CTRL + b + ]将文本粘贴到某处 "},{"id":35,"href":"/docs/programmer/platforms/os/steam/","title":"Steam","section":"平台","content":" 双人成行 # Win上存档位置： /Users/{user name}/AppData/Local/ItTakesTwo Linux Steam 存档位置: ~/.steam/steam/steamapps/compatdata/3097223920/pfx/drive_c/users/steamuser/AppData/Local/ItTakesTwo$ 说明 # ~/.steam/steam/steamapps/compatdata/为steam porton统一虚拟环境位置 3097223920为steam为每个游戏都创建一个独立的环境 pfx/drive_c/users/steamuser这些就是windows下的存储路径了, steamuser为默认用户名pfx表示私有存储空间？大概\n2686703063 - GTAV\n"},{"id":36,"href":"/docs/programmer/platforms/android/waydroid/","title":"Linux 跑安卓","section":"平台","content":" Waydroid # 安装 # sudo apt install curl ca-certificates curl https://repo.waydro.id | sudo bash sudo apt install waydroid 配置 # sudo http_proxy=\u0026#34;http://127.0.0.1:7890\u0026#34; https_proxy=\u0026#34;http://127.0.0.1:7890\u0026#34; waydroid init sudo systemctl stop waydroid-container sudo /usr/bin/python3 /usr/bin/waydroid -w container start sudo systemctl start waydroid-container sudo systemctl status waydroid-container ARM兼容层 # git clone https://github.com/casualsnek/waydroid_script cd waydroid_script python -m pip install -r requirements.txt # 建议用虚拟环境哈～ python main.py install libhoudini 配置页面 # https://docs.waydro.id/usage/waydroid-prop-options\n解决app检测网络问题 # 包名通配\nwaydroid prop set persist.waydroid.fake_wifi \u0026#34;com.netease.*\u0026#34; sudo ufw allow 53 sudo ufw allow 67 sudo ufw default allow FORWARD 挂载文件 # sudo mount --bind ~/Downloads ~/.local/share/waydroid/data/media/0/Download adb # adb connect \u0026lt;IP\u0026gt;:5555 "},{"id":37,"href":"/docs/programmer/cloudnative/%E5%AE%B9%E5%99%A8/note-of-podman/","title":"Podman","section":"云原生","content":" Podman # 常用命令 # 2. 启动容器并进入交互模式 # 你可以使用 docker run 命令启动容器并进入容器的交互式 shell。这样你就可以进入容器内部进行调试。\n复制代码\ndocker run -it --entrypoint /bin/bash nova-crawler:latest 参数说明： # -it：-i 表示以交互模式运行容器，-t 给容器分配一个伪终端，这样你就可以在终端与容器交互。 --entrypoint /bin/bash：这将覆盖容器的默认入口点，直接启动一个 bash shell 以便你进入容器进行调试。 nova-crawler:latest：你要运行的镜像名称。 3. 启动容器并调试特定命令 # 如果你不想进入容器的 shell，而是想直接执行调试命令（比如启动应用并在调试模式下运行），可以使用以下命令：\nbash\n复制代码\ndocker run -it --entrypoint /bin/bash nova-crawler:latest -c \u0026quot;your-debug-command\u0026quot;\n4. 查看容器日志 # 如果你希望在调试时查看容器的日志输出，可以使用以下命令：\nbash\n复制代码\ndocker logs \u0026lt;container_id\u0026gt;\n你可以通过 docker ps 查找运行的容器 ID，然后查看日志输出。\n5. 调试时挂载本地目录（可选） # 如果你需要调试代码，并且希望挂载本地目录到容器中进行实时编辑，可以使用 -v 参数来挂载本地目录。例如，假设你的本地代码在 /path/to/your/code 目录下：\nbash\n复制代码\ndocker run -it -v /path/to/your/code:/app --entrypoint /bin/bash nova-crawler:latest\n这会将本地的 /path/to/your/code 目录挂载到容器的 /app 目录下。你可以在容器内访问并调试这个代码。\n总结： # 使用 docker run -it --entrypoint /bin/bash 来启动容器并进入 bash shell 进行调试。 使用 docker run -it -v /local/dir:/container/dir 来挂载本地目录进行调试。 希望这能帮你顺利启动并调试 nova-crawler 容器！\n命令用法 # 命令几乎和docker一致, alias docker=podman完全可以无感知\n不同点 # pull路径需要完整(official) podman pull docker.io/library/mysql:5.7 pull 其他示例(主要看docker pull的输出👿) # FROM tiangolo/uvicorn-gunicorn:python3.11 podman pull docker.io/tiangolo/uvicorn-gunicorn:python3.11 迁移镜像存储路径 # 切换到\nlazydocker # [[Note of Docker#lazydocker 可视化]]\nexport DOCKER_HOST=unix:///run/user/1000/podman/podman.sock lazydocker VSCode # Dev Containers # https://code.visualstudio.com/remote/advancedcontainers/docker-options\n在插件设置中, 将Docker Path里docker修改为podman即可\n网络 # 容器内访问宿主机 # [!note] host.docker.internal\nDocker 提供了 host.docker.internal 这个特殊的 DNS 名称，它会解析为 宿主机的 IP 地址。\nslirp4netns问题 # podman network connect example-network example-container会报错 podman 网络连接未针对 slirp4netns 实现 #19577 本地镜像存储路径 # ⛔ 没生效\ngo install github.com/evnix/boltdbweb@latest sudo boltdbweb --db-name=/var/lib/containers/storage/libpod/bolt_state.db --port=8008 修改其中缓存的/etc/containers/storage.conf文件内容.\n换源 # 文件: /etc/containers/registries.conf\n[registries.search] registries = [\u0026#39;registry.aliyuncs.com\u0026#39;, \u0026#39;docker.io\u0026#39;] [registries.insecure] registries = [] [registries.block] registries = [] [registries_mirror] registry = \u0026#39;docker.io\u0026#39; mirrors = [\u0026#39;registry.aliyuncs.com\u0026#39;] "},{"id":38,"href":"/docs/programmer/ml/%E7%88%AC%E8%99%AB/","title":"爬虫","section":"机器学习","content":"https://github.com/SeleniumHQ/seleniumhq.github.io/blob/trunk/examples/python/tests/getting_started/first_script.py#L4\nSelenium # chromedriver地址 # https://googlechromelabs.github.io/chrome-for-testing/#stable\ngeckodriver(firefox)地址 # https://github.com/mozilla/geckodriver/releases\nFirefox headlees运行需要的依赖 # apt-get install -y wget bzip2 libxtst6 libgtk-3-0 libx11-xcb-dev libdbus-glib-1-2 libxt6 libpci-dev libasound2 "},{"id":39,"href":"/posts/android%E7%8E%A9%E6%9C%BA/","title":"安卓玩机","section":"Blog","content":" shizuku # 启动命令:\nadb shell sh /storage/emulated/0/Android/data/moe.shizuku.privileged.api/start.sh 自动任务 AutoTask # 自动化任务\nScene # 查看安卓进程管理\nApp Ops # App权限监测\nADB # 设置http代理 # adb shell settings put global http_proxy 192.168.105.230:8080 adb shell settings put global https_proxy 192.168.105.230:8080 # 删除代理 adb shell settings delete global http_proxy Deleted 1 rows adb shell settings delete global https_proxy Deleted 1 rows adb shell settings delete global global_http_proxy_host Deleted 1 rows adb shell settings delete global global_https_proxy_host Deleted 0 rows adb shell settings delete global global_http_proxy_port Deleted 1 rows adb shell settings delete global global_https_proxy_port Deleted 0 rows # 需要冲起生效 - 有的机器可能不用 adb reboot "},{"id":40,"href":"/docs/programmer/platforms/os/ubuntu/","title":"Ubuntu","section":"平台","content":" 一、Snap # 如果Ubuntu有问题,那么很有可能是因为Snap\nFirefox # 在升级Ubuntu 24.04后内存占用极为不正常, 多次排查无果, 增加了交换空间还是没有治本, 几经排查终于发现是firefox的问题, 且是Snap的firefox的问题,所以手动下载别的版本后修改如下:\n修改/usr/bin/firefox中的最一开始的监测安装和运行为自行下载软件路径 添加gnome favorite-apps 1. 添加Firefox到Favorites（喜爱应用） # 打开终端（Ctrl + Alt + T）。 输入以下命令来查看当前的喜爱应用列表： gsettings get org.gnome.shell favorite-apps 这会输出当前的喜爱应用列表 3. 如果没有看到 firefox.desktop 在列表中，可以使用以下命令将它添加进去,这个命令会将 firefox.desktop 添加到喜爱应用列表的末尾。：\ngsettings set org.gnome.shell favorite-apps \u0026#34;$(gsettings get org.gnome.shell favorite-apps | sed \u0026#34;s/]/, \u0026#39;firefox.desktop\u0026#39;]/\u0026#34;)\u0026#34; 2. 检查.desktop文件是否正确 # 确保 firefox.desktop 文件存在并且正确配置。通常，它应该位于 /usr/share/applications/ 目录或者在Snap安装中可能位于 /var/lib/snapd/desktop/applications/ 目录。你可以使用 ls 命令检查这些位置是否有相关的 .desktop 文件：\nls /usr/share/applications/firefox.desktop ls /var/lib/snapd/desktop/applications/firefox_firefox.desktop # 如果是通过Snap安装的Firefox` 3. 更新缓存和重启(可选) - 我用的 [[#^bef1ba]] # 如果以上步骤没有解决问题，尝试更新GNOME的缓存并重新启动GNOME Shell：\nsudo update-desktop-database 然后注销并重新登录GNOME Shell，看看是否能够显示Firefox图标。\n4. 手动创建.desktop文件(将软件添加到软件列表) # ^bef1ba\n如果 .desktop 文件确实存在但仍然无法正常显示图标，可以尝试手动创建一个 .desktop 文件。创建一个名为 firefox.desktop 的文件，并将以下内容复制粘贴进去：\n[Desktop Entry] Version=1.0 Name=Firefox Comment=Browse the World Wide Web GenericName=Web Browser Keywords=Internet;WWW;Browser;Web;Explorer Exec=firefox %u Terminal=false X-MultipleArgs=false Type=Application Icon=firefox Categories=Network;WebBrowser; MimeType=text/html;text/xml;application/xhtml+xml;application/xml;application/vnd.mozilla.xul+xml;application/rss+xml;application/rdf+xml;image/gif;image/jpeg;image/png;x-scheme-handler/http;x-scheme-handler/https; StartupNotify=true Actions=new-window;new-private-window; [Desktop Action new-window] Name=New Window Exec=firefox --new-window %u [Desktop Action new-private-window] Name=New Private Window Exec=firefox --private-window %u 保存文件后，将其放置在 /usr/share/applications/ 目录下，并确保具有适当的文件权限。\n5. 检查默认应用设置 # 最后，确保Firefox已经被正确设置为默认的Web浏览器。可以通过以下命令检查： xdg-settings get default-web-browser 如果没有设置为 firefox.desktop，可以使用以下命令设置： xdg-settings set default-web-browser firefox.desktop 完成上述步骤后，重新启动Firefox并检查是否显示了正确的图标和行为。希望这些步骤能帮助你解决在GNOME中Firefox图标未显示的问题！\n设置用户下中文目录为英文 # 每次cd切换输入法有些难受\nvim .config/user-dirs.dirs 桌面 # 如果桌面不显示文件图标, 1是检查上述配置路径是否正确 2有可能缺少了desktop-icons-ng插件\nsudo apt install gnome-shell-extension-desktop-icons-ng sudo apt install gnome-shell-extension-prefs 同理, 如果不想在桌面上显示文件, 那就把这插件给删了\n如果是双系统可以软链一些通用目录节省空间 # ln -s /mnt/Windows/Users/{用户名}/Downloads /home/{用户名}/Downloads 文件管理器 # nautilus\n二、apt # Ubuntu 中，使用 apt-get install 或 apt install 下载并安装软件时，相关文件存储在以下位置：\n软件包：/var/cache/apt/archives 安装位置：/usr/share 快捷方式：/usr/share/applications 可执行文件：/usr/bin 库文件：/usr/lib 配置文件：/etc 2.1 查找包 # 例如查找爪哇:\napt-cache search openjdk 2. 2依赖包缺失 # 一、安装向日葵缺失libgconf-2-4 # https://blog.csdn.net/lingzhou0909/article/details/139708197\n去https://packages.ubuntu.com/search?keywords=libgconf-2-4查看版本 发现没有24.04版的, 将22.04版本的加到 source.list 中 apt update sudo apt --fix-broken install dpkg -i SunloginClient_15.2.0.63062_amd64.deb 再次安装 三、.desktop 程序开发 # 自动启动配置: ~/.config/autostart/ 注册到应用中: /usr/share/applications/\n登陆自启 # 不过现在好多应用貌似都没放在这里, 就老牌的应用有放.\n不过这里貌似是很正规的地方, 毕竟在Ubuntu\u0026quot;启动应用程序\u0026quot;里可以看到这个配置\nsudo cp ~/.config/autostart/desktop-tools.desktop /usr/share/applications/ 配置详情: # 配置 说明 其他 Path 工作目录 [Desktop Entry] Name=desktoptools Name[zh_CN]=桌面工具 Comment=Desktop Tools Comment[zh_CN]=桌面工具 GenericName=Desktop Tools Keywords=tools Exec=/home/ian/env/ui/bin/python test.py %u Path=/home/ian/Apps/DesktopTools Icon=/home/ian/Apps/DesktopTools/DesktopTools/harry_potter.png Terminal=false Type=Application X-GNOME-Autostart-Delay=10 Categories=GNOME;Utility; Hidden=false 四、输入法问题 # ibus restart \u0026gt; 无法连接 IBus。 ibus-daemon -r -d -x # 可解决 五、修改开机广告 # cd /usr/share/plymouth/themes/ubuntu-text cd /usr/share/plymouth/themes/ubuntu-logo 六、图片查看器 # [!note] eog 太烂了 loupe 好用 打开matplotlib画的图能卡死 loupe 和它界面差不多 都听好看性能还好些 不过loupe 内存占用依然好高.. 难道是我300dpi太高了?\n# 卸载掉默认的图片查看 24.04还是这个 sudo apt remove eog # 安装新的rust写的图片查看器 sudo apt install loupe 使用源码编译的话需要\nsudo apt-get install fontconfig libfontconfig1-dev sudo apt-get install libcairo2 libcairo2-dev sudo apt-get install libpango-1.0-0 libpango1.0-dev sudo apt-get install libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-dev sudo apt-get install libgtk-4-dev sudo apt-get install libgraphene-1.0-0 libgraphene-1.0-dev 编译介绍 # 序号 库名称 描述 1 Cairo 一个 2D 图形库，用于提供高质量的绘图操作 2 Fontconfig 一个用于字体配置和管理的库，帮助应用程序找到和使用系统上的字体 3 Pango 一个用于文本布局和国际化的库，通常用于与 Cairo 一起处理文本渲染 4 GDK - Pixbuf 一个用于图像加载和处理的库，常用于 GTK+ 应用程序中 5 GTK4 GTK+ 的最新版本，用于创建图形用户界面 6 Graphene 一个数学库，提供用于图形计算的各种功能，如向量和矩阵操作 7 LibAdwaita 一个用于构建 GNOME 应用程序的用户界面库，提供一些现代化的 UI 组件和样式 8 GWeather ??? 一个用于获取和显示天气信息的库，通常与 GNOME 桌面环境集成 卡住情况说明 # pkg-config --modversion libadwaita-1 1.5.0 要求: \u0026gt; PKG_CONFIG_PATH=/usr/local/lib/pkgconfig PKG_CONFIG_ALLOW_SYSTEM_CFLAGS=1 pkg-config --libs --cflags libadwaita-1 libadwaita-1 \u0026gt;= 1.6 Terminal终端图片查看器 # apt install chafa chafa demo.png 七、Bye Snap # 关闭自动更新 # sudo snap set system refresh.hold=\u0026#34;$(date -u +%Y-%m-%dT%H:%M:%SZ)\u0026#34; # 解除 # sudo snap unset system refresh.hold 八、文档pdf查看器 # [!note] Evince 太烂了 Okular 还行 不知道从啥时候开始用Ubuntu-Gnome自带Evince打开pdf就直接卡死桌面了\u0026hellip; 不得已只能换了 Evince 用 Qkular\n"},{"id":41,"href":"/docs/programmer/cloudnative/redis/python-redis-%E5%AE%A2%E6%88%B7%E7%AB%AF/","title":"Python Redis 客户端","section":"中间件","content":" 异步调用时自动关闭 # 当事件循环正在运行时，会创建一个任务来关闭 redis 连接，而不会阻塞事件循环。如果事件循环没有运行，就可以像之前一样调用 run_until_complete。\nasync def close_redis(self): if self.redis: await self.redis.close() def __del__(self): loop = asyncio.get_event_loop() if loop.is_running(): asyncio.create_task(self.close_redis()) else: loop.run_until_complete(self.close_redis()) 数据迁移(hash数据) # 脚本 # import os import json import redis import argparse from loguru import logger home_path = os.environ.get(\u0026#39;HOME\u0026#39;) parser = argparse.ArgumentParser(description=\u0026#39;Copy Reten Config\u0026#39;) parser.add_argument(\u0026#39;--mode\u0026#39;, help=\u0026#39;Pull or Push data from Redis\u0026#39;) parser.add_argument(\u0026#39;-ds\u0026#39;, \u0026#39;--datasource\u0026#39;, help=\u0026#39;retens or events config data from Redis\u0026#39;) args = parser.parse_args() source_redis = redis.StrictRedis(host=\u0026#39;redis-product.com\u0026#39;, port=6379, db=0) def scan_keys_with_pattern(pattern): # 初始游标 cursor = \u0026#39;0\u0026#39; count_group = 0 while True: # 使用 SCAN 命令进行迭代 cursor, keys = source_redis.scan(cursor=cursor, match=pattern) # 游标为 \u0026#39;0\u0026#39; 表示迭代结束 if cursor == b\u0026#39;0\u0026#39; or cursor == 0 or cursor == \u0026#39;0\u0026#39;: break # 将找到的键添加到结果列表中 count_group += 1 logger.info(f\u0026#34;{count_group} - {len(keys)} = {cursor}\u0026#34;) yield [key.decode(\u0026#39;utf-8\u0026#39;) for key in keys] def append_2_file(data): # 将数据转换为字典 decoded_data = {} for key, value in data.items(): decoded_data[key.decode(\u0026#39;utf-8\u0026#39;)] = value.decode(\u0026#39;utf-8\u0026#39;) # 将数据写入文件 with open(f\u0026#39;data_{args.datasource}.json\u0026#39;, \u0026#39;a\u0026#39;) as file: file.write(json.dumps(decoded_data) + \u0026#39;\\n\u0026#39;) def pull(): # 连接到源 Redis 实例 # 从 Redis 中读取数据 all_keys = set() if args.datasource == \u0026#39;retens\u0026#39;: for keys in scan_keys_with_pattern(\u0026#39;mmp:cfgs:*:retens\u0026#39;): for key in keys: if key not in all_keys: all_keys.add(key) else: logger.warning(f\u0026#34;重复一次: {key}\u0026#34;) continue data = source_redis.hgetall(key) append_2_file(data=data) elif args.datasource == \u0026#39;events\u0026#39;: for keys in scan_keys_with_pattern(\u0026#39;mmp:cfgs:*:events\u0026#39;): for key in keys: if key not in all_keys: all_keys.add(key) else: logger.warning(f\u0026#34;重复一次: {key}\u0026#34;) continue data = source_redis.hgetall(key) append_2_file(data=data) else: logger.error(f\u0026#34;Invalid datasource: {args.datasource}\u0026#34;) return def push(): # 连接到目标 Redis 实例 target_redis = redis.StrictRedis(host=\u0026#39;localhost\u0026#39;, port=6379, db=1) # 读取文件内容并写入目标 Redis if not args.datasource in [\u0026#39;retens\u0026#39;, \u0026#39;events\u0026#39;]: logger.error(f\u0026#34;Invalid datasource: {args.datasource}\u0026#34;) return with open(os.path.join(home_path, f\u0026#39;data_{args.datasource}.json\u0026#39;), \u0026#39;r\u0026#39;) as file: for l in file: l = json.loads(l) for key, value in l.items(): value_obj = json.loads(value) pkg_name = value_obj[\u0026#34;pkg_name\u0026#34;] if args.datasource == \u0026#39;retens\u0026#39;: ok = target_redis.hset(f\u0026#39;mmp:cfgs:{pkg_name}:retens\u0026#39;, key, value) elif args.datasource == \u0026#39;events\u0026#39;: ok = target_redis.hset(f\u0026#39;mmp:cfgs:{pkg_name}:events\u0026#39;, key, value) else: print(f\u0026#34;Invalid datasource: {args.datasource}\u0026#34;) logger.info(f\u0026#39;Writing {key} {value} to Redis -\u0026gt; {ok}\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: if args.mode == \u0026#39;pull\u0026#39;: pull() elif args.mode == \u0026#39;push\u0026#39;: push() 使用 # python {thisscript}.py --mode=pull -ds=events python {thisscript}.py --mode=push -ds=events hash # import redis # 创建 Redis 连接 r = redis.Redis(host=\u0026#39;localhost\u0026#39;, port=6379, db=0) # 写入数据到哈希 r.hset(\u0026#39;my_hash\u0026#39;, \u0026#39;field1\u0026#39;, \u0026#39;value1\u0026#39;) r.hset(\u0026#39;my_hash\u0026#39;, mapping={\u0026#39;field2\u0026#39;: \u0026#39;value2\u0026#39;, \u0026#39;field3\u0026#39;: \u0026#39;value3\u0026#39;}) # 获取单个字段的值 value = r.hget(\u0026#39;my_hash\u0026#39;, \u0026#39;field1\u0026#39;) print(f\u0026#39;field1: {value.decode(\u0026#34;utf-8\u0026#34;)}\u0026#39;) # 获取所有字段和值 all_fields = r.hgetall(\u0026#39;my_hash\u0026#39;) print(\u0026#39;All fields:\u0026#39;) for field, value in all_fields.items(): print(f\u0026#39;{field.decode(\u0026#34;utf-8\u0026#34;)}: {value.decode(\u0026#34;utf-8\u0026#34;)}\u0026#39;) # 查看哈希中字段的数量 field_count = r.hlen(\u0026#39;my_hash\u0026#39;) print(f\u0026#39;Number of fields in my_hash: {field_count}\u0026#39;) 事务 # import asyncio import aioredis async def run_transaction(redis: aioredis.Redis): async with redis.pipeline() as pipe: # 开始事务 await pipe.multi() # 在事务中执行多个命令 await pipe.set(\u0026#39;key1\u0026#39;, \u0026#39;value1\u0026#39;) await pipe.set(\u0026#39;key2\u0026#39;, \u0026#39;value2\u0026#39;) # 提交事务 results = await pipe.execute() print(\u0026#39;Transaction results:\u0026#39;, results) async def main(): # 创建 Redis 连接 redis = await aioredis.from_url(\u0026#34;redis://localhost:6379\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;, decode_responses=True) # 运行事务 await run_transaction(redis) # 关闭连接 await redis.close() # 运行异步主函数 if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(main()) 乐观锁 # 详细解释\nasync with redis.pipeline() as pipe: 使用 pipeline 上下文管理器创建一个事务或管道。这会创建一个事务队列或管道。 await pipe.multi(): 开始一个事务。如果在管道中使用这个命令，则表示开始一个事务。如果不使用，则表示普通的管道操作。 await pipe.execute(): 提交事务或管道操作，并获取所有命令的结果。 await pipe.watch('key'): 监视指定的键，以便在事务提交之前确保这些键没有被其他客户端修改。如果在事务提交前键发生变化，事务会失败。 aioredis.WatchError: 捕获由于键被修改而导致的事务失败异常。 async def run_watch(redis: aioredis.Redis): async with redis.pipeline() as pipe: # 监视键 await pipe.watch(\u0026#39;key1\u0026#39;) # 开始事务 await pipe.multi() # 执行事务中的命令 await pipe.set(\u0026#39;key1\u0026#39;, \u0026#39;value1\u0026#39;) await pipe.set(\u0026#39;key2\u0026#39;, \u0026#39;value2\u0026#39;) # 提交事务 try: results = await pipe.execute() print(\u0026#39;Watch transaction results:\u0026#39;, results) except aioredis.WatchError: print(\u0026#39;Transaction failed due to concurrent modification\u0026#39;) async def main(): # 创建 Redis 连接 redis = await aioredis.from_url(\u0026#34;redis://localhost:6379\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;, decode_responses=True) # 运行 WATCH 事务 await run_watch(redis) # 关闭连接 await redis.close() # 运行异步主函数 if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(main()) 分布式锁 # async def release_counter_lock(account_id: int, package_name: str, identifier: str): lock_key = f\u0026#34;lock_{account_id}_{package_name}\u0026#34; # Lua 脚本：如果锁的值与标识符匹配，则删除锁 lua_script = \u0026#34;\u0026#34;\u0026#34; if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end \u0026#34;\u0026#34;\u0026#34; # 执行 Lua 脚本 result = await rds.eval(lua_script, 1, lock_key, identifier) # 如果返回值为 1，说明锁被删除 if result == 1: return True return False async def acquire_counter_lock(account_id: int, package_name: str) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; True 为被锁定,暂时不可用 \u0026#34;\u0026#34;\u0026#34; acquire_time = 2 identifier = str(uuid.uuid4()) # 使用UUID生成唯一标识 lock_key = f\u0026#34;lock_{account_id}_{package_name}\u0026#34; end = time.time() + acquire_time while time.time() \u0026lt; end: if await rds.setnx(lock_key, identifier): # 如果锁不存在，设置并返回True await rds.expire(lock_key, 10) return identifier # 成功获取锁，返回标识符 elif not await rds.ttl(lock_key): await rds.expire(lock_key, 10) time.sleep(0.01) # 超时未能获取锁 return \u0026#39;\u0026#39; "},{"id":42,"href":"/docs/programmer/platforms/%E9%98%BF%E9%87%8C%E4%BA%91%E4%BD%BF%E7%94%A8/","title":"阿里云使用","section":"平台","content":" oss 对象存储 # Python SDK # pip install oss2 export OSS_ACCESS_KEY_ID=SIHDoisdhuasuiUGDS export OSS_ACCESS_KEY_SECRET=asdih213asHSIDH2e1 一、Auth # import oss2 from oss2.credentials import EnvironmentVariableCredentialsProvider from itertools import islice auth = oss2.ProviderAuth(EnvironmentVariableCredentialsProvider()) 二、Bucket # bucket_info 字段说明 # 字段 type 注释 {bucket_info.name} Bucket的名称 {bucket_info.storage_class} Bucket的存储类型 {bucket_info.creation_date} Bucket的创建时间 {bucket_info.intranet_endpoint} Bucket的内网Endpoint {bucket_info.extranet_endpoint} Bucket的外网Endpoint {bucket_info.owner.id} Bucket的拥有者ID {bucket_info.acl.grant} Bucket的ACL授权 {bucket_info.data_redundancy_type} Bucket的数据冗余类型 {bucket_info.access_monitor} Bucket的访问跟踪状态 代码示例 # # 查看Bucket service = oss2.Service(auth, \u0026#39;oss-ap-xiaomengmai-1.aliyuncs.com\u0026#39;) for b in oss2.BucketIterator(service): print(b.name) # bucket信息 bucket = oss2.Bucket(auth, \u0026#39;oss-ap-xiaomengmai-1.aliyuncs.com\u0026#39;, \u0026#39;{bucket_name}\u0026#39;) bucket_info = bucket.get_bucket_info() 文件操作 # # 写入字符串 result = bucket.put_object(\u0026#39;exampleobject.txt\u0026#39;, \u0026#39;Hello OSS\u0026#39;) bucket.object_exists(\u0026#39;exampleobject.txt\u0026#39;) ##\u0026gt; True # 查看object列表 [i.key for i in bucket.list_objects(\u0026#34;\u0026#34;).object_list] 递归查看 - 有无/的区别 # for obj in oss2.ObjectIterator(bucket, prefix = \u0026#39;ods/\u0026#39;, delimiter = \u0026#39;/\u0026#39;): # 通过is_prefix方法判断obj是否为文件夹。 if obj.is_prefix(): # 判断obj为文件夹。 print(\u0026#39;directory: \u0026#39; + obj.key) else: # 判断obj为文件。 print(\u0026#39;file: \u0026#39; + obj.key) ## \u0026gt; file: ods/ ## \u0026gt; directory: ods/clicker/ ## \u0026gt; directory: ods/snapshot/ for obj in oss2.ObjectIterator(bucket, prefix = \u0026#39;.\u0026#39;, delimiter = \u0026#39;/\u0026#39;): # 通过is_prefix方法判断obj是否为文件夹。 if obj.is_prefix(): # 判断obj为文件夹。 print(\u0026#39;directory: \u0026#39; + obj.key) else: # 判断obj为文件。 print(\u0026#39;file: \u0026#39; + obj.key) ##\u0026gt; directory: .dlsdata/ aaa = bucket.put_object(\u0026#39;ods/haha-emu/\u0026#39;, \u0026#39;\u0026#39;) for obj in oss2.ObjectIterator(bucket, prefix = \u0026#39;ods/\u0026#39;, delimiter = \u0026#39;/\u0026#39;): # 通过is_prefix方法判断obj是否为文件夹。 if obj.is_prefix(): # 判断obj为文件夹。 print(\u0026#39;directory: \u0026#39; + obj.key) else: # 判断obj为文件。 print(\u0026#39;file: \u0026#39; + obj.key) ##\u0026gt; file: ods/ ##\u0026gt; directory: ods/clicker/ ##\u0026gt; directory: ods/haha-emu/ ##\u0026gt; directory: ods/snapshot/ "},{"id":43,"href":"/docs/programmer/cloudnative/redis/bigkey-and-hotkey/","title":"大key、热key问题","section":"中间件","content":" 如何找出优化大Key与热Key,产生的原因和问题_云数据库 Redis 版(Redis)-阿里云帮助中心 # 在使用Redis的过程中，如果未能及时发现并处理Big keys（下文称为“大Key”）与Hotkeys（下文称为“热Key”），可能会导致服务性能下降、用户体验变差，甚至引发大面积故障。本文将介绍大Key与热Key产生的原因、其可能引发的问题及如何快速找出大Key与热Key并将其优化的方案。\n名词 解释 大Key 通常以Key的大小和Key中成员的数量来综合判定，例如：- Key本身的数据量过大：一个String类型的Key，它的值为5 MB。- Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个。- Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。 热Key 通常以其接收到的Key被请求频率来判定，例如：- QPS集中在特定的Key：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。- 带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的HGETALL操作请求。- CPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的ZRANGE操作请求。 说明\n上述例子中的具体数值仅供参考，在实际业务中，您需要根据Redis的实际业务场景进行综合判断。\n大Key和热Key引发的问题 # 类别 说明 大Key - 客户端执行命令的时长变慢。- Redis内存达到maxmemory参数定义的上限引发操作阻塞或重要的Key被逐出，甚至引发内存溢出（Out Of Memory）。- 集群架构下，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。- 对大Key执行读请求，会使Redis实例的带宽使用率被占满，导致自身服务变慢，同时易波及相关的服务。- 对大Key执行删除操作，易造成主库较长时间的阻塞，进而可能引发同步中断或主从切换。 热Key - 占用大量的CPU资源，影响其他请求并导致整体性能降低。- 集群架构下，产生访问倾斜，即某个数据分片被大量访问，而其他数据分片处于空闲状态，可能引起该数据分片的连接数被耗尽，新的连接建立请求被拒绝等问题。- 在抢购或秒杀场景下，可能因商品对应库存Key的请求量过大，超出Redis处理能力造成超卖。- 热Key的请求压力数量超出Redis的承受能力易造成缓存击穿，即大量请求将被直接指向后端的存储层，导致存储访问量激增甚至宕机，从而影响其他业务。 大Key和热Key产生的原因 # 未正确使用Redis、业务规划不足、无效数据的堆积、访问量突增等都会产生大Key与热Key，如：\n大key 在不适用的场景下使用Redis，易造成Key的value过大，如使用String类型的Key存放大体积二进制文件型数据； 业务上线前规划设计不足，没有对Key中的成员进行合理的拆分，造成个别Key中的成员数量过多； 未定期清理无效数据，造成如HASH类型Key中的成员持续不断地增加； 使用LIST类型Key的业务消费侧发生代码故障，造成对应Key的成员只增不减。 热key 预期外的访问量陡增，如突然出现的爆款商品、访问量暴涨的热点新闻、直播间某主播搞活动带来的大量刷屏点赞、游戏中某区域发生多个工会之间的战斗涉及大量玩家等。 快速找出大Key和热Key # Redis提供多种方案帮助您轻松找出大Key与热Key。\n方法 优缺点 说明 实时Top Key统计（推荐） - 优点：准确性高、对性能几乎无影响。- 缺点：展示的Key数量有一定限制，但能满足常规场景下的需求。 可实时展示实例中的大Key和热Key信息，同时支持查看4天内大Key和热Key的历史信息。该功能可帮助您掌握Key在内存中的占用、Key的访问频次等信息，溯源分析问题，为您的优化操作提供数据支持。 离线全量Key分析 - 优点：可对历史备份数据进行分析，对线上服务无影响。- 缺点：时效性差，RDB文件较大时耗时较长。 对Redis的RDB备份文件进行定制化的分析，帮助您发现实例中的大Key，掌握Key在内存中的占用和分布、Key过期时间等信息，为您的优化操作提供数据支持，帮助您避免因Key倾斜引发的内存不足、性能下降等问题。 通过redis-cli的bigkeys和hotkeys参数查找大Key和热Key - 优点：方便、快速、安全。- 缺点：分析结果不可定制化，准确性与时效性差。 Redis提供了bigkeys参数能够使redis-cli以遍历的方式分析Redis实例中的所有Key，并返回Key的整体统计信息与每个数据类型中Top1的大Key，bigkeys仅能分析并输入六种数据类型（STRING、LIST、HASH、SET、ZSET、STREAM），命令示例为redis-cli -h r-***************.redis.rds.aliyuncs.com -a \u0026lt;password\u0026gt; --bigkeys。说明若您只需要分析STRING类型的大key或是找出成员数量超过10个的HASH Key，则bigkeys参数无法直接实现该类需求。同时，自Redis 4.0版本起提供了hotkeys参数，可以快速帮您找出业务中的热Key，具体操作，请参见通过redis-cli的hotkeys参数查找热Key。 通过Redis内置命令对目标Key进行分析 - 优点：方便、对线上服务影响小。- 缺点：返回的Key序列化长度并不等同于它在内存空间中的真实长度，因此不够准确，仅可作为参考。 对不同数据类型的目标Key，分别通过如下风险较低的命令进行分析，来判断目标Key是否符合大Key判定标准。- STRING类型：执行STRLEN命令，返回对应Key的value的字节数。- LIST类型：执行LLEN命令，返回对应Key的列表长度。- HASH类型：执行HLEN命令，返回对应Key的成员数量。- SET类型：执行SCARD命令，返回对应Key的成员数量。- ZSET类型：执行ZCARD命令，返回对应Key的成员数量。- STREAM类型：执行XLEN命令，返回对应Key的成员数量。说明DEBUG OBJECT与MEMORY USAGE命令在执行时需占用较多资源，且时间复杂度为O(N)，有阻塞Redis实例的风险，不建议使用。 通过业务层定位热Key - 优点：可准确并及时地定位热Key。- 缺点：业务代码复杂度的增加，同时可能会降低一些性能。 通过在业务层增加相应的代码对Redis的访问进行记录并异步汇总分析。 通过redis-rdb-tools工具以定制化方式找出大Key - 优点：支持定制化分析，对线上服务无影响。- 缺点：时效性差，RDB文件较大时耗时较长。 Redis-rdb-tools是通过Python编写，支持定制化分析Redis RDB快照文件的开源工具。您可以根据您的精细化需求，全面地分析Redis实例中所有Key的内存占用情况，同时也支持灵活地分析查询。 通过MONITOR命令找出热Key - 优点：方便、安全。- 缺点：会占用CPU、内存、网络资源，时效性与准确性较差。 Redis的MONITOR命令能够忠实地打印Redis中的所有请求，包括时间信息、Client信息、命令以及Key信息。在发生紧急情况时，可以通过短暂执行MONITOR命令并将返回信息输入至文件，在关闭MONITOR命令后，对文件中请求进行归类分析，找出这段时间中的热Key。说明由于MONITOR命令对Redis实例性能消耗较大，非特殊情况不推荐使用MONITOR命令。 优化大Key与热Key # 类别 处理方法 大Key - 对大Key进行拆分 例如将含有数万成员的一个HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围。在Redis集群架构中，拆分大Key能对数据分片间的内存平衡起到显著作用。 - 对大Key进行清理 将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。 说明 - Redis 4.0及之后版本：您可以通过UNLINK命令安全地删除大Key甚至特大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。 - Redis 4.0之前的版本：建议先通过SCAN命令读取部分数据，然后进行删除，避免一次性删除大量key导致Redis阻塞。 - 监控Redis的内存水位 您可以通过监控系统设置合理的Redis内存报警阈值进行提醒，例如Redis内存使用率超过70%、Redis的内存在1小时内增长率超过20%等。通过此类监控手段，可以提前规避许多问题，例如LIST数据类型的消费程序故障造成对应Key的列表数量持续增长，将告警转变为预警从而避免故障的发生，更多信息，请参见报警设置。 - 对过期数据进行定期清理 堆积大量过期数据会造成大Key的产生，例如在HASH数据类型中以增量的形式不断写入大量数据而忽略了数据的时效性。可以通过定时任务的方式对失效数据进行清理。 说明 在清理HASH数据时，建议通过HSCAN命令配合HDEL命令对失效数据进行清理，避免清理大量数据造成Redis阻塞。 - 使用阿里云的Tair服务（Redis企业版）避开失效数据的清理工作 若HASH Key过多，存在大量的成员失效需要被清理的问题，又由于大量Key与大量失效数据叠加，无法通过定时任务对无效数据进行及时地清理，您可以通过阿里云Tair服务高效地解决此类问题。 Tair是云数据库Redis的企业版，它具备Redis所有特性（包括Redis的高性能特点），同时提供了大量额外的高级功能。 TairHash是一种可为field设置过期时间和版本的Hash数据类型，它不但和Redis Hash一样支持丰富的数据接口和高处理性能，还改变了Hash只能为Key设置过期时间的限制，可以为field设置过期时间和版本。这极大地提高了HASH数据类型的灵活性，简化了很多场景下的业务开发工作。同时，TairHash使用高效的Active Expire算法，实现了在对响应时间几乎无影响的前提下，高效完成对field过期判断和删除的功能。 此类高级功能的合理使用能够解放大量Redis的运维、故障处理工作并降低业务的代码复杂度，更多信息，请参见exHash。 热Key - 在Redis集群架构中对热Key进行复制 在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。 说明 该方案的缺点在于需要联动修改代码，同时带来了数据一致性的挑战（由原来更新一个Key演变为需要更新多个Key），仅建议该方案用来解决临时棘手的问题。 - 使用读写分离架构 如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。不仅要为多个从节点提供转发层（如Proxy，LVS等）来实现负载均衡，还要考虑从节点数量显著增加后带来故障率增加的问题。Redis集群架构变更会为监控、运维、故障处理带来了更大的挑战。 然而，阿里云Redis服务以开箱即用的方式提供服务。在业务发生变化时，您仅需通过变配的方式调整实例架构来轻松应对，例如将主从架构转变为读写分离架构、将读写分构架构转变为集群架构，以及将社区版转变为支持大量高级特性的Tair版（Redis企业版）等，更多信息，请参见变更实例配置。 说明 读写分离架构同样存在缺点，在请求量极大的场景下，读写分离架构会产生不可避免的延迟，此时会有读取到脏数据的问题。因此，在读、写压力都较大且对数据一致性要求很高的场景下，读写分离架构并不是最优方案。 - 使用阿里云Tair的QueryCache特性 云数据库Redis会根据高效的排序和统计算法识别出实例中存在的热点Key（通常热点Key的QPS大于3,000），开启该功能后，代理节点Proxy会根据设定的规则缓存热点Key的请求和查询结果（仅缓存热点Key的查询结果，无需缓存整个Key）。当在缓存有效时间内收到相同的请求时，Proxy会直接返回结果至客户端，无需和后端的数据分片执行交互。在提升读取速度的同时，降低了热点Key对数据分片的性能影响，避免访问倾斜。 开通该功能后，来自客户端的同样请求无需再与Proxy后端的Redis进行交互而是由Proxy直接返回数据，指向热Key的请求由一个Redis节点承担转为多个Proxy共同承担，能够大幅度降低Redis节点的热Key压力。同时Tair的QueryCache功能还提供了大量的命令来方便您查看、管理代理查询缓存的情况，例如通过querycache keys命令查看所有被缓存热Key，通过querycache listall命令获取所有已缓存的所有命令等。更多信息，请参见通过Proxy Query Cache优化热点Key问题。 "},{"id":44,"href":"/docs/programmer/platforms/wps-for-linux/","title":"WPS for Linux","section":"平台","content":" wps 在linux上打开提示字体缺失 # wps 在linux上打开提示字体缺失 # git clone https://github.com/dv-anomaly/ttf-wps-fonts cd ttf-wps-fonts \u0026amp;\u0026amp; sudo ./install.sh "},{"id":45,"href":"/docs/programmer/langs/python/sqlalchemy/","title":"SqlAlchemy - 数据库Orm","section":"Python","content":" Sqlalchemy异步操作不完全指北 # 不完全抄袭自: 米洛丶 - 博客园 cnblogs.com\n异步SQLAlchemy # SQLAlchemy作为一款通用的Python Orm工具，在最近的版本也支持了异步操作。但网上很多资料都不是很齐全，API也不是很好查询的情况下，我便有了整理一份基础文档的想法。文章主要会以CRUD为入口，解决大家最基本的需求。\nengine的区别 # 在普通的SQLAlchemy中，建立engine对象，我们会采用下面的方式:\nfrom sqlalchemy import create_engine engine = create_engine(SQLALCHEMY_DATABASE_URI, pool_recycle=1500) 而异步的方式如下:\nfrom sqlalchemy.ext.asyncio import create_async_engine async_engine = create_async_engine(ASYNC_SQLALCHEMY_URI, pool_recycle=1500) 链接参数 # from sqlalchemy.ext.asyncio import create_async_engine async_engine = create_async_engine( SQLALCHEMY_DATABASE_URL, pool_size=10, # 设置最大连接池大小 max_overflow=20, # 设置最大溢出连接数 pool_timeout=30, # 设置获取连接的超时时间（单位：秒） pool_recycle=1500, # 设置连接回收时间（单位：秒） echo=True # 设置为True以便于调试，显示SQL日志 ) session的区别 # 我们一般用sessionmaker来建立session，不过异步的有点区别:\nfrom sqlalchemy.ext.asyncio import AsyncSession from sqlalchemy.orm import sessionmaker # 同步session Session = sessionmaker(engine) # 异步session 区别在于需要指定对应的class_ async_session = sessionmaker(async_engine, class_=AsyncSession) 建立会话 # 我们还是以代码的形式展示:\n# 同步 with Session() as session: # 里面是具体的sql操作 pass # 异步 async with Session() as session: # 里面是异步的操作，区别就是从with变成了async with 也就意味着方法必须是async修饰的 pass 以上是关于建立连接，处理会话的一些区别，接着我们讲对应的CRUD操作。\n查询 # 结果处理: https://docs.sqlalchemy.org/en/21/core/connections.html#sqlalchemy.engine.Result.scalars\n这里依旧会给出新老版本的对比:\n# 注意Session为同步Session，为了区分，异步session为async_session # model则为具体的Model类 # 异步查询方式 from sqlalchemy import select async def query(): async with async_session() as session: sql = select(model).where(model.id == 1) print(sql) # 这里可以打印出sql result = await session.execute(sql) # 第一条数据 data = result.scalars().first() # result.scalars().one_or_none() 不报错的获取方式 # 所有数据 # data = result.scalars().all() # 同步查询方式一 def query(): with Session() as session: # 查询id=1的第一条数据 result对应的就是model的实例 如果没有则是None result = session.query(model).filter_by(id=1).first() # 查询所有数据 result对应的数据为List[model]，即model数组 # result = session.query(model).filter_by(name=\u0026#34;zhangsan\u0026#34;).all() # 同步查询方式二 def query(): with Session() as session: # 查询id=1的第一条数据 result对应的就是model的实例 如果没有则是None result = session.query(model).filter(model.id == 1).first() # 查询所有数据 result对应的数据为List[model]，即model数组 # result = session.query(model).filter(model.name == \u0026#34;zhangsan\u0026#34;).all() 新增 # 这里开始就只讲异步的操作了。\nasync的新增不行啊, 好奇怪\ndata = DataModel(name=\u0026#39;\u0026#39;, phone=\u0026#39;\u0026#39;) async def insert(data): async with async_session() as session: async with session.begin(): session.add(data) # 刷新自带的主键 await session.flush() # 释放这个data数据 session.expunge(data) return data 先说一下session.begin，这个你可以理解为一个事务操作，当采用session的begin方法后，你可以发现我们不需要调用commit方法也能把修改存入数据库。\nexpunge方法，是用例释放这个实例，SQLAlchemy有个特点，当你的session会话结束以后，它会销毁你插入的这种临时数据，你再想访问这个data就访问不了了。所以我们可以释放这个数据。（expunge的作用）\n同步方法 # session.add(_data) session.commit() 这样就行, 异步的不行\u0026hellip; ID都拿到了, 但是数据库里查不到. 异步用上面的方法也不得行.\n编辑 # 一般编辑有2种方式:\n查询出对应的数据，在数据上修改 根据key-value的形式，修改对应数据的字段 from sqlalchemy import select, update # 方式一 async def update_record(model): async with async_session() as session: async with session.begin(): result = await session.execute(select(model).where(id=1)) now = result.scalars().first() if now is None: raise Exception(\u0026#34;记录不存在\u0026#34;) now.name = \u0026#34;李四\u0026#34; now.age = 23 # 这里测试过，如果去掉flush会导致数据不更新 await session.flush() session.expunge(now) return now # 方式二 async def update_by_map(): async with async_session() as session: async with session.begin(): # 更新id为1的数据，并把name改为李四 age改为23 sql = update(model).where(model.id == 1).values(name=\u0026#34;李四\u0026#34;, age=23) await session.execute(sql) 删除 # 删除的话，软删除大家都是update，所以不需要多说，物理删除的话，也有两种方式:\n查到以后删除之 直接根据条件删除（这种我没有仔细研究，我选的是第一种方式，容错率高点） async def delete_by_id(): async with async_session() as session: async with session.begin(): result = await session.execute(select(model).where(model.id == 2)) original = result.scalars().first() if original is None: raise Exception(\u0026#34;记录不存在\u0026#34;) # 如果是多条 # session.delete(original) # for item in result: # session.delete(item) 压缩 # 并不支持 mysql --compress 连接参数，以下是个伪实现\nfrom sqlalchemy.orm import validates class MyClass(Base): # ... data = Column(BLOB) @validates(\u0026#34;data\u0026#34;) def _set_data(self, key, value): return func.compress(value) 查询 # 逻辑操作符 # 1. and or # from sqlalchemy import and_, or_ print( select(Address.email_address).where( and_( or_(User.name == \u0026#34;squidward\u0026#34;, User.name == \u0026#34;sandy\u0026#34;), Address.user_id == User.id, ) ) ) 2. null # sql = select(DeviceData).where(DeviceData.device_json_new.is_not(None)) sql = select(DeviceData).where(DeviceData.device_json_new.is_(None)) 自适应查询 # async with async_session_install() as session: # 使用 DeviceData 模型直接构建查询 sql = select(DeviceData).where(DeviceData.device_json_new.is_not(None)) sql_max_min = select(func.max(DeviceData.id).label(\u0026#34;max_id\u0026#34;),func.min(DeviceData.id).label(\u0026#34;min_id\u0026#34;)).where(DeviceData.device_json_new.is_not(None),DeviceData.brand_name == ) for key, value in filters.items(): if not hasattr(DeviceData, key): continue sql = sql.where(getattr(DeviceData, key) == value) if limit != 0: sql = sql.limit(limit) if offset: sql = sql.offset(offset) logger.debug(f\u0026#34;fetch sql is: {sql}\u0026#34;) exec = await session.execute(sql) results = exec.scalars().all() 异步关系 # class AppPackage(Base): __tablename__ = \u0026#39;app_packages\u0026#39; id = Column(Integer, primary_key=True, autoincrement=True) app_id = Column(String(64), unique=True, nullable=False) description = Column(Text) icon = Column(String(128)) categories = Column(JSON) tags = Column(JSON) created_at = Column(TIMESTAMP, nullable=True, server_default=text(\u0026#39;CURRENT_TIMESTAMP\u0026#39;)) updated_at = Column(TIMESTAMP, nullable=True, onupdate=text(\u0026#39;CURRENT_TIMESTAMP\u0026#39;)) # Relationship to AppPlatform platforms = relationship(\u0026#39;AppPlatform\u0026#39;, back_populates=\u0026#39;app_package\u0026#39;, cascade=\u0026#39;all, delete\u0026#39;) class AppPlatform(Base): __tablename__ = \u0026#39;app_platforms\u0026#39; id = Column(Integer, primary_key=True, autoincrement=True) app_id = Column(String(64), ForeignKey(\u0026#39;app_packages.app_id\u0026#39;, ondelete=\u0026#39;CASCADE\u0026#39;), nullable=False) platform = Column(String(16), nullable=False) # Relationship to AppPackage app_package = relationship(\u0026#39;AppPackage\u0026#39;, back_populates=\u0026#39;platforms\u0026#39;) # Read async def get_package_by(app_id, platform) -\u0026gt; AppInfo: async with async_session_install() as session: appinfo = AppInfo(pkg_name=app_id) sql = select(AppPackage).options(joinedload(AppPackage.platforms)).where(AppPackage.app_id == app_id, AppPlatform.platform == platform) rst = await session.execute(sql) import ipdb; ipdb.set_trace() info = rst.scalars().first() if info: appinfo.description = info.description appinfo.tags = info.tags appinfo.categories = info.categories logger.info(f\u0026#34;app_id: {app_id}, len platforms: {len(info.platforms)}\u0026#34;) return appinfo else: return None 同步用就可\nsql = select(AppPackage).join(AppPackage).where(AppPackage.app_id == app_id, AppPlatform.platform == platform) like # sql_total = sql_total.where(or_(AppPackage.app_id.like(f\u0026#39;%{package}%\u0026#39;) for package in params.data.package)) 方法(动态表) # 创建表 # async def create_table_if_not_exists(package_name: str) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34; 创建包-账号-使用次数对照表 \u0026#34;\u0026#34;\u0026#34; try: table_name = TableNamePrefix.format(package_name=package_name) if table_name not in await get_installer_table_names(): await SavingsPool._add_support_package(package_name) async with async_engine.begin() as conn: # 创建表 table = Table( table_name, metadata, Column(\u0026#39;id\u0026#39;, Integer, primary_key=True), Column(\u0026#39;account_id\u0026#39;, Integer, comment=\u0026#34;账号ID, 账号表中的主键id\u0026#34;), Column(\u0026#39;count\u0026#39;, SmallInteger, comment=\u0026#34;该账号被使用的次数\u0026#34;), Column(\u0026#39;created_at\u0026#39;, DateTime, server_default=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;), Column(\u0026#39;updated_at\u0026#39;, DateTime, server_default=func.now(), onupdate=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;) ) await conn.run_sync(metadata.create_all, tables=[table]) logger.info(f\u0026#34;Table \u0026#39;{table_name}\u0026#39; created successfully.\u0026#34;) return True except Exception as e: logger.error(f\u0026#34;Failed to create table \u0026#39;{table_name}\u0026#39;: {e}, details: {traceback.format_exc()}\u0026#34;) return False 1. 有外键\u0026amp;有unsigned的时候(只一个) # 仔细对比与 2 中差异\nasync def create_table_if_not_exists(table_name: str) -\u0026gt; bool: \u0026#34;\u0026#34;\u0026#34; 创建包-账号-使用次数对照表 \u0026#34;\u0026#34;\u0026#34; try: if table_name not in await get_installer_table_names(): async with async_engine.begin() as conn: # 加载进已经存在的表 await conn.run_sync(lambda conn: metadata.reflect(bind=conn, only=[\u0026#39;google_accounts\u0026#39;])) logger.info(\u0026#34;Existing tables loaded into metadata.\u0026#34;) # 创建表 table = Table( table_name, metadata, Column(\u0026#39;id\u0026#39;, Integer, primary_key=True), Column(\u0026#39;account_id\u0026#39;, INTEGER(unsigned=True), unique=True, nullable=False, comment=\u0026#34;账号ID, 账号表中的主键id\u0026#34;), Column(\u0026#39;count\u0026#39;, SmallInteger, comment=\u0026#34;该账号被使用的次数\u0026#34;), Column(\u0026#39;created_at\u0026#39;, DateTime, server_default=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;), Column(\u0026#39;updated_at\u0026#39;, DateTime, server_default=func.now(), onupdate=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;), ForeignKeyConstraint([\u0026#39;account_id\u0026#39;], [\u0026#39;google_accounts.id\u0026#39;], name=\u0026#39;fk_account_id\u0026#39;), mysql_engine=\u0026#39;InnoDB\u0026#39;, extend_existing=True ) await conn.run_sync(lambda conn: metadata.create_all(bind=conn, tables=[table])) logger.info(f\u0026#34;Table \u0026#39;{table_name}\u0026#39; created successfully.\u0026#34;) else: logger.info(f\u0026#34;Table \u0026#39;{table_name}\u0026#39; already exists.\u0026#34;) return True except Exception as e: logger.error(f\u0026#34;Failed to create table \u0026#39;{table_name}\u0026#39;: {e}, details: {traceback.format_exc()}\u0026#34;) return False 2. 有外键\u0026amp;有unsigned的时候(可多个) # async with async_engine.begin() as conn: # 加载进已经存在的表 metadata.clear() # 没有这行(unique(`account_id`)会随着调用次数变多在建表语句中越来越多) await conn.run_sync(lambda conn: metadata.reflect(bind=conn, only=[\u0026#39;google_accounts\u0026#39;])) logger.info(\u0026#34;Existing tables loaded into metadata.\u0026#34;) # 创建表 fk_name = package_name.replace(\u0026#39;.\u0026#39;, \u0026#39;_\u0026#39;) table = Table( table_name, metadata, Column(\u0026#39;id\u0026#39;, Integer, primary_key=True), Column(\u0026#39;account_id\u0026#39;, INTEGER(unsigned=True), unique=True, nullable=False, comment=\u0026#34;账号ID, 账号表中的主键id\u0026#34;), Column(\u0026#39;count\u0026#39;, SmallInteger, comment=\u0026#34;该账号被使用的次数\u0026#34;), Column(\u0026#39;created_at\u0026#39;, DateTime, server_default=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;), Column(\u0026#39;updated_at\u0026#39;, DateTime, server_default=func.now(), onupdate=func.now(), nullable=False, comment=\u0026#34;UTC time\u0026#34;), ForeignKeyConstraint([\u0026#39;account_id\u0026#39;], [\u0026#39;google_accounts.id\u0026#39;], name=f\u0026#39;{fk_name}_account_id\u0026#39;), # 外键不能一样 mysql_engine=\u0026#39;InnoDB\u0026#39;, # extend_existing=True # 会修改-metadata 中缓存的建表语句 ) await conn.run_sync(lambda conn: metadata.create_all(bind=conn, tables=[table])) 异步获取表名 # from sqlalchemy.ext.asyncio import create_async_engine from sqlalchemy import inspect from sqlalchemy.ext.asyncio import AsyncConnection import asyncio # Configure your async engine DATABASE_URL = \u0026#34;mysql+aiomysql://user:password@host/dbname\u0026#34; async_engine = create_async_engine(DATABASE_URL, echo=True) # Define a synchronous function to get table names def get_table_names_sync(sync_conn): inspector = inspect(sync_conn) return inspector.get_table_names() # Define an async function to use the synchronous function async def get_installer_table_names(): async with async_engine.begin() as conn: # Use `run_sync` to call the synchronous function table_names = await conn.run_sync(get_table_names_sync) return table_names # Example usage async def main(): table_names = await get_installer_table_names() print(table_names) asyncio.run(main()) 异步加载表查询数据 # from sqlalchemy import Table, MetaData from sqlalchemy.ext.asyncio import create_async_engine from sqlalchemy.ext.asyncio import AsyncSession from sqlalchemy.orm import sessionmaker from sqlalchemy.future import select import asyncio # 配置异步引擎 DATABASE_URL = \u0026#34;mysql+aiomysql://user:password@host/dbname\u0026#34; async_engine = create_async_engine(DATABASE_URL, echo=True) # 创建同步函数来加载表 def load_table_sync(table_name, engine): metadata = MetaData() table = Table(table_name, metadata, autoload_with=engine) return table # 异步函数使用 `run_sync` 调用同步函数 async def query_data_and_add_counter(table_name, account_id): async with async_engine.connect() as conn: # 使用 `run_sync` 执行同步操作 table = await conn.run_sync(lambda sync_conn: load_table_sync(table_name, sync_conn)) # 构建查询并执行 query = table.select().where(table.c.account_id == account_id) result = await conn.execute(query) row = result.scalars().one_or_none() return row # 异步函数来插入数据 async def insert_data_counter(table_name, account_id, count) -\u0026gt; bool: async with async_engine.connect() as conn: async with conn.begin(): # 使用 `run_sync` 调用同步函数 table = await conn.run_sync(lambda sync_conn: load_table_sync(table_name, sync_conn)) # 构建插入语句 new_user = table.insert().values(account_id=account_id, count=count) await conn.execute(new_user) # 提交事务 await conn.commit() logger.debug(f\u0026#34;Data inserted into table \u0026#39;{table_name}\u0026#39; for account_id {account_id}.\u0026#34;) return True # 异步函数来查询和更新数据-事务 async def _query_data_and_add_counter(table_name, account_id: int) -\u0026gt; bool: async with async_engine.connect() as conn: async with conn.begin(): # 开始事务 # 使用 `run_sync` 调用同步函数 table = await conn.run_sync(lambda sync_conn: __load_table_sync(table_name, sync_conn)) # 构建查询 query = select(table.c.account_id, table.c.count, table.c.created_at).where(table.c.account_id == account_id) result = await conn.execute(query) account_id, count, create_at = result.fetchone() or (None, None, None) if account_id: logger.info(f\u0026#34;Update account_id {account_id} in table \u0026#39;{table_name}\u0026#39;: count+1 {count+1}\u0026#34;) count += 1 # 构建更新语句 update_stmt = table.update().where(table.c.account_id == account_id).values(count=count) await conn.execute(update_stmt) # 提交事务 await conn.commit() return True else: # 事务将在 `conn.begin()` 的上下文管理器退出时自动回滚 return False # 示例使用 async def main(): result = await query_data_and_add_counter(\u0026#34;your_table_name\u0026#34;, 12345) print(result) # 运行示例 asyncio.run(main()) 混用错误 # class GoogleAccounts(Base): pass table_account = await conn.run_sync(lambda sync_conn: __load_table_sync(\u0026#34;google_accounts\u0026#34;, sync_conn)) query = ( select(GoogleAccounts).select_from( table.join(table_account, table.c.account_id == table_account.c.id) ).where( and_( table.c.count \u0026gt;= 10, table_account.c.login_status == LoginStatus.Login.value ) ) ) # 报错 Not unique table/alias: \u0026#39;google_accounts\u0026#39; ## 原因 这个错误 `(pymysql.err.OperationalError) (1066, \u0026#34;Not unique table/alias: \u0026#39;google_accounts\u0026#39;\u0026#34;)` 表示 SQL 查询中的表别名 `google_accounts` 不是唯一的。这通常发生在你尝试在同一个查询中多次引用同一个表，并且没有为每次引用提供唯一的别名。 # 都使用table_account 就好啦 select(table_account).select_from( table.join(table_account, table.c.account_id == table_account.c.id) ).where( and_( table.c.count \u0026gt;= 10, table_account.c.login_status == LoginStatus.Login.value ) ) # 或者都用GoogleAccounts query = (select(GoogleAccounts).select_from(table.join(GoogleAccounts, table.c.account_id==GoogleAccounts.id)).where(and_(table.c.count \u0026gt;= 10,GoogleAccounts.login_status == LoginStatus.Login.value))) "},{"id":46,"href":"/docs/programmer/platforms/appsflyer/","title":"AppsFlyer-外网移动归因营销分析平台","section":"平台","content":" AppsFlyer # SDK集成 # Gradle、dependency 添加Android Install Referrer 到App 通过app权限准确化归因 应用内事件 # 注册 购买 广告点击 分享 邀请 唤醒 跳转 # OpenLink平台归因 跳转 深度链接 "},{"id":47,"href":"/docs/programmer/basetc/obsidian%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%E6%8F%92%E4%BB%B6/","title":"Obsidian思维导图插件","section":"基础工具和配置","content":" Enhancing Mind map # Links # https://github.com/MarkMindLtd/obsidian-enhancing-mindmap GitHub Related # coc-markmap gatsby-remark-markmap Features # links inline text styles multiline text inline code Katex - $x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$ 注意这里 # 该插件支持如上以及无序列表等有限的markdown格式，无法支持其他格式，一定要注意这点，否则可能会丢失数据，切记。\nShort cuts # 新建脑图 Ctrl/Cmd+P 新增子节点 Tab 新增兄弟节点 enter 删除节点 Delete 编辑节点 Space/dblclick node 后退 Ctrl/Cmd+Z 前进 Ctrl/Cmd+Y 取消编辑节点 Tab 展开节点 Ctrl/Cmd + / 收缩节点 Ctrl/Cmd + / 拖动节点 Drag and drop node 切换节点 Up/down/left/right 放大、缩小 Ctrl/Cmd + 滚轮 居中 Ctrl/Cmd + E 功能 # 编辑节点 拖动节点至某节点 前进/后退 在markdown和思维导图视图之间切换 数据同步 "},{"id":48,"href":"/docs/programmer/net/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","title":"网络编程","section":"Net","content":" 网络分层图 # ![[net_layer.png]]\nTCP是传输层的协议，而基于TCP造出来的HTTP和各类RPC协议，它们都只是定义了不同消息格式的应用层协议而已。 HTTP协议（Hyper Text Transfer Protocol），又叫做超文本传输协议。我们用的比较多，平时上网在浏览器上敲个网址就能访问网页，这里用到的就是HTTP协议。 RPC（Remote Procedure Call），又叫做远程过程调用。它本身并不是一个具体的协议，而是一种调用方式。虽然大部分RPC协议底层使用TCP，但实际上它们不一定非得使用TCP，改用UDP或者HTTP，其实也可以做到类似的功能。 RPC # vs HTTP # HTTP: ![[http.png]] RPC: ![[rpc.png]]\n服务发现 [x] # 首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道IP地址和端口。这个找到服务对应的IP端口的过程，其实就是服务发现。\n在HTTP中，你知道服务的域名，就可以通过DNS服务去解析得到它背后的IP地址，默认80端口。\n而RPC的话，就有些区别，一般会有专门的中间服务去保存服务名和IP信息，比如consul或者etcd，甚至是redis。想要访问某个服务，就去这些中间服务去获得IP和端口信息。由于dns也是服务发现的一种，所以也有基于dns去做服务发现的组件，比如CoreDNS。\n底层连接形式 [x] # 以主流的HTTP1.1协议为例，其默认在建立底层TCP连接之后会一直保持这个连接（keep alive），之后的请求和响应都会复用这条连接。\n而RPC协议，也跟HTTP类似，也是通过建立TCP长链接进行数据交互，但不同的地方在于，RPC协议一般还会再建个连接池，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，可以说非常环保。\n由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给HTTP加个连接池，比如go就是这么干的。\n可以看出这一块两者也没太大区别，所以也不是关键。\n传输的内容 # 基于TCP传输的消息，说到底，无非都是消息头header和消息体body。\nheader是用于标记一些特殊信息，其中最重要的是消息体长度。\nbody则是放我们真正需要传输的内容，而这些内容只能是二进制01串，毕竟计算机只认识这玩意。所以TCP传字符串和数字都问题不大，因为字符串可以转成编码再变成01串，而数字本身也能直接转为二进制。但结构体呢，我们得想个办法将它也转为二进制01串，这样的方案现在也有很多现成的，比如json，protobuf。\n这个将结构体转为二进制数组的过程就叫序列化，反过来将二进制数组复原成结构体的过程叫反序列化。 ![[tobytes.png]]\n序列化和反序列化\n对于主流的HTTP1.1，虽然它现在叫超文本协议，支持音频视频，但HTTP设计初是用于做网页文本展示的，所以它传的内容以字符串为主。header和body都是如此。在body这块，它使用json来序列化结构体数据。\n我们可以随便截个图直观看下。 ![[tobetes_details.png]] HTTP报文\n可以看到这里面的内容非常多的冗余，显得非常啰嗦。最明显的，像header里的那些信息，其实如果我们约定好头部的第几位是content-type，就不需要每次都真的把\u0026quot;content-type\u0026quot;这个字段都传过来，类似的情况其实在body的json结构里也特别明显。\n而RPC，因为它定制化程度更高，可以采用体积更小的protobuf或其他序列化协议去保存结构体数据，同时也不需要像HTTP那样考虑各种浏览器行为，比如302重定向跳转啥的。因此性能也会更好一些，这也是在公司内部微服务中抛弃HTTP，选择使用RPC的最主要原因。\n当然上面说的HTTP，其实特指的是现在主流使用的HTTP1.1，HTTP2在前者的基础上做了很多改进，所以性能可能比很多RPC协议还要好，甚至连gRPC底层都直接用的HTTP2。\n结论 # 纯裸TCP是能收发数据，但它是个无边界的数据流，上层需要定义消息格式用于定义消息边界。于是就有了各种协议，HTTP和各类RPC协议就是在TCP之上定义的应用层协议。 RPC本质上不算是协议，而是一种调用方式，而像gRPC和thrift这样的具体实现，才是协议，它们是实现了RPC调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时RPC有很多种实现方式，不一定非得基于TCP协议。 从发展历史来说，**HTTP主要用于b/s架构，而RPC更多用于c/s架构。但现在其实已经没分那么清了，b/s和c/s在慢慢融合。**很多软件同时支持多端，所以对外一般用HTTP协议，而内部集群的微服务之间则采用RPC协议进行通讯。 RPC其实比HTTP出现的要早，且比目前主流的HTTP1.1性能要更好，所以大部分公司内部都还在使用RPC。 HTTP2.0在HTTP1.1的基础上做了优化，性能可能比很多RPC协议都要好，但由于是这几年才出来的，所以也不太可能取代掉RPC。 TCP # 八股文常背，TCP是有三个特点，面向连接、可靠、基于字节流。\n粘包问题 # 因为： ![[tcp_is_dataflow.png]] 所以： ![[nianbaowenti.png]] 无法区分上述两种情况。 得出： 纯裸TCP是不能直接拿来用的，你需要在这个基础上加入一些自定义的规则，用于区分消息边界。\n于是我们会把每条要发送的数据都包装一下，比如加入消息头，消息头里写清楚一个完整的包长度是多少，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的消息体。\n建立连接示例 # ![[socket_connect.gif]]\n三次握手： # 客户端通过向服务器端发送一个SYN来创建一个主动打开，作为三次握手的一部分。客户端把这段连接的序号设定为随机数 A。 服务器端应当为一个合法的SYN回送一个SYN/ACK。ACK 的确认码应为 A+1，SYN/ACK 包本身又有一个随机序号 B。 最后，客户端再发送一个ACK。当服务端受到这个ACK的时候，就完成了三路握手，并进入了连接创建状态。此时包序号被设定为收到的确认号 A+1，而响应则为 B+1。 如图：![[3w4h.png]] # 四次挥手： # 注意: 中断连接端可以是客户端，也可以是服务器端。下面仅以客户端断开连接举例，反之亦然：\n客户端发送一个数据分段, 其中的 FIN 标记设置为1. 客户端进入 FIN-WAIT 状态. 该状态下客户端只接收数据, 不再发送数据. 服务器接收到带有 FIN = 1 的数据分段, 发送带有 ACK = 1 的剩余数据分段, 确认收到客户端发来的 FIN 信息. 服务器等到所有数据传输结束, 向客户端发送一个带有 FIN = 1 的数据分段, 并进入 CLOSE-WAIT 状态, 等待客户端发来带有 ACK = 1 的确认报文. 客户端收到服务器发来带有 FIN = 1 的报文, 返回 ACK = 1 的报文确认, 为了防止服务器端未收到需要重发, 进入 TIME-WAIT 状态. 服务器接收到报文后关闭连接. 客户端等待 2MSL 后未收到回复, 则认为服务器成功关闭, 客户端关闭连接. Web问题 # GET vs POST # 有人想要的答案 # 但是这个不正确\nGET使用URL或Cookie传参。而POST将数据放在BODY中。 GET的URL会有长度上的限制，则POST的数据则可以非常大。 POST比GET安全，因为数据在地址栏上不可见。 HTTP协议对GET和POST都没有对长度的限制 # HTTP协议明确地指出了，HTTP头和Body都没有长度的要求。而对于URL长度上的限制，有两方面的原因造成：\n浏览器。据说早期的浏览器会对URL长度做限制。据说IE对URL长度会限制在2048个字符内（流传很广，而且无数同事都表示认同）。但我自己试了一下，我构造了90K的URL通过IE9访问live.com，是正常的。网上的东西，哪怕是Wikipedia上的，也不能信。 服务器。URL长了，对服务器处理也是一种负担。原本一个会话就没有多少数据，现在如果有人恶意地构造几个几M大小的URL，并不停地访问你的服务器。服务器的最大并发数显然会下降。另一种攻击方式是，把告诉服务器Content-Length是一个很大的数，然后只给服务器发一点儿数据，嘿嘿，服务器你就傻等着去吧。哪怕你有超时设置，这种故意的次次访问超时也能让服务器吃不了兜着走。有鉴于此，多数服务器出于安全啦、稳定啦方面的考虑，会给URL长度加限制。但是这个限制是针对所有HTTP请求的，与GET、POST没有关系。 安全不安全和GET、POST没有关系 # Cookie和Session # Cookie Session 储存位置 客户端 服务器端 目的 跟踪会话，也可以保存用户偏好设置或者保存用户名密码等 跟踪会话 安全性 不安全 安全 session技术是要使用到cookie的，之所以出现session技术，主要是为了安全。 HTTP和HTTPS # 状态码 定义 1xx 报告 接收到请求，继续进程 2xx 成功 步骤成功接收，被理解，并被接受 3xx 重定向 为了完成请求,必须采取进一步措施 4xx 客户端出错 请求包括错的顺序或不能完成 5xx 服务器出错 服务器无法完成显然有效的请求 403: Forbidden 404: Not Found HTTPS握手,对称加密,非对称加密,TLS/SSL,RSA CSRF和XSS # CSRF(Cross-site request forgery)跨站请求伪造 XSS(Cross Site Scripting)跨站脚本攻击 CSRF 重点在请求，XSS 重点在脚本。 CGI和WSGI # CGI是通用网关接口，是连接web服务器和应用程序的接口，用户通过CGI来获取动态数据或文件等。 CGI程序是一个独立的程序，它可以用几乎所有语言来写，包括perl，c，lua，python等等。\nWSGI, Web Server Gateway Interface，是Python应用程序或框架和Web服务器之间的一种接口，WSGI的其中一个目的就是让用户可以用统一的语言(Python)编写前后端。\n"},{"id":49,"href":"/docs/programmer/cloudnative/redis/the-basics-of-redis/","title":"Redis基础","section":"中间件","content":" 基础理论 # 概况 # Redis (Remote Dictionary Server) 是一个开源的、支持网络、基于内存、可选持久性的键值对数据库。它支持多种类型的数据结构，如字符串（strings）、列表（lists）、集合（sets）、有序集合（sorted sets）以及散列（hashes）、位图（bitmaps）、超日志（hyperloglogs）和地理空间（geospatial）索引半径查询。\n特点包括：\n高性能：因为数据主要在内存中进行操作，读写速度非常快。 丰富的数据类型：提供多种数据结构来满足不同场景下的需求。 原子性：所有操作都是原子性的，支持事务（通过MULTI/EXEC命令）。 丰富的功能：支持发布订阅、Lua脚本、事务等。 数据结构 # Redis提供的数据结构包括： Redis 支持多种数据类型，以下是一些常用的数据类型以及它们的简要描述和使用场景：\n数据类型 描述 使用场景 String 二进制安全字符串，最大可以存储 512MB 存储文本或二进制数据，如缓存用户个人信息等 List 有序集合，按插入顺序排序 消息队列、时间线、最新消息列表 Set 无序集合，元素不重复 标签、社交网络中的朋友关系等 Sorted Set 有序集合，元素不重复，并且每个元素都会关联一个浮点数分数 排行榜、带权重的集合 Hash 键值对集合，适用于存储对象 存储、访问和修改对象属性 Bitmaps 通过位来表示数据的数据类型，适合做计数统计 在线状态、特性标志、统计等 HyperLogLog 近似去重计数的数据结构 大数据量的计数，如统计独立 IP 访问数量 Geospatial 存储地理位置信息，并进行相关地理操作 储存经纬度，查询附近的地点 Streams Redis 5.0 新增的数据类型，是一个可持久化的日志数据结构 实现消息队列，发布/订阅模式，日志记录 Redis 之所以快速，主要原因有以下几点： # 内存存储：Redis 将所有数据存储在内存中，内存的读写速度远高于硬盘。 数据结构简单：Redis 的数据结构设计简单直观，易于高效操作。 非阻塞 IO：Redis 使用非阻塞 IO 和多路复用技术，可以处理多个并发连接。 单线程模型：Redis 大部分操作是单线程执行，避免了多线程的上下文切换开销。 Redis高性能IO模型 # Redis的IO模型使用的是非阻塞IO复用技术，主要是epoll作为IO多路复用技术的实现方式。它通过单线程事件循环来处理所有客户端请求，确保绝大部分请求都是非阻塞的，并且使用异步编程模式来提高性能。\n引用一些数据的话，可以提及以下几点：\n内存读写速度：NVMe SSD 的 IOPS 可以达到数十万到数百万，而内存的 IOPS 可以达到千万级别，延迟通常小于100微秒。相比之下，内存的速度通常是硬盘的数千倍甚至更高。 性能表现：根据 Redis 官方给出的数据，在一个标准 Linux 系统上，Redis 可以达到每秒10万级别的读写操作（这个数字可能因配置、数据类型和具体操作而异）。 以上数据只是为了说明 Redis 为什么快速，具体的性能指标会根据使用环境、硬件配置以及具体的工作负载而有所变化。\n持久化机制 # Redis提供两种持久化机制：RDB（Snapshotting）和AOF（Append-only file）。\nRDB：在指定的时间间隔内生成数据集的时间点快照。 AOF：记录服务器接收到的每个写操作指令，并在服务器启动时重新执行这些命令来恢复数据。 缓存淘汰/删 # 当内存不足时，Redis会根据配置的策略来移除一些键，以释放空间。常见的淘汰策略包括：\nnoeviction：不进行淘汰，返回错误。 allkeys-lru：从所有键中淘汰最近最少使用的键。 volatile-lru：从设置了过期时间的键中淘汰最近最少使用的键。 其他 Redis 缓存淘汰策略是指当内存使用达到一定阈值时，Redis 会按照特定的策略自动移除一些键值对，以释放空间供新的写入操作使用。以下是 Redis 支持的几种缓存淘汰策略：\n策略 描述 noeviction 不进行任何淘汰，尝试写入导致超出内存限制时返回错误信息 allkeys-lru 根据最近最少使用算法（Least Recently Used），淘汰长时间未被查询或修改的键 volatile-lru 只根据 LRU 算法淘汰设置了过期时间的键 allkeys-random 随机移除键 volatile-random 随机移除已经设置了过期时间的键 volatile-ttl 移除即将过期的键 volatile-lfu (\u0026gt;=4.0) 根据最不经常使用算法（Least Frequently Used），淘汰数据访问频率低的键 allkeys-lfu (\u0026gt;=4.0) 同上，但是针对所有键，不仅仅是那些设置了过期时间的键 在这些策略中，LFU 和 LRU 是基于数据的访问模式来决定哪个键最有可能被淘汰：\nLRU（Least Recently Used）：这种策略假设如果数据最近很少用到，那么在将来也不太可能被用到。因此，当需要淘汰数据来腾出空间时，它会选取最长时间未被访问的数据。\nLFU（Least Frequently Used）：这个策略则是基于数据被访问的频率，删除那些访问次数最少的数据。相比于 LRU，LFU 在处理“热点数据”上表现更加出色。\n上述淘汰策略可以通过在 redis.conf 文件中设置 maxmemory-policy 来选择，例如：\nmaxmemory-policy allkeys-lru Redis 常用的显式删除操作，如：\nDEL 命令直接删除一个或多个键。 EXPIRE 命令设置键的过期时间，到期后键自动被删除。 SET 命令在设置新值的同时可以设置过期时间。 阻塞点与异步机制 # Redis 是一个基于事件驱动的服务器，它使用非阻塞 I/O 和事件通知机制来处理并发连接。这意味着 Redis 在执行某些操作时不会被阻塞等待 I/O 操作的完成，从而可以在等待磁盘或网络 I/O 时继续处理其他任务。\n阻塞点：\n尽管 Redis 大部分操作是非阻塞的，但仍有一些情况会引起阻塞：\n命令 BLPOP、BRPOP、BRPOPLPUSH 用于列表操作时，如果列表为空，会导致客户端阻塞直到有新元素插入。 发布订阅 (PUBLISH/SUBSCRIBE 命令) 中，客户端可能会等待新消息的到来。 对于慢查询和大数据量操作（如 KEYS * 或 SMEMBERS），可能会造成临时阻塞。 异步机制：\n为了减少阻塞时间，Redis 提供了异步处理能力：\n使用 AOF（Append Only File）日志时，Redis 支持后台异步进行磁盘写入。 主从同步和 RDB 快照生成也可以异步执行，以避免阻塞主线程。 客户端可以通过管道（pipelining）技术同时发送多个命令，然后一次性读取所有响应，这样可以减少网络延迟带来的影响。 原子操作、管道、事务 # 原子操作：\n在 Redis 中，单个命令总是原子性执行的。这意味着当一个命令在执行过程中，不会被其他命令打断。例如，INCR 命令增加一个整数值，并返回新值，这个过程是原子的。\n管道（Pipelining）：\n管道是一种技术，可以将多个命令打包后一次性发送给服务器，而无需等待每个命令的响应。这可以显著提高性能，特别是在高延迟网络环境中。管道减少了网络往返次数，使得批量操作更加高效。\n事务：\nRedis 的事务功能通过 MULTI、EXEC、DISCARD 和 WATCH 命令实现。一个事务由一系列命令组成，这些命令会被序列化并按顺序执行。以下是事务的关键点：\nMULTI 开始一个事务。 连续输入多个命令，这些命令不会立即执行，而是被放入队列中。 EXEC 执行所有队列中的命令。 如果在执行 EXEC 之前调用 DISCARD，则可以取消事务。 WATCH 可以监视一个或���个键，如果在事务开始之后任何监视的键被修改，则事务将被中断。 内存碎片 # 内存碎片是指由于多次申请和释放内存导致可用内存碎片化，从而降低内存使用效率。在 Redis 中，内存碎片化可以因以下原因产生：\n频繁地创建和删除大量的小对象。 分配给字符串或者列表等数据类型的内存大小动态变化。 内存碎片问题可能导致 Redis 占用更多的物理内存，超出实际数据需要的大小。可以通过 info memory 命令检查内存相关的统计信息，其中包括内存碎片率（memory fragmentation ratio），当这个比率超过 1.5 时，就说明存在一定的内存碎片问题。\n为了解决内存碎片问题，可以采取以下措施：\n定期重启 Redis 服务。 使用 jemalloc 等先进的内存分配器。 适当调整 Redis 中关于对象重用的策略。例如，可以通过调整 maxmemory 策略来控制内存使用，或者使用 lazyfree-lazy-eviction 等参数以更优化的方式释放内存。 优化数据结构和访问模式。比如，尽量避免存储过多的小对象；使用哈希表（hashes）来存储对象集合而非单独的字符串键；对大型列表进行分页处理等。 监控并剔除长时间未使用的键，这可以通过设置键的过期时间（TTL）来实现。 另外，Redis 4.0 及以上版本引入了 active defragmentation 功能，它允许 Redis 在运行时动态地减少内存碎片，而无需重启服务。这个特性可以在 redis.conf 配置文件中开启，并允许你配置不同的参数来控制碎片整理的行为。\n"},{"id":50,"href":"/docs/programmer/cloudnative/redis/advanced-knowledge-of-redis/","title":"Redis进阶","section":"中间件","content":" 主从架构-主从同步 # 在Redis中，主从同步是一种常用的数据复制方式，它允许一个或多个从服务器（slave）获得与主服务器（master）相同的数据副本。这种架构提供了数据的冗余和读取扩展性。\n全量复制：当一个从服务器第一次连接到主服务器时，或是由于某些原因需要重新同步时，会进行全量复制。在这个过程中，主服务器会生成一个当前所有数据的快照，并将这个快照发送至请求同步的从服务器。从服务器接收到数据后，加载到自己的数据空间内。\n部分复制：一旦完成了全量复制，如果从服务器断开连接又重新连接，且中断时间不长，主服务器可以只发送这段时间内发生变化的数据给从服务器，而不是再次进行全量复制。这依赖于主服务器的复制积压缓冲区来存储最近的写命令。\n同步策略：为了保证数据的一致性，从服务器在初始同步完成之前不会对外提供服务。在日常运行时，主服务器会将写命令同时发送给所有的从服务器，以此来保证数据的实时一致性。\n主从同步使得从服务器可以承担读操作，减轻主服务器的负载，同时也可以在主服务器遇到故障时，进行故障转移。\n主从哨兵架构 # Redis哨兵（Sentinel）系统是用于管理多个Redis服务器的系统。该体系结构具有以下特点：\n监控：哨兵会监控主从服务器是否正常运作。 自动故障转移：如果主服务器出现故障，哨兵可以自动选举新的主服务器，并让原来的从服务器指向新的主服务器。 配置提供者：哨兵还会将当前的主服务器地址提供给客户端，确保客户端总是连接到正确的主服务器。 哨兵机制通过这些功能增加了Redis环境的高可用性和稳定性。\n切片集群-Redis Cluster # Redis Cluster是Redis的分布式解决方案。它支持数据的水平分片，以下是其关键特性：\n自动分片：��动将数据分布在不同的节点上，每个节点只保存整个数据集的一部分。 高可用性：采用主从复制模型，即使在多个节点失败的情况下也能保证服务的可用性。 无中心设计：没有中心节点，每个节点都保存着整个集群状态的一部分，节点之间通过Gossip协议交换信息。 Redis Cluster通过对键进行CRC16计算并对16384取余数来决定将键分配到哪个槽位，每个节点负责一部分槽位，从而实现负载均衡。\nRedis Cluster 通信开销 # 由于Redis Cluster节点间需要频繁地交换消息以维护集群状态，因此会产生额外的通信开销：\nGossip通信：节点间通过Gossip协议定期交换信息，包括数据迁移、故障检测等。 重定向操作：客户端可能会尝试向不包含数据所在槽的节点发起请求，这时节点会返回一个重定向信息 切片集群-Codis\nRedis 分布式锁是一种用于多个计算节点之间同步访问共享资源的机制。在分布式系统中，当多个进程需要同时访问某些数据或执行某些任务时，为了避免竞态条件（race conditions）和数据不一致，通常需要使用分布式锁来保证在同一时间只有一个进程能够执行特定的操作。\nRedis 分布式锁实现 # 一个常见的Redis分布式锁实现是使用 Redis 的 SETNX 命令（Set if not exists）。这个命令只在键不存在的情况下设置键的值，并且返回是否成功设置。由于 SETNX 是原子操作，因此可以用来实现锁的功能。\n另一个更加推荐的方式是使用 Redis 2.6.12 版本引入的 SET 命令结合选项 NX（表示只有键不存在时才进行设置）和 PX（给键设置过期时间，单位为毫秒），这可以保证即使在客户端崩溃的情况下，锁也会在一定时间后自动释放，防止死锁。\n使用 Redis 分布式锁的步骤： # 尝试获取锁\n使用 SET key value NX PX milliseconds 进行设置。 如果返回 OK，则获取锁成功。 如果返回 nil，则获取锁失败。 执行业务逻辑\n在持有锁的时间内执行必要的操作。 释放锁\n完成操作后，使用 DEL 命令删除键来释放锁。 [!note] 注意事项\n安全性：为了确保只有获得锁的客户端能够释放锁，应该将锁和一个随机生成的值关联起来，并在解锁时验证这个值。 死锁：锁应该有一个合理的过期时间，以避免客户端在持有锁时崩溃导致其他客户端永远无法获取锁。 重入性：在某些场景下，同一个客户端可能需要再次获取已经持有的锁，需要考虑锁的重入性设计。 1. Python 实现示例-自信版 # 以下是使用 Python 和 redis-py 库实现 Redis 分布式锁的简单示例：\nimport redis import uuid import time class RedisLock: def __init__(self, redis_client, lock_key): self.redis_client = redis_client self.lock_key = lock_key self.lock_value = None def acquire_lock(self, timeout_ms=5000): \u0026#34;\u0026#34;\u0026#34;尝试获取锁\u0026#34;\u0026#34;\u0026#34; self.lock_value = str(uuid.uuid4()) # 生成唯一标识符作为锁的值 return self.redis_client.set(self.lock_key, self.lock_value, nx=True, px=timeout_ms) def release_lock(self): \u0026#34;\u0026#34;\u0026#34;释放锁\u0026#34;\u0026#34;\u0026#34; # Lua 脚本，用于检查和删除键，保证操作的原子性 script = \u0026#34;\u0026#34;\u0026#34; if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end \u0026#34;\u0026#34;\u0026#34; result = self.redis_client.eval(script, 1, self.lock_key, self.lock_value) return result == 1 # 如果删除成功，则返回 True # 创建 Redis 客户端 client = redis.Redis(host=\u0026#39;localhost\u0026#39;, port=6379, db=0) # 使用 RedisLock lock = RedisLock(client, \u0026#34;my_distributed_lock\u0026#34;) if lock.acquire_lock(timeout_ms=10000): # 尝试获取锁，设置10秒过期 try: # 执行你的业务逻辑 print(\u0026#34;Lock acquired. Doing some work...\u0026#34;) time.sleep(2) 2. Python 实现示例-增加了一个防止死锁处理 # async def release_pop_lock(package_name: str, identifier: str): lock_key = f\u0026#34;lock_pop_{package_name}\u0026#34; # Lua 脚本：如果锁的值与标识符匹配，则删除锁 lua_script = \u0026#34;\u0026#34;\u0026#34; if redis.call(\u0026#34;get\u0026#34;, KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;, KEYS[1]) else return 0 end \u0026#34;\u0026#34;\u0026#34; # 执行 Lua 脚本 result = await rds.eval(lua_script, 1, lock_key, identifier) # 如果返回值为 1，说明锁被删除 if result == 1: return True return False async def acquire_pop_lock(package_name: str, acquire_time=2) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; 获取不到表示暂时不可用 \u0026#34;\u0026#34;\u0026#34; identifier = str(uuid.uuid4()) # 使用UUID生成唯一标识 lock_key = f\u0026#34;lock_pop_{package_name}\u0026#34; end = time.time() + acquire_time while time.time() \u0026lt; end: if await rds.setnx(lock_key, identifier): # 如果锁不存在，设置并返回True await rds.expire(lock_key, 10) return identifier # 成功获取锁，返回标识符 elif await rds.ttl(lock_key) \u0026lt; 0: await rds.expire(lock_key, 10) await asyncio.sleep(0.01) # 超时未能获取锁 return \u0026#39;\u0026#39; "},{"id":51,"href":"/docs/programmer/cloudnative/redis/%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"Redis常用命令","section":"中间件","content":" scan 替代 keys # SCAN 0 MATCH key* COUNT 100 查看类型type # type # 使用了 GET 命令，这个命令通常用于获取字符串类型的值。如果key_hi 这个键在 Redis 中存储的不是字符串类型的值，而是其他类型（如列表、集合、哈希等），那么执行 GET 命令就会返回错误:\n(error) WRONGTYPE Operation against a key holding the wrong kind of value\n要解决这个问题，首先需要确定 key_hi 键存储的值的类型。你可以使用 TYPE 命令来检查键的类型：\nTYPE mmp:cfgs:com.easypeso:retens 查看list # 查看 List 长度： LLEN mylist 0 -1 查看 List 数据内容： LRANGE mylist 0 -1 "},{"id":52,"href":"/posts/%E5%B0%8F%E5%91%BD%E4%BB%A4/","title":"小命令","section":"Blog","content":"前传: [[Make things easy and enjoyable]]\n1. 递归删除某些文件 # 如以.py.bak 为结尾的文件: find . -name \u0026quot;*.py.bak\u0026quot; -exec rm {} \\;\n2. 批量杀死进程 # pkill -f uwsgi ps -axu | grep 关键字 | awk \u0026#39;{print $2}\u0026#39; | xargs kill 批量删除pod - xargs 的使用 # kubectl get pod -n argo | grep workflow-template | awk \u0026#39;{print $1}\u0026#39; | xargs kubectl -n argo delete pod 3. MySQL NOW # 指定东八：update scanner_device set update_time = CONVERT_TZ(NOW(), @@session.time_zone, \u0026quot;+08:00\u0026quot;);\n4. celery worker状态 # celery -A ncelery status\n-\u0026gt; celery@scan-celery.rcmrestat.00: OK\n-\u0026gt; celery@scan-celery.vulcombine.00: OK\n-\u0026gt; celery@scan-celery.rcmstat.00: OK\n5. base64解码 # echo YWRtaW46bnNmMGN1cy5Aazhz | base64 -d 使用场景: 如在USER/.docker/config寻找到docker登陆凭证可以用此解码后login登录\n6. k8s 复制文件 # kubectl cp -n websafe -c master-fizz-daemon master-fizz-daemon-66c89f7c9c-nlgd4:rcm_vul_info.json rcm_vul_info.json\n7. 查看k8s DNS解析 # kubectl get configmap -n kube-system coredns -o yaml\n8. 关闭WSL2 # #停止LxssManager服务: net stop LxssManager #启动LxssManager服务: net start LxssManager 9. nginx 代理 mongodb # FROM nginx RUN echo \u0026#34;stream {\\n upstream stream_mongo {\\n server mongo:27017;\\n }\\n\\n server {\\n listen 9876;\\n proxy_pass stream_mongo;\\n }\\n}\u0026#34; \u0026gt;\u0026gt; /etc/nginx/nginx.conf docker build -t nginx-proxy:v0 . docker run -p 12345:9876 --network websafe-network --name nginx-proxy nginx-proxy:v0 # 连接 12345 即可 10. MySQL删除锁修改表 # SHOW PROCESSLIST; KILL 6261330; -- 根据表所在的库名找见ID，然后删除锁 LOCK TABLES task WRITE; ALTER TABLE task ADD COLUMN module_id INT not null DEFAULT 1005 COMMENT \u0026#39;这里是SQL字段注释\u0026#39;; UNLOCK TABLES; 11. rz sz 上传下载服务器小文件 # 安装命令: apt install lrzsz 下载 sz xxx 上传 rz 12. 并行下发命令 # time parallel -N0 -j10 \u0026#34;argo submit success.yaml -n argo\u0026#34; ::: {1..100} 使用 -N 限制每行参数的个数，其中-N0表示一次只读取一个参数，且不输入这个参数（作为计数器来使用）。\nparallel -N4 echo 1={1} 2={2} 3={3} ::: A B C D E F G H 1=A 2=B 3=C // D传入了，但没接收所以下一行丢失 1=E 2=F 3=G parallel -N0 echo foo ::: 1 2 3 foo foo foo 如果要打印计数，可以使用time parallel -N1 -j10 \u0026quot;echo '[$(date)] 第 {}：次提交中...' \u0026amp; ls\u0026quot; ::: {1..10}或者不指定N1默认就是N1\n13. ffmpeg 提取视频中音频 # ffmpeg -i englishdemo.mp4 -vn -c:a copy english.aac 提取并转换为mp3格式 # ffmpeg -i englishdemo.mp4 -vn -b:a 128k -c:a mp3 english.mp3 14. Windows 休眠 # cmd 管理员模式运行\npowercfg.exe -h off powercfg.exe -h on 15. Windows刷新DNS缓存 - 修改hosts之后不生效使用 # ipconfig /flushdns 16. 解压当前目录所有压缩文件 # for f in *.zip; do unzip \u0026#34;$f\u0026#34;; done 17. 通过IP获取主机名 # 不过看情况，如果没有启动NetBIOS就查不到\n# 基於TCP/IP上的NetBIOS客戶用於查詢NetBIOS名字的程序 nmblookup -A {IP} 18. awk算数 # grep 400586 sched.log.2024-05-28 | grep 条 | awk \u0026#39;{print $8}\u0026#39; | awk -F\u0026#39;条,\u0026#39; \u0026#39;{sum += $1} END {print sum}\u0026#39; awk -F'条,' '{sum += $1} END {print sum}' 用条进行分割取$1第一个进行sum求和计算 awk '{print $8}' 这里注意使用单引号 250\n原日志数据为:\n2024-05-28 18:15:51 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 1条, 0 is: 400586 + 2024-05-28 05:24:52 + MY 2024-05-28 18:49:20 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 3条, 0 is: 400586 + 2024-05-28 03:02:38 + MY 2024-05-28 18:59:50 sched WARNING [1178]: await self.redis.enqueue_update_db(*update_tasks) 4条, 0 is: 400586 + 2024-05-28 04:12:04 + MY 19. 使用git commit信息来命名 # # 时间 echo \u0026#34;{name}-$(git log -1 --format=%cd --date=format:\u0026#39;%Y%m%d-%H%M%S\u0026#39;).tar.gz\u0026#34; # commit_id+时间 echo \u0026#34;name-$(git log -1 --format=%h)-$(date +\u0026#39;%Y%m%d-%H%M%S\u0026#39;).tar.gz\u0026#34; 20. 查看设备温度 # sudo apt install lm-sensors sensors 21. 压缩视频 # ffmpeg -i 原视频.mp4 -c:v libx264 -b:v 2000k -c:a aac -b:a 128k -pix_fmt yuv420p -movflags faststart 输出视频.mp4 22. 连接命令 # sl \u0026amp;\u0026amp; ls sl; ls 1中sl失败后不会执行后续的ls, 2中sl失败后也会执行ls\n23. 查看文件占用 # fuser -v {file path}\n24. 查看文件大小及排序 # du -sh ~/go/pkg/mod/github.com/* | sort -rh | head 25. 查看当前目录下隐藏目录磁盘占用大小 # find . -maxdepth 1 -type d -name \u0026#39;.[^.]*\u0026#39; -exec sudo du -sh {} \\; 26. 查看占用cpu \u0026amp; 内存最高的进程 # ps -aux | sort -k3nr | head 1 # 查看cpu ps -aux --sort=-%cpu | head -n 2 ps -aux --sort=-%mem | head -n 2 "},{"id":53,"href":"/docs/programmer/cloudnative/k8s/elk%E5%9C%A8k8s%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/","title":"elk在k8s上的部署使用示例","section":"k8s","content":" 示例Yaml # --- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-config namespace: ops labels: k8s-app: filebeat data: filebeat.yml: |- filebeat.config: inputs: # Mounted `filebeat-inputs` configmap: path: ${path.config}/inputs.d/*.yml # Reload inputs configs as they change: reload.enabled: false modules: path: ${path.config}/modules.d/*.yml # Reload module configs as they change: reload.enabled: false output.elasticsearch: hosts: [\u0026#39;49.65.125.91:9200\u0026#39;] --- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-inputs namespace: ops labels: k8s-app: filebeat data: kubernetes.yml: |- - type: docker containers.ids: - \u0026#34;*\u0026#34; processors: - add_kubernetes_metadata: in_cluster: true --- apiVersion: apps/v1 kind: DaemonSet metadata: name: filebeat namespace: ops labels: k8s-app: filebeat spec: selector: matchLabels: k8s-app: filebeat template: metadata: labels: k8s-app: filebeat spec: serviceAccountName: filebeat terminationGracePeriodSeconds: 30 containers: - name: filebeat image: elastic/filebeat:7.9.2 args: [ \u0026#34;-c\u0026#34;, \u0026#34;/etc/filebeat.yml\u0026#34;, \u0026#34;-e\u0026#34;, ] securityContext: runAsUser: 0 # If using Red Hat OpenShift uncomment this: #privileged: true resources: limits: memory: 200Mi requests: cpu: 100m memory: 100Mi volumeMounts: - name: config mountPath: /etc/filebeat.yml readOnly: true subPath: filebeat.yml - name: inputs mountPath: /usr/share/filebeat/inputs.d readOnly: true - name: data mountPath: /usr/share/filebeat/data - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true volumes: - name: config configMap: defaultMode: 0600 name: filebeat-config - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: inputs configMap: defaultMode: 0600 name: filebeat-inputs # data folder stores a registry of read status for all files, so we don\u0026#39;t send everything again on a Filebeat pod restart - name: data hostPath: path: /var/lib/filebeat-data type: DirectoryOrCreate --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: filebeat subjects: - kind: ServiceAccount name: filebeat namespace: ops roleRef: kind: ClusterRole name: filebeat apiGroup: rbac.authorization.k8s.io --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: filebeat labels: k8s-app: filebeat rules: - apiGroups: [\u0026#34;\u0026#34;] # \u0026#34;\u0026#34; indicates the core API group resources: - namespaces - pods verbs: - get - watch - list --- apiVersion: v1 kind: ServiceAccount metadata: name: filebeat namespace: ops labels: k8s-app: filebeat 将以上内容存储到 elk.yaml\nkubectl create namespace ops kubectl apply -f elk.yaml kubectl get pods -n ops "},{"id":54,"href":"/docs/programmer/cloudnative/nginx%E5%AE%9E%E7%94%A8%E9%85%8D%E7%BD%AE/","title":"Nginx实用配置","section":"云原生","content":"from: 这里\nlocation / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } location /test_vul_id_1000003 { alias /home/test_vul_id_1000003; autoindex on; } location /test_vul_id_1000003 { root /home; autoindex on; } 非以上配置访问404原因 # location /test_vul_id_1000003 { root /home/test_vul_id_1000003; autoindex on; } 如以上配置, nginx 配置文件会将 root 加上 以上的 localtion , 导致访问时实际定位是 /home/test_vul_id_1000003/test_vul_id_1000003 所以就 404 了\n生效命令 # nginx -t nginx -s reload service nginx restart "},{"id":55,"href":"/docs/programmer/net/nginx%E5%AE%9E%E7%94%A8%E9%85%8D%E7%BD%AE/","title":"Nginx实用配置","section":"Net","content":"from: 这里\nlocation / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } location /test_vul_id_1000003 { alias /home/test_vul_id_1000003; autoindex on; } location /test_vul_id_1000003 { root /home; autoindex on; } 非以上配置访问404原因 # location /test_vul_id_1000003 { root /home/test_vul_id_1000003; autoindex on; } 如以上配置, nginx 配置文件会将 root 加上 以上的 localtion , 导致访问时实际定位是 /home/test_vul_id_1000003/test_vul_id_1000003 所以就 404 了\n生效命令 # nginx -t nginx -s reload service nginx restart "},{"id":56,"href":"/docs/programmer/cloudnative/k8s/k8s-%E9%85%8D%E5%A5%97%E8%AF%B4%E6%98%8E/","title":"k8s 配套说明","section":"k8s","content":" ctr # 如果定义了 -n 应该是namesplace 那么每个命令都得跟上\nload镜像 # sudo ctr -n=k8s.io images import ${imageTarFile}\n保存文件 # sudo ctr -n k8s.io images export \u0026ndash;platform=linux/amd64 hi.tar 101.32.1.4:30002/web-docker/worker:2121\n切换tag # sudo ctr -n k8s.io images tag \u0026ndash;force repos.x.com/web-docker/worker:2121 101.32.1.4:30002/web-docker/worker:2121\n推送镜像 # sudo ctr -n k8s.io images push -k -u admin:fat213asfdFS2W \u0026ndash;plain-http 101.32.1.4:30002/web-docker/worker:2121\n拉取 # sudo ctr -n k8s.io images pull -k -u admin:fat1239ASD124W \u0026ndash;plain-http 101.32.1.4:30002/web-docker/worker:2121\nDocker # [[Note of Docker]] 好像并没有整理docker命令\u0026hellip; 后续补吧\n加载镜像 # docker load -i .\\hi.tar\n保存为本地文件 # docker save repos.x.com/web-docker/worker:2121 -o hi.tar\n使用 REST API # # 指向内部 API 服务器的主机名 APISERVER=https://kubernetes.default.svc # 服务账号令牌的路径 SERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount # 读取 Pod 的名字空间 NAMESPACE=$(cat ${SERVICEACCOUNT}/namespace) # 读取服务账号的持有者令牌 TOKEN=$(cat ${SERVICEACCOUNT}/token) # 引用内部证书机构（CA） CACERT=${SERVICEACCOUNT}/ca.crt # 使用令牌访问 API curl --cacert ${CACERT} --header \u0026#34;Authorization: Bearer ${TOKEN}\u0026#34; -X GET ${APISERVER}/api "},{"id":57,"href":"/docs/programmer/cloudnative/k8s/k8s-%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","title":"k8s技术分享","section":"k8s","content":" k8s技术分享 # 工作负载资源 # 一、pod # 1. 概要 # 可创建管理、最小的可部署计算单元，是可以在主机上运行的容器的集合 我们的服务都在其中运行。如我们的服务是nginx，则最内层是我们的服务 nginx，运行在 container 容器当中。container (容器) 的本质是进程，而 pod 是管理这一组进程的资源 所以pod可视为一个极为轻量化、没插网线的电脑，如果所需任务无需交互，那么用pod就很合适。例如给它挂载一个文件来训练模型、生成报表，可以根据场景使用 Job 或者 CronJob 或者其它 图示关系如下 # ![[k8s-pod-insert.png]]\n2. pod网络 # 当然，pod 可以管理多个 container，又因为container (容器) 的本质是进程，如果有本地网络通信需求(使用 localhost 或者 Socket 文件进行本地通信)，在这些场景中使用 pod 管理多个 container 就非常的推荐。\n如下图展示了Pod网络所依赖的3个网络设备\n1. eth0是节点主机上的网卡，支持该节点流量出入的设备、也是支持集群节点间IP寻址和互通的设备；\n2. docker0是一个虚拟网桥，可以简单理解为一个虚拟交换机，支持该节点上的Pod之间进行IP寻址和互通的设备；\n3. veth0则是Pod1的虚拟网卡，支持该Pod内容器互通和对外访问的虚拟设备；\n4. docker0网桥和veth0网卡，都是linux支持和创建的虚拟网络设备；\n5. pause属于特殊容器，其运行的唯一目的是为Pod建立共享的veth0网络接口\n![[k8s-nginx-pod.png]]\n二、deployment、StatefulSet # 1. 概要 # Deployment 使得 Pod 和 ReplicaSet 能够进行声明式更新\nStatefulSet 表示一组具有一致身份的 Pod：\n1. 身份定义为：\n- 网络：一个稳定的 DNS 和主机名。\n- 存储：根据要求提供尽可能多的 VolumeClaim。\nStatefulSet 保证给定的网络身份将始终映射到相同的存储身份。\n虽然pod完全具备在生产环境中部署独立的单体服务的能力，但在生产环境中，我们基本上不会直接管理 pod，我们会使用deployment 代为控管。延续上面的比喻就是将 deployment 视为一个好用的机房管理员：帮助我们进货，对pod进行开关机，对pod做系统升级和重装系统以实现功能升级和回滚。 StatefulSet 也相同，只不过每次它会保证一致性，而不像deployment 每次重启都是随机分配\n2. 滚动升级 # 至于为什么需要 deployment 协助我们管理，可以参考下图了解一下滚动升级的流程，并想象一下自己手动操作pod的复杂度（使用 kubectl get pods --watch 可在终端中查看pod变化）： ![[k8s-pod-rollupdate.png]]\n3. 分界线 # 了解完以上信息就已经足够覆盖大多数开发需求，就如去网吧玩游戏、来公司上班，我们都不会去关注网络，而只关心游戏是否流畅输赢，工作进度是否顺畅。因为各个服务间的网络依赖就应该长久保持稳定，不宜做高频调整。除非出现问题，或者恰好我们需要重头搭建这部分，那么我们首先需要考虑的就是网络关系。\nService资源 # Service、Ingress # 1. 概要 # Service 是软件服务（例如 mysql）的命名抽象，包含代理要侦听的本地端口（例如 3306）和一个选择算符，选择算符用来确定哪些 Pod 将响应通过代理发送的请求。 Ingress 是允许入站连接到达后端定义的端点的规则集合。Ingress 是允许入站连接到达后端定义的端点的规则集合。 Service 就相当于给上述pod组成的服务插上了一条稳定的网线（当然不仅如此），使之可以通过网络通信，而 Ingress 则负责对外，相当于之前的web部署方案中 nginx 扮演的角色，将外部调用通过规则，将请求转发到相应的 Service 上。\n2. Service网络原理 # 首先我们熟悉DNS，再者我们知道通过 deployment 管理的pod每次重启都是重新生成、重新分配网络的，最后我们知道k8s是有一个\n配置和存储资源 # ConfigMap、Secret、Volume\n身份认证资源 # ServiceAccount\n鉴权资源 # ClusterRole、ClusterRoleBinding\n其他 # LimitRange、NetworkPolicy\nNode、Namespace\n网络 # 深入理解k8s 网络：https://www.jianshu.com/p/80eb2e9e32db\n示意图 # 来源https://github.com/guangzhengli/k8s-tutorials\nkubectl get pods # NAME READY STATUS RESTARTS AGE # hellok8s-deployment-5d5545b69c-24lw5 1/1 Running 0 27m # hellok8s-deployment-5d5545b69c-9g94t 1/1 Running 0 27m # hellok8s-deployment-5d5545b69c-9gm8r 1/1 Running 0 27m # nginx 1/1 Running 0 41m kubectl get service # NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE # service-hellok8s-clusterip ClusterIP 10.104.96.153 \u0026lt;none\u0026gt; 3000/TCP 10s kubectl exec -it nginx-pod /bin/bash # root@nginx-pod:/# curl 10.104.96.153:3000 # [v3] Hello, Kubernetes!, From host: hellok8s-deployment-5d5545b69c-9gm8r # root@nginx-pod:/# curl 10.104.96.153:3000 #[v3] Hello, Kubernetes!, From host: hellok8s-deployment-5d5545b69c-9g94t 可以看到，我们多次 curl 10.104.96.153:3000 访问 hellok8s Service IP 地址，返回的 hellok8s:v3 hostname 不一样，说明 Service 可以接收请求并将它们传递给它后面的所有 pod，还可以自动负载均衡。你也可以试试增加或者减少 hellok8s:v3 pod 副本数量，观察 Service 的请求是否会动态变更。调用过程如下图所示：\nNodePort (负载均衡(略)) # 我们知道kubernetes 集群并不是单机运行，它管理着多台节点即 Node，可以通过每个节点上的 IP 和静态端口（NodePort）暴露服务。如下图所示，如果集群内有两台 Node 运行着 hellok8s:v3，我们创建一个 NodePort 类型的 Service，将 hellok8s:v3 的 3000 端口映射到 Node 机器的 30000 端口 (在 30000-32767 范围内)，就可以通过访问 http://node1-ip:30000 或者 http://node2-ip:30000 访问到服务。 ![[k8s-svc-nodeport.png]]\nIngress ![[k8s-ingress.png]]\n"},{"id":58,"href":"/docs/programmer/cloudnative/uwsgi-%E5%A4%84%E7%90%86%E8%AE%B0%E5%BD%95/","title":"uwsgi 处理记录","section":"云原生","content":" 日志输出到终端 # uwsgi.ini文件中配置\nlog-master = true ; logto=/var/log/uwsgi.log 同时这行不能有 启动命令: uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini --log-master\n隔一段时间卡死,重启不能 # 当作为纯后端API使用时, 使用 http-socket 不使用 http\n使用supervisor管理uwsgi # #daemonize=/var/log/uwsgi8011.log # 守护进程一定要注释掉(关键)\n查看性能数据 # 安装 uwsgitop 查看 uwsgi stats写入位置 查看 pip install uwsgitop cat /opt/trunk/textcheck/3rd/uwsgi/config.ini | grep stats # \u0026gt; stats=/var/run/uwsgi/uwsgi.status uwsgitop /var/run/uwsgi/uwsgi.status # \u0026gt; uwsgi-2.0.19.1 - Wed Oct 18 18:13:48 2023 - req: 113 - RPS: 0 - lq: 0 - tx: 75.1K node: app-58d8477f4-26fzb - cwd: /app - uid: 0 - gid: 0 - masterpid: 8 WID % PID REQ RPS EXC SIG STATUS AVG RSS VSZ TX ReSpwn HC RunT LastSpwn 1 28.3 132942 32 0 0 0 idle 19161ms 0 0 15.2K 1 0 155394.03 17:34:42 2 28.3 132950 32 0 0 0 idle 1781ms 0 0 20.1K 1 0 126123.093 17:34:42 3 22.1 132958 25 0 0 0 idle 5982ms 0 0 16.9K 1 0 127199.778 17:34:42 4 21.2 132963 24 0 0 0 idle 15274ms 0 0 22.8K 1 0 144018.093 17:34:42\n"},{"id":59,"href":"/docs/programmer/cloudnative/k8s/k8s%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/","title":"k8s学习-常用命令和配置文件","section":"k8s","content":"\nk8s学习 # 常用命令 # kubectl apply -f rcm_log_monut_k8s_pod.yaml kubectl get pod -A kubectl get pod -all-namespaces kubectl get node kubectl get deploy 持久卷 - PersistentVolume kubectl get persistentvolume kubectl describe persistentvolume example-pv kubectl **delete** persistentvolume example-pv 从kubectl cp -n \u0026lt;命名空间\u0026gt; -c :xxx.json xxx.json configmap / secret 存储文件内容 # sftpkey 为名称\n新建 # kubectl create secret generic sftpkey --from-file=/etc/id_rsa # kubectl create -n {NAMESPACE} secret generic sftpkey --from-file=/etc/id_rsa 删除 # kubectl delete secret sftpkey\n常用字段 # 下面是一些 Kubernetes 中常用的配置字段：\napiVersion： Kubernetes API 的版本，用于定义资源的 API 版本号。 kind： 资源的类型，比如 Pod、Deployment、Service 等。 metadata： 元数据字段，用于存储 Kubernetes 对象的名称、命名空间、标签等信息。 spec： 对象的规格，用于定义对象的期望状态，如 Pod 的容器、Service 的端口等。 status： 对象的状态，用于记录对象的实际状态，如 Pod 的运行状态、Service 的访问地址等。 另外还有一些常用的子字段，如：\ncontainers： Pod 中的容器定义，包括容器名称、镜像、命令、参数等。 ports： Service 中的端口定义，包括端口名称、协议、端口号、目标端口号等。 selector： Service 中用于选择后端 Pod 的标签选择器。 replicas： Deployment 中期望的副本数。 template： Deployment 中用于创建 Pod 的 PodTemplateSpec 定义。 其他 # 在 Kubernetes 中，annotations 字段是资源对象中的一个元数据字段，用于存储一些非标准化的元数据信息。与 metadata 字段中的标准化信息不同，annotations 字段中存储的信息往往是自定义的、不易归类的数据，比如代码库的提交 ID、配置文件的 MD5 校验值、外部系统的关联信息等等。\nannotations # 字段的格式为一个 key-value 对的列表，其中 key 表示注解的名称，value 表示注解的值。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod annotations: commit-id: abc123 spec: containers: - name: my-container image: my-image 在这个示例中，我们在 Pod 的 metadata 中添加了一个自定义注解 commit-id，并将其值设置为 abc123。这个注解表示当前 Pod 对应的代码库的提交 ID。\n需要注意的是，由于 annotations 字段是用于存储自定义元数据信息的，因此在使用时需要注意避免与其他标准化的字段发生冲突，以免产生意外的后果。同时，由于注解的值可以是任意字符串，因此需要对注解的内容进行适当的验证和转义，以避免安全风险\nownerReferences 字段 # 在 Kubernetes 中，ownerReferences 字段是资源对象中的一个元数据字段，用于指定当前对象的所有者（owner）。这个字段可以用来建立资源对象之间的父子关系，便于管理和垃圾回收。在一个资源对象中，可以同时指定多个父对象（owner）。\nownerReferences 字段的格式为一个包含多个 ownerReference 对象的列表。每个 ownerReference 对象表示一个父对象的引用，其中包含了父对象的 API 版本、资源类型、名称和 UID。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod ownerReferences: - apiVersion: apps/v1 kind: Deployment name: my-deployment uid: abc123 - apiVersion: apps/v1 kind: ReplicaSet name: my-replicaset uid: def456 spec: containers: - name: my-container image: my-image 这段 YAML 文件描述了一个名为 my-pod 的 Pod 对象，它有两个父对象，分别是一个 Deployment 和一个 ReplicaSet。其中，Deployment 的名称为 my-deployment，UID 为 abc123，ReplicaSet 的名称为 my-replicaset，UID 为 def456。 该 Pod 中只包含一个容器，名称为 my-container，使用镜像为 my-image。 需要注意的是，这个 Pod 对象的 ownerReferences 字段表示它是 Deployment 和 ReplicaSet 的子对象，当这两个父对象被删除时，该 Pod 对象也会被自动删除。另外，这个 Pod 对象和其父对象都属于同一个命名空间，因为没有在 metadata 中指定 namespace 字段 在这个示例中，我们在 Pod 的 metadata 中添加了两个父对象，分别是一个 Deployment 和一个 ReplicaSet。这些信息可以帮助 Kubernetes 更好地管理这些对象之间的依赖关系，便于进行垃圾回收和版本控制。\n需要注意的是，ownerReferences 字段中的对象必须是同一个命名空间中的资源对象，否则会引发错误。另外，在使用 ownerReferences 字段时需要注意避免循环引用的问题，以免产生意外的后果。\nownerReferences 中的name和该pod name相同有什么作用？ # 在 Kubernetes 中，如果一个资源对象的 ownerReferences 中的 name 字段与当前对象的 metadata 中的 name 字段相同，表示当前对象是父对象（owner）自己创建的。这种情况下，父对象的控制器不会对这个对象进行垃圾回收，因为这个对象本身就是父对象的一部分。\n例如，在一个 Deployment 中创建了一个 Pod，并且将 Pod 的 ownerReferences 中的 name 字段设置为 Pod 的名称。这样一来，当 Deployment 被删除时，由于 Pod 依赖于 Deployment，Kubernetes 会先删除 Deployment，然后再删除 Pod。在删除 Pod 时，由于 Pod 的 ownerReferences 中的 name 字段与 Pod 的 metadata 中的 name 字段相同，所以控制器不会对 Pod 进行垃圾回收，而是保留下来作为 Deployment 的一部分。\n通过这种方式，我们可以在 Kubernetes 中建立资源对象之间更加复杂的关系，实现更高级别的控制和管理。例如，可以通过设置 ownerReferences 字段来建立 Deployment 和 Service 的关系，从而实现负载均衡和服务发现。\nenv 环境变量 # spec: containers: - env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_OWN_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: POD_OWN_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace 这段 YAML 文件描述了一个 Pod 中的三个环境变量。这些环境变量的值是从 Kubernetes 中获取的，而不是直接在 Pod 中指定的。\n其中，POD_IP_ADDRESS 环境变量的值使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的状态中获取 podIP 字段的值。POD_IP_ADDRESS 环境变量的值就是当前 Pod 的 IP 地址。\nPOD_OWN_NAME 和 POD_OWN_NAMESPACE 环境变量的值也使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的元数据中获取 name 和 namespace 字段的值。POD_OWN_NAME 环境变量的值就是当前 Pod 的名称，POD_OWN_NAMESPACE 环境变量的值就是当前 Pod 所属的命名空间。\n这种方式可以让我们在定义 Pod 时，动态地获取 Pod 自身的元数据和状态信息，并将这些信息作为环境变量传递给 Pod 中的容器。在容器中，我们可以通过读取这些环境变量的值，来获取当前 Pod 的一些重要信息\ninitContainers # dnsPolicy: ClusterFirst enableServiceLinks: true initContainers: - command: - sh - -c - until nc -zvw3 hello-redis-svc.hello-prod.svc.cluster.local 6379; do echo Waiting hello-redis; sleep 5; done; image: xxxx.docker.io/hello-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-redis resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true - command: - sh - -c - until nc -zvw3 hello-mongodb-svc.hello.svc.cluster.local 27017; do echo Waiting hello-mongodb; sleep 5; done; image: xxxx.docker.io/hello-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-mongodb resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true 这段 YAML 配置是关于 Kubernetes 中的初始化容器（initContainers）的。 初始化容器是在 Pod 中所有容器启动之前运行的容器，用于预处理或准备容器的某些方面。 在这个 YAML 配置中，定义了两个初始化容器 init-redis 和 init-mongodb，分别检查 hello-redis 和 hello-mongodb 是否准备就绪。具体地，这两个初始化容器在容器内运行了一个 until 循环，每 5 秒尝试连接 hello-redis 或 hello-mongodb 服务，并打印 Waiting hello-redis 或 Waiting hello-mongodb 的日志信息。如果连接成功，则退出循环，容器初始化成功。初始化容器的镜像是 xxxx.docker.io/hello-docker/busybox:1.28.1，使用 IfNotPresent 策略拉取镜像。其中 resources 字段定义了该容器的资源限制和请求，volumeMounts 字段定义了将哪些存储卷挂载到该容器的哪些路径。 一些杂项 # nodeName: Pod所要调度的节点名称。 nodeSelector: 用于指定Pod所需的标签，使Pod只能被具有特定标签的节点调度。 preemptionPolicy: Pod优先级抢占策略。如果当前节点资源不足，可以抢占优先级低的Pod来为优先级高的Pod腾出资源。PreemptLowerPriority表示低优先级的Pod可以被抢占。 priority: Pod的优先级，数值越高表示优先级越高。 restartPolicy: Pod的重启策略，可以是Always、OnFailure或Never。Always表示Pod一旦终止就会自动重启，OnFailure表示只有在非0退出码时才会重启，Never表示不会自动重启。 schedulerName: 指定Pod使用的调度器。 securityContext: Pod的安全上下文。 serviceAccount: 默认使用的服务账户。 serviceAccountName: 指定使用的服务账户名称。 terminationGracePeriodSeconds: Pod终止的优雅期，即Pod终止时等待多长时间后强制终止。默认为30秒 其余一些状态信息 status : podIPs phase: Running phase initContainerStatuses containerStatuses containerStatuses conditions 持久卷 - PersistentVolume # 需要注意的是，PersistentVolume 是一个集群级别的资源，不属于任何一个命名空间，但可以通过在 metadata 字段中指定 namespace 字段来将其关联到某个命名空间中。这个关联只是用来方便查找和管理资源，不会对 PersistentVolume 对象本身产生影响。\n知识问答 # 1. nodeSelector 和 nodeSelectorTerms 有什么区别？ # ChatGPT:\n在 Kubernetes 中，nodeSelector 和 nodeSelectorTerms 都是用来选择哪些节点可以运行 Pod 的。 nodeSelector 是 PodSpec 中的一个字段，它用于指定一个键值对，只有运行在具有指定标签的节点上的 Pod 才会被调度到该节点上。例如： apiVersion: v1 kind: Pod metadata: name: my-pod spec: nodeSelector: kubernetes.io/hostname: node-1 containers: - name: my-container image: my-image 在上面的示例中，nodeSelector 字段指定了 Pod 只能调度到具有标签 kubernetes.io/hostname=node-1 的节点上。 而 nodeSelectorTerms 是一个更高级别的机制，它允许在一个 Pod 中指定多个选择条件。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod spec: nodeSelector: matchExpressions: - {key: zone, operator: In, values: [east, west]} - {key: region, operator: NotIn, values: [us-east-1]} matchLabels: environment: production containers: - name: my-container image: my-image 在上面的示例中，nodeSelector 字段指定了多个选择条件。其中 matchExpressions 指定了两个表达式，一个是 zone 标签的值必须是 east 或 west，另一个是 region 标签的值不能是 us-east-1。而 matchLabels 指定了 environment 标签的值必须是 production。\n因此，nodeSelector 只能指定一个选择条件，而 nodeSelectorTerms 可以指定多个选择条件。\\\n常用命令 # kubectl apply -f rcm_log_monut_k8s_pod.yaml 持久卷 - PersistentVolume kubectl get persistentvolume kubectl describe persistentvolume example-pv kubectl **delete** persistentvolume example-pv 常用字段 # 下面是一些 Kubernetes 中常用的配置字段：\napiVersion： Kubernetes API 的版本，用于定义资源的 API 版本号。 kind： 资源的类型，比如 Pod、Deployment、Service 等。 metadata： 元数据字段，用于存储 Kubernetes 对象的名称、命名空间、标签等信息。 spec： 对象的规格，用于定义对象的期望状态，如 Pod 的容器、Service 的端口等。 status： 对象的状态，用于记录对象的实际状态，如 Pod 的运行状态、Service 的访问地址等。 另外还有一些常用的子字段，如：\ncontainers： Pod 中的容器定义，包括容器名称、镜像、命令、参数等。 ports： Service 中的端口定义，包括端口名称、协议、端口号、目标端口号等。 selector： Service 中用于选择后端 Pod 的标签选择器。 replicas： Deployment 中期望的副本数。 template： Deployment 中用于创建 Pod 的 PodTemplateSpec 定义。 其他 # 在 Kubernetes 中，annotations 字段是资源对象中的一个元数据字段，用于存储一些非标准化的元数据信息。与 metadata 字段中的标准化信息不同，annotations 字段中存储的信息往往是自定义的、不易归类的数据，比如代码库的提交 ID、配置文件的 MD5 校验值、外部系统的关联信息等等。\nannotations # 字段的格式为一个 key-value 对的列表，其中 key 表示注解的名称，value 表示注解的值。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod annotations: commit-id: abc123 spec: containers: - name: my-container image: my-image 在这个示例中，我们在 Pod 的 metadata 中添加了一个自定义注解 commit-id，并将其值设置为 abc123。这个注解表示当前 Pod 对应的代码库的提交 ID。\n需要注意的是，由于 annotations 字段是用于存储自定义元数据信息的，因此在使用时需要注意避免与其他标准化的字段发生冲突，以免产生意外的后果。同时，由于注解的值可以是任意字符串，因此需要对注解的内容进行适当的验证和转义，以避免安全风险\nownerReferences 字段 # 在 Kubernetes 中，ownerReferences 字段是资源对象中的一个元数据字段，用于指定当前对象的所有者（owner）。这个字段可以用来建立资源对象之间的父子关系，便于管理和垃圾回收。在一个资源对象中，可以同时指定多个父对象（owner）。\nownerReferences 字段的格式为一个包含多个 ownerReference 对象的列表。每个 ownerReference 对象表示一个父对象的引用，其中包含了父对象的 API 版本、资源类型、名称和 UID。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod ownerReferences: - apiVersion: apps/v1 kind: Deployment name: my-deployment uid: abc123 - apiVersion: apps/v1 kind: ReplicaSet name: my-replicaset uid: def456 spec: containers: - name: my-container image: my-image 这段 YAML 文件描述了一个名为 my-pod 的 Pod 对象，它有两个父对象，分别是一个 Deployment 和一个 ReplicaSet。其中，Deployment 的名称为 my-deployment，UID 为 abc123，ReplicaSet 的名称为 my-replicaset，UID 为 def456。 该 Pod 中只包含一个容器，名称为 my-container，使用镜像为 my-image。 需要注意的是，这个 Pod 对象的 ownerReferences 字段表示它是 Deployment 和 ReplicaSet 的子对象，当这两个父对象被删除时，该 Pod 对象也会被自动删除。另外，这个 Pod 对象和其父对象都属于同一个命名空间，因为没有在 metadata 中指定 namespace 字段 在这个示例中，我们在 Pod 的 metadata 中添加了两个父对象，分别是一个 Deployment 和一个 ReplicaSet。这些信息可以帮助 Kubernetes 更好地管理这些对象之间的依赖关系，便于进行垃圾回收和版本控制。\n需要注意的是，ownerReferences 字段中的对象必须是同一个命名空间中的资源对象，否则会引发错误。另外，在使用 ownerReferences 字段时需要注意避免循环引用的问题，以免产生意外的后果。\nownerReferences 中的name和该pod name相同有什么作用？ # 在 Kubernetes 中，如果一个资源对象的 ownerReferences 中的 name 字段与当前对象的 metadata 中的 name 字段相同，表示当前对象是父对象（owner）自己创建的。这种情况下，父对象的控制器不会对这个对象进行垃圾回收，因为这个对象本身就是父对象的一部分。\n例如，在一个 Deployment 中创建了一个 Pod，并且将 Pod 的 ownerReferences 中的 name 字段设置为 Pod 的名称。这样一来，当 Deployment 被删除时，由于 Pod 依赖于 Deployment，Kubernetes 会先删除 Deployment，然后再删除 Pod。在删除 Pod 时，由于 Pod 的 ownerReferences 中的 name 字段与 Pod 的 metadata 中的 name 字段相同，所以控制器不会对 Pod 进行垃圾回收，而是保留下来作为 Deployment 的一部分。\n通过这种方式，我们可以在 Kubernetes 中建立资源对象之间更加复杂的关系，实现更高级别的控制和管理。例如，可以通过设置 ownerReferences 字段来建立 Deployment 和 Service 的关系，从而实现负载均衡和服务发现。\nenv 环境变量 # spec: containers: - env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_OWN_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: POD_OWN_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace 这段 YAML 文件描述了一个 Pod 中的三个环境变量。这些环境变量的值是从 Kubernetes 中获取的，而不是直接在 Pod 中指定的。\n其中，POD_IP_ADDRESS 环境变量的值使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的状态中获取 podIP 字段的值。POD_IP_ADDRESS 环境变量的值就是当前 Pod 的 IP 地址。\nPOD_OWN_NAME 和 POD_OWN_NAMESPACE 环境变量的值也使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的元数据中获取 name 和 namespace 字段的值。POD_OWN_NAME 环境变量的值就是当前 Pod 的名称，POD_OWN_NAMESPACE 环境变量的值就是当前 Pod 所属的命名空间。\n这种方式可以让我们在定义 Pod 时，动态地获取 Pod 自身的元数据和状态信息，并将这些信息作为环境变量传递给 Pod 中的容器。在容器中，我们可以通过读取这些环境变量的值，来获取当前 Pod 的一些重要信息\ninitContainers # dnsPolicy: ClusterFirst enableServiceLinks: true initContainers: - command: - sh - -c - until nc -zvw3 bsa-redis-svc.bsa-prod.svc.cluster.local 6379; do echo Waiting BSA-redis; sleep 5; done; image: repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-redis resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true - command: - sh - -c - until nc -zvw3 bsa-mongodb-svc.bsa-paas.svc.cluster.local 27017; do echo Waiting BSA-mongodb; sleep 5; done; image: repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-mongodb resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true 这段 YAML 配置是关于 Kubernetes 中的初始化容器（initContainers）的。 初始化容器是在 Pod 中所有容器启动之前运行的容器，用于预处理或准备容器的某些方面。 在这个 YAML 配置中，定义了两个初始化容器 init-redis 和 init-mongodb，分别检查 BSA-redis 和 BSA-mongodb 是否准备就绪。具体地，这两个初始化容器在容器内运行了一个 until 循环，每 5 秒尝试连接 BSA-redis 或 BSA-mongodb 服务，并打印 Waiting BSA-redis 或 Waiting BSA-mongodb 的日志信息。如果连接成功，则退出循环，容器初始化成功。初始化容器的镜像是 repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1，使用 IfNotPresent 策略拉取镜像。其中 resources 字段定义了该容器的资源限制和请求，volumeMounts 字段定义了将哪些存储卷挂载到该容器的哪些路径。 scancenter - init项目\n一些杂项 # nodeName: Pod所要调度的节点名称。 nodeSelector: 用于指定Pod所需的标签，使Pod只能被具有特定标签的节点调度。 preemptionPolicy: Pod优先级抢占策略。如果当前节点资源不足，可以抢占优先级低的Pod来为优先级高的Pod腾出资源。PreemptLowerPriority表示低优先级的Pod可以被抢占。 priority: Pod的优先级，数值越高表示优先级越高。 restartPolicy: Pod的重启策略，可以是Always、OnFailure或Never。Always表示Pod一旦终止就会自动重启，OnFailure表示只有在非0退出码时才会重启，Never表示不会自动重启。 schedulerName: 指定Pod使用的调度器。 securityContext: Pod的安全上下文。 serviceAccount: 默认使用的服务账户。 serviceAccountName: 指定使用的服务账户名称。 terminationGracePeriodSeconds: Pod终止的优雅期，即Pod终止时等待多长时间后强制终止。默认为30秒 其余一些状态信息 status : podIPs phase: Running phase initContainerStatuses containerStatuses containerStatuses conditions 持久卷 - PersistentVolume # 需要注意的是，PersistentVolume 是一个集群级别的资源，不属于任何一个命名空间，但可以通过在 metadata 字段中指定 namespace 字段来将其关联到某个命名空间中。这个关联只是用来方便查找和管理资源，不会对 PersistentVolume 对象本身产生影响。\nservice # k8s 路由解析 # \u0026ldquo;host\u0026rdquo;: \u0026ldquo;choi-wan-rabbitmq.nscloud.svc.cluster.local\u0026rdquo; 解释这段k8s配置\n4/24/2023, 5:36:06 PM\n这段 Kubernetes（k8s）配置中的 \u0026ldquo;host\u0026rdquo;: \u0026ldquo;choi-wan-rabbitmq.nscloud.svc.cluster.local\u0026rdquo; 是一个应用程序连接到 RabbitMQ 消息代理服务的主机地址。具体来说，它是一个 Kubernetes 集群内部的服务地址，该服务被命名为 choi-wan-rabbitmq，并位于 nscloud 命名空间的 svc（Service）资源中。\n如果应用程序需要连接到 scan.rabbitmq.ros.nsfocus.com 上运行的 RabbitMQ 服务，则需要在 Kubernetes 中创建一个外部服务或使用 Kubernetes 的 DNS 解析功能将该主机名映射到 RabbitMQ 服务的 IP 地址。\n4/24/2023, 5:54:22 PM\nsvc.cluster.local 分别代表什么？\n4/24/2023, 5:54:40 PM\n在 Kubernetes 中，svc.cluster.local 是一个特殊的域名后缀，用于将服务名称解析为集群内部的 IP 地址。具体来说，svc 代表 Kubernetes 中的 Service 资源类型，cluster.local 是 Kubernetes 集群的默认域名后缀。因此，当应用程序需要连接到 Kubernetes 集群中的服务时，可以使用该服务的名称作为主机名，并在末尾添加 svc.cluster.local 后缀来获得服务的 IP 地址。例如，在上述例子中，choi-wan-rabbitmq.nscloud.svc.cluster.local 是 choi-wan-rabbitmq 服务的完整域名，它将被解析为 RabbitMQ 消息代理服务的 IP 地址，从而使应用程序能够与该服务进行通信。\n访问别的命名空间下的Service # curl http://{{service_name}}.{{namespace_name}}:{{serverport}}/{{serverpath}} 配置一个rabbitmq给大家用 # 在k8s 新建一个公共rabbitmq供所有pod使用应该如何操作？\n4/24/2023, 5:34:27 PM\n在 Kubernetes 中创建一个共享的 RabbitMQ 服务供所有 Pod 使用，需要以下步骤：\n创建 RabbitMQ 镜像：可以使用 Dockerfile 或者从 Docker Hub 下载现成的 RabbitMQ 镜像。 配置 RabbitMQ：修改 RabbitMQ 的配置文件，包括默认用户名和密码、端口号、虚拟主机等。 创建 Kubernetes Service：使用 Kubernetes 的 Service 资源类型来创建一个 RabbitMQ 服务，这个服务会为 RabbitMQ 提供一个稳定的 IP 地址和端口。可以选择 ClusterIP、LoadBalancer 或者 NodePort 类型的服务。 创建 Kubernetes Deployment：创建一个 RabbitMQ 的 Deployment 资源，用于实例化 RabbitMQ 的容器，并且将这个资源归属到刚才创建的 Service 上，确保所有的 Pod 都可以访问到 RabbitMQ 服务。 验证 RabbitMQ 是否可用：使用 Kubernetes Dashboard 或者 kubectl 命令行工具，连接到 RabbitMQ 服务进行验证，确保它能够正常工作。 在其他的 Kubernetes Pod 中使用 RabbitMQ：在其他的 Pod 中安装 RabbitMQ 客户端，并使用 Service 的 IP 和端口访问 RabbitMQ 服务，实现 Pod 之间的消息传递。 总体来说，创建共享的 RabbitMQ 服务需要在 Kubernetes 中创建一个带有自动伸缩功能的 Deployment，并将它绑定到一个稳定的 Service 上，然后在其他的 Pod 中使用 RabbitMQ 客户端来连接该服务。\n4/24/2023, 5:34:49 PM\n请提供一下上述所需的示例yaml文件内容\n4/24/2023, 5:35:52 PM\n以下是创建共享的 RabbitMQ 服务所需的示例 YAML 文件内容：\nRabbitMQ 镜像的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-pod spec: containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http 注意，这里使用的是 Docker Hub 上的默认 RabbitMQ 镜像，也可以根据需要自定义 Dockerfile 来构建。\nRabbitMQ 配置文件的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: ConfigMap metadata: name: rabbitmq-config data: rabbitmq.conf: | loopback_users.guest = false listeners.tcp.default = 5672 management.listener.port = 15672 enabled_plugins: | [rabbitmq_management]. 这里使用 ConfigMap 来存储 RabbitMQ 的配置信息。配置文件中禁用了默认用户 guest，开启了 TCP 监听端口和管理界面端口，并且启用了 RabbitMQ 管理插件。\nRabbitMQ Service 的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Service metadata: name: rabbitmq-service spec: selector: app: rabbitmq ports: - name: amqp port: 5672 targetPort: amqp - name: http port: 15672 targetPort: http type: ClusterIP 这里创建的是 ClusterIP 类型的 Service，它会为 RabbitMQ 提供一个稳定的 IP 地址和端口。\nRabbitMQ Deployment 的 YAML 文件内容如下： 复制代码 apiVersion: apps/v1 kind: Deployment metadata: name: rabbitmq-deployment spec: selector: matchLabels: app: rabbitmq replicas: 1 template: metadata: labels: app: rabbitmq spec: volumes: - name: rabbitmq-config-volume configMap: name: rabbitmq-config containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http volumeMounts: - name: rabbitmq-config-volume mountPath: /etc/rabbitmq/ 这里创建了一个带有自动伸缩功能的 Deployment，并将其绑定到刚才创建的 Service 上。Deployment 中指定了 Pod 的标签，通过 ConfigMap 挂载了 RabbitMQ 的配置文件，确保所有的 Pod 都可以访问到 RabbitMQ 服务。\n验证 RabbitMQ 是否可用的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-client-pod spec: containers: 4/24/2023, 5:36:17 PM\n继续\n4/24/2023, 5:37:21 PM\n以下是创建共享的 RabbitMQ 服务所需的示例 YAML 文件内容：\nRabbitMQ 镜像的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-pod spec: containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http 注意，这里使用的是 Docker Hub 上的默认 RabbitMQ 镜像，也可以根据需要自定义 Dockerfile 来构建。\nRabbitMQ 配置文件的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: ConfigMap metadata: name: rabbitmq-config data: rabbitmq.conf: | loopback_users.guest = false listeners.tcp.default = 5672 management.listener.port = 15672 enabled_plugins: | [rabbitmq_management]. 这里使用 ConfigMap 来存储 RabbitMQ 的配置信息。配置文件中禁用了默认用户 guest，开启了 TCP 监听端口和管理界面端口，并且启用了 RabbitMQ 管理插件。\nRabbitMQ Service 的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Service metadata: name: rabbitmq-service spec: selector: app: rabbitmq ports: - name: amqp port: 5672 targetPort: amqp - name: http port: 15672 targetPort: http type: ClusterIP 这里创建的是 ClusterIP 类型的 Service，它会为 RabbitMQ 提供一个稳定的 IP 地址和端口。\nRabbitMQ Deployment 的 YAML 文件内容如下： 复制代码 apiVersion: apps/v1 kind: Deployment metadata: name: rabbitmq-deployment spec: selector: matchLabels: app: rabbitmq replicas: 1 template: metadata: labels: app: rabbitmq spec: volumes: - name: rabbitmq-config-volume configMap: name: rabbitmq-config containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http volumeMounts: - name: rabbitmq-config-volume mountPath: /etc/rabbitmq/ 这里创建了一个带有自动伸缩功能的 Deployment，并将其绑定到刚才创建的 Service 上。Deployment 中指定了 Pod 的标签，通过 ConfigMap 挂载了 RabbitMQ 的配置文件，确保所有的 Pod 都可以访问到 RabbitMQ 服务。\n验证 RabbitMQ 是否可用的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-client-pod spec: containers: - name: rabbitmq-client image: rabbitmq command: [\u0026#34;rabbitmqctl\u0026#34;, \u0026#34;list_users\u0026#34;] 这里创建了一个 Pod 来验证 RabbitMQ 是否可用，使用 rabbitmqctl 命令列出用户列表来检查服务是否正常工作。\ningress # 配置 # k8s kind ingress 是什么，有什么用途？ K8s Ingress 是 Kubernetes 集群中的一个资源对象，定义了一系列路由转发规则（或反向代理规则），规定了外部进来的 HTTP/HTTPS 请求应该被转发到哪个 Service 上。Ingress Controller 相当于是一个反向代理程序，负责解析 Ingress 的反向代理规则，并实时感知 Ingress 转发规则的变化。一旦 Ingress 规则有变化，Ingress Controller 会及时更新自己相应的转发规则，并根据这些规则，将接收到的请求转发到对应的 Service。12\nIngress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管等功能。\n举例说明。假设k8s中有一个服务A需要访问k8s中另一个服务B应该如何通过ingress 来实现 假设你的 Kubernetes 集群中有一个服务 A，需要访问另一个服务 B，可以通过 Ingress 来实现。首先，你需要创建一个 Ingress 资源对象，定义外部对集群内服务的访问路由。例如：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: /testpath pathType: Prefix backend: service: name: test port: number: 80 这个 Ingress 对象将会把 /testpath 的请求转发到名为 test 的 Service 上。这个 Service 可以是服务 B。1\n希望这些信息能够帮助你理解如何通过 Ingress 实现服务 A 访问服务 B。如果你还有其他问题，请随时问我。\n环境变量在k8s # k8s设定环境变量\n根据搜索结果，k8s设定环境变量的方法有以下几种12：\n在Pod的yaml文件中，使用env字段为容器指定环境变量，例如： apiVersion: v1 kind: Pod metadata: name: envar-demo spec: containers: - name: envar-demo-container image: nginx env: - name: DEMO_GREETING value: \u0026#34;Hello from the environment\u0026#34; - name: DEMO_FAREWELL value: \u0026#34;Such a sweet sorrow\u0026#34; 使用ConfigMap或Secret对象来存储环境变量的值，然后在Pod的yaml文件中，使用envFrom字段或valueFrom字段来引用这些对象，例如： apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: k8s.gcr.io/busybox command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;env\u0026#34; ] env: # Define the environment variable - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: # The ConfigMap containing the value you want to assign to SPECIAL_LEVEL_KEY name: special-config # Specify the key associated with the value key: special.how 使用env字段为容器指定环境变量 和 使用ConfigMap或Secret对象来存储环境变量 有什么区别？\n根据搜索结果，使用env字段为容器指定环境变量和使用ConfigMap或Secret对象来存储环境变量的区别主要有以下几点123：\n使用env字段时，需要为每个容器指定每个环境变量的值，而使用ConfigMap或Secret对象时，可以一次性引用所有的键值对作为环境变量 使用env字段时，环境变量的值是直接写在Pod的yaml文件中的，而使用ConfigMap或Secret对象时，环境变量的值是存储在Etcd中的，这样可以更好地管理和保护配置信息 使用env字段时，如果需要修改环境变量的值，需要重新创建Pod，而使用ConfigMap或Secret对象时，可以动态更新环境变量的值，不需要重启Pod ConfigMap # ConfigMap对象是一个存储配置数据的API对象\nvolumes: - configMap: defaultMode: 420 items: - key: env.json path: env.json name: env-config name: env-config 在这个配置中，k8s挂载的不是物理机的env.json文件，而是ConfigMap对象的env.json键的值。ConfigMap对象是一个存储配置数据的API对象，它可以被Pod或其他对象引用 。你可以使用kubectl命令来创建或查看ConfigMap对象。例如：\nkubectl create configmap env-config --from-file=env.json kubectl get configmap env-config -o yaml 这些命令会创建一个名为env-config的ConfigMap对象，它包含了一个键为env.json，值为文件内容的键值对。然后你可以在volume中引用这个ConfigMap对象，就像你的配置那样。\n升级单个服务流程(node namespace label) # 打包build docker image 保存服务docker镜像: docker save -o fizz_worker-2123.tar repos-xa.inone.nsfocus.com/websafe-docker/fizz_worker:2123 查看当前集群中node: kubectl get node -o wide --show-labels 并找出控制节点 如含有: run-package-node,worker k8s-worker1 是控制节点名称 通过node名查看其上所部署的pod是否是目标服务: kubectl get pod -A -o wide | grep k8s-worker1 查看当前服务运行所处node: kubectl get pod -n websafe -o wide 查看服务node 择选器: kubectl get deploy master-fizz-daemon -n websafe -o yaml | grep nodeSelector -9 一个 kv 给目标节点创建label kubectl label nodes k8s-worker1 app-select=websafe-rcmlog 查看是否成功 kubectl get node -n websafe -o wide --show-labels | grep \u0026quot;k8s-worker1\\\\|rcmlog” 上传镜像到harbor 修改deploy yaml文件(镜像版本、挂载目录、nodeSelector 其他(若有))，保存退出生效 hostPath 挂载\nvolumeMounts: - mountPath: /mnt/NPAI name: rcmlog-claim volumes: - hostPath: path: /opt/nsfocus/NPAI/data/sftp/bsa/rcm_log type: \u0026#34;\u0026#34; name: rcmlog-claim nodeSelector\nspec: nodeSelector: app-select: websafe-rcmlog 修改版本号为目标版本：2123（image: [repos-xa.inone.nsfocus.com/websafe-docker/fizz_daemon:](\u0026lt;http://repos-xa.inone.nsfocus.com/websafe-docker/fizz_daemon:1979\u0026gt;)2123)\nDocker Network # 创建网络 websafe-network 使用 IPv4Address 进行连接\ninit_mysql: docker run -p 3306:3306 \\\\ -e MYSQL_ROOT_PASSWORD=123456 \\\\ -e character-set-server=utf8mb4 \\\\ -e collation-server=utf8mb4_unicode_ci \\\\ --network websafe-network -v /x/Code/websafe_online_svn/mysql/conf:/etc/mysql/conf.d \\\\ -v /x/Code/websafe_online_svn/mysql/logs:/logs \\\\ -v /x/Code/websafe_online_svn/mysql/db:/var/lib/mysql \\\\ -v /c/Windows/System32/drivers/etc/HOSTS:/etc/hosts \\\\ --name mysql56 mysql:5.6 init_redis: docker run -p 6379:6379 \\\\ --network websafe-network \\\\ --name redislatest redis:latest --requirepass 3b21d032a7fd8eb51fa7bd8a2e812b78b7b3a36f join_network: docker network connect websafe-network mysql56 docker network connect websafe-network daemon-xxx init_network: docker network create websafe-network check_network: docker network inspect websafe-network docker network inspect websafe-network | findStr IPv4Address run: docker run --name $(CONTAINER_NAME) -p 8888:80 \\\\ -e POD_OWN_NAME=\u0026#34;master-xxxxxx\u0026#34; \\\\ --network websafe-network \\\\ -v /x/Code/websafe_online_svn/env.json:/etc/env.json \\\\ registry.nscloud:5000/kunkka/websafe/scancenter:latest Docker 限制内存/CPU占用 # 运行docker时如何限制其内存占用？\n运行docker时可以使用**–memory或-m**选项来限制其内存占用123。例如：\ndocker run -m 512m nginx 这个命令会限制nginx容器使用不超过512MB的内存。你还可以使用**–memory-reservation**选项来设置一个软限制，当主机内存不足时，docker会尽量保证容器的内存需求2。例如：\ndocker run -m 512m --memory-reservation=256m nginx 这个命令会保证nginx容器至少有256MB的内存，但最多不超过512MB。\n如何限制cpu占用呢？\n运行docker时可以使用**–cpus或–cpu-quota**选项来限制其CPU占用123456。例如：\ndocker run --cpus=2 nginx 这个命令会限制nginx容器使用不超过2个CPU的资源。你还可以使用**–cpu-shares**选项来设置容器的CPU优先级45。例如：\ndocker run --cpus=2 --cpu-shares=2000 nginx 这个命令会给nginx容器分配更高的CPU优先级，相对于默认值1024。\nDocker 在 k8s # 使用k8s 加载 docker镜像时，dockerfile中的CMD为什么没有执行？\n根据搜索结果12，k8s中的command和args会覆盖dockerfile中的entrypoint和cmd，所以如果您在k8s配置文件中设置了command或args，那么dockerfile中的cmd可能就不会执行。请检查您的k8s配置文件是否有这样的设置。\n另外，dockerfile中的cmd也可能被容器启动时附加的指令忽略3，请检查您是否在启动容器时指定了其他命令。\nDocker CMD 和 K8s Command # 如果在k8s配置中没有指定command，那么容器启动时会执行dockerfile中指定的CMD命令作为默认命令。如果dockerfile中也没有指定CMD命令，则容器启动时不会执行任何命令，只是启动一个空的容器。因此，如果想要在k8s中保留dockerfile中指定的CMD命令，可以不指定command，或者在指定command时将CMD命令包含在内。 启动命令应该写在k8s配置中的command中，因为这样可以灵活地控制容器启动时执行的命令，而不受dockerfile中的CMD命令的限制。此外，将启动命令写在k8s配置中也可以方便地进行配置管理和版本控制，便于维护和更新。当然，如果dockerfile中的CMD命令已经满足需求，也可以直接使用默认命令，不需要在k8s配置中指定command。 "},{"id":60,"href":"/posts/my-first-post/","title":"My First Post","section":"Blog","content":" Hello World # Hello, World\n"},{"id":61,"href":"/docs/programmer/langs/cmake/","title":"CMake 使用Tips","section":"编程语言","content":" 在编译时将编译产物放在build # 据网友所知，cmake文档中没有记录，仅出于兼容性原因或内部使用而保留：\n-B和-H标志 # cmake -Hpath/to/source -Bpath/to/build 甚至从源目录 -B # 重要：-B后没有空格\n该命令会自动创建build目录 之后cd到build下去make即可 cmake . -Bbuild 样例记录 # OpenCV # CMakeLists.txt 文件tree -L 1 |-- CMakeLists.txt |-- DisplayImage.cpp |-- DisplayImage.out |-- cmake_install.cmake |-- CMakeCache.txt |-- CMakeFiles |-- Makefile cmake_minimum_required(VERSION 2.8) project( DisplayImageExample ) find_package( OpenCV REQUIRED ) include_directories( ${OpenCV_INCLUDE_DIRS} ) add_executable( DisplayImage.out DisplayImage.cpp ) target_link_libraries( DisplayImage.out ${OpenCV_LIBS} ) Qt # "},{"id":62,"href":"/posts/gpt_share/","title":"GPT技术分享","section":"Blog","content":" GPT技术分享 # 先介绍几个名词 # GPT 和 ChatGPT # Generative Pre-Training Transformer 是一种基于Transformer架构的预训练语言模型.\n我们所接触到的chatgpt是针对gpt3.5模型的一种应用实例, 如今chatgpt已经为会员用户切换为gpt4.0模型. 未来短期时间内应该不会开放给免费用户使用.\nGPT模型本质是续写模型, 它根据输入的文本生成相应的续写文本, 从而实现对话、文章等自然语言文本的生成. 所以其并不具备实际的创新能力, 只能对以往的“经验”做出梳理.\nLLMs # Large language models (LLMs)大语言模型, 包括GPT和GLM等, 是一个统称. 以下是这个统称下的不同模型架构：\n主流预训练模型架构 # autoregressive自回归模型（AR模型）：代表作GPT. 本质上是一个left-to-right的语言模型. 通常用于生成式任务, 在长文本生成方面取得了巨大的成功, 比如自然语言生成（NLG）领域的任务：摘要、翻译或抽象问答. 当扩展到十亿级别参数时, 表现出了少样本学习能力. 缺点是单向注意力机制, 在NLU任务中, 无法完全捕捉上下文的依赖关系.\nautoencoding自编码模型（AE模型）：代表作BERT. 是通过某个降噪目标（比如MLM）训练的双向文本编码器. 编码器会产出适用于NLU任务的上下文表示, 擅长领域主要是自然语言处理领域, 例如文本分类、命名实体识别、情感分析、问答系统等. 但无法直接用于文本生成.\nencoder-decoder（Seq2seq模型）：代表作T5. 采用双向注意力机制, 通常用于条件生成任务, 比如文本摘要、机器翻译等.\nGLM模型基于autoregressive blank infilling方法, 结合了上述三种预训练模型的思想, 代表有清华大学的ChatGLM\nLoRA和Prompt # Prompt 提示词, 是一种用于指导模型生成输出的文本片段, Prompt通常包含一些关键词或短语, 用于提示模型生成特定类型的文本. Prompt的使用可以提高模型的生成效果和准确性, 特别是在处理特定领域的文本时. 通过使用Prompt, 模型可以更好地理解输入文本的含义和上下文信息, 从而生成更加符合要求的输出文本. LoRA英文全称Low-Rank Adaptation of Large Language Models, 直译为大语言模型的低阶适应, 是一种PEFT（参数高效性微调方法）, 这是微软的研究人员为了解决大语言模型微调而开发的一项技术. 当然参数高效性微调方法中实现最简单的方法还是Prompt tuning, 固定模型前馈层参数, 仅仅更新部分embedding参数即可实现低成本微调大模型 LLMs如何产生“思维” # 这是在训练数据达到一定规模后, LLMs模型开始表现出一种现象. 应该有论文讨论这个, 没有细看. 不过如今模型所表现出的效果都是佐以大量的指令微调, 才得以最终呈现出来.\n我们如何使用 # 因为并不能直接使用, 即使直接使用ChatGPT的API也需要对其进行一定的能力限制和格式化. 主要通过Prompt(提示词)来实现. 如果使用GPT-4或者GPT3.5接口的话, 可以仅通过调整和开发提示词来实现比较好的效果.\n但如果想要保证数据安全, 那必须使用可本地化部署的大语言模型. 如下《目前一些有有影响力的开源模型》中都是可本地化部署的大模型. 但是就使用体验来说, 距离ChatGPT都有比较大的差距. 所以使用的话需要做垂类的微调, 即使用LoRA.\nLoRA, 是微软的研究人员为了解决大语言模型微调而开发的一项技术. 比如, GPT-3有1750亿参数, 为了让它能干特定领域的活儿, 需要做微调, 但是如果直接对GPT-3做微调, 成本太高太麻烦了. LoRA的做法是, 冻结预训练好的模型权重参数, 然后在每个Transformer（Transforme就是GPT的那个T）块里注入可训练的层, 由于不需要对模型的权重参数重新计算梯度, 所以, 大大减少了需要训练的计算量. 研究发现, LoRA的微调质量与全模型微调相当. 要做个比喻的话, 就好比是大模型的一个小模型, 或者说是一个插件.\n目前一些有有影响力的开源模型 # Vicuna: a chat assistant fine-tuned from LLaMA on user-shared conversations by LMSYS WizardLM: an instruction-following LLM using evol-instruct by Microsoft GPT4All-Snoozy: A finetuned LLaMA model on assistant style data by Nomic AI Guanaco: a model fine-tuned with QLoRA by UW Koala: a dialogue model for academic research by BAIR RWKV-4-Raven: an RNN with transformer-level LLM performance Alpaca: a model fine-tuned from LLaMA on instruction-following demonstrations by Stanford ChatGLM: an open bilingual dialogue language model by Tsinghua University OpenAssistant (oasst): an Open Assistant for everyone by LAION LLaMA: open and efficient foundation language models by Meta Dolly: an instruction-tuned open large language model by Databricks StableLM: Stability AI language models MPT-Chat: a chatbot fine-tuned from MPT-7B by MosaicML FastChat-T5: a chat assistant fine-tuned from FLAN-T5 by LMSYS ChatYuan: 是由元语智能开发团队开发和发布的, 自称第一个国内最早的一个功能型对话大模型. 从披露的技术细节看, 底层采用7亿参数规模的T5模型, 并基于PromptClue进行了监督微调形成了ChatYuan privateGPT 和 localGPT # 如果在我们的使用场景中, 需要进一步规范化和对输出结果有更可控的预期. 可以参考privateGPT和localGPT的方案. 这两者都不是模型, 而是一种大模型的使用方式.\n其中privateGPT使用GPT4All大模型, localGPT使用 Vicuna大模型, 当然, 这localGPT本真就是基于privateGPT的架构和设计思路派生的, 我们完全可以使用ChatGLM模型用来增强中文能力——这种方式比使用GPT4ALL大模型借用Embeddings Model实现的中文支持效果要好.\n如上架构图所示, 这个架构分为两步式, 首先将我们提供的文档存储为知识库. 之后收到问题, 再将问题转换, 随后对存储文档进行搜索, 并对检索文档进行过滤, 随后返回文档摘要, 此种架构十分适合知识类问答. 但对有逻辑类问题处理不佳.\n结合公司使用场景分析 # 再了解到以上知识之后, 可以得出以下几点：\n数据处理需要处理哪些如何处理还不太了解 通过数据做报告是ChatGPT的强项, 不过对于输出格式每次输出都可能采取不同的格式, 每次关注的重点和排版都可能会有所变化. 如果使用的话还是需要多次的Prompt调试, 寻找到输出结果稳定, 符合我们预期的Prompt. 同时模型可能会对数据有所遗漏, 这个不太可控. －　对于代码安全优化的使用, 一是模型确实可以检测代码中的漏洞, 也可以对代码进行优化. －　二是模型可能会输出有漏洞的代码, 而我们再次反问它生成的代码是否有漏洞时, 它也会坦然承认 敏感数据识别、威胁语义检测、威胁定性分析、引导式运营分析、报告生成、以及处置建议都属于大模型适合处理的内容. 在攻击端的使用可能会有大的阻力, 因为生成钓鱼邮件和攻击内容, 是被模型训练方不断弱化的内容. 成熟的大模型都不会给出攻击建议. 知识提供也是适合模型去完成的内容. 综上, 在知识类问答中可以参考privateGPT的实现方式, 提供稳定的知识问答. 而在数据分析上则不可采用privateGPT的方法. 应该寻找效果好的模型进行Prompt tuning或者LoRA训练. 无论通过什么方法实现, 我们也应该同时注重模型基建. 这类基建任务, 无论是从头开始训练大模型还是在Prompt应用, 以及LoRA训练上都占有不下于百分之七十的工作量.\n"},{"id":63,"href":"/posts/gpt%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","title":"GPT技术分享","section":"Blog","content":" GPT技术分享 # 先介绍几个名词 # GPT 和 ChatGPT # Generative Pre-Training Transformer 是一种基于Transformer架构的预训练语言模型.\n我们所接触到的chatgpt是针对gpt3.5模型的一种应用实例, 如今chatgpt已经为会员用户切换为gpt4.0模型. 未来短期时间内应该不会开放给免费用户使用.\nGPT模型本质是续写模型, 它根据输入的文本生成相应的续写文本, 从而实现对话、文章等自然语言文本的生成. 所以其并不具备实际的创新能力, 只能对以往的“经验”做出梳理.\nLLMs # Large language models (LLMs)大语言模型, 包括GPT和GLM等, 是一个统称. 以下是这个统称下的不同模型架构：\n主流预训练模型架构 # autoregressive自回归模型（AR模型）：代表作GPT. 本质上是一个left-to-right的语言模型. 通常用于生成式任务, 在长文本生成方面取得了巨大的成功, 比如自然语言生成（NLG）领域的任务：摘要、翻译或抽象问答. 当扩展到十亿级别参数时, 表现出了少样本学习能力. 缺点是单向注意力机制, 在NLU任务中, 无法完全捕捉上下文的依赖关系.\nautoencoding自编码模型（AE模型）：代表作BERT. 是通过某个降噪目标（比如MLM）训练的双向文本编码器. 编码器会产出适用于NLU任务的上下文表示, 擅长领域主要是自然语言处理领域, 例如文本分类、命名实体识别、情感分析、问答系统等. 但无法直接用于文本生成.\nencoder-decoder（Seq2seq模型）：代表作T5. 采用双向注意力机制, 通常用于条件生成任务, 比如文本摘要、机器翻译等.\nGLM模型基于autoregressive blank infilling方法, 结合了上述三种预训练模型的思想, 代表有清华大学的ChatGLM\nLoRA和Prompt # Prompt 提示词, 是一种用于指导模型生成输出的文本片段, Prompt通常包含一些关键词或短语, 用于提示模型生成特定类型的文本. Prompt的使用可以提高模型的生成效果和准确性, 特别是在处理特定领域的文本时. 通过使用Prompt, 模型可以更好地理解输入文本的含义和上下文信息, 从而生成更加符合要求的输出文本. LoRA英文全称Low-Rank Adaptation of Large Language Models, 直译为大语言模型的低阶适应, 是一种PEFT（参数高效性微调方法）, 这是微软的研究人员为了解决大语言模型微调而开发的一项技术. 当然参数高效性微调方法中实现最简单的方法还是Prompt tuning, 固定模型前馈层参数, 仅仅更新部分embedding参数即可实现低成本微调大模型 LLMs如何产生“思维” # 这是在训练数据达到一定规模后, LLMs模型开始表现出一种现象. 应该有论文讨论这个, 没有细看. 不过如今模型所表现出的效果都是佐以大量的指令微调, 才得以最终呈现出来.\n我们如何使用 # 因为并不能直接使用, 即使直接使用ChatGPT的API也需要对其进行一定的能力限制和格式化. 主要通过Prompt(提示词)来实现. 如果使用GPT-4或者GPT3.5接口的话, 可以仅通过调整和开发提示词来实现比较好的效果.\n但如果想要保证数据安全, 那必须使用可本地化部署的大语言模型. 如下《目前一些有有影响力的开源模型》中都是可本地化部署的大模型. 但是就使用体验来说, 距离ChatGPT都有比较大的差距. 所以使用的话需要做垂类的微调, 即使用LoRA.\nLoRA, 是微软的研究人员为了解决大语言模型微调而开发的一项技术. 比如, GPT-3有1750亿参数, 为了让它能干特定领域的活儿, 需要做微调, 但是如果直接对GPT-3做微调, 成本太高太麻烦了. LoRA的做法是, 冻结预训练好的模型权重参数, 然后在每个Transformer（Transforme就是GPT的那个T）块里注入可训练的层, 由于不需要对模型的权重参数重新计算梯度, 所以, 大大减少了需要训练的计算量. 研究发现, LoRA的微调质量与全模型微调相当. 要做个比喻的话, 就好比是大模型的一个小模型, 或者说是一个插件.\n目前一些有有影响力的开源模型 # Vicuna: a chat assistant fine-tuned from LLaMA on user-shared conversations by LMSYS WizardLM: an instruction-following LLM using evol-instruct by Microsoft GPT4All-Snoozy: A finetuned LLaMA model on assistant style data by Nomic AI Guanaco: a model fine-tuned with QLoRA by UW Koala: a dialogue model for academic research by BAIR RWKV-4-Raven: an RNN with transformer-level LLM performance Alpaca: a model fine-tuned from LLaMA on instruction-following demonstrations by Stanford ChatGLM: an open bilingual dialogue language model by Tsinghua University OpenAssistant (oasst): an Open Assistant for everyone by LAION LLaMA: open and efficient foundation language models by Meta Dolly: an instruction-tuned open large language model by Databricks StableLM: Stability AI language models MPT-Chat: a chatbot fine-tuned from MPT-7B by MosaicML FastChat-T5: a chat assistant fine-tuned from FLAN-T5 by LMSYS ChatYuan: 是由元语智能开发团队开发和发布的, 自称第一个国内最早的一个功能型对话大模型. 从披露的技术细节看, 底层采用7亿参数规模的T5模型, 并基于PromptClue进行了监督微调形成了ChatYuan privateGPT 和 localGPT # 如果在我们的使用场景中, 需要进一步规范化和对输出结果有更可控的预期. 可以参考privateGPT和localGPT的方案. 这两者都不是模型, 而是一种大模型的使用方式.\n其中privateGPT使用GPT4All大模型, localGPT使用 Vicuna大模型, 当然, 这localGPT本真就是基于privateGPT的架构和设计思路派生的, 我们完全可以使用ChatGLM模型用来增强中文能力——这种方式比使用GPT4ALL大模型借用Embeddings Model实现的中文支持效果要好.\n如上架构图所示, 这个架构分为两步式, 首先将我们提供的文档存储为知识库. 之后收到问题, 再将问题转换, 随后对存储文档进行搜索, 并对检索文档进行过滤, 随后返回文档摘要, 此种架构十分适合知识类问答. 但对有逻辑类问题处理不佳.\n结合公司使用场景分析 # 再了解到以上知识之后, 可以得出以下几点：\n数据处理需要处理哪些如何处理还不太了解 通过数据做报告是ChatGPT的强项, 不过对于输出格式每次输出都可能采取不同的格式, 每次关注的重点和排版都可能会有所变化. 如果使用的话还是需要多次的Prompt调试, 寻找到输出结果稳定, 符合我们预期的Prompt. 同时模型可能会对数据有所遗漏, 这个不太可控. －　对于代码安全优化的使用, 一是模型确实可以检测代码中的漏洞, 也可以对代码进行优化. －　二是模型可能会输出有漏洞的代码, 而我们再次反问它生成的代码是否有漏洞时, 它也会坦然承认 敏感数据识别、威胁语义检测、威胁定性分析、引导式运营分析、报告生成、以及处置建议都属于大模型适合处理的内容. 在攻击端的使用可能会有大的阻力, 因为生成钓鱼邮件和攻击内容, 是被模型训练方不断弱化的内容. 成熟的大模型都不会给出攻击建议. 知识提供也是适合模型去完成的内容. 综上, 在知识类问答中可以参考privateGPT的实现方式, 提供稳定的知识问答. 而在数据分析上则不可采用privateGPT的方法. 应该寻找效果好的模型进行Prompt tuning或者LoRA训练. 无论通过什么方法实现, 我们也应该同时注重模型基建. 这类基建任务, 无论是从头开始训练大模型还是在Prompt应用, 以及LoRA训练上都占有不下于百分之七十的工作量.\n"},{"id":64,"href":"/docs/programmer/ml/paddle/","title":"Paddle","section":"机器学习","content":"slug: Paddle的坑 # 资源占用 # 命令示例(yml中修改了train,test样本地址,使用--gpus这里只用了一个GPU,可方便修改为多卡0,1,2,3)\npython -m paddle.distributed.launch --gpus \u0026#39;1\u0026#39; tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model=./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy.pdparams en_PP-OCRv3_rec默认性能配置在, 单卡V100上: +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ | 1 Tesla V100-SXM2\u0026hellip; On | 00000000:00:09.0 Off | 0 | | N/A 53C P0 223W / 300W | 23065MiB / 32510MiB | 100% Default | | | | N/A | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nPaddle 多卡训练 # You may need to install \u0026rsquo;nccl2\u0026rsquo; from NVIDIA official website\nTraceback: 这种问题可以参看Github Issues\n写在坑前头 # 经测试，下面预训练模型下载地址和检测训练效果的脚本之所以报错是因为PaddleOCR项目主页的readme中链接的子readme是develop分支的。且这个分支是落后于当前release/2.5的，所以出现了以下不匹配的情况. 切换了分支之后, 匹配度还可以接受.\nPaddleOCR 预训练模型 # 百度写文档的积极性是真的低，看来这东西用的人是真的少\u0026hellip; 这是官方说明文档:\ncd PaddleOCR/ # 下载MobileNetV3的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/MobileNetV3_large_x0_5_pretrained.tar # 或，下载ResNet18_vd的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/ResNet18_vd_pretrained.tar # 或，下载ResNet50_vd的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_vd_ssld_pretrained.tar # 解压预训练模型文件，以MobileNetV3为例 tar -xf ./pretrain_models/MobileNetV3_large_x0_5_pretrained.tar ./pretrain_models/ # 注：正确解压backbone预训练权重文件后，文件夹下包含众多以网络层命名的权重文件，格式如下： ./pretrain_models/MobileNetV3_large_x0_5_pretrained/ └─ conv_last_bn_mean └─ conv_last_bn_offset └─ conv_last_bn_scale └─ conv_last_bn_variance └─ ...... 但是 # Paddle 在1.8版本后已经不用这种格式的预训练模型了！ 2022-06-07 现在已经更新到2.3.0 所以下载下来压根不能使用 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/ResNet18_vd_pretrained.pdparams 增加dygraph 后缀修改为pdparams 使用训练结果检测单张图片 # 应使用:\npython tools/infer_det.py --config=configs/det/det_res18_db_v2.0.yml -o Global.infer_img=\u0026#34;./train_data/icdar2015/ch4_test_images/img_4.jpg\u0026#34; Global.checkpoints=\u0026#34;./output/ch_db_res18/latest.pdparams\u0026#34; Global.use_gpu=false 而非官网所示的:\npython3 tools/infer_det.py -c configs/det/det_mv3_db_v1.1.yml -o Global.infer_img=\u0026#34;./doc/imgs_en/img_10.jpg\u0026#34; Global.checkpoints=\u0026#34;./output/det_db/best_accuracy\u0026#34; 否则会报错:\nTraceback (most recent call last): File \u0026#34;... /PaddleOCR/tools/infer_det.py\u0026#34;, line 133, in \u0026lt;module\u0026gt; config, device, logger, vdl_writer = program.preprocess() File \u0026#34;... /PaddleOCR/tools/program.py\u0026#34;, line 535, in preprocess FLAGS = ArgsParser().parse_args() File \u0026#34;... /PaddleOCR/tools/program.py\u0026#34;, line 57, in parse_args assert args.config is not None, \\ AssertionError: Please specify --config=configure_file_path. 多卡和断点续传 # 断点可能怕是不行了。。。\n多卡使用:\npython -m paddle.distributed.launch --gpus \u0026#39;1,2\u0026#39; tools/train.py -c configs/det/det_res18_db_v2.0.yml -o Global.use_gpu=true Global.checkpoints=\u0026#34;./output/ch_db_res18/latest.pdparams\u0026#34; | tee train_det.log 会出现:\n[2022/06/08 18:36:48] ppocr INFO: num_workers : 4 [2022/06/08 18:36:48] ppocr INFO: shuffle : True [2022/06/08 18:36:48] ppocr INFO: profiler_options : None [2022/06/08 18:36:48] ppocr INFO: train with paddle 2.3.0 and device Place(gpu:1) server not ready, wait 3 sec to retry... not ready endpoints:[\u0026#39;127.0.0.1:36939\u0026#39;] W0608 18:36:51.403939 745832 dynamic_loader.cc:276] You may need to install \u0026#39;nccl2\u0026#39; from NVIDIA official website: https://developer.nvidia.com/nccl/nccl-downloadbefore install PaddlePaddle. Traceback (most recent call last): File \u0026#34;tools/train.py\u0026#34;, line 191, in \u0026lt;module\u0026gt; main(config, device, logger, vdl_writer) File \u0026#34;tools/train.py\u0026#34;, line 47, in main dist.init_parallel_env() File \u0026#34;/data/anaconda3/lib/python3.8/site-packages/paddle/distributed/parallel.py\u0026#34;, line 315, in init_parallel_env parallel_helper._init_parallel_ctx() File \u0026#34;/data/anaconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel_helper.py\u0026#34;, line 42, in _init_parallel_ctx __parallel_ctx__clz__.init() RuntimeError: (PreconditionNotMet) The third-party dynamic library (libnccl.so) that Paddle depends on is not configured correctly. (error code is libnccl.so: cannot open shared object file: No such file or directory) Suggestions: 1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed. 2. Configure third-party dynamic library environment variables as follows: - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...` - Windows: set PATH by `set PATH=XXX; (at /paddle/paddle/phi/backends/dynload/dynamic_loader.cc:303) LSTM Model # import os import sys import jieba import codecs import chardet import shutil import time from tqdm import tqdm, trange from bs4 import BeautifulSoup import paddle import paddlenlp chardet.__dict__ import numpy as np from functools import partial import paddle.nn as nn import paddle.nn.functional as F import paddlenlp as ppnlp from paddlenlp.data import Pad, Stack, Tuple print(paddle.__version__, paddlenlp.__version__) # from paddlenlp.datasets import MapDatasetWrapper # 加载文件列表 import pandas as pd columns = [\u0026#39;id\u0026#39;, \u0026#39;flag\u0026#39;, \u0026#39;filename\u0026#39;, \u0026#39;url\u0026#39;] tempdf = pd.read_csv(\u0026#39;MaliciousWebpage/file_list.txt\u0026#39;, sep=\u0026#39;,\u0026#39;,skiprows=0, header=None, names=columns, skipfooter=0) tempdf[:5] # p为钓鱼页面，d为被黑页面，n为正常页面 tempdf[\u0026#39;flag\u0026#39;].unique() tempdf[\u0026#39;flag\u0026#39;].value_counts() # 查看正常页面对应的filename df1=tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;n\u0026#39;] df1.head() # 选择一个正常页面进行html内容解析 html = BeautifulSoup(open(\u0026#39;MaliciousWebpage/file1/\u0026#39;+\u0026#39;66178272dee70b26f1400bb5c2aea1ab\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;),\u0026#39;html.parser\u0026#39;, from_encoding=\u0026#39;utf-8\u0026#39;) # 获取最后20组非标签字符串，会自动去掉空白字符串，返回的是一个list list(html.stripped_strings)[-20:] # 由于在PaddleNLP进行文本分类时，我们需要构造的输入内容是一串连续的文字，因此这里要用到list和string的转化 # 将list转化为string print(\u0026#39;\u0026#39;.join(list(html.stripped_strings)[-20:])) n_page = tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;n\u0026#39;] # 对正常页面进行随机采样 n_page = n_page.sample(n=500) # 提取全部被黑页面样本 d_page = tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;d\u0026#39;] # 合并样本 train_page = pd.concat([n_page,d_page],axis=0) # 做一个乱序 train_page = train_page.sample(frac = 1) # 查看效果，确认数据集的样本准备完成 train_page.head(10) for filename in tqdm(train_page[\u0026#39;filename\u0026#39;]): # 这里要先做个判断，有的file_list里面的文件不存在 if os.path.exists(\u0026#39;MaliciousWebpage/file1/\u0026#39;+filename): # 读取文件，获取字符集 content = codecs.open(\u0026#39;MaliciousWebpage/file1/\u0026#39;+filename,\u0026#39;rb\u0026#39;).read() source_encoding = chardet.detect(content)[\u0026#39;encoding\u0026#39;] # 个别文件的source_encoding是None，这里要先进行筛选 if source_encoding is None: pass # 只对字符集是gb2312格式的文件尝试转码 elif source_encoding == \u0026#39;gb2312\u0026#39;: # 转码如果失败，就跳过该文件 try: content = content.decode(source_encoding).encode(\u0026#39;utf-8\u0026#39;) codecs.open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename,\u0026#39;wb\u0026#39;).write(content) except UnicodeDecodeError: print(filename + \u0026#34;读取失败\u0026#34;) pass # 字符集是utf-8格式的文件直接保存 elif source_encoding == \u0026#39;utf-8\u0026#39;: codecs.open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename,\u0026#39;wb\u0026#39;).write(content) else: pass else: pass for i, filename in enumerate(tqdm(train_page[\u0026#39;filename\u0026#39;])): # 这里要先做个判断，有的file_list里面的文件不存在 if os.path.exists(\u0026#39;TrainWebpage/file1/\u0026#39;+filename): # 读取文件，解析HTML页面 html = BeautifulSoup(open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename, encoding=\u0026#34;utf-8\u0026#34;),\u0026#39;html.parser\u0026#39;, from_encoding=\u0026#39;utf-8\u0026#39;) text = \u0026#39;\u0026#39;.join(list(html.stripped_strings)[-20:]) # 去掉多余的换行符（部分数据最后解析结果为） text = text.replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) text = text.replace(\u0026#34; \u0026#34;, \u0026#34;,\u0026#34;) # real_label = train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] if i % 5 == 0: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webtest.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webtest.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) elif i % 5 == 1: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webdev.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webdev.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) else: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webtrain.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webtrain.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) else: pass class MyDataset(paddle.io.Dataset): \u0026#34;\u0026#34;\u0026#34; 步骤一：继承 paddle.io.Dataset 类 \u0026#34;\u0026#34;\u0026#34; def __init__(self, data_path=\u0026#34;\u0026#34;, data_list=[]): \u0026#34;\u0026#34;\u0026#34; 步骤二：实现 __init__ 函数，初始化数据集，将样本和标签映射到列表中 \u0026#34;\u0026#34;\u0026#34; super().__init__() if data_list: self.data_list = data_list else: self.data_list = [] with open(data_path, encoding=\u0026#39;utf-8\u0026#39;) as f: for line in f: self.data_list.append(line.strip().split(\u0026#39;\\t\u0026#39;)) def __getitem__(self, index): \u0026#34;\u0026#34;\u0026#34; 步骤三：实现 __getitem__ 函数，定义指定 index 时如何获取数据，并返回单条数据（样本数据、对应的标签） \u0026#34;\u0026#34;\u0026#34; # 根据索引，从列表中取出一个图像 try: data = self.data_list[index] if len(data) == 2: content, label = data elif len(data) \u0026gt;= 2: label = data[-1] content = \u0026#39;\u0026#39;.join(data[0: -1]) print(f\u0026#34;fuck you: {data} index: {index}\u0026#34;) except Exception as err: print(f\u0026#34;阿西吧: {self.data_list[index]}， index: {index}\u0026#34;) label = int(label) return [content, label] def __len__(self): \u0026#34;\u0026#34;\u0026#34; 步骤四：实现 __len__ 函数，返回数据集的样本总数 \u0026#34;\u0026#34;\u0026#34; return len(self.data_list) def get_labels(self): return [0, 1] train_ds, dev_ds, test_ds = MyDataset(\u0026#39;webtrain.txt\u0026#39;), MyDataset(\u0026#39;webdev.txt\u0026#39;), MyDataset(\u0026#39;webtest.txt\u0026#39;) label_list = train_ds.get_labels() print(label_list) for i in range(10): print (train_ds[i]) import jieba dict_path = \u0026#39;webdict.txt\u0026#39; #创建数据字典，存放位置：webdict.txt。在生成之前先清空webdict.txt #在生成all_data.txt之前，首先将其清空 with open(dict_path, \u0026#39;w\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.seek(0) f.truncate() dict_set = set() train_data = open(\u0026#39;webtrain.txt\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) for data in train_data: seg = jieba.lcut(data[:-3]) for datas in seg: if datas != \u0026#34; \u0026#34;: dict_set.add(datas) dicts = open(dict_path,\u0026#39;w\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) dicts.write(\u0026#39;[PAD]\\n\u0026#39;) dicts.write(\u0026#39;[UNK]\\n\u0026#39;) for data in dict_set: dicts.write(data + \u0026#39;\\n\u0026#39;) dicts.close() # # 下载词汇表文件word_dict.txt，用于构造词-id映射关系。 # !wget https://paddlenlp.bj.bcebos.com/data/senta_word_dict.txt def load_vocab(vocab_file): \u0026#34;\u0026#34;\u0026#34;Loads a vocabulary file into a dictionary.\u0026#34;\u0026#34;\u0026#34; vocab = {} with open(vocab_file, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as reader: tokens = reader.readlines() for index, token in enumerate(tokens): token = token.rstrip(\u0026#34;\\n\u0026#34;).split(\u0026#34;\\t\u0026#34;)[0] vocab[token] = index return vocab # 加载词表 # vocab = load_vocab(\u0026#39;data/webdict.txt\u0026#39;) vocab = load_vocab(\u0026#39;./webdict.txt\u0026#39;) for k, v in vocab.items(): print(k, v) break def convert_example(example, vocab, unk_token_id=1, is_test=False): tokenizer = jieba \u0026#34;\u0026#34;\u0026#34; Builds model inputs from a sequence for sequence classification tasks. It use `jieba.cut` to tokenize text. Args: example(obj:`list[str]`): List of input data, containing text and label if it have label. vocab(obj:`dict`): The vocabulary. unk_token_id(obj:`int`, defaults to 1): The unknown token id. is_test(obj:`False`, defaults to `False`): Whether the example contains label or not. Returns: input_ids(obj:`list[int]`): The list of token ids.s valid_length(obj:`int`): The input sequence valid length. label(obj:`numpy.array`, data type of int64, optional): The input label if not is_test. \u0026#34;\u0026#34;\u0026#34; input_ids = [] # print(\u0026#34;example 是: \u0026#34;, example) if len(example) != 2: print(f\u0026#34;fuck you!: {example}\u0026#34;) for token in tokenizer.cut(example[0]): token_id = vocab.get(token, unk_token_id) input_ids.append(token_id) valid_length = np.array([len(input_ids)]) input_ids = np.array(input_ids, dtype=\u0026#34;int32\u0026#34;) if not is_test: label = np.array(example[-1], dtype=\u0026#34;int64\u0026#34;) return input_ids, valid_length, label else: return input_ids, valid_length # python中的偏函数partial，把一个函数的某些参数固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 trans_function = partial( convert_example, vocab=vocab, unk_token_id=vocab.get(\u0026#39;[UNK]\u0026#39;, 1), is_test=False) # 版本不匹配的兼容修改方式 from paddlenlp.datasets import MapDataset train_ds_new = MapDataset(train_ds) dev_ds_new = MapDataset(dev_ds) test_ds_new = MapDataset(test_ds) # train_ds_new.map(trans_function, lazy=True) def create_dataloader(dataset, trans_function=None, mode=\u0026#39;train\u0026#39;, batch_size=1, pad_token_id=0, batchify_fn=None): if trans_function: dataset = dataset.map(trans_function, lazy=True) # return_list 数据是否以list形式返回 # collate_fn 指定如何将样本列表组合为mini-batch数据。传给它参数需要是一个callable对象，需要实现对组建的batch的处理逻辑，并返回每个batch的数据。在这里传入的是`prepare_input`函数，对产生的数据进行pad操作，并返回实际长度等。 dataloader = paddle.io.DataLoader( dataset, return_list=True, batch_size=batch_size, collate_fn=batchify_fn) return dataloader # 将读入的数据batch化处理，便于模型batch化运算。 # batch中的每个句子将会padding到这个batch中的文本最大长度batch_max_seq_len。 # 当文本长度大于batch_max_seq时，将会截断到batch_max_seq_len；当文本长度小于batch_max_seq时，将会padding补齐到batch_max_seq_len. batchify_fn = lambda samples, fn=Tuple( Pad(axis=0, pad_val=vocab[\u0026#39;[PAD]\u0026#39;]), # input_ids Stack(dtype=\u0026#34;int64\u0026#34;), # seq len Stack(dtype=\u0026#34;int64\u0026#34;) # label ): [data for data in fn(samples)] train_loader = create_dataloader( train_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;train\u0026#39;, batchify_fn=batchify_fn) dev_loader = create_dataloader( dev_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;validation\u0026#39;, batchify_fn=batchify_fn) test_loader = create_dataloader( test_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;test\u0026#39;, batchify_fn=batchify_fn) class LSTMModel(nn.Layer): def __init__(self, vocab_size, num_classes, emb_dim=64, padding_idx=0, lstm_hidden_size=96, direction=\u0026#39;forward\u0026#39;, lstm_layers=2, dropout_rate=0, pooling_type=None, fc_hidden_size=48): super().__init__() # 首先将输入word id 查表后映射成 word embedding self.embedder = nn.Embedding( num_embeddings=vocab_size, embedding_dim=emb_dim, padding_idx=padding_idx) # 将word embedding经过LSTMEncoder变换到文本语义表征空间中 self.lstm_encoder = ppnlp.seq2vec.LSTMEncoder( emb_dim, lstm_hidden_size, num_layers=lstm_layers, direction=direction, dropout=dropout_rate, pooling_type=pooling_type) # LSTMEncoder.get_output_dim()方法可以获取经过encoder之后的文本表示hidden_size self.fc = nn.Linear(self.lstm_encoder.get_output_dim(), fc_hidden_size) # 最后的分类器 self.output_layer = nn.Linear(fc_hidden_size, num_classes) def forward(self, text, seq_len): # text shape: (batch_size, num_tokens) # print(\u0026#39;input :\u0026#39;, text.shape) # Shape: (batch_size, num_tokens, embedding_dim) embedded_text = self.embedder(text) # print(\u0026#39;after word-embeding:\u0026#39;, embedded_text.shape) # Shape: (batch_size, num_tokens, num_directions*lstm_hidden_size) # num_directions = 2 if direction is \u0026#39;bidirectional\u0026#39; else 1 text_repr = self.lstm_encoder(embedded_text, sequence_length=seq_len) # print(\u0026#39;after lstm:\u0026#39;, text_repr.shape) # Shape: (batch_size, fc_hidden_size) fc_out = paddle.tanh(self.fc(text_repr)) # print(\u0026#39;after Linear classifier:\u0026#39;, fc_out.shape) # Shape: (batch_size, num_classes) logits = self.output_layer(fc_out) # print(\u0026#39;output:\u0026#39;, logits.shape) # probs 分类概率值 probs = F.softmax(logits, axis=-1) # print(\u0026#39;output probability:\u0026#39;, probs.shape) return probs model= LSTMModel( len(vocab), len(label_list), direction=\u0026#39;bidirectional\u0026#39;, padding_idx=vocab[\u0026#39;[PAD]\u0026#39;]) model = paddle.Model(model) model optimizer = paddle.optimizer.Adam( parameters=model.parameters(), learning_rate=1e-4) loss = paddle.nn.CrossEntropyLoss() metric = paddle.metric.Accuracy() model.prepare(optimizer, loss, metric) # 设置visualdl路径 log_dir = \u0026#39;./visualdl\u0026#39; callback = paddle.callbacks.VisualDL(log_dir=log_dir) model.fit(train_loader, dev_loader, epochs=100, save_dir=\u0026#39;./checkpoints\u0026#39;, save_freq=5, callbacks=callback) results = model.evaluate(dev_loader) print(\u0026#34;Finally test acc: %.5f\u0026#34; % results[\u0026#39;acc\u0026#39;]) print(results) import random label_map = {0: \u0026#39;正常页面\u0026#39;, 1: \u0026#39;被黑页面\u0026#39;} results = model.predict(test_loader, batch_size=128)[0] predictions = [] for batch_probs in results: # 映射分类label idx = np.argmax(batch_probs, axis=-1) idx = idx.tolist() labels = [label_map[i] for i in idx] predictions.extend(labels) # 看看预测数据前5个样例分类结果 for idx, data in enumerate(test_ds.data_list[:10]): print(\u0026#39;Data: {} \\t Value: {} \\t Label: {}\u0026#39;.format(data[0], data[-1], predictions[idx])) 可视化 # python -m pip install visualdl -i https://mirror.baidu.com/pypi/simple visualdl.exe --logdir . "},{"id":65,"href":"/docs/3dgame/blender/","title":"Blender","section":"建模和游戏","content":" 快捷键 # 切换为四视图 | Ctrl+Alt+q 复制并移动(进入Grab模式) ｜ Shift+d(+x|y|x 选择移动轴) 线/面挤出 ｜ e(+x|y|x 选择挤出方向轴) 上一步的操作应用到当前选择 ｜ Shift+r 打开模型右侧的小工具栏(位置插件功能等调整) ｜ n 填充(两点连成线,线圈填成面) ｜ n 备忘 # 合并物体时,谁被最后选择\u0026ndash;是Active状态,将作为母体合并 "},{"id":66,"href":"/docs/programmer/langs/python/pypi/","title":"PyPi使用说明","section":"Python","content":" Pypi包管理 # 示例项目 # py-muti-scrcpy\n配置文件 # pyproject\n工具介绍 # poetry\n增加安装包 # 直接修改pyproject.toml文件并不能生效, 因为还依赖于poetry.lock\n可使用poetry add {xxx}进行添加\n注意事项 # 需要链接外网 # HTTPSConnectionPool(host=\u0026#39;files.pythonhosted.org\u0026#39;, port=443): Max retries exceeded with url: /packages/17/61/32c3ab8951142e061587d957226b5683d1387fb22d95b4f69186d92616d1/typing_extensions-4.0.0-py3-none-any.whl (Caused by ProxyError(\u0026#39;Cannot connect to proxy.\u0026#39;, ConnectionResetError(54, \u0026#39;Connection reset by peer\u0026#39;))) HTTPSConnectionPool(host=\u0026#39;pypi.org\u0026#39;, port=443): Max retries exceeded with url: /pypi/colorama/0.4.4/json (Caused by ProxyError(\u0026#39;Cannot connect to proxy.\u0026#39;, ConnectionResetError(54, \u0026#39;Connection reset by peer\u0026#39;))) 需要安装ssl # SSLError HTTPSConnectionPool(host=\u0026#39;pypi.org\u0026#39;, port=443): Max retries exceeded with url: /pypi/importlib-metadata/4.2.0/json (Caused by SSLError(SSLEOFError(8, \u0026#39;EOF occurred in violation of protocol (_ssl.c:1129)\u0026#39;))) 该问题可通过安装openssl解决:\npip install ndg-httpsclient pip install pyopenssl pip install pyasn1 CI WorkFlows # workflows\npypi token # 注册pypi账号 进入账号管理中心这里 找见API tokens创建新token或者使用旧的，随个人 在GitHub项目配置中找到Action secrets管理这里 Repository secrets 中加入PYPI_TOKEN 因为WorkFlows中使用的是PYPI_TOKEN 见POETRY_PYPI_TOKEN_PYPI: ${{ secrets.PYPI_TOKEN }} "},{"id":67,"href":"/docs/programmer/ml/tensorflow/","title":"Tensorflow","section":"机器学习","content":"\nv2兼容v1 API # import tensorflow.compat.v1 as tf tf.disable_v2_behavior() "},{"id":68,"href":"/docs/programmer/gui/pyinstaller-python%E6%89%93%E5%8C%85/","title":"python打包","section":"图形用户界面-GUI","content":" 打包 # pyinstaller\npip install pyinstaller pyinstaller /path/to/yourscript.py pyinstaller -key yourpasswd -F /path/to/yourscript.py 解包 # 解包工具 # pyinstxtractor.py\nhex编辑器 # 010Editor 下载地址\n步骤 # 将pyinstxtractor.py与exe放置在一个文件夹内，打开cmd，输入下列指令生成一个文件夹\npython pyinstxtractor.py xxx.exe 使用010Editor打开文件夹中的main和struct，将struct中E3前面的字节复制粘贴到010Editor的E3前 修改main文件后缀为main.pyc 使用在线工具https://tool.lu/pyc/ 将main.pyc反编译为py文件\n应对增加key之后的解包 # 暂无\n安装程序 # 先将程序打包exe(以多文件模式, 但文件运行起来每次都需要解压再运行很慢，大文件的话多次运行还会挤压C盘空间) 将打包好的目录压缩打包zip 编写本质为mv lnk的脚本 把脚本打包成exe 执行脚本exe 具体代码可以看这里 "},{"id":69,"href":"/docs/programmer/gui/qt/","title":"Qt/PySide","section":"图形用户界面-GUI","content":"\n绘制界面和使用 # 安装Qt本体后可以使用Design绘制图形化界面.而后保存为xxx.ui文件.\n转换为py # 注意版本 pyside6-uic xxx.ui -o ui_xxx.py 不过信号槽就不要在Design中去标了, 放在py中手动创建和管理目前看来更为直观方便.\npyside6-designer 不能用的问题 # 桌面环境: Ubuntu 24.04 LTS Wayland\npip 安装后运行pyside6-designer 提示, 可以显示欢迎页但是无法进入主页面:\nqt.pysideplugin: Environment variable PYSIDE_DESIGNER_PLUGINS is not set, bailing out. qt.pysideplugin: No instance of QPyDesignerCustomWidgetCollection was found. 安装Qtica后莫名恢复pip install Qtica 本来是本着指定PYSIDE_DESIGNER_PLUGINS, 指定registerwigglywidget.py文件, 然后补充wigglywidget包的目的安装的Qtica但是wigglywidget包依然没有安装上, 但是pyside6-designer它好了,可以进入主界面了\u0026hellip;.\n"},{"id":70,"href":"/docs/programmer/platforms/install_some/","title":"安装问题","section":"平台","content":" 记录一些安装问题 # Debian 使用 apt-add-repository(ppa) # sudo apt update sudo apt install software-properties-common FreeBSD桌面 # 换源 pkg install xorg xfce echo \u0026lsquo;dbus_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf echo \u0026ldquo;/usr/local/etc/xdg/xfce4/xinitrc\u0026rdquo; \u0026gt; ~/.xinitrc startx 登录界面 # pkg install slim slim-themes echo \u0026lsquo;slim_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf vbox(没测试) # pkg install virtualbox-ose-additions 向/etc/rc.conf写入 vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; 仅供参考看这里 因为vbox显卡太弱安装了vmware后就一直没用回过vbox,我还没测试过\nvmware # pkg install open-vm-tools xf86-video-vmware xf86-input-vmmouse 继续向/etc/rc.conf中写入 hald_enable=\u0026#34;YES\u0026#34; moused_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmblock_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmhgfs_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmmemctl_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmxnet_enable=\u0026#34;YES\u0026#34; # vmware_guest_enable=\u0026#34;YES\u0026#34; 下面注释掉的是因为在测试中如果打开的话会有各种问题\u0026hellip;.尤其鼠标 其他可见这里参考 仅供参考, 这里面的东西很多都是有问题的.\nClash(樹莓派4 cli版) # 下載對應版本地址 注意不要選擇1.9.0版本,我用的1.8.0,9多人反映(以及我)有問題 我是樹莓派4 用的armv8 樹莓派3 據說用armv7 解壓給運行權限 從無論某處拿到配置文件 大多給訂閱地址, 但這裏使用需要我們手動下載好 配置systemd或其他(手動啓動的話注意需要root,或者給相應用戶配置端口權限) [Unit] Description=clash daemon [Service] Type=simple User=root ExecStart=/home/pi/apps/clash-linux-armv8-v1.8.0/clash-linux-armv8-v1.8.0 -f /home/pi/.config/clash/config.yaml Restart=on-failure [Install] WantedBy=multi-user.target 啓用 sudo systemctl enable clash sudo systemctl start clash sudo systemctl status clash Windows下wsl2 安装 npm \u0026amp;\u0026amp; nodejs # 摘抄自微软说明文档\n安装nvm (Node 版本管理器) 国内网可能有问题, 下载下保存直接bash install.sh就可安装. curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash command -v nvm验证是否安装成功,它会自行添加.bashrc需重启bash nvm ls查看Node版本 nvm install --lts即可安装lts版, nvm install node安装最新版 会安装这么多东西 -\u0026gt; v16.13.2 default -\u0026gt; lts/* (-\u0026gt; v16.13.2) iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v16.13.2) (default) stable -\u0026gt; 16.13 (-\u0026gt; v16.13.2) (default) lts/* -\u0026gt; lts/gallium (-\u0026gt; v16.13.2) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.9 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.18.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.13.2 可以了 或者官网下载不过在wsl2里node好使唤,npm无效(只有0K)\u0026hellip; Dgraph # 问题见: 这里\nnpm # 树莓派 # 官网下载 树莓派4b 选择ARMv8之前的树莓派型号选择ARMv7 配置PATH 向/usr/local/bin/下建立node软链 export PATH=\u0026#34;~/node-v16.14.0-linux-arm64/bin:$PATH\u0026#34; #sudo ln -s ~/node-v16.14.0-linux-arm64/bin/node /usr/bin/node Windows下wsl2 安装 npm \u0026amp;\u0026amp; nodejs # 摘抄自微软说明文档\n安装nvm (Node 版本管理器) 国内网可能有问题, 下载下保存直接bash install.sh就可安装. curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash command -v nvm验证是否安装成功,它会自行添加.bashrc需重启bash nvm ls查看Node版本 nvm install --lts即可安装lts版, nvm install node安装最新版 会安装这么多东西 -\u0026gt; v16.13.2 default -\u0026gt; lts/* (-\u0026gt; v16.13.2) iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v16.13.2) (default) stable -\u0026gt; 16.13 (-\u0026gt; v16.13.2) (default) lts/* -\u0026gt; lts/gallium (-\u0026gt; v16.13.2) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.9 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.18.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.13.2 可以了 或者官网下载不过在wsl2里node好使唤,npm无效(只有0K)\u0026hellip; "},{"id":71,"href":"/docs/programmer/database/dgraph-graph-db/","title":"Dgraph使用小记","section":"Database","content":"\n概念 # 以下参考自: 这里 Console # Mutate: 突变, 结构/数据变化的时候用 Query: 查询, Emmmm查询的时候用 所以看来没有getset了???? Schema # 管理字段(Predicate, Type, list,lang,index等)\n问题 # 在新手村的时候使用dgraph/standalone 但此时(2021-12-8 18:30:23)文档使用的版本为dgraph/standalone:v21.03.2但是这个版本的Ratel UI不工作\u0026hellip;. 导致hello 不了 world很是难受\n结果换了dgraph/standalone:v20.11.3好了诶.\nsudo docker run --rm -it -p \u0026#34;8080:8080\u0026#34; -p \u0026#34;9080:9080\u0026#34; -p \u0026#34;8000:8000\u0026#34; -v ~/dgraph:/dgraph \u0026#34;dgraph/standalone:v20.11.3\u0026#34; http://127.0.0.1:8000 突变 # set # 内容较多, 下面单独罗列\ndelete # 根据UID 删除指定predicate_name\n{ delete { \u0026lt;UID\u0026gt; \u0026lt;predicate_name\u0026gt; * . } } set # 创建 # 直接json给出结构和数据,即可完成创建.只不过如果有用到@lang时就需要去Schema里更新一下字段 - 类型 ???? (Schema-Type)的支持项\n{ \u0026#34;set\u0026#34;: [ { \u0026#34;food_name\u0026#34;: \u0026#34;Sushi\u0026#34;, \u0026#34;review\u0026#34;: [ { \u0026#34;comment\u0026#34;: \u0026#34;Tastes very good\u0026#34;, \u0026#34;comment@jp\u0026#34;: \u0026#34;とても美味しい\u0026#34;, \u0026#34;comment@ru\u0026#34;: \u0026#34;очень вкусно\u0026#34; } ], \u0026#34;origin\u0026#34;: [ { \u0026#34;country\u0026#34;: \u0026#34;Japan\u0026#34; } ] } ] } 更新 # 使用和创建差不多,不过目前我已知的更新只能用UID否则都会直接创建一个相同内容的新数据出来\n{ \u0026#34;set\u0026#34;:[ { \u0026#34;uid\u0026#34;: \u0026#34;{UID}\u0026#34;, \u0026#34;age\u0026#34;: 41 } ] } 查询 # has # 直接json 返回值也会按照这个格式给出,层级深浅可随意自定\n{ good_name(func: has(food_name)) { food_name review } } { good_name(func: has(food_name)) { food_name review{ comment } } } uid # 除了上述的has还有很多查询内置方法,不过深度的话除了手动罗列也可通过recurse - depth来确定,写多了也不会多返回\n{ find_follower(func: uid({UID})) @recurse(depth: 4) { name age follows } } eq\u0026amp;索引 # 需要设置hash索引, 如下为查询Sushi的review *为统配 可指定lang, 什么都不加默认无指定lang的数据\n{ food_review(func: eq(food_name,\u0026#34;Sushi\u0026#34;)) { food_name review { comment@* } } } \u0026lt;\u0026gt;= # func 说明 eq 等于 lt 小于 le 小于等于 gt 大于 ge 大于等于 { authors_and_ratings(func: ge(rating, 4.0)) { uid author_name rating published { title content dislikes } } } 索引 # hash 可等查询(eq), 但不支持字符串比较大小 exact 唯一允许字符串比较(ge,gt,le,lt)查询的索引(很牛逼的样子) term 带有任意一个(anyofterms), 同时拥有(allofterms), 相等(eq) // 多个关键字(术语)使用空格隔开即可. // 查询大小写不敏感 // dgraph 优化机制是将全文转换为token 查询使用查询token 所以多个查询关键词会进行重排列 获取唯一token后去全文中对比. 由此查询词的顺序无关紧要 // 也就是说anyofterms\u0026amp;allofterms的 `1 2 3 == 3 2 1 == 2 1 3` (结果相同是理所当然的, 消耗和内部逻辑也是相同) { find_tweets(func: anyofterms(tweet, \u0026#34;Go GraphQL\u0026#34;)) { tweet } } "},{"id":72,"href":"/docs/programmer/cloudnative/note-of-docker/","title":"Docker","section":"云原生","content":" Docker # 教程手册 # 好用的使用教程\nInstall # 略过~ 😁\n打镜像和跑 # docker build -t server:v0 . -f server.dockerfile 跑 # docker run -p 9080:80 --name server server:v0 指定启动命令 # sudo docker run -it -p 9080:80 --name nova_server nova_server:v0 sh -c \u0026#34;echo hello\u0026#34; 加入自定义网络 # --network {{network name}} 详见：[[#Network]]\n跑出问题-进入容器排查 # sudo docker run -it -p 9080:80 --name nova_server nova_server:v0 sh -c \u0026#34;bash\u0026#34; 使用-it进入容器手动执行命令进行调试\n启动全部容器 # docker ps -a | grep \u0026#34;Exited\u0026#34; | awk \u0026#39;{print $1}\u0026#39; | xargs docker start Network # docker run时容器加入方法-redis为例 后期加入方式 创建一个新网 检测 init_redis: docker run -p 6379:6379 \\\\ --network websafe-network \\\\ --name redislatest redis:latest --requirepass 3b21d032a7fd8eb51fa7bd8a2e812b78b7b3a36f join_network: docker network connect websafe-network mysql56 docker network connect websafe-network daemon-xxx init_network: docker network create websafe-network check_network: docker network inspect websafe-network docker network inspect websafe-network | findStr IPv4Address 删除 # 可视化 # go install github.com/jesseduffield/lazydocker@latest 如果需要sudo权限的话无法直接执行命令，只能where获取原始路径后sudo+原始路径执行 如：\n✓sudo /home/ian/go/bin/lazydocker ✗sudo lazydocker 常见问题和模板 # 用户sudo问题 # debian增加docker用户组,优化每次sudo问题 或\nsudo groupadd docker # 安装完docker.io之后一般都会自动创建所以这一步其实没啥用 sudo gpasswd -a $USERNAME docker newgrp docker # 更新 Docker Mysql编码 # version: \u0026#34;2.2\u0026#34; services: redis: image: \u0026#34;redis\u0026#34; # ports: # - 6379:6379 command: redis-server --appendonly yes #一个容器启动时要运行的命令 restart: always # 自动重启 myserver: image: mainName/myserver restart: always # 自动重启 mainServer: image: mainName/mainServer # container_name: mainServerv1.0.0 depends_on: - redis ports: - 9001:9001 restart: always volumes: - \u0026#34;./logs:/src/build/logs\u0026#34; links: - redis - myserver mysql 编码问题|单条: docker run --name predix_mysql -e MYSQL_ROOT_PASSWORD=predix123predix -p 33061:3306 -e LANG=C.UTF-8 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci\n时区/时间修改 # #docker #时区\nFROM alpine:3.14 RUN apk add -U tzdata \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone ENV TZ=Asia/Shanghai \\ GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ PROGRAM_ENV=pro WORKDIR /src/build # 复制构建应用程序所需的代码 COPY ./build . EXPOSE 8088 CMD [\u0026#34;./main\u0026#34;] bash进入某App内 # docker exec -it webserver bash webserver 为APP名称\nSwarm # Docker Compose Docker Machine: Mac、Windows区别预先安装。 Linux直接安装 Win10 Hyper-V 发布镜像 镜像充当已部署容器，填写必要信息：username、repo、tag dockers-compose.yml 副本\n其实以上在官方教程有很好说明在这里，但毕竟高级应用，暂且记下。\n创建虚拟机来试验一下 # $ docker-machine create --driver virtualbox myvm1 $ docker-machine create --driver virtualbox myvm2 第一个管理节点：docker swarm init，第二个工作节点`docker swarm join``\nshould like this show: # $ docker-machine ssh myvm1 \u0026#34;docker swarm init\u0026#34; Swarm initialized: current node \u0026lt;node ID\u0026gt; is now a manager. To add a worker to this swarm, run the following command: docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt; 通过运行 docker-machine ls 来复制 myvm1 的 IP 地址，然后使用 该 IP 地址并通过 \u0026ndash;advertise-addr 指定端口 2377（用于 swarm join 的端口）， 以便再次运行 docker swarm init 命令。例如：\ndocker-machine ssh myvm1 \u0026#34;docker swarm init --advertise-addr 192.168.99.100:2377\u0026#34; 复制此命令，然后通过 docker-machine ssh 将其发送给 myvm2，从而让 myvm2 加入 # $ docker-machine ssh myvm2 \u0026#34;docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;\u0026#34; This node joined a swarm as a worker. 至此， 创建swarm完成。 # 连接 # 使用ssh连接docker-machine ssh myvm1,运行docker node ls查看此中节点。\nMybe like this. # docker@myvm1:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS brtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active rihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leader mybe not you are ture. 😂\n之后，其余东西z有用到再去官网查看吧。 记录与否，取决于俺。\n"},{"id":73,"href":"/docs/programmer/cloudnative/%E5%AE%B9%E5%99%A8/note-of-docker/","title":"Docker","section":"云原生","content":" Docker # 教程手册 # 好用的使用教程\nInstall # 略过~ 😁\n基础命令 # 打镜像和跑 # 打 # docker build -t server:v0 . -f server.dockerfile dockerignore # 如果您想在 Dockerfile 中将当前目录中的所有文件都复制到 Docker 镜像中，可以使用 Dockerfile 中的 COPY 指令。具体的语法如下：\nCOPY . /目标路径/ 其中. 表示当前目录，/目标路径/ 表示目标路径，这里可以是绝对路径或相对路径。 这将会将当前目录中的所有文件复制到镜像中的 /app/ 目录下。请注意，在这种情况下，所有文件和文件夹都会被复制到镜像中，包括隐藏文件和文件夹。如果您不想复制某些文件或文件夹，可以在运行 COPY 指令之前通过 .dockerignore 文件来指定忽略的文件和文件夹。\n跑 # docker run -p 9080:80 --name server server:v0 指定启动命令 # sudo docker run -it -p 9080:80 --name nova_server nova_server:v0 sh -c \u0026#34;echo hello\u0026#34; 加入自定义网络 # --network {{network name}} 详见：[[#Network]]\n跑出问题-进入容器排查 # sudo docker run -it -p 9080:80 --name nova_server nova_server:v0 sh -c \u0026#34;bash\u0026#34; 使用-it进入容器手动执行命令进行调试\n启动全部容器 # docker ps -a | grep \u0026#34;Exited\u0026#34; | awk \u0026#39;{print $1}\u0026#39; | xargs docker start 重命名 # podman rename {old_name} {new_name} Network # docker run时容器加入方法-redis为例 后期加入方式 创建一个新网 检测 init_redis: docker run -p 6379:6379 \\\\ --network websafe-network \\\\ --name redislatest redis:latest --requirepass 3b21d032a7fd8eb51fa7bd8a2e812b78b7b3a36f join_network: docker network connect websafe-network mysql56 docker network connect websafe-network daemon-xxx init_network: docker network create websafe-network check_network: docker network inspect websafe-network docker network inspect websafe-network | findStr IPv4Address 删除 # lazydocker 可视化 # go install github.com/jesseduffield/lazydocker@latest 如果需要sudo权限的话无法直接执行命令，只能where获取原始路径后sudo+原始路径执行 如：\n✓sudo /home/ian/go/bin/lazydocker ✗sudo lazydocker 常见问题和模板 # 用户sudo问题 # debian增加docker用户组,优化每次sudo问题 或\nsudo groupadd docker # 安装完docker.io之后一般都会自动创建所以这一步其实没啥用 sudo gpasswd -a $USERNAME docker newgrp docker # 更新 不好使的话 # 这里我有个docker(Docker version 24.0.5, build ced0996)\ndocker --version sudo groupadd docker sudo gpasswd -a ian docker sudo systemctl status snap.docker.dockerd.service sudo systemctl restart snap.docker.dockerd.service sudo systemctl status snap.docker.dockerd.service sudo usermod -aG docker ian sudo chmod 666 /var/run/docker.sock sudo setfacl --modify user:ian:rw /var/run/docker.sock docker ps -a Docker Mysql编码 # version: \u0026#34;2.2\u0026#34; services: redis: image: \u0026#34;redis\u0026#34; # ports: # - 6379:6379 command: redis-server --appendonly yes #一个容器启动时要运行的命令 restart: always # 自动重启 myserver: image: mainName/myserver restart: always # 自动重启 mainServer: image: mainName/mainServer # container_name: mainServerv1.0.0 depends_on: - redis ports: - 9001:9001 restart: always volumes: - \u0026#34;./logs:/src/build/logs\u0026#34; links: - redis - myserver mysql 编码问题|单条 # docker run --name predix_mysql -e MYSQL_ROOT_PASSWORD=predix123predix -p 33061:3306 -e LANG=C.UTF-8 -e TZ=Asia/Shanghai -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci` 时区修改-镜像时间问题 # FROM alpine:3.14 RUN apk add -U tzdata \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone ENV TZ=Asia/Shanghai \\ GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ PROGRAM_ENV=pro WORKDIR /src/build # 复制构建应用程序所需的代码 COPY ./build . EXPOSE 8088 CMD [\u0026#34;./main\u0026#34;] Mysql 时区问题 # -e TZ=Asia/Shanghai bash进入某App内 # docker exec -it webserver bash webserver 为APP名称\nSwarm # Docker Compose Docker Machine: Mac、Windows区别预先安装。 Linux直接安装 Win10 Hyper-V 发布镜像 镜像充当已部署容器，填写必要信息：username、repo、tag dockers-compose.yml 副本\n其实以上在官方教程有很好说明在这里，但毕竟高级应用，暂且记下。\n创建虚拟机来试验一下 # $ docker-machine create --driver virtualbox myvm1 $ docker-machine create --driver virtualbox myvm2 第一个管理节点：docker swarm init，第二个工作节点`docker swarm join``\nshould like this show: # $ docker-machine ssh myvm1 \u0026#34;docker swarm init\u0026#34; Swarm initialized: current node \u0026lt;node ID\u0026gt; is now a manager. To add a worker to this swarm, run the following command: docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt; 通过运行 docker-machine ls 来复制 myvm1 的 IP 地址，然后使用 该 IP 地址并通过 \u0026ndash;advertise-addr 指定端口 2377（用于 swarm join 的端口）， 以便再次运行 docker swarm init 命令。例如：\ndocker-machine ssh myvm1 \u0026#34;docker swarm init --advertise-addr 192.168.99.100:2377\u0026#34; 复制此命令，然后通过 docker-machine ssh 将其发送给 myvm2，从而让 myvm2 加入 # $ docker-machine ssh myvm2 \u0026#34;docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;\u0026#34; This node joined a swarm as a worker. 至此， 创建swarm完成。\n空间占用问题 # 首先查看docker存储位置 sudo docker info # 这里: Docker Root Dir: 修改/etc/docker/deamon.json or ~/.config/docker/daemon.json: { \u0026quot;data-root\u0026quot;: \u0026quot;/home/hellxz/docker-home\u0026quot;}\n通过snap安装的docker配置文件路径 # /var/snap/docker/current/etc/docker/daemon.json /var/snap/docker/current/config/daemon.json sudo snap restart docker 连接 # 使用ssh连接docker-machine ssh myvm1,运行docker node ls查看此中节点。\nMybe like this. # docker@myvm1:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS brtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active rihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leader mybe not you are ture. 😂\n之后，其余东西z有用到再去官网查看吧。 记录与否，取决于俺。\nsupervisord 禁用日志文件或使用logfile=/dev/stdout # from: https://www.coder.work/article/100835 标签 docker supervisord\n[supervisord] nodaemon=true logfile=/dev/stdout pidfile=/var/run/supervisord.pid childlogdir=/var/log/supervisor 当我这样做时，这个主管会崩溃，因为它无法在/dev/stdout 中寻找\n如何禁用 supervisord 在我的 docker 容器中创建任何日志文件？\n最佳答案\n对于主主管，nodaemon 将导致日志转到 stdout\n[supervisord] nodaemon=true logfile=/dev/null logfile_maxbytes=0 然后将每个托管进程的日志发送到标准输出文件描述符/dev/fd/1\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 redirect_stderr=true 或者，如果您希望将 stderr 保留在不同的流上:\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 stderr_logfile=/dev/fd/2 stderr_logfile_maxbytes=0 关于docker - supervisord 禁用日志文件或使用 logfile=/dev/stdout，我们在Stack Overflow上找到一个类似的问题： https://stackoverflow.com/questions/45645758/\nsed报Device or resource busy错误的处理原因及方式 # 转载 kuSorZ 博主文章分类：Linux 文章标签: docker | sed 文章分类: Docker 原文出处： https://www.cnblogs.com/xuxinkun/p/7116737.html错误现象\n在docker容器中想要修改/etc/resolv.conf中的namesever，使用sed命令进行执行时遇到错误：\n/ # sed -i \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf sed: can\u0026rsquo;t move \u0026lsquo;/etc/resolv.conf73UqmG\u0026rsquo; to \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n但是可以通过vi/vim直接修改这个文件/etc/resolv.conf这个文件的内容。 问题原因\nsed命令的实质并不是修改文件，而是产生一个新的文件替换原有的文件。这里我们做了一个实验。\n我先创建了一个test.txt的文件，文件内容是123。然后我使用sed命令对文件内容进行了替换。再次查看test.txt。\n/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 265 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:28:35.000000000Modify: 2017-07-04 06:28:17.000000000Change: 2017-07-04 06:29:03.000000000/ # cat test.txt 123/ # sed -i \u0026rsquo;s/123/321/g\u0026rsquo; test.txt/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 266 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:29:31.000000000Modify: 2017-07-04 06:29:31.000000000Change: 2017-07-04 06:29:31.000000000/ # cat test.txt321\n可以看到文件内容被正确修改了，但是同时，文件的inode也修改了。说明了实质上是新生成的文件替换了原有的文件。但是vim/vi是在原文件基础上修改的，所以inode没有变化。\n在docker中，/etc/resolv.conf是通过挂载入容器的。所以当你想去删除这个挂载文件，也就是挂载点时，自然就会报Device or resource busy。\n这个跟是不是特权privilege没有关系。即使是privilege的容器，也会有这个问题。 / # rm /etc/resolv.conf rm: can\u0026rsquo;t remove \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n其实不仅仅/etc/resolv.conf，还有/etc/hostname，/etc/hosts等文件都是通过挂载方式挂载到容器中来的。所以想要用sed对他们进行修改，都会遇到这样的问题。我们可以通过df -h查看容器内的挂载情况。\n/ # df -h Filesystem Size Used Available Use% Mounted on/dev/mapper/docker-253:2-807144231-37acfcd86387ddcbc52ef8dac69d919283fc5d9d8ab5f55fd23d1c782e3b1c70 10.0G 33.8M 10.0G 0% /tmpfs 15.4G 0 15.4G 0% /devtmpfs 15.4G 0 15.4G 0% /sys/fs/cgroup/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /run/secrets/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /dev/termination-log/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/resolv.conf/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostname/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostsshm 64.0M 0 64.0M 0% /dev/shmtmpfs 15.4G 0 15.4G 0% /proc/kcoretmpfs 15.4G 0 15.4G 0% /proc/timer_stats\n如何解决\n使用vi固然可以，但是对于批量操作就不是很合适了。可以通过sed和echo的组合命令echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf 即可实现替换。\n/ # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.1options ndots:5/ # echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf / # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.254options ndots:5\n这里如果使用sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf \u0026gt; /etc/resolv.conf是无效的。最终会导致/etc/resolv.conf内容为空。\n示例 # Dockerfile # CMD mkdir -p /var/log/scancenter \\ \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \\ \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini --log-master k8s yaml # spec: containers: - command: - /bin/sh - -c - mkdir -p /var/log/scancenter \u0026amp;\u0026amp; echo -e \u0026#34;10.120.16.12\\tapi.s.com\\n10.5.25.5\\tpp.api.com\u0026#34; \u0026gt;\u0026gt; /etc/hosts \u0026amp;\u0026amp; echo \u0026#34;$(sed \u0026#39;s/^-e //g\u0026#39; /etc/hosts)\u0026#34; \u0026gt; /etc/hosts \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP "},{"id":74,"href":"/docs/programmer/cloudnative/fastapi/","title":"Django的建站的(｡･･)ﾉﾞ","section":"云原生","content":" 多一层目录时 # # Dir Tree just like: # . # ├── app # │ ├── __init__.py # │ └── main.py # ├── Dockerfile # └── requirements.txt 如果在app同级目录，而非app下运行时：\nuvicorn app.main:app --reload "},{"id":75,"href":"/docs/programmer/net/tips-of-grpc/","title":"gRpc使用小记","section":"Net","content":"\ngRpc HelloWorld # helloWorld # quickstart\nprotoc --go_out=. --go_opt=paths=source_relative \\ --go-grpc_out=. --go-grpc_opt=paths=source_relative \\ helloworld/helloworld.proto MacOS下问题 # 原本protobuf中没有mac的gen-go和gen-go-grpc,所以需要额外运行安装. 除了使用brew用go get应该也是可以的,就是有路径问题,所以还是使用brew吧 brew install protobuf brew install protoc-gen-go brew install protoc-gen-go-grpc "},{"id":76,"href":"/docs/programmer/langs/golang/advanced-knowledge-of-golang/","title":"Golang进阶笔记","section":"Golang","content":" Golang进阶笔记 # 性能分析 # import ( \u0026#34;net/http\u0026#34; _ \u0026#34;net/http/pprof\u0026#34; ) go func() { log.Println(http.ListenAndServe(\u0026#34;localhost:6060\u0026#34;, nil)) }() 将以上代码插入程序中 启动之后执行\ngo tool pprof http://localhost:6060/debug/pprof/profile?seconds=30 具体使用方法可以help 如果使用top的话就可以查看方法占用了\n(pprof) top Showing nodes accounting for 29.59s, 98.60% of 30.01s total Dropped 35 nodes (cum \u0026lt;= 0.15s) flat flat% sum% cum cum% 28.98s 96.57% 96.57% 28.98s 96.57% time.Now 0.24s 0.8% 97.37% 0.51s 1.70% runtime.selectgo 0.16s 0.53% 97.90% 0.16s 0.53% memeqbody 0.13s 0.43% 98.33% 0.29s 0.97% runtime.mapaccess2_faststr 0.08s 0.27% 98.60% 29.95s 99.80% example.com//pts/services/monitor.Run 如以上就是说monitor.Run方法中使用了select, 然后其中的time.Now被疯狂执行.\n路径问题 # test_test.go # package main import \u0026#34;testing\u0026#34; func TestHelloWorld(t *testing.T) { // t.Fatal(\u0026#34;not implemented\u0026#34;) path := getCurrentPath() t.Log(\u0026#34;getCurrentPath: \u0026#34;, path) } test.go # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(\u0026#34;getTmpDir（当前系统临时目录） = \u0026#34;, getTmpDir()) fmt.Println(\u0026#34;getCurrentAbPathByExecutable（仅支持go build） = \u0026#34;, getCurrentAbPathByExecutable()) fmt.Println(\u0026#34;getCurrentAbPathByCaller（仅支持go run） = \u0026#34;, getCurrentAbPathByCaller()) fmt.Println(\u0026#34;getCurrentAbPath（最终方案-全兼容） = \u0026#34;, getCurrentAbPath()) fmt.Println(\u0026#34;getCurrentPath（runtime.Caller1） = \u0026#34;, getCurrentPath()) } // 最终方案-全兼容 func getCurrentAbPath() string { dir := getCurrentAbPathByExecutable() if strings.Contains(dir, getTmpDir()) { return getCurrentAbPathByCaller() } return dir } func getCurrentPath() string { _, filename, _, _ := runtime.Caller(1) return path.Dir(filename) } // 获取系统临时目录，兼容go run func getTmpDir() string { dir := os.Getenv(\u0026#34;TEMP\u0026#34;) if dir == \u0026#34;\u0026#34; { dir = os.Getenv(\u0026#34;TMP\u0026#34;) } res, _ := filepath.EvalSymlinks(dir) return res } // 获取当前执行文件绝对路径 func getCurrentAbPathByExecutable() string { exePath, err := os.Executable() if err != nil { log.Fatal(err) } res, _ := filepath.EvalSymlinks(filepath.Dir(exePath)) return res } // 获取当前执行文件绝对路径（go run） func getCurrentAbPathByCaller() string { var abPath string _, filename, _, ok := runtime.Caller(0) if ok { abPath = path.Dir(filename) } return abPath } 输出 # ian@ianDebian:~$ ./test getTmpDir（当前系统临时目录） = . getCurrentAbPathByExecutable（仅支持go build） = /home/ian getCurrentAbPathByCaller（仅支持go run） = /home/ian getCurrentAbPath（最终方案-全兼容） = /home/ian getCurrentPath（runtime.Caller1） = /home/ian ian@ianDebian:~$ ian@ianDebian:~$ go run test.go getTmpDir（当前系统临时目录） = . getCurrentAbPathByExecutable（仅支持go build） = /tmp/go-build3048077768/b001/exe getCurrentAbPathByCaller（仅支持go run） = /home/ian getCurrentAbPath（最终方案-全兼容） = /tmp/go-build3048077768/b001/exe getCurrentPath（runtime.Caller1） = /home/ian ian@ianDebian:~$ ian@ianDebian:~$ go test test_test.go test.go -v === RUN TestHelloWorld test_test.go:8: getCurrentPath: /home/ian --- PASS: TestHelloWorld (0.00s) PASS ok command-line-arguments\t0.002s Golang 私有仓库 # xxx替换为具体地址\nexport GOPRIVATE=github.com/xxx/xxx 修改~/.gitconfig让go get始终通过ssh而非http\n[url \u0026#34;git@github.com:\u0026#34;] insteadOf = https://github.com/ [url \u0026#34;git@gitlab.com:\u0026#34;] insteadOf = https://gitlab.com/ -和_不同的分隔符引发的包导入错误 # 适用于Github仓库名为xxxxx-xxxxx但包名为xxxxx_xxxxx, 因为go mod 不支持-分隔.\nmodule example.com go 1.16 replace github.com/xxx-xx/xxxxx_xxxxx =\u0026gt; github.com/xxx-xx/xxxxx-xxxxx v0.0.1 // indirect require github.com/xxx-xx/xxxxx_xxxxx v0.0.1 非硬性结束服务 # http.Server.Shutdown # http.Server结构体有一个终止服务的方法Shutdown\n首先关闭所有开启的监听器 关闭所有闲置连接 等待活跃的连接均闲置了才终止服务 长链接 # 对诸如WebSocket等的长连接，Shutdown不会尝试关闭也不会等待这些连接。若需要，需调用者分开额外处理（诸如通知诸长连接或等待它们关闭，使用RegisterOnShutdown注册终止通知函数）\nsignal.Notify # 可指定信号类型/all incoming signals will be relayed to c\n综上 # Demo1 # srv := http.Server{ Addr: *addr, Handler: handler, } // make sure idle connections returned processed := make(chan struct{}) go func() { c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) \u0026lt;-c ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second) defer cancel() if err := srv.Shutdown(ctx); nil != err { log.Fatalf(\u0026#34;server shutdown failed, err: %v\\n\u0026#34;, err) } log.Println(\u0026#34;server gracefully shutdown\u0026#34;) close(processed) }() // serve err := srv.ListenAndServe() if http.ErrServerClosed != err { log.Fatalf(\u0026#34;server not gracefully shutdown, err :%v\\n\u0026#34;, err) } // waiting for goroutine above processed \u0026lt;-processed } Demo2 # func main() { c := make(chan os.Signal) // 监听信号 signal.Notify(c, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2) go func() { for s := range c { switch s { case syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM: fmt.Println(\u0026#34;退出:\u0026#34;, s) ExitFunc() case syscall.SIGUSR1: fmt.Println(\u0026#34;usr1\u0026#34;, s) case syscall.SIGUSR2: fmt.Println(\u0026#34;usr2\u0026#34;, s) default: fmt.Println(\u0026#34;其他信号:\u0026#34;, s) } } }() fmt.Println(\u0026#34;启动了程序\u0026#34;) sum := 0 for { sum++ fmt.Println(\u0026#34;休眠了:\u0026#34;, sum, \u0026#34;秒\u0026#34;) time.Sleep(1 * time.Second) } } func ExitFunc() { fmt.Println(\u0026#34;开始退出...\u0026#34;) fmt.Println(\u0026#34;执行清理...\u0026#34;) fmt.Println(\u0026#34;结束退出...\u0026#34;) os.Exit(0) } Demo3 # package main import ( \u0026#34;log\u0026#34; \u0026#34;io\u0026#34; \u0026#34;time\u0026#34; \u0026#34;net/http\u0026#34; ) func startHttpServer() *http.Server { srv := \u0026amp;http.Server{Addr: \u0026#34;:8080\u0026#34;} http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { io.WriteString(w, \u0026#34;hello world\\n\u0026#34;) }) go func() { if err := srv.ListenAndServe(); err != nil { // cannot panic, because this probably is an intentional close log.Printf(\u0026#34;Httpserver: ListenAndServe() error: %s\u0026#34;, err) } }() // returning reference so caller can call Shutdown() return srv } func main() { log.Printf(\u0026#34;main: starting HTTP server\u0026#34;) srv := startHttpServer() log.Printf(\u0026#34;main: serving for 10 seconds\u0026#34;) time.Sleep(10 * time.Second) log.Printf(\u0026#34;main: stopping HTTP server\u0026#34;) // now close the server gracefully (\u0026#34;shutdown\u0026#34;) // timeout could be given instead of nil as a https://golang.org/pkg/context/ if err := srv.Shutdown(nil); err != nil { panic(err) // failure/timeout shutting down the server gracefully } log.Printf(\u0026#34;main: done. exiting\u0026#34;) } "},{"id":77,"href":"/docs/programmer/langs/python/pytest/","title":"PyTest","section":"Python","content":" 一、命令 # 常用参数 # 1. 忽略报警信息 # -p no:warnings 2. pdb调试 # ipdb有的版本可以有的不行\n--pdb 3. 指定工作目录 # 有时候需要使用python -m pytest才生效, 直接pytest不生效 总之不如使用sys.path.insert\n--rootdir /home/path/ 4. Django使用pytest测试 # pip install pytest-django pytest -s -vv .\\tests\\test_step2.py --rootdir X:\\Code\\workflows\\ --ds project.settings rootdir 指定项目根目录 ds 指向django setting.py 文件 二、泛论 # 1、为什么需要pytest # helps you write better programs\n提高阅读理解代码效率 提高debug效率 提高开发效率 保证交付代码质量 简单例子 # 入门例子:\n了解使用test文件命名格式: test_前缀 了解断言assert 了解测试输出 # content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5 输出\n$ pytest =========================== test session starts ============================ platform linux -- Python 3.x.y, pytest-7.x.y, pluggy-1.x.y rootdir: /home/sweet/project collected 1 item test_sample.py F [100%] ================================= FAILURES ================================= _______________________________ test_answer ________________________________ def test_answer(): \u0026gt; assert inc(3) == 5 E assert 4 == 5 E + where 4 = inc(3) test_sample.py:6: AssertionError ========================= short test summary info ========================== FAILED test_sample.py::test_answer - assert 4 == 5 ============================ 1 failed in 0.12s ============================= 常用命令 # 熟悉测试命令和备忘, 了解常用参数含义\npytest -s 输出print和日志 --pdb 允许pdb调试 -vv 详细输出 Django # python2 manage.py test tests/ # Django Test Allure # pytest --alluredir=./allure_report allure serve ./allure_report 安装 # 涉及到的库和依赖安装命令备忘\napt install npm apt install openjdk-11-jdk npm install -g allure-commandline --save-dev pip install pytest pip install allure-pytest # -i https://pypi.tuna.tsinghua.edu.cn/simple 2、API测试 # 批量API测试简化写法, 初步体验一下简化工作的快乐\n简单且重复的接口测试 以CSV为例 # test.csv # url body contains https://httpbin.org/post {\u0026ldquo;key\u0026rdquo;: \u0026ldquo;value\u0026rdquo;} {\u0026ldquo;url\u0026rdquo;: \u0026ldquo;https://httpbin.org/post\"} https://httpbin.org/post {\u0026ldquo;key\u0026rdquo;: \u0026ldquo;value\u0026rdquo;} {\u0026ldquo;data\u0026rdquo;: \u0026ldquo;{\u0026quot;key\u0026quot;: \u0026quot;value\u0026quot;}\u0026rdquo;} test_api.py # def readCsv(): data=list() with open(\u0026#39;test.csv\u0026#39;,\u0026#39;r\u0026#39;) as f: reader=csv.reader(f) next(reader) for item in reader: data.append(item) return data @pytest.mark.parametrize(\u0026#39;data\u0026#39;, readCsv()) def test_csv_login(data): r=requests.post( url=data[0], json=json.loads(data[1])) _temp = r.json() _temp_update = copy.deepcopy(_temp) _temp_update.update(json.loads(data[2])) assert _temp == _temp_update 输出\npytest test_api.py ==================================== test session starts ==================================== platform linux -- Python 3.9.2, pytest-7.2.1, pluggy-1.0.0 rootdir: /mnt/share/code plugins: allure-pytest-2.12.0, anyio-3.6.2 collected 2 items test_api.py .. [100%] ===================================== 2 passed in 3.12s ===================================== 3、Mock 和测试 # 了解测试中常用的小工具, 增进开发自测幸福感\n前、后端并行开发, 摆脱依赖 模拟无法访问的资源 隔离系统, 避免脏数据干扰或生产脏数据 0. Mock的方式 # i. 手动指定 mock 范围 # def test_get_sum(): mock_get_sum = mock.patch(\u0026#34;app.get_sum\u0026#34;, return_value=20) mock_get_sum.start() rst = app.get_sum(1, 3) mock_get_sum.stop() ii. 装饰器 # @mock.patch(\u0026#34;app.get_sum\u0026#34;) def test_get_sumv2(mock_get_sum): mock_get_sum.side_effect = mock_sum rst = app.get_sum(1, 3) assert rst == 10 iii. 上下文管理器 # with mock.patch(\u0026#34;app.get_sum\u0026#34;, new_callable=mock_sum) as mock_get_sum: rst = app.get_sum assert rst == 10 总结 # - 手动指定 装饰器 上下文管理器 优点 可以更精细控制mock的范围 方便mock多个对象 1 不足 需要手动start和stop 装饰器顺序和函数参数相反容易混乱 一个with只能mock一个对象 1. Mock一个方法 # from pathlib import Path def test_getssh(monkeypatch): monkeypatch.setattr(Path, \u0026#34;home\u0026#34;, mockreturn) 2. Mock一个类 # 以 requests 为例, mock get 任意url的(.json())返回值\nimport requests class App: def get_json(self, url): return requests.get(url).json() class MockResponse: @staticmethod def json(): return {\u0026#34;mock_key\u0026#34;: \u0026#34;mock_response\u0026#34;} def test_get_json(monkeypatch): def mock_get(*args, **kwargs): return MockResponse() monkeypatch.setattr(requests, \u0026#34;get\u0026#34;, mock_get) result = App().get_json(\u0026#34;https://fakeurl\u0026#34;) assert result[\u0026#34;mock_key\u0026#34;] == \u0026#34;mock_response\u0026#34; 3. 实例 # backent - Django Test # from django.test import TestCase from events.preview_service import PreviewService class MailTestCase(TestCase): def setUp(self): pass @patch(\u0026#39;events.preview_service.get_app_platform_logo\u0026#39;) @patch(\u0026#39;events.preview_service.is_master_node\u0026#39;) def test_preview_info_master(self, mock_node, mock_logo): mock_node.return_value = True base64_image = \u0026#34;R0lGODlhAQABAIAAAAUEBAAAACwAAAAAAQABAAACAkQBADs=\u0026#34; # 黑色图片 mock_logo.return_value = (2000, base64_image) cnt = PreviewService({ \u0026#34;notice_object\u0026#34;: \u0026#34;customer\u0026#34;, \u0026#34;event_object\u0026#34;: { \u0026#34;event_list\u0026#34;: [ { \u0026#34;start_time\u0026#34;: \u0026#34;2023-01-16\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2023-01-16\u0026#34;, \u0026#34;customer_name\u0026#34;: \u0026#34;6\u0026#34;, } ]} }).get_preview_info() self.assertEqual(type(cnt), dict) self.assertEqual(cnt.keys(), {\u0026#34;flag\u0026#34;: None, \u0026#34;preview_info\u0026#34;: None, \u0026#34;sender\u0026#34;: None}.keys()) self.assertEqual(cnt[\u0026#34;flag\u0026#34;], True) self.assertEqual(cnt[\u0026#34;sender\u0026#34;][\u0026#34;address\u0026#34;], \u0026#34;mdr@nsfocus.com\u0026#34;) self.assertEqual(cnt[\u0026#34;preview_info\u0026#34;][\u0026#34;email_title\u0026#34;], u\u0026#34;【绿盟科技1】MDR威胁分析服务安全事件通知\u0026#34;) MOC # from common.nscloud import NsCloudNuriClient class MockResponse: @staticmethod def json(): return {\u0026#34;results\u0026#34;: []} def test_a(monkeypatch): def mock_request(*args, **kwargs): return MockResponse() monkeypatch.setattr(NsCloudNuriClient, \u0026#34;request\u0026#34;, mock_request) # import pdb; pdb.set_trace() content = generate_daily_report_content(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;) assert bool(content) 4、功能重用(pytest.fixture) # fixture一点需要考虑的是初始化与清理。\n也就是说在一个完整的测试用例中, 都必须都得有初始化与清理的部分, 这样才是一个完整的测试用例的 还有一点是fixture的函数也可以和返回值整合起来构成完整流程, 以get案例, 那么首先需要add书籍, 然后是get, 最后是del #!coding:utf-8 import pytest import requests from loguru import logger def add_book(get_token): r=requests.post( url=\u0026#39;https://www.example.org/\u0026#39;, headers={\u0026#39;Authorization\u0026#39;:\u0026#39;JWT {0}\u0026#39;.format(get_token)} ) del_book = add_book # 仅演示用 @pytest.fixture() def init(get_token): add_book(get_token) logger.info(\u0026#34;add_book in init\u0026#34;) yield del_book(get_token) logger.info(\u0026#34;del_book in init\u0026#34;) def test_get_book(init, get_token): r=requests.post( url=\u0026#39;https://www.example.org/\u0026#39;, headers={\u0026#39;Authorization\u0026#39;:\u0026#39;JWT {0}\u0026#39;.format(get_token)} ) logger.info(\u0026#34;get_book in test\u0026#34;) assert r.text fixture作用范围(scope) # @pytest.fixture()如果不写参数, 默认就是scope=\u0026quot;function\u0026quot; 它的作用范围是每个测试用例来之前运行一次, 销毁代码在测试用例运行之后运行\n详细如下:\nfunction 每一个函数或方法都会调用 class 每一个类调用一次, 一个类可以有多个方法 module 每一个.py文件调用一次, 该文件内又有多个function和class session 是多个文件调用一次, 可以跨.py文件调用, 每个.py文件就是module 输出\npytest test_api.py -s test_api.py 2023-02-07 15:38:22.906 | INFO | test_api:init:17 - add_book in init 2023-02-07 15:38:24.471 | INFO | test_api:test_get_book:27 - get_book in test 2023-02-07 15:38:25.894 | INFO | test_api:init:20 - del_book in init ================ 1 passed in 6.71s ================ 5、流程规范(Allure) # 同样以add, get, del为例 详参这里 和 这里 import allure import pytest import requests @pytest.fixture(scope=\u0026#34;session\u0026#34;) def login_setup(): return \u0026#34;token\u0026#34; @allure.feature(\u0026#34;功能模块\u0026#34;) @allure.story(\u0026#34;测试用例小模块-成功案例\u0026#34;) @allure.title(\u0026#34;测试用例名称: 流程性的用例, 添加测试步骤\u0026#34;) def test_add_goods_and_buy(login_setup): \u0026#39;\u0026#39;\u0026#39; 用例描述: 前置: 登陆 用例步骤: 1.浏览商品 2.添加购物车 3.购买 4.支付成功 \u0026#39;\u0026#39;\u0026#39; with allure.step(\u0026#34;step1: 浏览商品\u0026#34;): assert True with allure.step(\u0026#34;step2: 添加购物车\u0026#34;): assert True with allure.step(\u0026#34;step3: 生成订单\u0026#34;): # assert False assert True with allure.step(\u0026#34;step4: 支付\u0026#34;): assert True with allure.step(\u0026#34;断言\u0026#34;): assert True @allure.feature(\u0026#34;MDR服务邮件通知去绿盟云\u0026#34;) @allure.story(\u0026#34;客户安全事件邮件通知去绿盟化\u0026#34;) @allure.link(\u0026#34;https://inone.intra.nsfocus.com/jira/browse/MDR-4271\u0026#34;) @allure.title(\u0026#34;标题1\u0026#34;) def test_f1(): \u0026#39;\u0026#39;\u0026#39; 用例描述: 前置: 无 用例步骤: 1.测试1 2.测试2 \u0026#39;\u0026#39;\u0026#39; with allure.step(\u0026#34;step1\u0026#34;): assert True with allure.step(\u0026#34;step2\u0026#34;): assert True ![[pytest-demo.jpg]]\n三、异步方法测试 # 安装 # pip install pytest pytest-asyncio 使用 # # -------------------待测函数--------------- import asyncio async def async_function(x): await asyncio.sleep(1) # 模拟异步操作 return x * 2 # 测试用例 import pytest from your_module import async_function # 替换为你的模块名 @pytest.mark.asyncio async def test_async_function(): result = await async_function(5) assert result == 10 "},{"id":78,"href":"/docs/3dgame/noteofue4/","title":"UE4 笔记","section":"建模和游戏","content":" UE4 笔记 # 手机 # 路径必须不能用汉字, 一律全英文(神奇\u0026hellip;以前习惯就是全英,以为这问题是上世纪的了,测试时不知怎么就把顺手的英文换成中文了,结果就莫名中枪了) java8 (ue4.26.2, 之前4.25也是, 反正就找个稳定版java一直使吧, 这语言太amazing了.) 虽然对java版本有一定要求, 不过按照我这次的测试和使用, 觉得折腾那么久完全是汉字项目名不支持\u0026hellip;所以java版本要求应该不是很严重 动画 # 事件图表\u0026amp;动画图表 # 事件图表: 收集动画-\u0026gt;存储在变量中 动画图表: 驱动所有动作 事件图表 # isValid # 蓝图不知道被哪个实例持有(通用)\n朝向 # 主角本地坐标X轴正方向表正前方\nGetVelocity\nRotationFromXVector\nGetControlRotaion\n2,3求Delta.\n输出 # 速度 方向 总步骤 # 向量长度获取Speed 向量方向-控制器方向获取Direction 以上2保存为变量, 交由动画图表 动画图表 # Params-Blend-Result:\n获取速度,方向(看情况可多可少) 将1输入动画混合空间 输出姿势 State Machine # 在以上一组动作中加入状态细分\nState Machine - State1-(rule)-State2\u0026hellip;StateN State - (Params-Blend-Result) 生效 # 角色 网格体(骨骼网格体) 动画-动画类-动画蓝图 "},{"id":79,"href":"/docs/programmer/cloudnative/nginx-%E9%AB%98%E5%8F%AF%E7%94%A8/","title":"Nginx高可用","section":"云原生","content":" Keepalived+Nginx实现高可用 # Nginx 关键字 # IO多路复用epoll(IO复用) 轻量,插件: Nginx仅保留了HTTP CPU亲和: 每个worker进程固定在一个CPU Nginx配置 # 代理 # 动静分离 # 动态页面和静态页面交给不同的服务器来解析\n负载均衡 # upstream balanceServer { server 10.1.22.33:12345; server 10.1.22.34:12345; server 10.1.22.35:12345; } server { server_name fe.server.com; listen 80; location /api { proxy_pass http://balanceServer; } } 机制 # 默认: 轮询, 单机卡顿, 影响分配在这台服务器下的用户 默认: 权重轮询, 宕机Nginx会自动剔除出队列, ip_hash-来源IP分配分配给同个服务器 fair: 根据相应时间均衡分配, 默认不支持. 需安装upstream_fair, url_hash类ip_hash同样需要安装Nginx的hash软件包. Keepalived 配置 # 粘贴自: 这里\n概览 # VIP IP 主机名 Nginx端口 默认主从 192.168.50.130 192.168.50.133 liuyazhuang133 88 MASTER 192.168.50.130 192.168.50.134 liuyazhuang134 88 BACKUP 主机器配置 # vi /etc/keepalived/keepalived.conf # 主要 global_defs { ## keepalived 自带的邮件提醒需要开启 sendmail 服务。 建议用独立的监控或第三方 SMTP router_id liuyazhuang133 ## 标识本节点的字条串，通常为 hostname } ## keepalived 会定时执行脚本并对脚本执行的结果进行分析，动态调整 vrrp_instance 的优先级。如果脚本执行结果为 0，并且 weight 配置的值大于 0，则优先级相应的增加。如果脚本执行结果非 0，并且 weight配置的值小于 0，则优先级相应的减少。其他情况，维持原本配置的优先级，即配置文件中 priority 对应的值。 vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/nginx_check.sh\u0026#34; ## 检测 nginx 状态的脚本路径 interval 2 ## 检测时间间隔 weight -20 ## 如果条件成立，权重-20 } ## 定义虚拟路由， VI_1 为虚拟路由的标示符，自己定义名称 vrrp_instance VI_1 { state MASTER ## 主节点为 MASTER， 对应的备份节点为 BACKUP interface eth0 ## 绑定虚拟 IP 的网络接口，与本机 IP 地址所在的网络接口相同， 我的是 eth0 virtual_router_id 33 ## 虚拟路由的 ID 号， 两个节点设置必须一样， 可选 IP 最后一段使用, 相同的 VRID 为一个组，他将决定多播的 MAC 地址 mcast_src_ip 192.168.50.133 ## 本机 IP 地址 priority 100 ## 节点优先级， 值范围 0-254， MASTER 要比 BACKUP 高 nopreempt ## 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题 advert_int 1 ## 组播信息发送间隔，两个节点设置必须一样， 默认 1s ## 设置验证信息，两个节点必须一致 authentication { auth_type PASS auth_pass 1111 ## 真实生产，按需求对应该过来 } ## 将 track_script 块加入 instance 配置块 track_script { chk_nginx ## 执行 Nginx 监控的服务 } # # 虚拟 IP 池, 两个节点设置必须一样 virtual_ipaddress { 192.168.50.130 ## 虚拟 ip，可以定义多个 } } 备份机配置 # vi /etc/keepalived/keepalived.conf # 备份 ! Configuration File for keepalived global_defs { router_id liuyazhuang134 } vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/nginx_check.sh\u0026#34; interval 2 weight -20 } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 33 mcast_src_ip 192.168.50.134 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } track_script { chk_nginx } virtual_ipaddress { 192.168.50.130 } } Nginx 运维命令 # # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务 nginx -s stop # 平稳关闭Nginx，保存相关信息，有安排的结束web服务 nginx -s quit # 因改变了Nginx相关配置，需要重新加载配置而重载 nginx -s reload # 重新打开日志文件 nginx -s reopen # 为 Nginx 指定一个配置文件，来代替缺省的 nginx -c filename # 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件 nginx -t # 显示 nginx 的版本 nginx -v # 显示 nginx 的版本，编译器版本和配置参数 nginx -V # 格式换显示 nginx 配置参数 2\u0026gt;\u0026amp;1 nginx -V | xargs -n1 2\u0026gt;\u0026amp;1 nginx -V | xargs -n1 | grep lua "},{"id":80,"href":"/docs/programmer/ml/opencv/","title":"OpenCV","section":"机器学习","content":"\n问题(libSM.so.6 缺失) # 运行opencv的代码时，报以下错误： # Traceback (most recent call last): File \u0026#34;data_generator.py\u0026#34;, line 24, in \u0026lt;module\u0026gt; import cv2 File \u0026#34;/usr/local/lib/python3.5/dist-packages/cv2/__init__.py\u0026#34;, line 3, in \u0026lt;module\u0026gt; from .cv2 import * ImportError: libSM.so.6: cannot open shared object file: No such file or directory 解决 # 原因是缺少共享文件库，解决办法如下：\n安装apt-file $ apt-get update $ apt-get install apt-file $ apt-file update\n寻找依赖库 $ apt-file search libSM.so.6\nlibsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6 libsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1\n根据提示，安装合适的依赖库 $ apt-get install libsm6\n其余文件缺失类似, 即可解决问题。 "},{"id":81,"href":"/docs/programmer/basetc/for_china/","title":"各个软件换源","section":"基础工具和配置","content":"\n在国内用原源都会很慢, 所以总结一下各个软件(?吧)换源方法.\nQt # 使用Maintain管理kit时，可以在Settings中设置Repositories，设置地址可从Qt Downloads页面查询.\napt # 可解决版本升级时的问题,即使用了国内源,最后一个文件不知道为什么还是从国外拉取\u0026hellip;\n# sudo touch /etc/apt/apt.conf sudo vim /etc/apt/apt.conf -\u0026gt; Acquire::http::Proxy \u0026ldquo;http://127.0.0.1:8001\u0026rdquo;;\nFreeBSD # mkdir -p /usr/local/etc/pkg/repos vim /usr/local/etc/pkg/repos/bjtu.conf\nbjtu: { url: \u0026#34;pkg+http://mirror.bjtu.edu.cn/reverse/freebsd-pkg/${ABI}/quarterly\u0026#34;, mirror_type: \u0026#34;srv\u0026#34;, signature_type: \u0026#34;none\u0026#34;, fingerprints: \u0026#34;/usr/share/keys/pkg\u0026#34;, enabled: yes } FreeBSD: { enabled: no } pkg update\nQt # 源 # 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/ 清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/ 北京理工大学：http://mirror.bit.edu.cn/qtproject/ 中国互联网络信息中心：https://mirrors.cnnic.cn/qt/ Python Pip # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) 源 # 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ Nodejs Npm # 不过好像换了会有问题.Npm各个包依赖混乱不堪,不忍直视.\nnpm install --registry=https://registry.npm.taobao.org Ubuntu # 地址: /etc/apt/sources.list\n注意备份, sudo 权限\n看这里: https://mirrors.ustc.edu.cn/repogen/\n文件内容如下, 原源部分没有粘贴完全 # 20.04 Focal Fossa # # 国内源 # Ali deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse # QH # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to # newer versions of the distribution. deb http://archive.ubuntu.com/ubuntu/ focal main restricted # deb-src http://archive.ubuntu.com/ubuntu/ focal main restricted ## Major bug fix updates produced after the final release of the ## distribution. deb http://archive.ubuntu.com/ubuntu/ focal-updates main restricted # deb-src http://archive.ubuntu.com/ubuntu/ focal-updates main restricted # 原源(以下可保存也可不保存吧, 以上可选其一也可全部都放着, 目前没啥问题) ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team. Also, please note that software in universe WILL NOT receive any ## review or updates from the Ubuntu security team. Pi # 同debian\n"},{"id":82,"href":"/docs/programmer/net/epoll%E5%AE%9E%E7%8E%B0/","title":"Epoll实现","section":"Net","content":"\nC++ \u0026amp; Epoll # 代码可见这里\n也没啥高级就是:\ncreate_socket epoll_create1 epoll_ctl(1. \u0026amp; 2.) struct epoll_event events[MAX_EPOLL_EVENTS] = {0}; while1: epoll_wait(2, \u0026amp; 4.) eventfd == sockfd accept else =\u0026gt; connfd read 所以就是:\nepoll_event -\u0026gt; 内核空间 epitem -\u0026gt; 红黑 设备事件就绪 - callback (epitem -\u0026gt; rdlist链表) emmmm\u0026hellip;有需要再继续整理吧 和select-poll区别为: 一个遍历, 一个触发式的.\n"},{"id":83,"href":"/docs/programmer/langs/tips-of-debugers/","title":"Tips of debuggers","section":"编程语言","content":" Clang \u0026amp;\u0026amp; lldb # 听说clang+lldb \u0026gt;= gcc + gdb, 所以一试:\nlldb基本命令 # 与GDB相同\nbreak (b) - 设置断点，也就是程序暂停的地方 run (r) - 启动目标程序，如果遇到断点则暂停 step (s) - 进入下一条指令中的函数内部 backtrace (bt) - 显示当前的有效函数 frame (f) - 默认显示当前栈的内容，可以通过 frame arg 进入特定的 frame（用作输出本地变量） next (n) - 运行当前箭头指向行 continue (c) - 继续运行程序直到遇到断点。 clang hello.c -g -o hello lldb hello # lldb b main run n p str 还有颜色 😂 可视效果确实提高了不少 而且这四个工具可以混用,也蛮好.\nGDB # First and foremost, you will need to compile your program with the flag \u0026ldquo;-g\u0026rdquo; (for debug) to run it via GDB. From there the syntax to start debugging is:\n$ gdb -tui [executable\u0026#39;s name] placing breakpoints\nbreak [line number] or b [line number] or [file name]:[line number] or [function name] And even better, can set conditional breakpoints:\nbreak [line number] if [condition] For example, can set (if have a loop)\nbreak 11 if i \u0026gt; 97 Place a \u0026ldquo;watchpoint\u0026rdquo; which will pause the program if a variable is modified:\nwatch [variable] Once our breakpoints are set, we can run the program with the \u0026ldquo;run\u0026rdquo; command, or simply:\nr [command line arguments if your program takes some] How we got to that point:\nbt Display all the local variables and their current values.\ninfo locals Of course:\np [variable] ptype [variable] step next delete [line number] continue quit Playing with fire. As well do it all the way:\nset var [variable] = [new value] "},{"id":84,"href":"/docs/programmer/cloudnative/notesdjango/","title":"Django的建站的(｡･･)ﾉﾞ","section":"云原生","content":"author: Ian\nDjango 建站的一些东西 # 一些问题 # 使用字体 zh-cn时如果报错: # OSError: No translation files found for default language zh-cn.\nLANGUAGE_CODE = \u0026#39;zh-Hans\u0026#39; TIME_ZONE = \u0026#39;Asia/Shanghai\u0026#39; # zh-Hans是简体中文 zh-Hant是繁体中文 # 如果数据库有UTC的时间，那么可以设置： # USE_TZ = True 改为 USE_TZ = False 时区问题 # python3.8/site-packages/django/db/models/fields/init.py:1416: RuntimeWarning: DateTimeField {DATABASEMODEL}.update_time received a naive datetime (2023-09-14 21:55:56) while time zone support is active. warnings.warn(\u0026ldquo;DateTimeField %s received a naive datetime (%s)\u0026rdquo;\n这个警告是由于在使用带有时区支持的DateTimeField字段时，传入了一个没有时区信息的datetime对象。要修复这个警告，你可以将传入DateTimeField字段的datetime对象转换为带有时区信息的datetime对象。\n有两种方法可以解决这个问题：\n使用带有时区信息的datetime对象：确保在创建datetime对象时，使用正确的时区信息。你可以使用pytz库来设置时区信息，例如： from datetime import datetime import pytz # 创建带有时区信息的datetime对象 naive_datetime = datetime(2023, 9, 14, 21, 55, 56) timezone = pytz.timezone(\u0026#34;Asia/Shanghai\u0026#34;) aware_datetime = timezone.localize(naive_datetime) # 将带有时区信息的datetime对象传递给DateTimeField字段 ScannerDevice.update_time = aware_datetime 将DateTimeField字段的auto_now或auto_now_add属性设置为True：这将自动将字段的值设置为当前的带有时区信息的datetime对象。例如： from django.db import models class DATABASEMODEL(models.Model): update_time = models.DateTimeField(auto_now=True) 通过以上两种方法之一，你可以修复这个警告并确保正确处理时区信息。\ndaemon 命令 # Django 的 BaseCommand怎么使用？\nAI: 要使用 Django 的 BaseCommand，你需要按照以下步骤操作：\n创建一个新的 Python 模块或文件，例如 myapp/management/commands/mycommand.py 这里的路径很重要 在 mycommand.py 文件中导入必要的模块和类： from django.core.management.base import BaseCommand 创建一个继承自 BaseCommand 的子类，并实现 handle() 方法来定义你的命令逻辑。例如： class Command(BaseCommand): help = \u0026#39;My custom command\u0026#39; def handle(self, *args, **options): # 在这里编写你的命令逻辑 self.stdout.write(\u0026#39;Hello, world!\u0026#39;) 在 Django 项目中运行你的命令。使用以下命令格式： python manage.py mycommand 这将执行你在 handle() 方法中定义的逻辑。 你还可以在 handle() 方法中使用 self.stdout.write() 方法来输出信息到命令行。\n示例如下: # from django.core.management.base import BaseCommand class Command(BaseCommand): def add_arguments(self, parser): parser.add_argument(\u0026#39;-s\u0026#39;, \u0026#34;--start\u0026#34;, required=True) parser.add_argument(\u0026#39;-e\u0026#39;, \u0026#34;--end\u0026#34;, required=True) def handle(self, **options): try: start_timed = datetime.datetime.strptime(options.get(\u0026#39;start\u0026#39;, None), \u0026#34;%Y-%m-%d\u0026#34;) end_timed = datetime.datetime.strptime(options.get(\u0026#39;end\u0026#39;, None), \u0026#34;%Y-%m-%d\u0026#34;) run(start_timed, end_timed) except Exception: print(traceback.print_exc()) 如此就可以使用如下命令执行:\npython manage.py {pyfilename} --start 2023-04-01 --end 2023-05-01 利用nginxfd反向代理解决跨域问题 # 纠结了很久的跨域问题。。。。。。一直配置Django。。。。。问题重重，从配置方面这条路还没找到解决方案，如以后确认无误后就再放在这儿。告慰前面付出的种种艰辛 😓😀\n来自(这儿)[https://www.jb51.net/article/105786.htm]\n方法是： 打开nginx默认配置文件/etc/nginx/sites-available/default 更改如下：\n## demo listen 5017 proxy 5000 and 5001 ## server { listen 5017; server_name a.xxx.com; access_log /var/log/nginx/a.access.log; error_log /var/log/nginx/a.error.log; root html; index index.html index.htm index.php; ## send request back to flask ## location / { proxy_pass http://127.0.0.1:5000/ ; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; } location /proxy { rewrite ^.+proxy/?(.*)$ /$1 break; proxy_pass http://127.0.0.1:5001/ ; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; } } ## End a.xxx.com ## 很显然，这种解决方法仅仅适用于同服务器，架设两个网站。进行跨域访问。 所以这种东西……就很欠缺。 或者nginx也支持多服务器“并联”？\n但这种解决方案依然不能解决两个“严格无关”的网站通信。\n摒弃java后的\u0026rsquo;欢乐\u0026rsquo;?时光? # Django 的前端相关 # [^_^]虽然我前端不用这个吧，但就一记录。届时估计还是回来翻Django官方文档的。 摘一个看一个牛逼哄哄的东西： Removing hardcoded URLs in templates Remember, when we wrote the link to a question in the polls/index.html template, the link was partially hardcoded like this\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/polls/{{ question.id }}/\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; The problem with this hardcoded, tightly-coupled approach is that it becomes challenging to change URLs on projects with a lot of templates. However, since you defined the name argument in the path() functions in the polls.urls module, you can remove a reliance on specific URL paths defined in your url configurations by using the \\{\\% url \\%\\} template tag: The problem with this hardcoded, tightly-coupled approach is that it becomes challenging to change URLs on projects with a lot of templates. However, since you defined the name argument in the path() functions in the polls.urls module, you can remove a reliance on specific URL paths defined in your url configurations by using the \\{\\% url \\%\\} template tag:\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; The way this works is by looking up the URL definition as specified in the polls.urls module. You can see exactly where the URL name of ‘detail’ is defined below:\n# the \u0026#39;name\u0026#39; value as called by the {% url %} template tag path(\u0026#39;\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), If you want to change the URL of the polls detail view to something else, perhaps to something like polls/specifics/12/ instead of doing it in the template (or templates) you would change it in polls/urls.py:\n# added the word \u0026#39;specifics\u0026#39; path(\u0026#39;specifics/\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), Namespacing URL names # The answer is to add namespaces to your URLconf. In the polls/urls.py file, go ahead and add an app_name to set the application namespace:\nfrom django.urls import path from . import views app_name = \u0026#39;polls\u0026#39; urlpatterns = [ path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/results/\u0026#39;, views.results, name=\u0026#39;results\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/vote/\u0026#39;, views.vote, name=\u0026#39;vote\u0026#39;), ] Change your polls/index.html template from: polls/templates/polls/index.html¶\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; to point at the namespaced detail view: polls/templates/polls/index.html¶\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;polls:detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; 版本 # 其中，很令人头疼的便是版本。 如果遇到什么莫名其妙的错，请查看是否是版本的原因。 这里的版本原因并不☞一些人说的库依赖严重，好像开发者版本更迭不考虑兼容——或者说居然勤奋的接口重换那般严重。 此处仅仅☞在运行新版本时否个方法时，或许会莫名其妙引发一个早已摒弃的函数错误。这时候就可能是在折腾版本是导致有的不同版本有文件残留。在运行时莫名其妙的被import了然后它有调取其他东西，但是找不到的…\n这时候轻则pip uninstall 重则环境重建。所以可见虚拟环境还是挺有用的嘛——\nMVC # 全名： Model 、View、Controller。模型，视图，控制器这种功能分离的软件设计规范。所以它是通用的…不要和爪哇捆绑，搞得和某个神奇技术一般… (⊙﹏⊙)\n简介 # 在安装之后，使用django-admin startproject +名字来初始化一个工程。 对比到python中就是创建好了文档目录，还在文件中写入相关框架代码，以此支持运行。\n试一下? # python manage.py runserver 便可开启服务器，这时候访问相应端口，就一个欢迎界面，提示嗯~ o(￣▽￣)o，你能开跑了。\n再试一下？ # 在11版本中有\\admin地址可以访问，访问之后便是一个登陆界面.但,并不知道用户名和密码啊~ emm… 不过好处是能看到这个页面至少保证了django在render一个.html页面时是正常的。而之前说的老版本残留就会导致render时出错。\n结构 # 根目录下，\u0026lsquo;项目名文件\u0026rsquo;是项目容器😰 manage.py 命令行工具，emm 类似于python click库的命令行程序，使用参数干不同的事情。 进入到项目容器中，其中settings.py顾名思义 urls.py同上，管理各个url通往哪里 wsgl.py某个兼容啥，现在不用管…\n得知结构之后 # 然后就能\n在urls.py里愉快的添加各个功能url。这里面就一个urlpatterns列表，使用djangol.conf.urls.url方法来配置。 不过其对应的执行函数都需要一个request来接受请求数据。 return回一个页面~ 现在用到的有django,shortcuts.render 及 render_to_response出来的，以及django.http.HttpResponse出来的东西。\n嗯…… ulr 链接的执行方法详情就放在新创建的view.py中管理。\n而在view中需要渲染的html文件则放置在根目录新创建的templates文件夹中。通过在setting.py中的\u0026rsquo;TEMPLATES\u0026rsquo;列表中的不知名字典(因为它确实没取名啊😔)deDIRS元素来指路。\n这下可以很厉害了 # 进而进行数据库配置—— 还在setting.py中的\u0026rsquo;DATABASES\u0026rsquo;来指路。 但Django规定要使用模型，就要创建一个爱怕怕app：\ndjango-admin startapp TestModel 🦑 再将此爱怕怕领到setting.py中NSTALLED_APPS中签一下到。 随后在TestModel下的models中创建继承于django.db.models.Model的数据类，然后使用隶属于models下的方法来制定数据类型eg:\nname = models.CharField(max_length=20) 毕竟不能直接通过Python的自由类嘛… 然后也肯定不能通过python的制定类型… 毕竟python数据类型和MySQL天差地别。\n最后 再回到命令行中使用\npython manage.py migrate //创建表结构 python manage.py makemigrations //通知更改 python manage.py testModel // 创建表结构 😲❓ 正式拉入编制之后就能用了。 2019年1月23日\n- Change your models(in *models.py*) - Run *python manage.py makemigrations* to create migration for those changes - Run *python manage.py migrate* to apply those changes to the database Of courses, If Null Run python manage.py migrate can make a models.py whitch has nothings.\n那么这个数据库怎么操作呢？ # 自然是到urls.py中添加🔗链接到方法的路 再到容器里面添加testdb.py来说明方法详细。\n增删改查 # 实例化类 直接.save()即保存 未实例化类，all标识查找全部 .objects.filter(填写删选条件) .objects.get(获取) .order_by(排序条件) 更改则是将查出来的东西直接修改.update(修改东西) 再.save保存 删除便是.delete() ``. 差不多了 之后的详细再随情况更新。 ### 那么数据库表多了怎么一键生成对应类呢？ ```shell python manage.py inspectdb //自动生成models模型文件 python manage.py inspectdb \u0026gt; app/models.py //假设有了名为\u0026#39;app\u0026#39;的爱怕怕 // 老一套 python manage.py makemigrations python manage.py migrate 但是会将之前models.py中的东西删掉… 还会把数据库中的表名重命名… 按它的规矩来生成，嗯…其实也🆗的。\n我爱Java 2018年6月24日16点40分的我由衷的写到 # 在MySQL中读取blob存储的字段时，使用BinaryField不可使用其逆向生成的模型读取方式。当然，对照表如下\n\u0026#39;AutoField\u0026#39;: \u0026#39;integer AUTO_INCREMENT\u0026#39;, \u0026#39;BigAutoField\u0026#39;: \u0026#39;bigint AUTO_INCREMENT\u0026#39;, \u0026#39;BinaryField\u0026#39;: \u0026#39;longblob\u0026#39;, \u0026#39;BooleanField\u0026#39;: \u0026#39;bool\u0026#39;, \u0026#39;CharField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;CommaSeparatedIntegerField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;DateField\u0026#39;: \u0026#39;date\u0026#39;, \u0026#39;DateTimeField\u0026#39;: \u0026#39;datetime\u0026#39;, \u0026#39;DecimalField\u0026#39;: \u0026#39;numeric(%(max_digits)s, %(decimal_places)s)\u0026#39;, \u0026#39;DurationField\u0026#39;: \u0026#39;bigint\u0026#39;, \u0026#39;FileField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;FilePathField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;FloatField\u0026#39;: \u0026#39;double precision\u0026#39;, \u0026#39;IntegerField\u0026#39;: \u0026#39;integer\u0026#39;, \u0026#39;BigIntegerField\u0026#39;: \u0026#39;bigint\u0026#39;, \u0026#39;IPAddressField\u0026#39;: \u0026#39;char(15)\u0026#39;, \u0026#39;GenericIPAddressField\u0026#39;: \u0026#39;char(39)\u0026#39;, \u0026#39;NullBooleanField\u0026#39;: \u0026#39;bool\u0026#39;, \u0026#39;OneToOneField\u0026#39;: \u0026#39;integer\u0026#39;, \u0026#39;PositiveIntegerField\u0026#39;: \u0026#39;integer UNSIGNED\u0026#39;, \u0026#39;PositiveSmallIntegerField\u0026#39;: \u0026#39;smallint UNSIGNED\u0026#39;, \u0026#39;SlugField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;SmallIntegerField\u0026#39;: \u0026#39;smallint\u0026#39;, \u0026#39;TextField\u0026#39;: \u0026#39;longtext\u0026#39;, \u0026#39;TimeField\u0026#39;: \u0026#39;time\u0026#39;, \u0026#39;UUIDField\u0026#39;: \u0026#39;char(32)\u0026#39;, 以上是一部分，具体点这里\n模型字段名称 # 在逆向生成时，我遇到过一次将数据库名修改的先例，不过后来似乎没有修改过。 然后就是驼峰命名法的字段可能emm也是因为此我才开始写这些信息，就是，驼峰命名法的字段可能在模型字段中为全小写。 还有就是Django莫名其妙的的编码错误，真的是一分钟编程，一小时修改编码…而且调试起来真的…我目前的调试方式极为原始，所以感觉真的不想编程嗯…\nDjango 返回文件下载 # def readFile(fn, buf_size=262144): # 大文件下载，设定缓存大小 f = open(fn, \u0026#34;rb\u0026#34;) while True: # 循环读取 c = f.read(buf_size) if c: yield c else: break f.close() response = HttpResponse(readFile(filePath), content_type=\u0026#39;APPLICATION/OCTET-STREAM\u0026#39;) # 设定文件头，这种设定可以让任意文件都能正确下载，而且已知文本文件不是本地打开 fileName = \u0026#39;haya\u0026#39; fileType = \u0026#39;.docx\u0026#39; response[\u0026#39;Content-Disposition\u0026#39;] = \u0026#39;attachment; filename=\u0026#39; + fileName.encode(\u0026#39;utf-8\u0026#39;) + fileType.encode(\u0026#39;utf-8\u0026#39;) # 设定传输给客户端的文件名称 response[\u0026#39;Content-Length\u0026#39;] = os.path.getsize(filePath) # 传输给客户端的文件大小 return response Python Docx编辑 # 替换 # 在`.docx`文件中将需要替换的位置 使用变量站位，写法{{ placheholdParaName }} 使用文件时，只能写做{{placheholdParaName}}不能有空格…另外docx使用docx中的Document读入即可\ntpl = DocxTemplate(self.prjRootPath + \u0026#39;/word_template/\u0026#39; + \u0026#34;word_template.docx\u0026#34;) sub1 = tpl.new_subdoc() sub1.subdocx = Document(temPath + \u0026#39;sub1_bond.docx\u0026#39;) subContext[\u0026#39;sub1\u0026#39;] = sub1 上述中，只能写作……难道是因为使用{{someThing}}这种写法而隐藏了？！！ 那么，今后写彩带注释岂不是不需要使用^_^而直接使用双花括号的写法就能直接隐藏了么(⊙o⊙ ) 凄い Py中：\nfrom docxtpl import DocxTemplate, InlineImage from docx.shared import Mm, Inches, Pt doc = DocxTemplate(\u0026#34;my_word_template.docx\u0026#34;) myimage = InlineImage(doc, \u0026#39;C:/Users/GuPengxiang/Pictures/ha.jpg\u0026#39;,width=Mm(20)) context = { \u0026#39;fundName\u0026#39; : u\u0026#39;这里是基金名称\u0026#39;, \u0026#39;stars\u0026#39;:u\u0026#39;五星级琉璃六\u0026#39;, \u0026#39; bench\u0026#39;: u\u0026#39;对比基金\u0026#39;, \u0026#39;income\u0026#39;: u\u0026#39;12\u0026#39;, \u0026#39;bb\u0026#39;: u\u0026#39;0.1%\u0026#39;, \u0026#39;image0\u0026#39; : myimage} doc.render(context) doc.save(\u0026#34;generated_doc.docx\u0026#34;) 生成echarts图表图片 # 环境 # # 更新软件列表 \u0026amp; 更新软件 sudo apt-get update sudo apt-get upgrade # 下载包 pip install pyecharts-snapshot wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.5.0-beta-linux-ubuntu-xenial-x86_64.tar.gz # 解压 tar -xzvf phantomjs-2.5.0-beta-linux-ubuntu-xenial-x86_64.tar.gz # 进入路径 cd phantomjs-2.5.0-beta-ubuntu-xenial/bin # 赋予权限 chmod +x phantomjs # 查看版本号 phantomjs -v # 若显示版本号，如 2.1.1 则生效 生成图片 # from pyecharts import Line, Pie, Grid from pyecharts_snapshot.main import make_a_snapshot attr = [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;] v1 = [5, 20, 36, 10, 10, 100] v2 = [55, 60, 16, 20, 15, 80] line = Line(\u0026#34;折线图示例\u0026#34;) line.add(\u0026#34;商家A\u0026#34;, attr, v1, mark_point=[\u0026#34;average\u0026#34;]) line.add(\u0026#34;商家B\u0026#34;, attr, v2, is_smooth=True, mark_line=[\u0026#34;max\u0026#34;, \u0026#34;average\u0026#34;]) line.render(\u0026#39;test.html\u0026#39;) make_a_snapshot(\u0026#39;test.html\u0026#39;, \u0026#39;test.pdf\u0026#39;) # 或者直接生成 line.render(\u0026#39;test.png\u0026#39;) 在生成图片时，插件包文件源码中有Log，但却是print出来的，而在部署环境中不允许出现print，所以…… 得在包源码中将之屏蔽\n连续生成图片 # 用以上方法来生成图片是…很慢的🐢⬅这个速度。但可以通过使用为渲染创建一个默认配置环境来避免多次生成环境配置。所以—— 具体来看pyecharts中的高级说明🕶\nfrom pyecharts import Bar, Line from pyecharts.engine import create_default_environment bar = Bar(\u0026#34;我的第一个图表\u0026#34;, \u0026#34;这里是副标题\u0026#34;) bar.add(\u0026#34;服装\u0026#34;, [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;], [5, 20, 36, 10, 75, 90]) line = Line(\u0026#34;我的第一个图表\u0026#34;, \u0026#34;这里是副标题\u0026#34;) line.add(\u0026#34;服装\u0026#34;, [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;], [5, 20, 36, 10, 75, 90]) env = create_default_environment(\u0026#34;html\u0026#34;) # 为渲染创建一个默认配置环境 # create_default_environment(filet_ype) # file_type: \u0026#39;html\u0026#39;, \u0026#39;svg\u0026#39;, \u0026#39;png\u0026#39;, \u0026#39;jpeg\u0026#39;, \u0026#39;gif\u0026#39; or \u0026#39;pdf\u0026#39; env.render_chart_to_file(bar, path=\u0026#39;bar.html\u0026#39;) env.render_chart_to_file(line, path=\u0026#39;line.html\u0026#39;) (￣▽￣)o 如上\n注意 # 在生成报表时， 由于采用的是浏览器截图的方式，在使用`phantomjs`时会自动判断图片是否加载完成（echarts在显示图表之前是有一段动画的……）然后再`pyecharts`中并没有关闭动画的接口，而echarts是有的。 但毕竟`echarts`是在做翻译，所以只要在\u0026quot;Chart\u0026quot;基类中，将`animation=False`就可以了。 我改的时候在`chart.py`文件的29行，def __init__中。 SSl加密，https配置 # 虽然就配置过之后显得操作很简单，而且也很明显，但就配置之初着实还是费了一些功夫的。或许是因为大而全的东西懒得看，而网上搜索到的粘贴复制之词又太过片面，或许大家写的时候也就当作日记来写的，本就没准备让别人去参考。所以再加上搜索的时候俺表述词不达意，所以总是很曲折（呵，用谷歌搜外文网就不存在这问题，前面就谦虚一下🙃）\n之前写的文档 # 1 ssl加密部署步骤说明文档 一．申请ssl证书 1.生成csr文件，可使用openssl工具生成 (1)例:openssl genrsa -des3 -out server.key 1024 生成服务器key文件; (2)例:openssl req -new -key server.key -out server.csr 生成服务器证书请求CSR文件; 或使用CSR文件生成工具生成(例https://www.chinassl.net/ssltools/generator-csr.html，填写信息后点击生成CSR文件即可) （CSR文件中包括组织部门、国家地区、算法、以及邮箱和域名等信息） 2.申请/购买HTTPS证书， 填写与上述相同的信息，验证类型选择DNS，CSR生成选择提供CSR(即提供第一步生成的CSR文件)（例：在阿里云或腾讯等地，本文档撰写时是通过https://freessl.org/ 免费申请而来（一年有效期，单域名，）） 二、验证域名所属关系 1.到域名管理控制台中选择云解析DNS, 选择域名，添加“记录”，记录类型选择‘TXT’，主机记录及记录值填写证书申请方提供内容。 2.等待1分钟或10分钟后，等待生效 3.点击验证 三、证书下载 验证通过后，下载网站提供证书，含（CA证书、服务器证书、服务器私钥） 四、Apache2部署开启SSL加密 更改httpd.conf 文件设置： 1.Listen {内网IP}:80 2.开启models (1)LoadModule ssl_module modules/mod_ssl.so (2)LoadModule socache_shmcb_module modules/mod_socache_shmcb.so (3)LoadModule rewrite_module modules/mod_rewrite.so (4)ServerName {与域名相同}（未测试是否必须相同） 3.http跳转到https: (1)RewriteEngine on (2)RewriteCond %{SERVER_PORT} !^443$ (3)RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] 更改extra/httpd-ssl.conf 文件设置 1.Listen 443 2.ServerName www.lejinrong.cn 3.ServerAdmin admin@lejinrong 4.SSLCertificateFile \u0026ldquo;c:/Apache24/conf/ssl/server.crt\u0026rdquo; 5.SSLCertificateKeyFile \u0026ldquo;c:/Apache24/conf/ssl/server.key\u0026rdquo; 第四步中crt文件指向服务器证书文件， 第五步中.key文件指向私钥文件 (其余部署方案或许有所不同，会使用CA证书)\n1.1 注意： 确保服务器中防火墙入站规则中添加了80端口和443端口。\n2 附： 2.1.1 本地测试方案：\n环境：wamp Apache 2.4.9 前言：wamp安装好后，默认的只有http服务，以下配置启用https服务 条件：在Apache安装目录下需要有一下文件 [Apache安装目录]/modules/ mod_ssl.so [Apache安装目录]/bin/ openssl.exe, libeay32.dll, ssleay32.dll [Apache安装目录]/conf/ openssl.cnf 步骤： 一、修改配置文件httpd.conf，去掉下面行首的#（载入ssl模块和其他配置文件） LoadModule socache_shmcb_module modules/mod_socache_shmcb.so LoadModule ssl_module modules/mod_ssl.so Include conf/extra/httpd-ssl.conf 二、认证文件生成（生成证书签发请求） 进入Apache安装目录的bin目录下，输入cmd，进入DOS窗口，输入以下命令 openssl req -new -out server.csr -config ../conf/openssl.cnf 回车后提示输入密码和确认密码，本机输入：keypasswd 后面会提示输入一系列的参数 \u0026hellip;\u0026hellip; Country Name (2 letter code) [AU]: （要求输入国家缩写，只能输入2个字母，这里输入cn） State or Province Name (full name) [Some-State]: （要求输入州名或省名，这里输入hubei） Locality Name (eg, city) []: （要求输入城市名，这里输入wuhan） Organization Name (eg, company) [Internet Widgits Pty Ltd]: （要求输入组织名或公司名，这里输入gg） Organizational Unit Name (eg, section) []: （要求输入部门名，这里输入gg） Common Name (eg, YOUR name) []: （要求输入服务器域名或IP地址） Email Address []: （要求输入邮件地址） A challenge password[]:（要求输入密码） An optional company name[]（要求输入公司别名，这里输入ggs） \u0026hellip;.. 生成私钥，在DOS窗口下的Apache的bin目录下输入命令 openssl rsa -in privkey.pem -out server.key 然后要求输入之前 privkey.pem 的密码（keypasswd) 创建证书，输入命令 openssl x509 -in server.csr -out server.crt -req -signkey server.key -days 8000 回车后，显示创建成功，有效期为 8000 天 将Apache的bin目录下的server.csr、server.crt、server.key拷贝到Apache安装目录下的conf\\ssl，若没有ssl文件则创建 打开Apache安装目录conf/extra/httpd-ssl.conf文件，设置SSLCertificateFile和SSLCertificateKeyFile SSLCertificateFile \u0026ldquo;C:/apache2.4.9/conf/ssl/server.crt\u0026rdquo; SSLCertificateKeyFile \u0026ldquo;C:/apache2.4.9/conf/ssl/server.key\u0026rdquo; 最后重启Apache服务，HTTPS服务的默认监听端口为443 随后在本机中安装server.crt至收信人的根证书颁发机构即可不再提示证书无效 注意：在重启Apache时，若Apache服务启动不起来，则在Apache安装目录的bin目录下，输入httpd –t，可以根据提示来修改你的配置文件\n附 # 现在是2018年8月25日16点01分 所以上面其实是一个月前写给别人看的文档。 在我搜的时候由于先在本地配置，尔后再网上找CA发证书，自我感觉这个步骤没有什么问题。就今天在\nApache配置双网站/https # 的时候，也是这样，先在本地通过不同端口测试，确定方案之后再在服务器上通过ServerName进行区分。 也就是启用httpd-vhosts.conf之后，再\n# Virtual Hosts # # Required modules: mod_log_config # If you want to maintain multiple domains/hostnames on your # machine you can setup VirtualHost containers for them. Most configurations # use only name-based virtual hosts so the server doesn\u0026#39;t need to worry about # IP addresses. This is indicated by the asterisks in the directives below. # # Please see the documentation at # \u0026lt;URL:http://httpd.apache.org/docs/2.4/vhosts/\u0026gt; # for further details before you try to setup virtual hosts. # # You may use the command line option \u0026#39;-S\u0026#39; to verify your virtual host # configuration. # # VirtualHost example: # Almost any Apache directive may go into a VirtualHost container. # The first VirtualHost section is used for all requests that do not # match a ServerName or ServerAlias in any \u0026lt;VirtualHost\u0026gt; block. # \u0026lt;VirtualHost 192.168.1.81:80\u0026gt; ServerName www.lejinrong.cn ServerAlias www.lejinrong.cn ServerAdmin www.lejinrong.cn #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; RewriteEngine on RewriteCond %{SERVER_PORT} !^400$ RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] ErrorLog \u0026#34;logs/dummy-host.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/dummy-host.example.com-access.log\u0026#34; common \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.81:8880\u0026gt; ServerName lejinrong.cn ServerAlias vip.lejinrong.cn ServerAdmin vip.lejinrong.cn #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; ErrorLog \u0026#34;logs/dummy-host.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/dummy-host.example.com-access.log\u0026#34; common RewriteEngine on RewriteCond %{SERVER_PORT} !^443$ RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] \u0026lt;/VirtualHost\u0026gt; 同理，在httpd-ssl.conf中也是通过配置不同VirtualHost进行区分\n# # This is the Apache server configuration file providing SSL support. # It contains the configuration directives to instruct the server how to # serve pages over an https connection. For detailed information about these # directives see \u0026lt;URL:http://httpd.apache.org/docs/2.4/mod/mod_ssl.html\u0026gt; # # Do NOT simply read the instructions in here without understanding # what they do. They\u0026#39;re here only as hints or reminders. If you are unsure # consult the online docs. You have been warned. # # Required modules: mod_log_config, mod_setenvif, mod_ssl, # socache_shmcb_module (for default value of SSLSessionCache) # # Pseudo Random Number Generator (PRNG): # Configure one or more sources to seed the PRNG of the SSL library. # The seed data should be of good random quality. # WARNING! On some platforms /dev/random blocks if not enough entropy # is available. This means you then cannot use the /dev/random device # because it would lead to very long connection times (as long as # it requires to make more entropy available). But usually those # platforms additionally provide a /dev/urandom device which doesn\u0026#39;t # block. So, if available, use this one instead. Read the mod_ssl User # Manual for more details. # #SSLRandomSeed startup file:/dev/random 512 #SSLRandomSeed startup file:/dev/urandom 512 #SSLRandomSeed connect file:/dev/random 512 #SSLRandomSeed connect file:/dev/urandom 512 # # When we also provide SSL we have to listen to the # standard HTTP port (see above) and to the HTTPS port # Listen 443 Listen 400 #ServerName www.lejinrong.cn ## ## SSL Global Context ## ## All SSL configuration in this context applies both to ## the main server and all SSL-enabled virtual hosts. ## # SSL Cipher Suite: # List the ciphers that the client is permitted to negotiate, # and that httpd will negotiate as the client of a proxied server. # See the OpenSSL documentation for a complete list of ciphers, and # ensure these follow appropriate best practices for this deployment. # httpd 2.2.30, 2.4.13 and later force-disable aNULL, eNULL and EXP ciphers, # while OpenSSL disabled these by default in 0.9.8zf/1.0.0r/1.0.1m/1.0.2a. SSLCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES SSLProxyCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES # By the end of 2016, only TLSv1.2 ciphers should remain in use. # Older ciphers should be disallowed as soon as possible, while the # kRSA ciphers do not offer forward secrecy. These changes inhibit # older clients (such as IE6 SP2 or IE8 on Windows XP, or other legacy # non-browser tooling) from successfully connecting. # # To restrict mod_ssl to use only TLSv1.2 ciphers, and disable # those protocols which do not support forward secrecy, replace # the SSLCipherSuite and SSLProxyCipherSuite directives above with # the following two directives, as soon as practical. # SSLCipherSuite HIGH:MEDIUM:!SSLv3:!kRSA # SSLProxyCipherSuite HIGH:MEDIUM:!SSLv3:!kRSA # User agents such as web browsers are not configured for the user\u0026#39;s # own preference of either security or performance, therefore this # must be the prerogative of the web server administrator who manages # cpu load versus confidentiality, so enforce the server\u0026#39;s cipher order. SSLHonorCipherOrder on # SSL Protocol support: # List the protocol versions which clients are allowed to connect with. # Disable SSLv3 by default (cf. RFC 7525 3.1.1). TLSv1 (1.0) should be # disabled as quickly as practical. By the end of 2016, only the TLSv1.2 # protocol or later should remain in use. SSLProtocol all -SSLv3 SSLProxyProtocol all -SSLv3 # Pass Phrase Dialog: # Configure the pass phrase gathering process. # The filtering dialog program (`builtin\u0026#39; is an internal # terminal dialog) has to provide the pass phrase on stdout. SSLPassPhraseDialog builtin # Inter-Process Session Cache: # Configure the SSL Session Cache: First the mechanism # to use and second the expiring timeout (in seconds). #SSLSessionCache \u0026#34;dbm:c:/Apache24/logs/ssl_scache\u0026#34; SSLSessionCache \u0026#34;shmcb:c:/Apache24/logs/ssl_scache(512000)\u0026#34; SSLSessionCacheTimeout 300 # OCSP Stapling (requires OpenSSL 0.9.8h or later) # # This feature is disabled by default and requires at least # the two directives SSLUseStapling and SSLStaplingCache. # Refer to the documentation on OCSP Stapling in the SSL/TLS # How-To for more information. # # Enable stapling for all SSL-enabled servers: #SSLUseStapling On # Define a relatively small cache for OCSP Stapling using # the same mechanism that is used for the SSL session cache # above. If stapling is used with more than a few certificates, # the size may need to be increased. (AH01929 will be logged.) #SSLStaplingCache \u0026#34;shmcb:c:/Apache24/logs/ssl_stapling(32768)\u0026#34; # Seconds before valid OCSP responses are expired from the cache #SSLStaplingStandardCacheTimeout 3600 # Seconds before invalid OCSP responses are expired from the cache #SSLStaplingErrorCacheTimeout 600 ## ## SSL Virtual Host Context ## \u0026lt;VirtualHost 192.168.1.81:400\u0026gt; # General setup for the virtual host DocumentRoot \u0026#34;c:/Apache24/htdocs\u0026#34; ServerName www.lejinrong.cn ServerAdmin admin@lejinrong.cn ErrorLog \u0026#34;c:/Apache24/logs/error.log\u0026#34; TransferLog \u0026#34;c:/Apache24/logs/access.log\u0026#34; # SSL Engine Switch: # Enable/Disable SSL for this virtual host. SSLEngine on # Server Certificate: # Point SSLCertificateFile at a PEM encoded certificate. If # the certificate is encrypted, then you will be prompted for a # pass phrase. Note that a kill -HUP will prompt again. Keep # in mind that if you have both an RSA and a DSA certificate you # can configure both in parallel (to also allow the use of DSA # ciphers, etc.) # Some ECC cipher suites (http://www.ietf.org/rfc/rfc4492.txt) # require an ECC certificate which can also be configured in # parallel. SSLCertificateFile \u0026#34;c:/Apache24/conf/ssl/server.crt\u0026#34; #SSLCertificateFile \u0026#34;c:/Apache24/conf/server-dsa.crt\u0026#34; #SSLCertificateFile \u0026#34;c:/Apache24/conf/server-ecc.crt\u0026#34; # Server Private Key: # If the key is not combined with the certificate, use this # directive to point at the key file. Keep in mind that if # you\u0026#39;ve both a RSA and a DSA private key you can configure # both in parallel (to also allow the use of DSA ciphers, etc.) # ECC keys, when in use, can also be configured in parallel SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/ssl/server.key\u0026#34; #SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/server-dsa.key\u0026#34; #SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/server-ecc.key\u0026#34; # Server Certificate Chain: # Point SSLCertificateChainFile at a file containing the # concatenation of PEM encoded CA certificates which form the # certificate chain for the server certificate. Alternatively # the referenced file can be the same as SSLCertificateFile # when the CA certificates are directly appended to the server # certificate for convenience. #SSLCertificateChainFile \u0026#34;c:/Apache24/conf/server-ca.crt\u0026#34; # Certificate Authority (CA): # Set the CA certificate verification path where to find CA # certificates for client authentication or alternatively one # huge file containing all of them (file must be PEM encoded) # Note: Inside SSLCACertificatePath you need hash symlinks # to point to the certificate files. Use the provided # Makefile to update the hash symlinks after changes. #SSLCACertificatePath \u0026#34;c:/Apache24/conf/ssl.crt\u0026#34; #SSLCACertificateFile \u0026#34;c:/Apache24/conf/ssl.crt/ca-bundle.crt\u0026#34; # Certificate Revocation Lists (CRL): # Set the CA revocation path where to find CA CRLs for client # authentication or alternatively one huge file containing all # of them (file must be PEM encoded). # The CRL checking mode needs to be configured explicitly # through SSLCARevocationCheck (defaults to \u0026#34;none\u0026#34; otherwise). # Note: Inside SSLCARevocationPath you need hash symlinks # to point to the certificate files. Use the provided # Makefile to update the hash symlinks after changes. #SSLCARevocationPath \u0026#34;c:/Apache24/conf/ssl.crl\u0026#34; #SSLCARevocationFile \u0026#34;c:/Apache24/conf/ssl.crl/ca-bundle.crl\u0026#34; #SSLCARevocationCheck chain # Client Authentication (Type): # Client certificate verification type and depth. Types are # none, optional, require and optional_no_ca. Depth is a # number which specifies how deeply to verify the certificate # issuer chain before deciding the certificate is not valid. #SSLVerifyClient require #SSLVerifyDepth 10 # TLS-SRP mutual authentication: # Enable TLS-SRP and set the path to the OpenSSL SRP verifier # file (containing login information for SRP user accounts). # Requires OpenSSL 1.0.1 or newer. See the mod_ssl FAQ for # detailed instructions on creating this file. Example: # \u0026#34;openssl srp -srpvfile c:/Apache24/conf/passwd.srpv -add username\u0026#34; #SSLSRPVerifierFile \u0026#34;c:/Apache24/conf/passwd.srpv\u0026#34; # Access Control: # With SSLRequire you can do per-directory access control based # on arbitrary complex boolean expressions containing server # variable checks and other lookup directives. The syntax is a # mixture between C and Perl. See the mod_ssl documentation # for more details. #\u0026lt;Location /\u0026gt; #SSLRequire ( %{SSL_CIPHER} !~ m/^(EXP|NULL)/ \\ # and %{SSL_CLIENT_S_DN_O} eq \u0026#34;Snake Oil, Ltd.\u0026#34; \\ # and %{SSL_CLIENT_S_DN_OU} in {\u0026#34;Staff\u0026#34;, \u0026#34;CA\u0026#34;, \u0026#34;Dev\u0026#34;} \\ # and %{TIME_WDAY} \u0026gt;= 1 and %{TIME_WDAY} \u0026lt;= 5 \\ # and %{TIME_HOUR} \u0026gt;= 8 and %{TIME_HOUR} \u0026lt;= 20 ) \\ # or %{REMOTE_ADDR} =~ m/^192\\.76\\.162\\.[0-9]+$/ #\u0026lt;/Location\u0026gt; # SSL Engine Options: # Set various options for the SSL engine. # o FakeBasicAuth: # Translate the client X.509 into a Basic Authorisation. This means that # the standard Auth/DBMAuth methods can be used for access control. The # user name is the `one line\u0026#39; version of the client\u0026#39;s X.509 certificate. # Note that no password is obtained from the user. Every entry in the user # file needs this password: `xxj31ZMTZzkVA\u0026#39;. # o ExportCertData: # This exports two additional environment variables: SSL_CLIENT_CERT and # SSL_SERVER_CERT. These contain the PEM-encoded certificates of the # server (always existing) and the client (only existing when client # authentication is used). This can be used to import the certificates # into CGI scripts. # o StdEnvVars: # This exports the standard SSL/TLS related `SSL_*\u0026#39; environment variables. # Per default this exportation is switched off for performance reasons, # because the extraction step is an expensive operation and is usually # useless for serving static content. So one usually enables the # exportation for CGI and SSI requests only. # o StrictRequire: # This denies access when \u0026#34;SSLRequireSSL\u0026#34; or \u0026#34;SSLRequire\u0026#34; applied even # under a \u0026#34;Satisfy any\u0026#34; situation, i.e. when it applies access is denied # and no other module can change it. # o OptRenegotiate: # This enables optimized SSL connection renegotiation handling when SSL # directives are used in per-directory context. #SSLOptions +FakeBasicAuth +ExportCertData +StrictRequire \u0026lt;FilesMatch \u0026#34;\\.(cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory \u0026#34;c:/Apache24/cgi-bin\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; # SSL Protocol Adjustments: # The safe and default but still SSL/TLS standard compliant shutdown # approach is that mod_ssl sends the close notify alert but doesn\u0026#39;t wait for # the close notify alert from client. When you need a different shutdown # approach you can use one of the following variables: # o ssl-unclean-shutdown: # This forces an unclean shutdown when the connection is closed, i.e. no # SSL close notify alert is sent or allowed to be received. This violates # the SSL/TLS standard but is needed for some brain-dead browsers. Use # this when you receive I/O errors because of the standard approach where # mod_ssl sends the close notify alert. # o ssl-accurate-shutdown: # This forces an accurate shutdown when the connection is closed, i.e. a # SSL close notify alert is send and mod_ssl waits for the close notify # alert of the client. This is 100% SSL/TLS standard compliant, but in # practice often causes hanging connections with brain-dead browsers. Use # this only for browsers where you know that their SSL implementation # works correctly. # Notice: Most problems of broken clients are also related to the HTTP # keep-alive facility, so you usually additionally want to disable # keep-alive for those clients, too. Use variable \u0026#34;nokeepalive\u0026#34; for this. # Similarly, one has to force some clients to use HTTP/1.0 to workaround # their broken HTTP/1.1 implementation. Use variables \u0026#34;downgrade-1.0\u0026#34; and # \u0026#34;force-response-1.0\u0026#34; for this. BrowserMatch \u0026#34;MSIE [2-5]\u0026#34; \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 # Per-Server Logging: # The home of a custom SSL log file. Use this when you want a # compact non-error SSL logfile on a virtual host basis. CustomLog \u0026#34;c:/Apache24/logs/ssl_request.log\u0026#34; \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b\u0026#34; #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.81:443\u0026gt; DocumentRoot \u0026#34;c:/Apache24/htdocs\u0026#34; ServerName www.lejinrong.cn ServerAdmin admin@lejinrong.cn ErrorLog \u0026#34;c:/Apache24/logs/error.log\u0026#34; TransferLog \u0026#34;c:/Apache24/logs/access.log\u0026#34; SSLEngine on SSLCertificateFile \u0026#34;c:/Apache24/conf/ssl/server.crt\u0026#34; SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/ssl/server.key\u0026#34; \u0026lt;FilesMatch \u0026#34;\\.(cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory \u0026#34;c:/Apache24/cgi-bin\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; BrowserMatch \u0026#34;MSIE [2-5]\u0026#34; \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 CustomLog \u0026#34;c:/Apache24/logs/ssl_request.log\u0026#34; \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b\u0026#34; WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/Fund_Evaluation_System/wsgi.py Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; 但其实 都写了跳转，所以在httpd-vhosts.conf文件中的项目以及静态资源路径指定就不用指定了，只不过我懒得删… 还有一个坑点就是 原本有一个指定项目路径以及python环境的语句：\n#WSGIPythonPath \u0026#34;C:/Python27/Lib;C:/Python27/Lib/site-packages;C:/Python27/DLLs\u0026#34; #WSGIPythonPath D:/FundEvaluationSystem_svn1 #WSGIPythonHome \u0026#34;C:/Python27\u0026#34; 我不知道按照上下这两种为什么会出问题，但网上那些人不会。但中间那个是用来指向项目路径的一个取巧的办法。哦因为wsgi或许我已经在别处制订过了。所以只要在wsgi.py中声明sys.path.append('D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2')就可以将项目包括进来，而不需要通过 第二句那个制定python路径的东西。而用那个，会导致资源只有声明的项目1会被加载，而项目2的资源就不会声明，而将那三句话注释，只要分别在\u0026rsquo;wsgi.py\u0026rsquo;中声明项目资源，而在.conf文件中指向\u0026rsquo;wsgi.py\u0026rsquo;文件就可以如数加载了。\n(⊙﹏⊙)语序 逻辑混乱之后不加班了再整理吧~~😭\n前端 Vue # vue的使用方式可以通过html页面直接引用，也能直接用vue-cil创建项目。 网上人称vue脚手架？晓不大得 而我这里自然说的就是 vue-cil即 通过vue init webpack \u0026lt;prjName\u0026gt;来生成的项目喽\n系统的创建以及介绍之后使用再熟一些再写，现在先记一些零散的东西。 [^_^]2018年9月18日 21点36分\n路由配置登陆访问 # 在`router/index.js`中： { path: \u0026#39;/\u0026#39;, // 首页 name: \u0026#39;Main\u0026#39;, component: Main, meta: { requireAuth: true, // 添加该字段，表示进入这个路由是需要登录的 } }, "},{"id":85,"href":"/docs/programmer/langs/golang/note-of-golang/","title":"Golang笔记","section":"Golang","content":" Golang笔记 # 先贴一个客观的教程文档网站http://www.runoob.com/go/go-slice.html\n垃圾回收 # 常见的回收算法 # 引用计数 优点：对象可以被很快回收 缺点：不太好处理循环引用 标记-清除 优点：解决了引用计数的缺点 缺点：需要 STW(Stop The World),暂时停止程序运行 分代收集(按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，段的放入新生代，不同代有不同的回收算法和回收频率) 优点：回收性能好 缺点：算法复杂 三色标记法(初始状态：白色、从根节点开始遍历，遍历到的变成灰色，遍历灰色，将灰色引用的标记灰色，遍历过的灰色对象变为黑色。循环遍历灰色对象。通过写屏障检测对象的变化，重复。收集所有白色对象(垃圾)) GPM调度和CSP模型 # CSP 模型？ # CSP 模型是“以通信的方式来共享内存”，不同于传统的多线程通 过共享内存来通信。用于描述两个独立的并发实体通过共享的通 讯 channel (管道)进行通信的并发模型。\nGPM 分别是什么、分别有多少数量？ # • G（Goroutine）： 即Go协程，每个go关键字都会创建一个协 程。 • M（Machine）：工作线程，在Go中称为Machine，数量对应真 实的CPU数（真正干活的对象）。 • P（Processor）： 处理器（Go中定义的一个摡念，非CPU）， 包含运行Go代码的必要资源，用来调度 G 和 M 之间的关联关 系，其数量可通过 GOMAXPROCS() 来设置，默认为核心数。 M必须拥有P才可以执行G中的代码，P含有一个包含多个G的队 列，P可以调度G交由M执行。\nGoroutine调度策略 # • 队列轮转：P 会周期性的将G调度到M中执行，执行一段时间 后，保存上下文，将G放到队列尾部，然后从队列中再取出一个 G进行调度。除此之外，P还会周期性的查看全局队列是否有G等 待调度到M中执行。 • 系统调用：当G0即将进入系统调用时，M0将释放P，进而某个空 闲的M1获取P，继续执行P队列中剩下的G。M1的来源有可能是 M的缓存池，也可能是新建的。 当G0系统调用结束后，如果有空闲的P，则获取一个P，继续执 行G0。如果没有，则将G0放入全局队列，等待被其他的P调度。 然后M0将进入缓存池睡眠。 ![[goroutine.png]]\nCHAN 原理 # 结构体 # type hchan struct { qcount uint // 队列中的总元素个数 dataqsiz uint // 环形队列大小，即可存放元素的个数 buf unsafe.Pointer // 环形队列指针 elemsize uint16 //每个元素的大小 closed uint32 //标识关闭状态 elemtype *_type // 元素类型 sendx uint // 发送索引，元素写入时存放到队列中的位置 recvx uint // 接收索引，元素从队列的该位置读出 recvq waitq // 等待读消息的goroutine队列 sendq waitq // 等待写消息的goroutine队列 lock mutex //互斥锁，chan不允许并发读写 } 读写流程 # 向 channel 写数据: # 若等待接收队列 recvq 不为空，则缓冲区中无数据或无缓冲区，将直接从 recvq 取出 G ，并把数据写入，最后把该 G 唤醒，结束发送过程。 若缓冲区中有空余位置，则将数据写入缓冲区，结束发送过程。 若缓冲区中没有空余位置，则将发送数据写入 G，将当前 G 加入sendq ，进入睡眠，等待被读 goroutine 唤醒。 从 channel 读数据 # 若等待发送队列 sendq 不为空，且没有缓冲区，直接从 sendq中取出 G ，把 G 中数据读出，最后把 G 唤醒，结束读取过程。 如果等待发送队列 sendq 不为空，说明缓冲区已满，从缓冲区中首部读出数据，把 G 中数据写入缓冲区尾部，把 G 唤醒，结束读取过程。 如果缓冲区中有数据，则从缓冲区取出数据，结束读取过程。 将当前 goroutine 加入 recvq ，进入睡眠，等待被写 goroutine唤醒。 关闭 channel # 关闭 channel 时会将 recvq 中的 G 全部唤醒，本该写入 G 的数据位置为 nil。将 sendq 中的 G 全部唤醒，但是这些 G 会panic。 panic 出现的场景还有： # 关闭值为 nil 的 channel 关闭已经关闭的 channel 向已经关闭的 channel 中写数据 无缓冲 Chan 的发送和接收是否同步? # // 无缓冲的channel由于没有缓冲发送和接收需要同步 ch := make(chan int) //有缓冲channel不要求发送和接收操作同步 ch := make(chan int, 2) channel 无缓冲时，发送阻塞直到数据被接收，接收阻塞直到读 到数据；channel有缓冲时，当缓冲满时发送阻塞，当缓冲空时接 收阻塞。\ncontext 结构原理 # 用途 # Context（上下文）是Golang应用开发常用的并发控制技术 ，它 可以控制一组呈树状结构的goroutine，每个goroutine拥有相同的 上下文。Context 是并发安全的，主要是用于控制多个协程之间 的协作、取消操作。\n数据结构 # Context 只定义了接口，凡是实现该接口的类都可称为是一种context。\ntype Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key interface{}) interface{} } 「Deadline」 方法：可以获取设置的截止时间，返回值 deadline是截止时间，到了这个时间，Context 会自动发起取消请求，返回值 ok 表示是否设置了截止时间。 「Done」 方法：返回一个只读的 channel ，类型为 struct{}。如果这个 chan 可以读取，说明已经发出了取消信号，可以做清理操作，然后退出协程，释放资源。 「Err」 方法：返回Context 被取消的原因。 「Value」 方法：获取 Context 上绑定的值，是一个键值对，通过 key 来获取对应的值。 竞态、内存逃逸 # 竞态 # 资源竞争，就是在程序中，同一块内存同时被多个 goroutine 访问。我们使用 go build、go run、go test 命令时，添加 -race 标识可以检查代码中是否存在资源竞争。解决这个问题，我们可以给资源进行加锁，让其在同一时刻只能被一个协程来操作。\nsync.Mutex sync.RWMutex 逃逸分析 # 「逃逸分析」就是程序运行时内存的分配位置(栈或堆)，是由编译器来确定的。堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。\n逃逸场景： # 指针逃逸 栈空间不足逃逸 动态类型逃逸 闭包引用对象逃逸 并发 Channel # 使用关键字go开启goroutine 轻量级线程 代码\ngo fun_name(paras_list) # eg: go f(x, y, z) package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func say(s string) { for i := 0; i \u0026lt; 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) } } func main() { go say(\u0026#34;world\u0026#34;) say(\u0026#34;hello\u0026#34;) } Channel # 用于传递数据的数据结构 可用于两个goroutine之间传递指定类型值，同步和通讯 \u0026lt;- 指定通道方向(发送or接受)，未指定则双向通道\n声明通道 # 使用chan关键字, 在使用之前，需先创建.\nch := make(chan int) // 示例 package main import \u0026#34;fmt\u0026#34; func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c \u0026lt;- sum // 把 sum 发送到通道 c } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := \u0026lt;-c, \u0026lt;-c // 从通道 c 中接收 fmt.Println(x, y, x+y) } Cache-有缓冲通道 # 在创建通道时可创建缓冲区，做压入存储\nch := make(chan int, 100) // cache size // 示例 package main import \u0026#34;fmt\u0026#34; func main() { // 这里我们定义了一个可以存储整数类型的带缓冲通道 // 缓冲区大小为2 ch := make(chan int, 2) // 因为 ch 是带缓冲的通道，我们可以同时发送两个数据 // 而不用立刻需要去同步读取数据 ch \u0026lt;- 1 ch \u0026lt;- 2 // 获取这两个数据 fmt.Println(\u0026lt;-ch) fmt.Println(\u0026lt;-ch) } go的循环 # golang 只有for while==for golang 中没有小括号包裹, 只需要用{}分隔作用域就可以 for 可以有\nfor A;B;C {} for ;B; {} for {} go的switch # 每个case自动break fallthrough 显式声明可以继续执行下一个case case 无需常量 switch {case} 可做 if-else 用 go的指针 # go的指针 没有指针运算.\n函数定义 # func function_name([参数列表])[返回类型]{ balabala } 如：\nfunc Divide(varDividee int, varDivider int) (result int, errorMsg string) { if varDivider == 0 { dData := DivideError{ dividee: varDividee, divider: varDivider, } errorMsg = dData.Error() return } else { return varDividee / varDivider, \u0026#34;\u0026#34; } } 接口 # package main import ( \u0026#34;fmt\u0026#34; ) # 或者 直接 import \u0026#34;fmt\u0026#34; type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\u0026#34;I am Nokia, I can call you!\u0026#34;) } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\u0026#34;I am iPhone, I can call you!\u0026#34;) } func main() { var phone Phone phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } 错误 # package main import ( \u0026#34;fmt\u0026#34; ) // 定义一个 DivideError 结构 type DivideError struct { dividee int divider int } // 实现 `error` 接口 func (de *DivideError) Error() string { // 以上函数中，取结构体地址是（等同于面向对象实例化对象吧，然后下方可以 // de.使用.的方式去调取结构体中定义的某变量） //错误Error()是调用接口中的函数，制定返回类型为string strFormat := ` Cannot proceed, the divider is zero. dividee: %d divider: 0 ` return fmt.Sprintf(strFormat, de.dividee) } // 定义 `int` 类型除法运算的函数 func Divide(varDividee int, varDivider int) (result int, errorMsg string) { if varDivider == 0 { dData := DivideError{ dividee: varDividee, divider: varDivider, } errorMsg = dData.Error() return } else { return varDividee / varDivider, \u0026#34;\u0026#34; } } func main() { // 正常情况 if result, errorMsg := Divide(100, 10); errorMsg == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;100/10 = \u0026#34;, result) } // 当被除数为零的时候会返回错误信息 if _, errorMsg := Divide(100, 0); errorMsg != \u0026#34;\u0026#34; { fmt.Println(\u0026#34;errorMsg is: \u0026#34;, errorMsg) } } 以上总结 # 函数定义真是… 也或许刚开始接触太多。也不知道这么设计的目的 其中 功能重写见d.Data.Error。先是将d.Data定义为结构体，然后再去调用结构体下的Error，分明结构体里并没有定义，所以下面的那个函数定然是将Error,与DicideError连接的函数。\n所以Go并没有类与对象一说吧…\n生动点来说那个函数（func (de *DivideError) Error() string {...}）的定义就好像是在强行给这个地址的结构体中塞进去一个执行函数。 一个言简意骇的对象实现方法\n附录 # 快问快答 # 1. go 中除了加 Mutex 锁以外还有哪些方式安全读写共享变量？ # Go 中 Goroutine 可以通过 Channel 进行安全读写共享变量。\n2. golang中new和make的区别？ # make 仅用来分配及初始化类型为 slice、map、chan 的数据。 new 可分配任意类型的数据，根据传入的类型申请一块内存，返回指向这块内存的指针，即类型 *Type。 make 返回引用，即 Type，new 分配的空间被清零， make 分配空间后，会进行初始。 3. Go中对nil的Slice和空Slice的处理是一致的吗? # 首先Go的JSON 标准库对 nil slice 和 空 slice 的处理是不一致。\nslice := make([]int,0）：slice不为nil，但是slice没有值，slice的底层的空间是空的。 slice := []int{} ：slice的值是nil，可用于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回值。 4. 协程和线程和进程的区别？ # 进程: # 进程是具有一定独立功能的程序，进程是系统资源分配和调度的最小单位。 每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n线程: # 线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n协程: # 协程是一种用户态的轻量级线程，协程的调度完全是由用户来控制的。协程拥有自己的寄存器上下文和栈。 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\nGolang的内存模型中为什么小对象多了会造成GC压力？ # 通常小对象过多会导致GC三色法消耗过多的CPU。优化思路是，减少对象分配。\nVim 高亮 # emmmm，偶尔会有不支持Go高亮的情况 所以，步骤如下：\ncd ~ mkdir .vim cd .vim mkdir autoload plugged cd plugged git clone https://github.com/fatih/vim-go vim-go cd autoload wget https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 配置 .vimrc\nvim ~/.vimrc set shiftwidth=4 softtabstop=4 expandtab call plug#begin() Plug \u0026#39;fatih/vim-go\u0026#39;, { \u0026#39;do\u0026#39;: \u0026#39;:GoInstallBinaries\u0026#39; } call plug#end() let g:go_version_warning = 0 over~! "},{"id":86,"href":"/docs/programmer/gui/vn.py%E7%AC%94%E8%AE%B0-%E4%BA%A4%E6%98%93%E5%B9%B3%E5%8F%B0%E5%AE%A2%E6%88%B7%E7%AB%AF/","title":"Vn.Py学习笔记（Python交易平台框架）","section":"图形用户界面-GUI","content":"author: Ian\nVn.Py笔记 ✏📔 # # 一个开源Python交易软件，主使用CTP协议。当然，还有其他协议了其源项目在http://www.vnpy.org/ 初期笔记 # 报单交易过程中， CTP使用BrokerID 从业务层面完全隔离不同经纪公司的交易、风控及结算用户的接入。 BrokerID具体取值咨询开户的经纪公司。 CTP中 UserID为操作员代码，InversterID为投资者代码； 投资者自己下单两者同为投资者代码\nCTP-API中，OrderRef和OrderAction 前者为CTP后台提供给客户端标识一笔报 单的字段，从客户端可通过（FrontID、SessionID、OrderRef）唯一确定一笔报 单；；；后者与OrderRef功能相似，提供给客户端来标识一笔撤单。 前者的数据类型为字符数组，必须为阿拉伯数字字符。 OrderRef（OrderActionRef）取值必须保证在同一会话内发送的报单 OrderRef（OrderActionRef）值大于之前的最大值，开发多线程客户端尤为需要 注意。 CTP-API库：\nerror.dtd\\error.xml 错误定义文件 ---- ThostFrfcMdApi.h 交易接口类定义文件 ——— ThostFtfcUserApiDataType.h 类型定义文件 ------ thostmduserapi.lib,thostmduserpi.dll 行情接口库文件 ----- thosttraderapi.lib,thosttraderapi.dll交易接口库文件 ----- 交易和行情接口类定义文件都包含API 和 SPI类定义，客户端使用API向CTP后台 发送请求，CTP后台则使用SPI向客户端回传响应及回报 行情Demo开发： 1.将API文件复制到工程目录；并将所有的头文件和静态、动态库连链接库 并将文件导入到项目工程中。 先继承行情接口类CThostFtdcMdspi，并实现需要实现的虚函数。 OnFrontConnectde、OnFrontDisconnected、OnPspUserLogin、 OnRspSubMarketDAta /API工作流程***/\nAPI压缩包——API含常量对应字符、类型定义、操作系统编译定义、回调函数（MdSpi）（柜台向用户端发送信息后被系统自动调用的函数）、主动函数（MdApi）（向柜台发送各种请求和指令）\nAPI工作流程： 创建MdSpi对象（回掉函数），调用MdApi类，以Create开头的静态方法，创建MdApi对象（主动函数），注册MdSpi对象指针，行情柜台前置机地址，调用MdApi对象Init方法初始化连接前置机，连接成功会通过OnFrontConnected回调通知用户，用户获得连接成功通知后，调MdApi的ReqUserLogin登陆，登陆后MdSpi的OnRsqUserLogin通知用户 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-到此登陆完成\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nMdApi：（行情相关） 使用MdApi对象的SubscribeMarketData方法，传入参数为想要订阅的“合约 代码”，订阅成功当合约有新行情通过MdApi的OnRtnDepthMarketData回调通知 用户 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-至此订阅完成\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 当用户的某次请求发生错误时，会通过OnRspError通知用户 MdApi也含有退订合约、登出功能。 而一般退出程序则直接杀进程（不太安全便是）\nTraderApi：（交易相关） 不同于以上的有 注册TraderSpi对象的指针后需要调用TraderApi对象的 SubscribePrivateTopic和SubscribePublicTopic方法去选择公开和私有数据流的重 传方法 对于期货柜台，每一日第一次登陆需要先查询前一日的结算单，等待查询 结果返回，确认，才可进行后续操作（CTP、恒生UFT），证券（LTS）无此要求 上一步完成后，用户可以调用ReqQryInstrument的方法查询柜台上所有可 以交易的合约信息（包括代码、中文名、涨跌停、最小价位变动、合约乘数等大 量细节），一般是在这里获得合约信息列表后，再去MdApi中订阅合约；经常有 人问为什么在MdApi中找不到查询可供订阅的合约代码的函数，这里尤其要注 意，必须通过TraderApi来获取 当用户报单、成交状态发生变化时，TraderApi会自动通过OnRtnOrder、 OnRtnTrade通知，无需额外订阅 /封装API****/ 封装后API的动作： 主动函数： 调用封装API主动函数，传入Python变量作为参数—\u0026gt;封装API将Python变量转换成C++变量—\u0026gt;API调用原生API主动函数传入C++变量作为参数 回掉函数： 交易柜台通过原生API传入参数为C++变量-\u0026gt;封装API将C++变量转换为Python变量-\u0026gt;封装API调用封装后的回调函数想Python程序中推送数\n封装处理： 将回调函数Spi类和主动函数Api类封装为一个类，使用中更加方便 在API中包含一个缓冲队列，当回调函数收到新的数据信息时只是简单存入 并立即返回，而数据信息的处理和向Python中的推送则由另一个工作线程执行 鉴于Python中dict字典内的键和值的类型可以不同，所以利用此来代替 C++的结构体 处理示例： getChar()： d(Python字典对象) key(d中想要提取的数据键名) if(d.has_key(key)) 判断是否存在这个键； object o = d[key]; 提取对应值 extract\u0026lt;string\u0026gt; x(o); 生成提取 std::string类的提取器 if (x.check()) 检测能否提取出数据 string s = x(); 执行解包器，提取 string对象 const char *buffer = s.c_str(); 从s中获取字符串指针bufffer strcpy_s(value, strlen(buffer) + 1, buffer); 将字符串指针指向的字符串数组复制到结构体成员的指针上 对字符串指针赋值 必须使用strcpy_s, vs2013使用strcpy 编译通不过+1应该是因为C++字符串的结尾符号？不是特别确定，不加这个 1会出错 /事件驱动***/\n时间驱动： 定时调用 事件驱动： 新事件被推送时（如新行情、成交）则调用 初始化： 事件队列、引擎开关（标志）、事件线程、定时器、一个事件和处理函数对应字典（__handlers） 引擎运行： 循环检查引擎开关 若开则一直尝试获取事件（阻塞开，时间1s），处理事件； 若出错则pass 处理事件： 检测是否有对当前事件监听的处理函数，若有则循环调用相应处理函数对事件进行处理 计时器事件： 创建计时器事件，推入计时器事件 引擎启动： 打开引擎开关、启动事件处理线程、启动定时器（事件默认间隔1s） 停止引擎： 关闭。。。。、停止计时器、等待事件处理线程退出 注册事件处理： 尝试获取对应处理此类型函数列表（对应字典），若无则创建。 注销函数监听： 。。。。。。。。。。。。。。。。。。。。。，若无则pass，若函数存在于列表则将之移除，若函数列表为空，则引擎中移除该事件类型 put： 向事件队列中存入事件\n底层接口对接： 交易程序架构分：底层接口、中层引擎、顶层GUI， 为将某API对接到程序中需：1.将API的回调函数收到的数据—\u0026gt;中层引擎 等待处理 2.将API的主动函数进行一定的简化封装，便于中层引擎调用\n中层引擎设计： 进一步封装底层接口所暴露出的API函数，使得其更容易被上层的GUI和策略组件调用。 构造函数： 以主引擎成员变量形式创建事件驱动引擎ee，行情接口md和交易接口td的对象。 随后立即启动，当用户调用接口连接、登陆等功能、收到事件推送，ee可以立即推送到监听这些事件的组件进行处理。 LTS和CTP接口的持仓情况和账户情况不通过推送，需手动查询。Demo选择循环查询模式，不断更新。可选择不进行查询，降低占用网络带宽。 登陆成功后，查询柜台所有可交易信息，保存到dictInstrument字典中，方便后续查询 优化了一些函数方法的调用方式，将经纪商一起提供的接口登陆封装在一个函数中，减少了重复书写的次数。\n引擎之间执行过程 # 发单为例： # 设置发单按钮 -\u0026gt; 将点按动作关联sendOrder发单实现函数（从输入框获取合约代码-\u0026gt;获取合约信息对象（见下） -\u0026gt; 如果成功获取 -\u0026gt; 再获取方向价格等信息 -\u0026gt; 调用主引擎下发单实现 -\u0026gt; 主引擎转到TdApi下发单函数执行（请求编号（API管理） -\u0026gt; 将传入信息数据存入字典（合约代码、方向价格等） -\u0026gt; 报单编号（API管理） -\u0026gt; 用户id、单子属性（投机、立即发单、今日有效）等信息存入字典） -\u0026gt; self.reqOrderInsert(req（信息字典）, self.__reqid（请求编号）) -\u0026gt; 返回订单号（报单编号））\n主引擎：（负责对API的调度） # init()初始化中的动作： 创建事件驱动引擎、创建API接口、启动事件驱动引擎、循环查询持仓和账户相关（之后学习）、创建合约存储空字典，注册插入合约对象执行函数事件类型和其处理函数。 其中包含几乎所有的功能函数，包含了每个功能函数的实现方法\n事件驱动引擎： # init()初始化中的动作： 创建事件队列、创建设置事件引擎开关（关）、创建事件处理线程(目标为引擎运行)、创建计时器（将超时动作连接到__onTimer函数）、创建__handlers空字典（存储对应事件调用关系） 统筹管理事件的执行，在其中建立起事件执行队列管理向队列中插入事件，分配事件对象类型（据此注册其执行函数）和具体事件数据（时间及日志），拥有注册事件处理监听及注销监听。最终使得整个程序有序的进行。\n调用关系 # 主引擎在初始化时即启动事件驱动引擎（调用启动函数start()（将引擎开关设为启动、启动事件处理线程、启动计时器）） -\u0026gt; 事件处理线程运行目标__run()（若开关开则将从事件队列中get()到事件，放到处理函数__process()中执行） -\u0026gt; __process()处理事件函数（检查事件类型，在__handlers字典中是否有对此监听处理函数，若存在则调用字典中处理函数）\n事件启动引擎start()中启动定时器 -\u0026gt; 创建计时器事件 -\u0026gt; 向队列存入计时器事件 获取合约信息对象： # 从合约字典中读取合约信息对象有则继续执行原本程序操作（获取名称、发单撤单），无则None\n以初始化查询为例： # 主引擎初始化中注册self.ee.register(EVENT_TDLOGIN, self.initGet),EVENT_TDLOGIN为交易服务器登陆成功事件。即此事件为登录成功后开始初始化查询。 步骤：打开设定文件setting.vn，尝试读取设定字典。载入后，设定事件类型、将事件推入事件队列、查询投资者、循环查询账户和持仓。（若不存在or合约数据非今天，则发出获取合约请求。）-\u0026gt; 获取合约 -\u0026gt; 定义事件类型 -\u0026gt; 推入事件队列 -\u0026gt; API查询合约\nctpGateway 接入方法 # 考虑到现阶段大部分CTP中的ExchangeID字段返回的都是空值 vtSymbol直接使用symbol\n创建CTP价格方向交易所持仓产品等类型映射，方便调用 然后 class CtpGateway(VtGateway):CTP接口中初始化动作（继承VtGateway实例化事件引擎、设定网关名称为’CTP‘、实例化ctpMdApi，ctpTdApi、初始化行情交易连接状态，循环查询允许）\n连接过程 初始化账号密码等、连接服务器、注册服务器地址、登陆 订阅合约里有个设计为：尚未登陆就调用了订阅则保存订阅信号，则在成功登陆之后的登陆回报函数中重新订阅\n数据记录器 # drBase.py中（定义数据类型）：（数据记录器和CTA两模块共同使用） # K线数据 构造函数（定义数据类型）：vt系统代码、合约代码、交易所代码、开高低 关、bar开始时间、时间、成交量持仓量 Tick数据 构造函数（定义数据类型）：vt系统代码、合约代码、交易所代码、成交数 据、tick时间、五档行情 DrEngine数据记录引擎 # 获取当前文件绝对路径\nsettingFileName = 'DR_setting.json' path = os.path.abspath(os.path.dirname(__file__)) settingFileName = os.path.join(path, settingFileName) 初始化中动作：实例化设置主引擎、事件引擎、获取当前日期、创建主力合约代码映射字典、Tick对象字典、K线对象字典、初始化数据库插入单独线程、载入设置，订阅行情\n载入设置、订阅行情 # 打开DR_setting.json文件，以json载入，其中’working‘决定是否启动行情记录功能。随后从json文件中循环获取合约代码订阅tick和bar\n启动数据插入线程（run函数（向MongoDB中插入数据））、注册事件监听（procecssTickEvent处理行情推送（下详））\n处理行情推送 # 从事件字典中取出保存的具体事件数据、vtSymbol为tick识别信号（合约代码）、转化Tick格式、更新TIck数据（并发出日志）、更新分钟线数据\n风控模块 # 从配置json文件中读取设定信息 操作运作：1.检测风控设定值变化 2.每笔交易发单时使用风控模块决定该次发单是否允许 （其中流控计数在每次调用风控检测时计数、成交合约量在更新成交数据中加交易数值）\nCTA策略 # 直接来到改版之后：\nCTP交易托管API # 介绍 # 基于C++的类库，通过使用提供接口实现相关交易功能，含：报单与报价录入、的撤销、的挂起、的激活、的修改、的查询、成交单查询、投资者查询、 投资者持仓查询、合约查询、交易日获取等\n含文件：交易接口、API所需数据类型、业务相关数据结构i、的头文件、动态链接库、导入库\n体系结构 # 建立在TCP协议之上FTD协议与交易托管系统进行通讯 FTD通讯模式：\n对话通讯模式 - 会员端请求、接收处理、响应 私有通讯模式 - 交易所主动向特定会员发出 广播通讯模式 - 交易所主动、全员发送 接口模式 # CThostFtdeTraderApi和CThostFtdeTraderSpi，前者发送请求，后者回调响应。旗下函数方法前者以Req开头后者以OnRsp开头。请求接口第一个参数为请求的内容，不能为空。第二个参数为请求号。\n如果接收到的响应数据不止一个，则回调函数会被多次调用。第一个参数为响应的具体数据，第二个参数为处理结果，第三个参数为请求号，第四个参数为响应结束标志，表明是否是本次响应的最后一次回调。\n运行模式 # 至少两个线程，一个为应用程序主线程，一个为交易员API工作线程，其间通讯由API工作线程驱动。\n撤单 发单 # 发单为例： # 在用户点击发单之后，程序从“交易”栏的text()获取合约代码，随后从详细合约保存字典中读取其他信息，将之保存到一个字典中之后，调用主引擎对特定接口发单。\n发单完成之后，马上会收到报单响应 OnRspOrderInsert，说明交易系统已经收到报单。报单进入交易系统后，如果报单的交易状态发生变化，就会收到报单回报 OnRtnOrder。如果报单被撮(部分)成交，就会收到成交回报 OnRtnTrade。通过更新\n撤单时： # 程序从单元格中获取exchange、frontID、orderID、sessionID、symbol、gatewayName等信息，调用主引擎对特定接口撤单。撤单时调用Api函数为reqOrderAction其内容包括撤销、挂起、激活、修改，故还需一个Flag参数\nps：如果报单还停留在 Thost，Thost 可以用 Front 、SessionID、OrderRef 来定位 如果报单停留在交易所，Thost 可以用 ExchangID、OrderSysID 来定位，然后向交易 所转发撤单指令。\nTraderApi所有方法功能 # OnFrontConnected/Disconnected # 客户端与交易托管系统建立起通信连接时 OnHeartBeatWarning # 当长时间未收到报文时 OnRspUserLogin/Logout # 登陆注销响应 OnRspUserPasswordUpdate # 改密响应 OnRspTradingAccountPasswordUpdate # 当客户端发出资金账户口令更新指令后，交易托管系统返回响应时 OnRspError # 请求出错时 OnRspOrderInsert # 报单录入 OnRspOrderAction # 报单操作包括报单的撤销、报单的挂起、报单的激活、报单的修改。当客户端 发出过报单操作指令后，交易托管系统返回响应时 OnRspQueryMaxOrderVolume # 查询最大报单 OnRspSettlementInfoConfirm # 当客户端发出投资者结算结果确认指令后，交易托管系统返回响应时 等…… lol 统计无力 ？\nCTA 策略引擎 # _init_()的工作： # 加载主引擎、事件引擎；获取当前日期 设定是否在回测 保存策略实例的字典strategyDict(key为策略名称，value为策略实例)、 保存vtSymbol和策略实例映射的字典(用于推送tick数据，可能多个策略交易同一个vtSymbol因此key为vtSymbol.value为包含所有相关策略对象的list)、 保存vtOrderID和strategy对象映射的字典(用于推送order和trade数据key为vtOrderID，value为strategy对象）、 本地停止单编号计数、本地停止单字典(key为stopOrderID，value为stopOrder对象)、 持仓缓存字典(key为vtSymbol，value为PositionBuffer对象)、 成交号集合、 设置引擎类型为实盘、 注册事件监听 初始化策略 # 从数据库中读取3天的历史TICK数据、行情更新。。。。。有的话待续\n启动策略 # 从策略实例字典中取出策略实例，调用策略函数（已经初始化，没有在进行策略交易），开启进行交易标志位。\n停止策略 # 从策略实例字典中取出策略实例，调用策略函数（ 在进行策略交易），关闭策略交易标志位 -\u0026gt; 对该策略发出的所有限价单进行撤单 -\u0026gt; 发出的所有本地停止单撤单 -\u0026gt;\n保存、读取策略配置 # 触发策略状态变化事件（通常用于通知GUI更新） 获取策略的参数字典 获取策略当前的变量字典\n记录 # 报单更新、成交更新都是先检测是否有对此监听的策略 限价单成交处理：成交回报、报单回报、记录成交到列表、删除该限价单\n基础功能的策略调用 # 策略中发单时，需要在设置参数时考虑设置。 另获取持仓缓存数据，做平昨平今的选择。 策略中发单时，检查报单是否有效，赋参，撤单。 发停止单，编号，赋参，保存至字典 撤停止单，从工作停止单字典中移除\nTa-Lib # 趋势策略分为以下部分：\n趋势信号（通常是基于某几个参数计算出来的指标值超过某个阈值）、 信号过滤（和趋势信号类似）、 出场方案（固定点数/百分比的止盈和止损，移动止损）。 所以，Ta-lib是策略实现工具罢了。 此库中提供了多种技术分析的函数，有多种指标：ADX、MACD、RSI、布林轨道等 ；K线形态识别，如“黄昏之星”、“锤形线”等。\n依靠此库对数据的分析，来下达发单撤单的动作即为策略。\n策略示例： # 基于Talib模块的双指数均线策略`class TalibDoubleSmaDemo(CtaTemplate):` 就是两个指标的数据来判断当前局势罢了\n设定策略参数 策略变量 参数列表（保存参数名称） 变量列表（保存变量名称） 步骤 # 初始化策略（加载Bar数据）、启动策略、停止策略、收到行情Tick推送（计算K线）、收到Bar推送（缓存最新收盘价到列表 -\u0026gt; 数量足够后转化为Numpy数组后传入talib函数SMA中计算 -\u0026gt; 读取当前K线和上一根K线数值，用于判断均线交叉 -\u0026gt; 检测持仓状态，做出相应交易动作）\nCTA回测 # _init_()的工作 # 本地停止单编号计数 self.stopOrderCount 本地停止单字典 self.stopOrderDict And self.workingStopOrderDict 设引擎类型为回测 回测相关变量定义 当前最新数据，用于模拟成交使用 运行回测 # 载入历史数据\n根据回测模式确定要使用数据类\n初始化策略\n启动策略\n回放数据（从数据库中取得推到newBar或者newTick）\n策略获得新数据，执行相应操作\n基于最新数据撮合限价单 # 先确定会撮合成交的价格 -\u0026gt; 遍历限价单字典中所有限价单 -\u0026gt; 判断是否会成交 -\u0026gt; 发生成交推送成交数据（买入 -\u0026gt; 增加持仓 推送委托数据、从字典中删除该限价单）\n计算原理 # 改版之后程序架构 # | | | | | | | | | | | | | |:\u0026mdash;- |\u0026mdash; | \u0026mdash; | |\u0026mdash; |\u0026mdash; |\u0026mdash;- | \u0026mdash; | \u0026mdash; | \u0026mdash; |\u0026mdash; |\u0026mdash;: | | |APIs | |*** | | | | | Trader | | | | |CTP | |KSGold |*** |Common |Condig |Core|Gateway |Setting |Strategy |UI |main| |CtpMdApi、CtpTdApi | ………… | ………… |Md、Td| ……………… | ……………… |CTA、HTA、引擎、事件管理| ……………… |配置文件| ……………… | ……………… | ……………… |\n事件引擎 # 两版都一样，作为一个程序运行最外层的生成的实例，来进行各个实例之间的数据传输。因为每个实例都将数据在事件引擎中保存，调用事件引擎中的事件队列来对进行事件运行安排。\nLike This：\nclass A(object): \u0026quot;\u0026quot;\u0026quot;docstring for A\u0026quot;\u0026quot;\u0026quot; def __init__(self, name): super(A, self).__init__() self.name = name self.a = 0 def da(self): print self.name print self.a a = A('I am A') a.da() class B(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(B, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() b = B(a) b.dada() class C(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(C, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() c = C(a) c.dada() I am A\n0\nI am A\n1\nI am A\n2\nB与C分别在去改变读取在A中定义的数值。 嗯，没错，这么看的画确实时Python基础……所以没有这个基础的我看起来前期还挺费劲。当然，理解很好理解，就是在实现方法上不知原理的话就很难过。最主要的是，知道了原理在自己编写的时候可以的心用手，信手拈来。嗯~ o(￣▽￣)o就是这么写意和惬意。Indigo色在纯黑背景下不好辨识哈哈，还是换少女粉吧\nVn.Py 界面 # Icon 图标下载网: http://www.easyicon.net/\n界面设计文档 # 功能要求 # 连接、登陆，订阅，发撤单，持仓、账户信息、成交（下单时间、成交时间、备注（下单动作者））、保留交易模块、跟随鼠标点击更新交易模块中单子内容\n文档编写步骤 # 由需求确定功能，划分模块，模块关系，下分框架，框架实现\n模块 # 工具栏、行情显示、策略池、账户持仓、消息栏\n工具栏 # 连接（含各个端口） 风控、帮助、登陆状态显示\n工具功能 # 工具名称 说明 备注 连接 弹出端口列表 通过复选框选中对应端口 风控 弹出设定列表 通过文本框输入设定数值 帮助 弹出帮助窗口 策略池 # 操作位置 热点操作 策略名称单元格 鼠标指针悬停 展开操作界面 动作按钮 鼠标单击 执行选中 动作按钮 鼠标右击 展开操作界面 消息栏 # 分“成交”、“错误”、“日志”三个模块，选择相应模块显示对应内容\n日志 错误 成交 时间、内容、接口 时间、错误代码、错误信息、接口 成交编号、委托编号、合约代码、名称、方向、开平、价格、成交量、成交时间、接口 显示操作日志 显示当前操作错误信息 显示成交单信息 账户持仓信息 # 账户显示账户信息，并具备切换账户功能 当前选中账户 显示在旁label中。\n界面切换 # 记录笔记 # 照例，先贴网址： http://www.qaulau.com/books/PyQt4_Tutorial/index.html\n窗口设置 # resize(8, 8) setWindowTitle(u'标题') 获取图标 # def getIcon(filename): \u0026quot;\u0026quot;\u0026quot; 获取图标 \u0026quot;\u0026quot;\u0026quot; fileInfo = Qt.QFileInfo(filename) fileIcon = Qt.QFileIconProvider() icon = QtGui.QIcon(fileIcon.icon(fileInfo)) return icon 使用时： self.setWindowIcon(getIcon('../hi/app.ico')) Dock # widgetTestM, dockTestM = self.createDock(AllMarketMonitor, vtText.“dock 标题”, QtCore.Qt.RightDockWidgetArea) # 方向有： RightDockWidgetArea,BottomDockWidgetArea,LeftDockWidgetArea # 创建dock窗口 # 可利用 self.tabifyDockWidget(dockMarketM, dockAllDataM) 来合并同一个方向上的dock # 此下还没看… dockTradeM.raise_() dockPositionM.raise_() # 连接组件之间的信号 widgetPositionM.itemDoubleClicked.connect(widgetTradingW.closePosition) # 保存默认设置 self.saveWindowSettings('default') 其实现函数为： \u0026ldquo;\u0026ldquo;\u0026ldquo;创建停靠组件\u0026rdquo;\u0026rdquo;\u0026rdquo;\ndef createDock(self, widgetClass, widgetName, widgetArea): widget = widgetClass(self.mainEngine, self.eventEngine) dock = QtGui.QDockWidget(widgetName) dock.setWidget(widget) dock.setObjectName(widgetName) dock.setFeatures(dock.DockWidgetFloatable|dock.DockWidgetMovable) self.addDockWidget(widgetArea, dock) return widget, dock 再本质一点的东西为：\nwidget1 = Ha(self) dock = QtGui.QDockWidget('haha') dock.setObjectName('ha1') dock.setWidget(widget1) dock.setFeatures(dock.DockWidgetFloatable | dock.DockWidgetMovable) self.addDockWidget(QtCore.Qt.BottomDockWidgetArea, dock) 动作 # exit = QtGui.QAction(QtGui.QIcon('hello.ico'), 'exit', self) exit.setShortcut('Ctrl+Q') exit.setStatusTip('Exit application') # 图标、文字、快捷键、提示信息 menubar = self.menuBar() file = menubar.addMenu('\u0026amp;File') file.addAction(exit) # 创建目录和工具栏，将动作添加进去。工具栏同理 定位布局 # 绝对定位 # label1 = QtGui.QLabel(u'绝对定位', self) label1.move(15, 60) # 创建、移动到显示位置 框布局 及 布局元素平均分布 # okButton = QtGui.QPushButton(\u0026quot;OK\u0026quot;) cancelButton = QtGui.QPushButton(\u0026quot;Cancel\u0026quot;) # 创建按钮 hbox = QtGui.QHBoxLayout() hbox.addStretch(1) hbox.addWidget(okButton) # 增加组件 hbox.addWidget(cancelButton) # 创建水平栏 hbox.addStretch() # 平均分布 vbox = QtGui.QVBoxLayout() vbox.addStretch(1) # 创建竖列 vbox.addLayout(hbox) # 将水平栏插入竖列 self.setLayout(vbox) # 显示最终竖列 注意一下add时选择对类型就好了。\n组件之间连接信号 # # classA(QtGui.QTableWidget): # pass classA.itemDoubleClicked.connect(classB.actionFunction) # 这样单纯调用还是可以的，但是数据传输… 就得继续研究一下了。 调用Windows程序 # import win32api path = 'D:/vnpy- \\ master/docker/dockerTrader/gateway/ctpGateway/CTP_connect.json' win32api.ShellExecute(0, 'open', 'notepad.exe', path, '', 1) # 使用记事本打开此文件 Json # with open('D:/vnpy- \\ master/docker/dockerTrader/gateway/ctpGateway/CTP_connect.json', 'r') as f: setting = json.load(f) self.userID = str(setting['userID']) self.password = str(setting['password']) 关闭事件退出提示 # def closeEvent(self, event): reply = QtGui.QMessageBox.question(self, 'Message',\u0026quot;Are you sure to quit?\u0026quot;, QtGui.QMessageBox.Yes, QtGui.QMessageBox.No) if reply == QtGui.QMessageBox.Yes: event.accept() else: event.ignore() 函数放置位置就是主窗口类下就好。\nVS2015 快捷键 # Ctrl + k Ctrl + c # 多行注释 Ctrl + k Ctrl + u # 多行取消注释 鼠标事件 # press move release doubleClick clicked() enterEvent 鼠标移入 leaveEvent 鼠标移出 回去看看具体函数\n信号槽（传输额外参数） # 一般来说，比如一个按钮吧。 在链接点击信号与槽时buttonInit[i].clicked.connect(partial(self.init, i))就完事了。然而，当循环创建按钮，对应同样的槽函数，只是需要执行的变量有区别时，就需要传输额外的参数。 这时，方法有二：\n环境：\npython2.7.8\npyqt 4.11.1\n一： 使用lambda表达式 # 二： 使用functools里的partial函数 # 三：感谢来源\n策略管理 # 策略类，引擎，报单管理\u0026amp;\u0026amp;仓位管理\n引擎 # 引擎中将策略事件有序添加到事件引擎和主引擎中。 读取setting.json 文件对策略参数以及是否启用进行配置。设定日期。 使用策略实例字典保存策略名与实例关系—— 并将此字典在推送字典中与tick数据ID对应（ID对多实例。） 再有orderID与策略对应字典，用以推送order和trade数据 计数本地停止单 、 持仓缓存字典\n报单管理 # 成交推送处理 # 成交回调 - \u0026gt; 订单ID和策略对应字典 -\u0026gt; 计算策略持仓（根据策略方向，持仓增加交易笔数）-\u0026gt; 更新持仓缓存数据\n报单者类 # 单一合约订单缓存类——初始化buffer 存储字典_log策略日志存储\n"},{"id":87,"href":"/docs/programmer/langs/tips-of-markdown/","title":"Tips of MarkDown","section":"编程语言","content":" Markdown Notes 📪 # 对勾和叉叉(叉号) # #对勾 #叉号\n- \u0026amp;#9744; x \u0026amp;cross; - \u0026amp;#9745; \u0026amp;#10004; \u0026amp;check; ☐ x ✗ ☑ ✔ ✓ HTML锚点 - 页面内点击跳转 # 可以使用 HTML 锚点来实现点击内容跳转当前页面某标题。 具体实现方法如下：\n首先，在需要跳转到的标题前插入一个 HTML 锚点，例如： ### \u0026lt;a name=\u0026#34;section1\u0026#34;\u0026gt;Section 1\u0026lt;/a\u0026gt; 这个锚点的名称为 \u0026#34;section1\u0026#34;，可以根据需要自定义。 在需要点击跳转的内容处，使用 Markdown 的链接语法，将链接地址设置为锚点名称加上 # 符号，例如： [跳转到 Section 1](#section1) 这样，点击这个链接就会跳转到页面中的 \u0026#34;Section 1\u0026#34; 标题处。 注意事项： # 锚点名称必须是唯一的，否则链接可能会跳转到错误的位置。 如果需要跳转到其他页面的锚点，链接地址应该包括页面路径和锚点名称，例如：/path/to/page.html#section1。\n## Test 二级标题\nNow I will test the Markdown\u0026rsquo;s hobiy 二级 # Maybe is a nice way to impove my blog. 三级 # 原来标题 要# 与正文隔开一个空格… ···print “hello Markdown”··· 欸？ 怎么回事？上面的文字 莫非是用Tab能将其放到一个容器里？\n新的区块 # 你好，这是我新创建的容器。 ———好吧，只有直接在标题之下的Tab才能创建 no~，在空行下面也是可以的。 address@example.com\nMarkdown 字体颜色、流程图 # 斜体 # *文字*：前后星号斜体 就像这样？\n流程图 # st=\u0026gt;start: Start e=\u0026gt;end: End opl=\u0026gt;operation: My Operation sub1=\u0026gt;subroutine: My subroutine cond=\u0026gt;condition: Yes or No? io=\u0026gt;inputoutput: catch something\n呃 流程图我不清楚，不过\n字体颜色 # 可以内嵌html ：你好，我是红色吗?，\n你好，我是自定义色吗? 即\n\u0026lt;font color=red\u0026gt;你好，我是红色吗?\u0026lt;/font\u0026gt; \u0026lt;font color=#75362109\u0026gt;你好，我是自定义色吗?\u0026lt;/font\u0026gt; 刚开始我还在好奇怎么三色RGB怎么变成四个了，原来起作用的还是三个，只不过markdown选择性忽略了多余的字节。😰 这段话的配置如下：\n\u0026lt;font color=#ff36ff\u0026gt;骚气的颜色~\u0026lt;/font\u0026gt; 超链接 # Super Link is me? Yes , you are successful link to Google.hk\n[Super Link is me?](https://www.google.com.hk) 表格 # 1 111 a 2 222 b 3 333 c 4 444 d 6 555 e 7 666 f 序列 # 这是第一行 这是第二行 第三 Like This 另种表现 实现方式 阿门 @的用法 # @后跟随的关键字可以生成Github的搜索超链接 例如： @markdown\n注释 # [^_^]: 这里是注释：这个是在制作ppt的时候来写注释的…… 毕竟在笔记里面写注释怕是失了智… 毕竟不会被显示出来… 不过因为上面也说了是支持html语法的。所以……\n\u0026lt;!-- 这里是注释 隐藏区域--\u0026gt; 插入图片：只能插入网图… # 关于``` 痛苦的进行中 # (⊙﹏⊙)， ```这东西是用来标注代码开始的，然而在有的编辑器中，若不是以单独一行会识别为`，也就是对平常语句中的字符的修饰。但是hexo显然不这么认为，所以只好将之前使用```的地方都改成`了 【2018年5月18日 纪念我勤奋的修改史】 折叠 代码 # obsidian 一个好看的Callouts栏 # [!note] 可折叠部分 这里是可折叠的长文本内容，可以包含多行。 啊23阿斯顿仨的阿斯顿 阿斯顿仨的阿斯顿阿斯顿大as\n文本字体速查表 # 参考自: csdn 王大雄\n高亮 # 1. 使用\u0026#34;`\u0026#34;双引, eg: `{要高亮的文本}`; 2. 使用\u0026#34;```\u0026#34; 跨行, eg:```\\n{要高亮的文本}\\n```; 3. HTML \u0026lt;mark\u0026gt;双引, eg: \u0026lt;mark\u0026gt;{要高亮的文本}\u0026lt;mark\u0026gt; 要高亮的文本 见下 要高亮的文本 要高亮的文本 "},{"id":88,"href":"/docs/programmer/basetc/tipsofvim/","title":"tip Of vim","section":"基础工具和配置","content":" Vim 使用 # 除去“简便生活”里的几条配置，在纠结是否添加到别的地方，果然还是单独给vim一个使用手册比较好……\n注释 # # 注释 1， 12s/^/#/g --- # 取消注释 1， 12s/^#//g 其实 是vim中的 :s替换命令… 下方解释\n或者，使用列编辑的模式:\nv、选择区域、ctrl q置行首、I插入#、Esc应用到全列 ctrl v、I、#、Esc 因为有的ctrl q或者ctrl v 不能用…… 取消，即使用上述方法选中行首，删除第一个字节即可了 替换 # :s/oldWords/newWords/g g : 代表当前光标所在行。\n由此可知: # ^表行首标识符。 /^/表示行首的空字符。 而取消注释中的/^#/即表示行首的#，被//空字符所替换。\n删除:g/出现计算意外/d # :g/出现计算意外/d 查找高亮 # set hlsearch set nohlsearch 分屏 # 实现 # 在外部使用-o or -O参数 内部split or vsplit 操作 # 移动光标 Ctrl + w hjkl 移动分区Ctrl + w HJKL 统一高度Ctrl + w = 改变高度Ctrl + w +- more and less # 阅读器~~~ 因为经常读大文件发现了这两个的无敌好处——快。\n使用命令 # cat cat -b # 查看且标注行号 -n # 同上，但也会显示空行行号 more # - space 向下翻页 # - Ctrl+F 同上 # - b back 返回一页显示 # - Ctrl+B 同上 # - Enter 向下n行,默认1 # - = 输出当前行号 # - v 调用vi/vim # - !命令 调用shell 执行命令 # - q 退出 less Vi \u0026amp;\u0026amp; Vim # 三个模式:\n命令模式 插入模式 Ex模式 para : 说明 o : 在当前行下面插入新空白行 dd : 删除当前一行。 u : 撤销一步操作 yy : 当前行-\u0026gt;缓冲区 p : 缓冲区-\u0026gt;光标之后插入 n+ y 当前及接下来n行-\u0026gt;缓冲区 r : 替换当前字符 / : 查找关键字——支持汉字呐！难得 n : 上命令下切换 next Ex下: # set number: 显示行号。（不过我已经改了配置文件，默认显示） ！+命令 代理执行系统命令。如ls cd sh 挂下编辑 显示系统命令行。 ctrl+d返回（PS:命令行下，这是关闭虚拟终端快捷键） tip:tail head 等查看命令可以和 \u0026raquo; 命令合用，将文件的首行或者结尾字添加到另一个文档～ "},{"id":89,"href":"/docs/programmer/platforms/android/android/","title":"安卓","section":"平台","content":" 将安卓手机用于开发 # Termux # 类似于WIN端的Subsystem——其实更像Ubuntu下的虚拟终端。 不过这东西功能强大，除了将安卓里的Linux发挥出来。还有Termux API来调用手机的底层接口。\nXFCE4 # 步骤：\n安装Termux 执行pkg update 执行pkg install git \u0026amp;\u0026amp; git clone https://github.com/Yisus7u7/termux-desktop-xfce.git 执行cd termux-desktop-xfce \u0026amp;\u0026amp; bash boostrap.sh 当然，3\u0026amp;4步可以合并为一句curl -sLf https://raw.githubusercontent.com/Yisus7u7/termux-desktop-xfce/main/boostrap.sh | bash\nVNC # 默认VNC只能通过localhost:1来连接，局域网不能访问。想用大屏来看就不是很方便。\n# 先执行`vncserver`使用本机的`VNC Viewer`看看效果，主要是需要先设置一下密码 vncserver # 现在还无法通过局域网连接 # 去设置 cd ~/.vnc/ vim config # 打开最后一行注释 # 重新运行 vncserver -kill :1 vncserver 配置文件一览 # 将config文件最后一行的注释打开，即可\n## Supported server options to pass to vncserver upon invocation can be listed ## in this file. See the following manpages for more: vncserver(1) Xvnc(1). ## Several common ones are shown below. Uncomment and modify to your liking. ## # securitytypes=vncauth,tlsvnc # desktop=sandbox geometry=1280x720 # localhost # alwaysshared 将这行注释取消注释 alwaysshared # 修改成这样 现在各个版本概览 # python - 3.10 clang - 14.0.5 opencv - 4.5.5 NumPy # # pip3 install numpy 不能安装 MATHLIB=\u0026#34;m\u0026#34; pip3 install numpy # numpy 1.22.4 C++ \u0026amp; OpenCV # 现在安装opencv-python还有问题,可能问题出现在安装numpy上,但后来经过努力安装好了,但版本或者其他问题导致还是不能正常运行.但C++还是很好呀.\npkg install opencv opcv.cpp # #include \u0026lt;opencv2/opencv.hpp\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace cv; using namespace std; int main() { Mat src = imread(\u0026#34;logo-red.png\u0026#34;, IMREAD_GRAYSCALE); if (src.empty()) { printf(\u0026#34;could not find the image\\n\u0026#34;); return -1; } imwrite(\u0026#34;grayscale.png\u0026#34;, src); printf(\u0026#34;save grayscale success\\n\u0026#34;); // waitKey(0); // system(\u0026#34;path\u0026#34;); // getchar(); return 0; } 编译 \u0026amp; 运行 # g++ opcv.cpp -o opcv `pkg-config --cflags --libs opencv4` ./opcv 指定编译器版本 # opencv4 需要C++11\ng++ opcv.cpp -o opcv `pkg-config --cflags --libs opencv4` -std=c++11 ssh与手机连接 # 手机端sshpc端 # 电脑生成密匙,无视密码设置全部回车 ssh-keygen -t rsa 电脑开启sshd服务,用于手机的ssh连接到电脑, 拷贝id_rsa.pub内容 systemctl start sshd wsl: sshd re-exec requires execution with an absolute path 转去手机端操作 手机连接拷贝 $HOME/.ssh/authorized_keys -\u0026gt; 不管用什么复制，然后放到这个路径就好。 查看手机的用户名 whoami 开启服务 sshd -p 9000 pcssh手机端 # ssh u0_222@192.168.1.14 -p 9000 可能有文件权限问题 chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys 😓\n快捷键(有用的音量键？) # 显示扩展功能按键 # 方法一: 从左向右滑动,显示隐藏式导航栏,长按左下角的KEYBOARD.\n方法二: 使用Termux快捷键:音量++Q键\n常用快捷键 # Ctrl键是终端用户常用的按键 – 但大多数触摸键盘都没有这个按键。为此，Termux使用音量减小按钮来模拟Ctrl键。在触摸键盘上按音量减小+ L发送与在硬件键盘上按Ctrl + L相同的输入。 Ctrl+A -\u0026gt; 将光标移动到行首 Ctrl+C -\u0026gt; 中止当前进程 Ctrl+D -\u0026gt; 注销终端会话 Ctrl+E -\u0026gt; 将光标移动到行尾 Ctrl+K -\u0026gt; 从光标删除到行尾 Ctrl+L -\u0026gt; 清除终端 Ctrl+Z -\u0026gt; 挂起（发送SIGTSTP到）当前进程 加键也可以作为产生特定输入的特殊键. 音量加+E -\u0026gt; Esc键 音量加+T -\u0026gt; Tab键 音量加+1 -\u0026gt; F1（和音量增加+ 2→F2等） 音量加+0 -\u0026gt; F10 音量加+B -\u0026gt; Alt + B，使用readline时返回一个单词 音量加+F -\u0026gt; Alt + F，使用readline时转发一个单词 音量加+X -\u0026gt; Alt+X 音量加+W -\u0026gt; 向上箭头键 音量加+A -\u0026gt; 向左箭头键 音量加+S -\u0026gt; 向下箭头键 音量加+D -\u0026gt; 向右箭头键 音量加+L -\u0026gt; | （管道字符） 音量加+H -\u0026gt; 〜（波浪号字符） 音量加+U -\u0026gt; _ (下划线字符) 音量加+P -\u0026gt; 上一页 音量加+N -\u0026gt; 下一页 音量加+. -\u0026gt; Ctrl + \\（SIGQUIT） 音量加+V -\u0026gt; 显示音量控制 音量加+Q -\u0026gt; 显示额外的按键视图 获取当前ip # curl -m3 -s \u0026#34;http://ipinfo.io\u0026#34; "},{"id":90,"href":"/docs/programmer/database/note-of-db-data-mongodb/","title":"数据库-MongoDB篇","section":"Database","content":" DB数据库 🖥 📊🖥 # MongoDB笔记 # 学习网站：http://www.runoob.com/mongodb/mongodb-tutorial.html (其学习教程还挺可观，很多，不过还不清楚好不好)\n安装 # Docker 安装 4.4.12版本 # pull: docker pull mongo:4.4.13 run: docker run -itd --name mongo --restart=always \\ -v /mongodb/datadb:/data/db \\ -p 27017:27017 \\ --network websafe-network \\ --privileged=true mongo:4.4.12 进入容器docker exec -it mongo bash后:\nmongo use admin # db.createUser({user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;admin\u0026#34;, roles: [{role: \u0026#34;root\u0026#34;, db: \u0026#34;admin\u0026#34;}]}) # db.createUser({user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;admin\u0026#34;, roles: [{role: \u0026#34;userAdminAnyDatabase\u0026#34;, db: \u0026#34;admin\u0026#34;}]}) # 如果能auth就不用createUser了 db.auth(\u0026#34;admin\u0026#34;, \u0026#34;admin\u0026#34;) 网上传的将 MONGO_INITDB_ROOT_PASSWORD 和 MONGO_INITDB_ROOT_USERNAME传入环境变量的方式，在mongo4.4.12 和 4.4.13上都不好使。\n数据迁移 # insert into device_data_current select * from device_data; 使用 mysqldump # 很慢 很大 很方便 很！不好！使用！在使用\u0026ndash;host时 下面命令没一次正常工作的，很难受\nmysqldump -h192.168.0.25 -u{user} -p{passwd} {dbname} {tablename} \u0026gt; {tablename}.sql sed -i \u0026#39;s/{tablename}/{new_tablename}/g\u0026#39; {tablename}.sql mysql -u{user} -p{passwd} {dbname} \u0026lt; {table}.sql # 增加条数限制 bash-4.2# mysqldump -u{user} -p{passwd} test demo --host {host} --where=\u0026#34;true limit 5000\u0026#34; \u0026gt; demo.sql 还是用自己写的脚本好使 sql_one2one.py\n注意事项 # Mongo 数据库锁 # mongo只提供库级粒度锁，所以一个写操作锁定时，其他读写操作都等待… 所以这个导致了Mongo多线程写操作反而没有一个线程写来的快？\n前台建立索引时，Mongo需占用一个写锁（且不同上述、不会临时放弃） 为避免此问题需采用background方式\ndb.posts.ensureIndex({user_id: 1}) #此方式将引起全面战争 db.posts.ensureIndex({user_id: 1}， {background: 1}) # 这个就比较和平 操作命令简单记录 # 创建、插入 # use DATABASE_NAME #如果数据库不存在，则创建数据库，否则切换到指定数据库。 show dbs #查看所有数据库“name size” 刚创建的数据库，如没有内容则不现实在其中\ndb.runoob.insert({\u0026quot;name\u0026quot;:\u0026quot;教程\u0026quot;}) #插入数据 删除 # db.dropDatabase() #删除当前数据库，如未选择则删除test db.collection.drop() #删除集合 db.site.drop() #：如删除site集合 插入文档 # db.COLLECTION_NAME.insert(document) db.col.insert({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }) # 例如这样 db.col.find() # 查看已插入文档\n也可以将document=括号里要插入内容，然后插入document变量，效果一样。\n3.2版本新加 # db.collection.insertOne() #向指定集合中插入一条文档数据 db.collection.insertMany() #向指定集合中插入多条文档数据 插入单条数据 var document = db.collection.insertOne({\u0026quot;a\u0026quot;: 3}) document { \u0026ldquo;acknowledged\u0026rdquo; : true, \u0026ldquo;insertedId\u0026rdquo; : ObjectId(\u0026ldquo;571a218011a82a1d94c02333\u0026rdquo;) }\n插入多条数据 var res = db.collection.insertMany([{\u0026quot;b\u0026quot;: 3}, {'c': 4}]) res { \u0026ldquo;acknowledged\u0026rdquo; : true, \u0026ldquo;insertedIds\u0026rdquo; : [ ObjectId(\u0026ldquo;571a22a911a82a1d94c02337\u0026rdquo;), ObjectId(\u0026ldquo;571a22a911a82a1d94c02338\u0026rdquo;) ] }\n更新、添加文档 # db.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}}) #更新标题 db.collection.save( #通过传入的文档来替换已有文档 \u0026lt;document\u0026gt;, { writeConcern: \u0026lt;document\u0026gt; }) 参数说明： document : 文档数据。 writeConcern : 可选，抛出异常的级别。\neg： 实例中替换了 _id 为 56064f89ade2f21f36b03136 的文档数据：\ndb.col.save({ \u0026quot;_id\u0026quot; : ObjectId(\u0026quot;56064f89ade2f21f36b03136\u0026quot;), \u0026quot;title\u0026quot; : \u0026quot;MongoDB\u0026quot;, \u0026quot;description\u0026quot; : \u0026quot;MongoDB 是一个 Nosql 数据库\u0026quot;, \u0026quot;by\u0026quot; : \u0026quot;Runoob\u0026quot;, \u0026quot;url\u0026quot; : \u0026quot;http://www.runoob.com\u0026quot;, \u0026quot;tags\u0026quot; : [ \u0026quot;mongodb\u0026quot;, \u0026quot;NoSQL\u0026quot; ], \u0026quot;likes\u0026quot; : 110 })\n导入csv文件 # mongoimport --db Trader_1Min_Db --collection Au(T+D) --type csv --file D:\\\\IFData\\\\md_Au(T+D)_20170101_20170531\\\\md_Au(T+D)_2017010301.csv --headerline --upsert --ignoreBlanks 注意需要另开一个命令行，在其中运行。 2017-10-25T08:43:40.917+0800 E QUERY [thread1] SyntaxError: missing ; before statement @(shell):1:16 否则就是这个错误\n-d 指定把数据导入到哪一个数据库中 -c 指定把数据导入到哪一个集合中 --type 指定导入的数据类型 csv/tsv 逗号或者tab分割值 --file 指定从哪一个文件中导入数据 --headerline 仅适用于导入csv,tsv格式的数据，表示文件中的第一行作为数据头 --upsert 以新增或者更新的方式来导入数据 --f 导入字段名 --ignoreBlanks 忽略空白符 导出 # mongoexport -d test -c students -o students.dat connected to: 127.0.0.1 exported 9 records # 指明导出格式为csv mongoexport -d test -c students --csv -f classid,name,age -o students_csv.dat connected to: 127.0.0.1 exported 9 records 添加 # db.collectionName.update({}, {$set:{'key' : value}}, false, true); 改 # .update 更改字段名称 # db.CollectionName.update({}, {$rename : {\u0026quot;OldName\u0026quot; : \u0026quot;NewName\u0026quot;}}, false, true) # false为如不存在update记录，是否插入新的纪录 # ture位置为更新全部数据，如设定false 则为只更新第一条 # 另外 没有输入名称时没有输全，也会显示查找，但不会执行更改 统配 # db.CollectionName.update(\u0026lt;query\u0026gt;, \u0026lt;update\u0026gt;,{upsert : \u0026lt;boolean\u0026gt;, multi : \u0026lt;boolean\u0026gt;, writeConcern : \u0026lt;document\u0026gt;}) # query : update 查找条件，类似sql update查询内where后面的 # update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查 #\u0026gt;询内set后面的 # upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插 #\u0026gt;入，默认是false，不插入。 # multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把 #\u0026gt;按条件查出来多条记录全部更新。 # writeConcern :可选，抛出异常的级别。 eg # db.col.update({'title':'MongoDB'},{$set:{'title':'IamNewTitle'}}) 删除文档 # remove()函数是用来移除集合中的数据。\ndb.collection.remove( \u0026lt;query\u0026gt;, \u0026lt;justOne\u0026gt; ) 2.6版以后 # db.collection.remove( \u0026lt;query\u0026gt;, { justOne: \u0026lt;boolean\u0026gt;, writeConcern: \u0026lt;document\u0026gt; }) 参数说明： query :（可选）删除的文档的条件。 justOne : （可选）如果设为 true 或 1，则只删除一个文档。 writeConcern :（可选）抛出异常的级别。\ndb.col.remove({}) #删除所有 (就很恐怖) 查询文档 # 操作 格式 范例 RDBMS中的类似语句 等于 {\u0026lt;key\u0026gt;:\u0026lt;value\u0026gt;} db.col.find({\u0026quot;by\u0026quot;:\u0026quot;教程\u0026quot;}).pretty() where by = '教程' 小于 {\u0026lt;key\u0026gt;:{$lt:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$lt:50}}).pretty() where likes \u0026lt; 50 小于或等于 {\u0026lt;key\u0026gt;:{$lte:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$lte:50}}).pretty() \u0026hellip; 大于 {\u0026lt;key\u0026gt;:{$gt:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$gt:50}}).pretty() \u0026hellip; 大于或等于 {\u0026lt;key\u0026gt;:{$gte:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$gte:50}}).pretty() \u0026hellip; 不等于 {\u0026lt;key\u0026gt;:{$ne:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$ne:50}}).pretty() where likes != 50 And # find可以传入多个键(key),逗号隔开：\ndb.col.find({key1:value1, key2:value2}).pretty() db.col.find({\u0026quot;by\u0026quot;:\u0026quot;教程\u0026quot;, \u0026quot;title\u0026quot;:\u0026quot;MongoDB \u0026quot;}).pretty() #类似于 WHERE by='教程' AND title='MongoDB ' Or # db.test.find({$[{key1:value1},(key2:value2)]}).pretty() #注意小中大括号😰 db.col.find({\u0026quot;likes\u0026quot;: {$gt:50}, $or: [{\u0026quot;by\u0026quot;: \u0026quot;教程\u0026quot;},{\u0026quot;title\u0026quot;: \u0026quot;MongoDB \u0026quot;}]}) And 与 Or # db.col.find({\u0026quot;likes\u0026quot;: {$gt:50}, $or: [{\u0026quot;by\u0026quot;: \u0026quot;教程\u0026quot;},{\u0026quot;title\u0026quot;: \u0026quot;MongoDB \u0026quot;}]}) #类似于（其中pretty()是显示样式） where likes\u0026gt;50 AND (by = '教程' OR title = 'MongoDB ‘ 简写说明 # $gt \u0026mdash;\u0026mdash;\u0026ndash; greater than \u0026gt; $gte \u0026mdash;\u0026mdash;\u0026mdash; gt equal \u0026gt;= $lt \u0026mdash;\u0026mdash;\u0026ndash; less than \u0026lt; $lte \u0026mdash;\u0026mdash;\u0026mdash; lt equal \u0026lt;= $ne \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; not equal != $eq \u0026mdash;\u0026mdash;\u0026ndash; equal = Type # db.col.find({\u0026quot;title\u0026quot; : {$type : 2}}) #获取“col”集合中title为String的数据 对照表：\n类型 数字 备注 Double 1 String 2 Object 3 Array 4 Binary data 5 Undefined 6 已废弃。 Object id 7 Boolean 8 Date 9 Null 10 Regular Expression 11 JavaScript 13 Symbol 14 JavaScript (with scope) 15 32-bit integer 16 Timestamp 17 64-bit integer 18 Min key 255 Query with -1. Max key 127 Limit() Skip()方法 # db.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).limit(2) 参数说明： “title”后1为判断语句，表示是否只查询“title”内容0为否，显示这条的全部信息。_id的0亦为判断表示是否显示“_id”内容。limit为限制搜索信息条数。\ndb.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).limit(1).skip(1) skip(NUMBER) #NUMBER为阶跃，即每隔几条数据来搜索 排序 # db.COLLECTION_NAME.find().sort({KEY:1}) #KEY后数字可为1OR-1，升序OR降序 db.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).sort({\u0026quot;likes\u0026quot;:-1} #按“likes”降序排序 MongoDB 索引 （建立索引干嘛……） # ensureIndex() 方法 # db.COLLECTION_NAME.ensureIndex({KEY:1}) # Key 值为要创建的索引字段，1为指定按升序创建索引，降序-1 聚合 # aggregate()方法 # db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$sum : 1}}}]) #类似于 select by_user, count(*) from mycol group by by_user 输出结果： { \u0026ldquo;_id\u0026rdquo; : \u0026ldquo;Neo4j\u0026rdquo;, \u0026ldquo;num_tutorial\u0026rdquo; : 1 } { \u0026ldquo;_id\u0026rdquo; : \u0026ldquo;runoob.com\u0026rdquo;, \u0026ldquo;num_tutorial\u0026rdquo; : 2 } { \u0026ldquo;_id\u0026rdquo; : null, \u0026ldquo;num_tutorial\u0026rdquo; : 1 }\n参数说明：“$by_user” 即为分类依据，并打印出来（如上）。 num_tutorial 仅为显示提示，可以更改为任意提示甚至汉字。 $sum : 1 其中1为每次计数值，即重复一次加几。1+1+1+1…… ：重复一次加1；0.1+0.1+0.1……重复一次加0.1。这个意思\n计算符： # 表达式 描述 实例 $sum 计算总和。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$sum : \u0026quot;$likes\u0026quot;}}}]) $avg 计算平均值 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$avg : \u0026quot;$likes\u0026quot;}}}]) $min 获取集合中所有文档对应值得最小值。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$min : \u0026quot;$likes\u0026quot;}}}]) $max 获取集合中所有文档对应值得最大值。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$max : \u0026quot;$likes\u0026quot;}}}]) $push 在结果文档中插入值到一个数组中。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, url : {$push: \u0026quot;$url\u0026quot;}}}]) $addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, url : {$addToSet : \u0026quot;$url\u0026quot;}}}]) $first 根据资源文档的排序获取第一个文档数据。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, first_url : {$first : \u0026quot;$url\u0026quot;}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, last_url : {$last : \u0026quot;$url\u0026quot;}}}]) 条件操作符 # $gt 大于 $lt 小于 $gte 大于等于 $lte 小于等于 eg： # db.col.find({likes : {$gte : 100}}) # 查询“col”集合中\u0026quot;likes\u0026quot;大于100的数据 # 比较与 `SQL Select * from col where likes \u0026gt;=100;` 取前n条数据 # .find().limit(n) 执行顺序 # skip(), limilt(), sort()三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()。 数据导出 # mongoexport -d *** -c *** -o *** # -d 后为 dbName -c 后为 collectionName -o 后为 outputFileName 导出文件名 名字都不用加引号，直接上的~， 然后导出格式都是json 那样，不管后缀是什么用文本打开都是一个样子——骗鬼👻\n数据导入 # mongoimport -h 127.0.0.1 -p 27017 -d Trader_1Min_Db -c ag1806 --file /home/ian/Downloads/ag1806.json Linux 下使用Robo3T错误 # 错误最后字段为：已放弃 (核心已转储)\nmkdir ~/robo-backup mv robo3t-1.1.1-linux-x86_64-*/lib/libstdc++* ~/robo-backup/robo3t-1.1.1-linux-x86_64-*/bin/robo3t 移动备份之后即可运行\nFor Python # PyMongo # from pymongo import MongoClient client = MongoClient(\u0026quot;localhost\u0026quot;, 27017) client.server_info() # 查看信息，检测是否成功连接 db = client[\u0026quot;someData\u0026quot;] collection = db.zn1801_30Min # 两种命名方式，一种是直接. 一种是使用“” 乖乖的用双引号，因为，在这里的单双引号是区分的… 我现在也懒得去管它是字符字符串的什么鬼。┏┛墓┗┓\u0026hellip;(((m -__-)m\ninsert # collection.insert( {\u0026quot;name\u0026quot;:\u0026quot;text\u0026quot; } ) find # d = {u'Volume':{'$gte':50353,'$lte':50355}} a = collection.find(d) 最小与最大，另外，find出来的东西是数据库指针，需要用for...in...来循环取出内容来\n查询库名 # from pymongo import MongoClient client = MongoClient('localhost', 27017) client.database_names() [u\u0026rsquo;Trader_1Min_Db\u0026rsquo;, u\u0026rsquo;Trader_30Min_Db\u0026rsquo;, u\u0026rsquo;Trader_Tick_Db\u0026rsquo;, u\u0026rsquo;VnTrader_Log_Db\u0026rsquo;, u\u0026rsquo;VnTrader_Position_Db\u0026rsquo;, u\u0026rsquo;admin\u0026rsquo;, u\u0026rsquo;local\u0026rsquo;, u\u0026rsquo;someData\u0026rsquo;, u\u0026rsquo;test']\n查询集合名 # collectionNames = client[dbName].collection_names() print collectionNames 使用 # 其读写速度还是可以的… 二十万条数据查询的话不到一秒，然而… 频繁多量的读取，再加上不断地往其中写入就出问题了…… 卡的极慢…简直恐怖（数个小时的延迟 怕不怕）。（当然以上情况是完全没有做任何优化的情况（直接insert 、find），不知道优化之后会怎样） 另外不知道不增加条数，去增加内容会怎样…… emm 果然还是缓存比较好用…在高速多量多频次的情况下还是用内存里面不去手动做任何保存比较好。 等积攒够量之后再去保存，就好比文件压缩不去一个个小文件传输一个道理。\n"},{"id":91,"href":"/docs/programmer/database/note-of-db-data-mysql/","title":"数据库-MySQL篇","section":"Database","content":" MySQL数据库 🖥 📊🖥 # 安装 # docker # podman run -d --name mysql-container -e MYSQL_ROOT_PASSWORD={my-secret-pw} -e MYSQL_TIME_ZONE=UTC -e MYSQL_CHARSET=utf8 -p 3306:3306 mysql:5.7 使用 # 常用命令 # CREATE DATABASE {database_name} DEFAULT CHARACTER SET utf8mb4 DEFAULT COLLATE utf8mb4_unicode_ci; 按天统计 # SELECT DATE(created_at) AS date, COUNT(*) AS count FROM `TABLE_NAME` WHERE created_at \u0026gt;= \u0026#34;2025-01-01\u0026#34; AND created_at \u0026lt; \u0026#34;2025-02-01\u0026#34; GROUP BY DATE(created_at) ORDER BY date LIMIT 100 连接 # 使用MySQL命令行工具连接MySQL时，你可以使用以下命令来：\n启用压缩传输 # mysql --compress -u username -p 完整命令如：\nmysql --compress -u{username} -p{passwd} --host {host} {db name} 2024-05-27: 但是很可惜，很多第三方连接库都不支持这个参数。\nMySQL 8.0 # 因为在更新8.0 之后更改了用户密码加密形式所以在使用客户端连接的时候会出现错误，所以需要\nALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER; #修改加密规则 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password'; #更新用户的密码 FLUSH PRIVILEGES; #刷新权限 经此步骤，就可以将密码加密形式改为图形化客户端支持的加密形式，也或者更待客户端跟着服务端同步更新。\n另外，配置之初，windows 中配置步骤如下：\n添加系统环境变量path 为MySQL/bin 初始化 mysqld --initialize --user=mysql --console 根据初始化随机生成密码登陆 修改密码 emm 这里说的是在外部，当然也可以在修改加密形式的时候一并修改 😄 mysqladmin -u root -p password 添加系统服务 mysqld -install 启动服务 net start mysql 另外在图像化里面注意密码格式呦，还有使用navicat的话需要最新版本，否则无法设置加密格式，还得用命令行去修改……果然还是命令行永远最好用\n更新 # MySQL的update在被更新数值和更新传入数值相同时，执行速度相当的快，据说是mysql并不会执行更新动作但是它晓得更新动作的发生\n删除 # 删除重复数据 # 零:\n# 删除有重复的数据, 保留最大ID SELECT id FROM playstore_pkg_info WHERE `id` NOT IN ( SELECT MAX(id) FROM playstore_pkg_info GROUP BY `packageName` HAVING COUNT(id) \u0026gt; 1 ) AND `packageName` IN ( SELECT `packageName` FROM playstore_pkg_info GROUP BY `packageName` HAVING COUNT(id) \u0026gt; 1 ) LIMIT 200 一:\ndelete from alarm_calendar where id not in (SELECT maxid from (SELECT MAX(id) as maxid, CONCAT(user_id,time,generic_name) as nameAndCode from alarm_calendar GROUP BY nameAndCode) t); 根据user_id, time, generic_name来打包重复，将重复数据删掉, 留下max，在自增里面即：最新数据\n**二: **\nSELECT pid, status FROM offer WHERE pid IN (SELECT pid FROM offer GROUP BY pid HAVING COUNT(id) \u0026gt; 1) ORDER BY `pid` asc LIMIT 100 MySQL 中文乱码 # 需要在连接时就指定✱charset✲ 而不该一味纠结于在程序在存储时的数据准备 此处使用的是\ncharset='gb2312' 另外，干脆就在数据库中设置存为 blob 格式\n连接远程 win 数据库 # 开启某端口的示例： 添加防火墙例外端口 ## 导出表记录 [^_^] 2021-04-22 看了上面,深表惭愧... ```bash mysql -uuser -ppasswd -hhost -e \u0026#34;use db_name; select * from table_name where chat_id in (...);\u0026#34; \u0026gt;\u0026gt; hello2.csv 在bash中直接执行sql语句，重定向保存\n好处 # 可以规避 into outfile 的权限问题，导出的东西用csv也是可以看的，分隔符得以保留，csv可以正常阅览\n注意点 # 只不过有,时分隔符可能有些问题，全文替换了就好\n入站规则设置 # 第一步 选择 入站规则 然后 新建规则，选择 端口，然后下一步 第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如: 3306 第三步 选择允许连接 第四步 选择配置文件 第五步 输入规则名称 mysqlport\n出站规则设置 # 第一步 选择出站规则 然后 新建规则，选择 端口，然后下一步 第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如: 3306 第三步 选择允许连接 第四步 选择配置文件 第五步 输入规则名称 mysqlport（或者无特殊要求下直接关闭防火墙） 字符串存储 # 1、总体来说： 1、char，存定长，速度快，存在空间浪费的可能，会处理尾部空格，上限255。\n2、varchar，存变长，速度慢，不存在空间浪费，不处理尾部空格，上限65535，但是有存储长度实际65532最大可用。\n3、text，存变长大数据，速度慢，不存在空间浪费，不处理尾部空格，上限65535，会用额外空间存放数据长度，顾可以全部使用65535。\n2、应用场景的问题： 当 varchar(n) 后面的 n 非常大的时候,我们是使用 varchar 好，还是 text 好呢？ 这是个明显的量变引发质变的问题。我们从2个方面考虑，第一是空间，第二是性能。\n（1）首先从空间方面 从官方文档中我们可以得知当varchar大于某些数值的时候，其会自动转换为text，大概规则如下：\n大于varchar（255）变为 tinytext 大于varchar（500）变为 text 大于varchar（20000）变为 mediumtext 所以对于过大的内容使用varchar和text没有太多区别。 （2）从性能方面 索引会是影响性能的最关键因素，而对于text来说，只能添加前缀索引，并且前缀索引最大只能达到1000字节。 而貌似varhcar可以添加全部索引，但是经过测试，其实也不是。由于会进行内部的转换，所以long varchar其实也只能添加1000字节的索引，如果超长了会自动截断。 我们认为当超过255的长度之后，使用varchar和text没有本质区别，只需要考虑一下两个类型的特性即可。（主要考虑text没有默认值的问题）\n数据迁移 # 因为已有从数据库中读取数据进行返回的函数，所以没有必要再去写读取数据库的步骤（也没法写，因为数据库设计混乱，分不清哪儿是哪儿只有通过其对外函数才能取对相应数据） 但对外其是将一段时间内数据全部读取并且打包为json返回，所以一次性的话将是极大的一个文件，所以解决方法有：\n阅读其中源码，返回相应数据库指针，以此取出一个迁移一个 编写分段读取函数，保证每次取出的数据不多，一段一段的迁移 反正我是采用一段一段了，毕竟源码太… 另外，一段一段的话打好日志，出现问题后可以分段纠正，也能间歇运行，另外下载好再迁也保证了数据emm，考虑如上\n简单总结 # 数据迁移程序 数据检验补差程序 断点运行机制 # 初始化 1. 读取配置文件（其中保存 * 数据迁移顺序——列表（内元素为字典key为* value为相应数据库、表名， 时间起止，一次插入的时间跨度） ） 2. 根据移植顺序读取目标数据库中相应数据的最新数据日期（ * 若为空开始则开始插入） * 删除此日期的所有数据， * 根据一次插入的时间跨度以及终点生成时间区间 * 根据时间区间去移植数据 3. 当此类型数据移植完毕之后删除配置文件中列表的相应元素 # 执行动作 是 ## 日志 将每一步的重要信息都打印~ 常用命令 # 1. 建立唯一约束 # ALTER TABLE app_platforms ADD CONSTRAINT unique_app_id_platform UNIQUE (app_id, platform) 2. 删除重复数据 # app_id, platform 重复\nDELETE FROM app_platforms WHERE id in (SELECT id from ( SELECT MIN(id) as id, app_id, platform, COUNT(*) as count FROM app_platforms GROUP BY app_id, platform HAVING count \u0026gt; 1 ) as keep_ids) 3. 用临时表的方式删除重复数据 # -- 创建一个临时表保存最新的记录 CREATE TEMPORARY TABLE latest_pkg AS SELECT * FROM playstore_pkg_info p1 WHERE update_time = ( SELECT MAX(p2.update_time) FROM playstore_pkg_info p2 WHERE p2.packageName = p1.packageName ); -- 删除原表中所有数据 DELETE FROM playstore_pkg_info; -- 插入回保留的最新记录 INSERT INTO playstore_pkg_info SELECT * FROM latest_pkg; "},{"id":92,"href":"/docs/programmer/platforms/os/freebsd/","title":"FreeBSD","section":"平台","content":" FreeBSD # 桌面 # 换源 pkg install xorg xfce echo \u0026lsquo;dbus_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf echo \u0026ldquo;/usr/local/etc/xdg/xfce4/xinitrc\u0026rdquo; \u0026gt; ~/.xinitrc startx 登录界面 # pkg install slim slim-themes echo \u0026lsquo;slim_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf vbox(没测试) # pkg install virtualbox-ose-additions 向/etc/rc.conf写入 vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; 仅供参考看这里 因为vbox显卡太弱安装了vmware后就一直没用回过vbox,我还没测试过\nvmware # pkg install open-vm-tools xf86-video-vmware xf86-input-vmmouse 继续向/etc/rc.conf中写入 hald_enable=\u0026#34;YES\u0026#34; moused_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmblock_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmhgfs_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmmemctl_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmxnet_enable=\u0026#34;YES\u0026#34; # vmware_guest_enable=\u0026#34;YES\u0026#34; 下面注释掉的是因为在测试中如果打开的话会有各种问题\u0026hellip;.尤其鼠标 其他可见这里参考 =\u0026gt; 该Blog仅供参考, 这里面的东西很多都是有问题的.\n换源 # mkdir -p /usr/local/etc/pkg/repos vim /usr/local/etc/pkg/repos/bjtu.conf bjtu: { url: \u0026#34;pkg+http://mirror.bjtu.edu.cn/reverse/freebsd-pkg/${ABI}/quarterly\u0026#34;, mirror_type: \u0026#34;srv\u0026#34;, signature_type: \u0026#34;none\u0026#34;, fingerprints: \u0026#34;/usr/share/keys/pkg\u0026#34;, enabled: yes } FreeBSD: { enabled: no } pkg update 附录 # Ian 整理的各个软件换源Blog\n"},{"id":93,"href":"/docs/programmer/basetc/editer/","title":"编辑器使用","section":"基础工具和配置","content":" Jupyter-Note # 局域网访问 # 方法1: 使用jupyter notebook --generate-config生成配置文件 修改配置文件中c.NotebookApp.allow_root(因为安卓用的Termux跑的,所以伪root),c.NotebookApp.ip这样就能通过局域网和Token访问了 如果想要使用密码(长期使用局域网的话),可以使用from notebook.auth import passwd;passwd()生成加密密码,配置到c.NotebookApp.password 方法2: 如果只是临时的,那传入运行命令肯定最好了,如下可以使用如下格式: jupyter-notebook --allow-root --ip=0.0.0.0 自动补全 # 安装插件: pip install jupyter_contrib_nbextensions -i https://pypi.tuna.tsinghua.edu.cn/simple(此命令包含代理) 到Nbextensions中将Disable改为Enable 开始 Vim # vim 查看日志中文乱码(2021) # .bash_profile # export LC_ALL=en_US.utf-8 .vimrc # set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 set termencoding=utf-8 set encoding=utf-8 双管齐下, 一个解决系统配置, 一个解决vim配置\n中文乱码问题(2018) # 在.bash_profile中增加\nexport LANG=zh_CN.utf8 export LC_ALL=zh_CN.utf8 即可增加中文支持。 不过，还是\nexport LANG=en_US.utf8 export LC_ALL=en_US.utf8 比较香，因为中文字体这里渲染出来很难看… ^_^: 2019年5月5日19点46分\nvscode vs code # venv # Python # Command Palette...(Ctrl+Shift+p)\n\u0026gt;Python: Select Interpreter 然后选择就好了.\n当然不会那么安逸(.vscode/launch.json) 2022-01-18 11：34\n.vscode/launch.json配置(图形化都是骗人的) # { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Python: Current File\u0026#34;, // 自定义名称 \u0026#34;type\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;pythonPath\u0026#34;: \u0026#34;{配置python解释器路径}\u0026#34;, //调试程序时的工作目录，一般为${workspaceRoot}即代码所在目录 \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceRoot}\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${file}\u0026#34;, // 可直接指定文件 \u0026#34;console\u0026#34;: \u0026#34;integratedTerminal\u0026#34; } ] } find + vim 查找打开一条龙 # find * -name \u0026#34;*wd.csv\u0026#34; -exec vim {} \\; 来自find --help的解释: -exec COMMAND ; -exec COMMAND {} + -ok COMMAND ; -exec兼容多条命令, bash监控;,但find也用;中断,所以在bash运行需要转义一层\u0026hellip;.也就变成了\\;\n三兄弟『grep sed awk』 # 搬迁 -\u0026gt; [[文本三剑客]]\n"},{"id":94,"href":"/docs/programmer/platforms/os/note-of-linux/","title":"Linux 笔记","section":"平台","content":"git fetch \u0026ndash;all git reset \u0026ndash;hard origin/master git pull 交换分区 # 大小推荐 # 物理内存 交换分区（SWAP） \u0026lt;= 4G 至少4G 4~16G 至少8G 16G~64G 至少16G 64G~256G 至少32G 调节操作 # # 查看命令相关 sudo swapo swapoff swapon # 关闭现有的交换分区 sudo swapoff /swapfile # 查看效果 htop # 预支出一块儿空地 sudo fallocate -l 16G /swapfile du -sh /swapfile # 设置权限 防止误操作 sudo chmod 600 /swapfile # 整上 sudo mkswap /swapfile mkswap: /swapfile：警告，将擦除旧的 swap 签名。 正在设置交换空间版本 1，大小 = 16 GiB (17179865088 个字节) 无标签， UUID=6de8b5e1-bdc3-4e7b-98c9-6801126fcb0b # 开! sudo swapon /swapfile # 查看 swapon --show NAME TYPE SIZE USED PRIO /swapfile file 16G 535.3M -2 # 写到fstab自动挂载 sudo vim /etc/fstab fstab示例:\n# /etc/fstab: static file system information. # # Use \u0026#39;blkid\u0026#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # \u0026lt;file system\u0026gt; \u0026lt;mount point\u0026gt; \u0026lt;type\u0026gt; \u0026lt;options\u0026gt; \u0026lt;dump\u0026gt; \u0026lt;pass\u0026gt; # / was on /dev/nvme0n1p5 during installation UUID=a99e475d-766f-49db-85ce-5c1308beab58 / ext4 errors=remount-ro 0 1 # /boot/efi was on /dev/nvme0n1p1 during installation UUID=5C1D-5115 /boot/efi vfat umask=0077 0 1 /swapfile none swap sw 0 0 LABEL=Windows /mnt/Windows auto nosuid,nodev,nofail,x-gvfs-show,x-gvfs-name=Windows 0 0 靓仔是/swapfile none swap sw 0 0\ntar 指定解压目录 # tar xvf test.tar.gz -C /data/ tree . ├── data │ ├── test Ubuntu22.04 切换wifi # # 切换 sudo nmcli con up CMCC-XXXX-5G # 使用show可以查看保存wifi e # 连接wifi sudo nmcli dev wifi connect CMCC-XXXX password woshipassword123 # 删除记录 sudo nmcli con delete CMCC-YYYY # 开关wifi sudo nmcli radio wifi on sudo nmcli radio wifi off Ubuntu22.04 依赖项整理 # vbox: libqt5opengl5 kate: konsole Qt5.12.12: mesa-common-dev, libgl1-mesa-dev OpenCV4.6.0: libgtk2.0-dev, pkg-config, libcanberra-gtk-module 如果没有安装这俩依赖不会影响编译，但是编译后会有功能损失，补充安装后不会修复； 如果想修复，只能安装后再编译一次； dpkg .deb # Install # sudo dpkg -i file.deb\nc l r P L s # -c列出内容 -l提取包信息 -r移除一个已安装的包 -P完全清除一个已安装包 -L列出安装所有文件清单 -s显示已安装包信息 WSL # wsl问题 因为后面不太喜欢这种东西了,还是上了物理机. 所以就不粘贴过来了.\nsudo apt upgrade # E: Sub-process /usr/bin/dpkg returned an error code (1)\n解决 # sudu下\n备份/var/lib/dpkg/info 新建/var/lib/dpkg/info 重新执行更新 合并/var/lib/dpkg/info 和 备份文件 完 说明 # 非原理性解决方案, 若解决不了, 另寻他法或者需要直击灵魂.\n磁盘操作 # NTFS # 修复挂载问题 # ntfsfix /dev/{disk name} 一般发行版 # 在此中可以使用ntfsfix, 不过刚才看了一圈儿, 好像, 这工具就是来源于下面所介绍的\n树莓派 # 因为没有预装ntfsfix, 所以\n安装 ntfs-3g 很久远的工具: sudo apt install ntfs-3g (看3g就知道年代久远 😄) 取消挂载, sudo umount /dev/sda{N} 重新挂载, mount –t ntfs /dev/sda{n} /media/pi 就可以有读写权限了. 不然只有读的, 挺不好的.\n不过在windows放了缓存在里面的话就没办法挂载为可写了， 方法是取消Win的快速启动功能后关机，不使用休眠.\n磁盘查询命令 # fdisk -l df -h LVM概要（がいよう）\n自弁の理解：\n将零散的集合起来，再进行动态分组。 PV \u0026raquo; VG \u0026raquo; LV じゃあ作成（さくせい）： # pvcreat disk1 disk2 di3 ...　# 集合 pvs|pvdisplay vgcreat 集合name 1 2 3 ... # 集合 vgs|vgdisplay lvcreat -n name -L size 集name lvs|lvdisplay 格式化磁盘: # mkfs.ext4 /dev/集name/name # 格式化此（PS：路径为所示） 注: 不过要采用这种方法来给Linux扩容的话需要之前时就选定Linux磁盘管理为LVM，否则主目录在之后不能添加lv组，也就谈不上添加。\nLVMの削除（さくじょ）： # LV lvremove /dev/... VG vgremove 集name PV(物理卷) pvremove /dev/... disk LVの追加（ついか）： # lvexpend -L +1G /dev/集name/name # 增加了空白空间 resize2fs /dev/... 更新文件系统 使空白空间得以有身份（文件系统） disk VGの追加 # pvcreat /dev/sdd(new) vgexpend 集name /dev/sdd 网络 # SSH 远程终端控制 # ssh root(usrname)@192.168.^.^ (IP) 输入密码错误之后——就…之前解决过，然而忘了上次怎么解决的了(京东云)反正这次是等着等着突然就能连接了。 以后可得把解决方案记录到这儿ヽ(*。\u0026gt;Д\u0026lt;)o゜\n另外，ssh公钥🔑连接方式可以参考makethingseasy中的描写。\nping 测试连通 # mtr 测试网络+每个路由信息 * + IP VNC 桌面远程 # Emmmm 当时还写了这个？现在倒是用这个在链接树莓派o(∩∩)o\u0026hellip;哈哈(2021-04-22)\n壓縮打包 # tar -zxvf **.tar.gz: .tar.gz tar -jxvf **.tar.bz2: .tar.bz2 tar # tar xvzf fileName.tar.gz tar cvzf fileName.tar.gz targerName x: 解压 c : 压缩\nexclude # exclude 后目录不用带/, --exclude需放在-cvf参数之前\ntar --exclude=\u0026#39;.*\u0026#39; --exclude=\u0026#39;.git\u0026#39; --exclude=\u0026#39;mysql*\u0026#39; -cvf xxx.tar xxx/ Ubuntu 16.04 升级 Ubuntu 18.04 # ___ 经尝试真的不如备份自我资料后重装……因为太…慢…了… 更新还不稳。\n其实还好… 就是更新速度慢了点儿。早不到十点更新到了下午13点38分。不过基于是一键式的所以还是有多点儿好处的。 更新命令\nsudo do-release-upgrade # 提示是没法找到可用更新… # 所以 之后增加了 -c # 还是不行 -d # 参数完成更新 但是python被重装了！！！！ 里面的包都没了…🐎a算了，好在软件级别的东西都还在…另外pip也损坏了，apt安装也失败，后面我就用了.py脚本重新安装，所以apt卸载再重装没试，不知道行不行。 收回前面“软件级别的都还在”，其实软件级别的也待测。\n设定系统常量 # 在用户目录下profile文件中可通过export 增加(一般来说是增加路径)\nexport IAN=/mnt/c/Users/ian sourse ~/.profile 之后便可通过cd $IAN 来访问win下的用户目录。当然，这个方法是在添加GoPath时注意到的。\nemm 其实在/etc/profile 文件下才是系统王道\nps # 今年面试还碰到个问这个问题，说什么是变量\u0026hellip;.. 把我给整蒙了\u0026hellip;.. 结果一番问下才发现他想问的就是放在/etc/profile和~/.profile里有啥区别，\n啥是系统,用户,会话级变量.唉.. 有时候突然听到基本问题就觉得对方是不是有什么深意\u0026hellip;\ntmux 虚拟多终端 # 类似于vim多窗口编辑一类的东西，emm 或者说图形化ubuntu使用ctrl+alt+t叫出来的东西。这么一对比的话就是无界面化的虚拟终端——那个是界面里的虚拟终端嘛。 用于解决ssh连接远程开启应用，断开后不关闭进程的方案。因为nohup好像并不稳定的样子…… 不过用起来… 不太了解怎么这就能够持久化了…因为毕竟是虚拟窗口，间makethingseasy中，其实…好像…大概…没什么关系吧。这两者。\n最大文件数/单进程最大文件数 # bump fs.nr_open + fs.max-file to their largest possible values\ncat /proc/sys/fs/file-max cat /proc/sys/fs/nr_open 今天(2021-04-22)看epoll的时候好奇看了一下,发现我的fs/file-max居然有9223372036854775807震惊一下.\n查看某进程限制 # 有时候某进程的远远小于上述两个的设定值\ncat /proc/21975/limits | grep \u0026#34;Max open files\u0026#34; 修改 # vim /etc/sysctl.conf # 修改/添加: fs.file-max = 1048576 sysctl -p 查看局域网内设备IP # arp -a bash 查看当前unix时间 # 在 Bash 中，你可以使用 date 命令来查看当前的 Unix 时间（即从 1970 年 1 月 1 日 00:00:00 UTC 到现在的秒数）。具体命令如下：\ndate +%s 这个命令会输出当前的 Unix 时间戳。例如：\n1697049600 如果你需要毫秒级的 Unix 时间，可以使用以下命令：\ndate +%s%3N 这个命令会输出当前的 Unix 时间戳，精确到毫秒。例如：\n1697049600123 "},{"id":95,"href":"/docs/programmer/basetc/bash/","title":"Bash","section":"基础工具和配置","content":" Bash # Auther: Ian\n自动补全 # linux中使用bash_completion工具进行自动不全，在某些发行版或者版本中make或者git没有Tab自动补全，这时在Github上找一个bash_completion文件放在相应位置就可以了。\nsudo cp bash_completion /usr/share/bash-completion/bash_completion source /usr/share/bash-completion/bash_completion Powershell # 命令历史存储在: C:\\Users\\{USERNAME}\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadLine下 ConsoleHost_history.txt文件\n"},{"id":96,"href":"/docs/programmer/basetc/gitbook/","title":"Gitbook","section":"基础工具和配置","content":" Gitbook # Author: Ian\n安装 # 官方文档 Github Gitbook 打造的 Gitbook 说明文档 使用npm进行安装, 安装npm (v4.0.0 and above is recommended) npm install gitbook-cli -g 需要sudo权限 实际在执行gitbook -V后才算是安装完成 问题 # TypeError: cb.apply is not a function # npm 安装软件不出点儿问题貌似都不是很合适, 该问题代码级问题是因为在适配某些可能本机上并没有安装的npm版本时写了bug，导致执行出错.\n所以注释掉相关代码即可，或者直接删除。删除的好处是不会因为编辑器的原因触发npm的某些缩进问题。\n62. // fs.stat = statFix(fs.stat) 63. // fs.fstat = statFix(fs.fstat) 64. // fs.lstat = statFix(fs.lstat) 固然可以通过安装相匹配版本进行适配，不过\u0026hellip;Ian怕导致本机上的hexo再出现版本不兼容的问题。 使用 # 功能 示例 个人使用习惯(Ian) 新建book gitbook init gitbook init gitbooks/Architecture 编译和运行服务 gitbook serve 编译 gitbook serve pdf # 参考自 码谱\n安装calibre sudo apt install calibre gitbook pdf \u0026lt;gitbook-folder-location\u0026gt; \u0026lt;pdf-location\u0026gt;.pdf 新版的gitbook，官方已经不支持导出pdf等电子书格式，官方的解读如下：\nPDF and other ebook formats exports ？ The new version of GitBook no longer supports exporting to PDF and other ebooks format. A lot of rich-content does not translate well from the Web to PDF. GitBook will expose a developer API for people to consume and extend their content. It is not excluded that someone build a PDF export tool using the API, but it will not be officially supported. See the section about offline access if this is the part you cared about. 放到Blog中 # hexo 为例\n将gitbook作为自项目添加到当前项目中 git submodule add git@github.com:IanVzs/book_architecture.git gitbooks/book_architecture build gitbook和hexo 再将两者静态文件放在一起 cd gitbooks/book_architecture/ \u0026amp;\u0026amp; gitbook build hexo build cp -r gitbooks/book_architecture/_book/ public/book_architecture 使用https://ianvzs.github.io | localhost:4000访问原Blog，增加uri/book_architecture访问gitbook "},{"id":97,"href":"/docs/programmer/basetc/vim/","title":"Vim","section":"基础工具和配置","content":" Vim 使用 # Auther: Ian\n注释 # # 注释 1， 12s/^/#/g --- # 取消注释 1， 12s/^#//g 其实 是vim中的 :s替换命令… 下方解释\n或者，使用列编辑的模式:\nv、选择区域、ctrl q置行首、I插入#、Esc应用到全列 ctrl v、I、#、Esc 因为有的ctrl q或者ctrl v 不能用…… 取消，即使用上述方法选中行首，删除第一个字节即可了 替换 # :s/oldWords/newWords/g g : 代表当前光标所在行。\n由此可知: # ^表行首标识符。 /^/表示行首的空字符。 而取消注释中的/^#/即表示行首的#，被//空字符所替换。\n查找高亮 # set hlsearch set nohlsearch 分屏 # 实现 # 在外部使用-o or -O参数 内部split or vsplit 操作 # 移动光标 Ctrl + w hjkl 移动分区Ctrl + w HJKL 统一高度Ctrl + w = 改变高度Ctrl + w +- # and less 阅读器~~~ 因为经常读大文件发现了这两个的无敌好处——快。\n使用命令 # cat cat -b # 查看且标注行号 -n # 同上，但也会显示空行行号 more # - space 向下翻页 # - Ctrl+F 同上 # - b back 返回一页显示 # - Ctrl+B 同上 # - Enter 向下n行,默认1 # - = 输出当前行号 # - v 调用vi/vim # - !命令 调用shell 执行命令 # - q 退出 less Vi \u0026amp;\u0026amp; Vim # 三个模式:\n命令模式 插入模式 Ex模式 para : 说明 o : 在当前行下面插入新空白行 dd : 删除当前一行。 u : 撤销一步操作 yy : 当前行-\u0026gt;缓冲区 p : 缓冲区-\u0026gt;光标之后插入 n+ y 当前及接下来n行-\u0026gt;缓冲区 r : 替换当前字符 / : 查找关键字——支持汉字呐！难得 n : 上命令下切换 next Ex下: # set number: 显示行号。（不过我已经改了配置文件，默认显示） ！+命令 代理执行系统命令。如ls cd sh 挂下编辑 显示系统命令行。 ctrl+d返回（PS:命令行下，这是关闭虚拟终端快捷键） tip:tail head 等查看命令可以和 \u0026raquo; 命令合用，将文件的首行或者结尾字添加到另一个文档～ "},{"id":98,"href":"/docs/programmer/cloudnative/k8s/argo-workflow%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90/","title":"Argo Workflow性能测试和使用场景分析","section":"k8s","content":"Github: https://github.com/argoproj\n一、简介 # Argo Workflow 是一个开源的、基于 Kubernetes 的工作流引擎，用于编排和运行容器化应用的工作流程。它使用 YAML 文件来定义工作流、依赖关系和参数。\nArgo Workflow 还支持任务的重试、跳过、并行执行和失败处理等功能。它提供了丰富的工作流控制和监控功能，可以查看工作流的状态、日志和执行历史，并支持自定义的事件触发和通知机制。\n目前Argo团队下中有如下几个子项目：\nargoproj Common project repo for all Argo Projects gitops-engine Public Democratizing GitOps argo-workflows Workflow engine for Kubernetes argo-cd Declarative continuous deployment for Kubernetes. argo-events Event-driven automation framework argo-rollouts Progressive Delivery for Kubernetes cd和rollouts一个是持续交付工具，一个是渐进式发布工具。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。这两者搭配可以设计出一个由新建任务事件触发从而启动工作流的方案。\n流程如下： ![[content/docs/programmer/base/argo_events_workfows.png]] sensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排示例 # 以下是一个扔硬币和打印结果的示例，借此可以熟悉一下Workflow的编排语法\napiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: coinflip-recursive- spec: entrypoint: coinflip templates: - name: coinflip steps: - - name: flip-coin template: flip-coin - - name: heads template: heads when: \u0026#34;{{steps.flip-coin.outputs.result}} == heads\u0026#34; - name: tails template: coinflip when: \u0026#34;{{steps.flip-coin.outputs.result}} == tails\u0026#34; - name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = \u0026#34;heads\u0026#34; if random.randint(0,1) == 0 else \u0026#34;tails\u0026#34; print(result) - name: heads container: image: alpine:3.6 command: [sh, -c] args: [\u0026#34;echo \\\u0026#34;it was heads\\\u0026#34;\u0026#34;] 至于部署Argo的步骤网上都有，为了精简文章就不在此赘述。下面关于一些在使用中需要注意的重要问题进行一些说明。\n三、空间和性能 # ETCD占用 # 因为Argo是基于Kubernetes的，所以空间问题一般不需要怎么关注，但如果在使用场景中需要频繁创建工作流，还是需要关注一下etcd的空间情况。因为Kubernetes集群中的配置、运行状态和其他各项关键信息都存储在etcd，在频繁创建工作流、且工作流很长时，这类信息会占据大量空间：\nETCDCTL_API=3 etcdctl --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/healthcheck-client.crt --key /etc/kubernetes/pki/etcd/healthcheck-client.key --write-out=table endpoint status ENDPOINT ID VERSION DB SIZE IS LEADER IS LEARNER RAFT TERM RAFT INDEX RAFT APPLIED INDEX ERRORS 127.0.0.1:2379 871f72e4ab5a28e8 3.5.0 104 MB true false 35 348058564 348058564 根据提供的信息，可以看到以下解释：\nVERSION: etcd的版本为3.5.0。 DB SIZE: etcd数据库当前占用的空间大小为104 MB。 RAFT APPLIED INDEX: 当前etcd集群已应用的Raft Index为348058564。 ERRORS: 没有显示任何错误信息。 总体上，这些信息展示了etcd集群的状态，包括节点角色、版本、数据库大小等，经过测试，创建100个十步左右的工作流需要占用20mb空间。 性能 # 以下测试全部是通过创建一个概率性失败和重试的workflow测试而来：\n它总共包括三步(第二步和第三步并行执行) 每一步都有一定的几率失败，失败后每一步最多重试10次，一旦成功后进入下一步 可以通过调节失败几率模拟出在实际环境中各个workflow分别处于不同进度的情况 下图中第一步一共重试了四次，失败三次，第四次时成功，随后2b全部失败，2a第三步成功，整个工作流耗时4分钟 ![[三步随机出错workflow.png]] 在并发启动十五个工作流时，并且每一步都保证100%成功，整个流程花费2min左右，三个子步骤分别花费50-60秒。 ![[全部成功的树状图.png]] ![[全成功workflow耗时.png]] ![[全成功的step耗时.png]]\n在全部错误时，并且每一步都保证100%失败，总计经历11次尝试，整个流程花费10分钟左右，11个子步骤分别花费60秒左右 ![[全部失败的树状图.png]] ![[全错误workflow耗时.png]] ![[全错误的step耗时.png]]\n可见每一步成功与否，与执行花费无关。不会出现错误重试避让成功工作流的现象。\n使用argo submit retry_template.yaml -n websafe --watch 和 kubectl get pod -n {NAMESPACE} | grep workflow查看工作流运行状态，可知在工作流的每一步执行时都是实时初始化pod，所以以上花费约等于每一步初始化pod所用的时间。即以上时间是在运行逻辑之外无法优化的固定时间花费。 ![[watch_workflow.png]] ![[work_flow_pod.png]]\n总结 # 由以上信息可见Argo WorkFlow有基于 Kubernetes的简单、易用、便于迁移的优点，但同时有启动速度慢，执行工作流的每一步时都具有额外消耗的缺点。\n所以它适用于不关注实时性的业务，本身执行时间长的任务。例如AI中的模型训练，可以令每次训练都无需关注环境配置，可以做到自动资源、埋点分析和生成报表。例如在以下场景中： ![[ai_model_workflow.png]] 训练人员可以通过yaml文件自由更换训练、测试数据，选择输出模型发布方案。可以很方便的查看每一阶段信息，且不用编写代码关注运行环境。 进了工作流程中步骤之间的松耦合，并开辟了在未来工作流中重用组件的可能性。\n"},{"id":99,"href":"/docs/programmer/cloudnative/k8s/argo-%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","title":"Argo 使用记录","section":"k8s","content":"Github: https://github.com/argoproj\n一、简介 # 目前Argo项目中有如下几个子项目：\nargoproj Common project repo for all Argo Projects\ngitops-engine Public Democratizing GitOps\nargo-workflows Workflow engine for Kubernetes\nargo-cd Declarative continuous deployment for Kubernetes.\nargo-events Event-driven automation framework\nargo-rollouts Progressive Delivery for Kubernetes\ncd和rollouts一个是持续交付工具，一个是渐进式发布工具，与原子能力关系不大。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。都与本次原子能力相关。\n这样，就可以设计出一个由新建扫描任务事件触发，实例化经过编排可实现扫描全流程的方案。\n流程如下：![[book_architecture/content/docs/programmer/base/argo_events_workfows.png]]\nsensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排 # name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = \u0026ldquo;heads\u0026rdquo; if random.randint(0,1) == 0 else \u0026ldquo;tails\u0026rdquo; print(result)\nname: heads container: image: alpine:3.6 command: [sh, -c] args: [\u0026ldquo;echo \u0026quot;it was heads\u0026quot;\u0026rdquo;] 三、Argo Events使用 # 定义一个webhook(名称: webhook_example)路径/webhook, 端口12000, 接收 POST 方法. apiVersion: argoproj.io/v1alpha1 kind: EventSource metadata: name: webhook spec: service: ports: - port: 12000 targetPort: 12000 webhook: webhook_example: port: \u0026#34;12000\u0026#34; endpoint: /webhook method: POST 定义Sensor 指定行为 Yaml说明: i. 定义了订阅的EventSource以及具体的Webhook(一个EventSource可以定义多个Webhook,因此指定俩参数) ii. Trigger中定义了对应Action 创建一个werkflow, workflow的spec在respirce中配置 iii. parameters定义了workfolw的参数,从event中获取,如上将整个event都作为input(只获取body部分可通过: dataKey: body.message) iv: 此时 curl -X POST -d '{\u0026quot;message\u0026quot;: \u0026quot;Hello\u0026quot;}' 127.0.0.1:12000/webhook,可见argo workflow中创建了一个实例. 如传入整个请求,获得的数据可能经由base64编码的,需要解码后使用{\u0026quot;context\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;data\u0026quot;: \u0026quot;包含header和body\u0026quot;} v: 其他用法查看: 这里\n需验证的问题 # workflow并行处理多个不同参数的相同任务效率需要验证 四、部署 # 1. 运维命令 # argo submit hello-world.yaml # submit a workflow spec to Kubernetes argo list # list current workflows argo get hello-world-xxx # get info about a specific workflow argo logs hello-world-xxx # print the logs from a workflow argo delete hello-world-xxx # delete workflow 2. 安装和启动 # kubectl create namespace argo kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml # 最全-精简安装看别的 # 查看运行状态 kubectl get pods -n argo kubectl get svc -n argo # 将svc改为nodeport方便访问Web UI kubectl edit svc -n argo argo-workflow-argo-workflows-server # 或者argo-server 名字会变但是差不多这意思 进去手动将ClusterIP改为NodePort # 查看argo server pod在哪个node上运行 端口映射到了node哪个端口 kubectl get pods -n argo -o wide # 查看该node IP kubectl get node -o wide # http//nodeip:nodePort访问 # 提交任务 argo submit https://github.com/argoproj/argo-workflows/blob/master/examples/coinflip.yaml --watch -n argo # 将yaml下载下载执行为佳 权限问题 # User \u0026#34;system:serviceaccount:argo:default\u0026#34; cannot patch resource \u0026#34;pods\u0026#34; in API group \u0026#34;\u0026#34; in the namespace \u0026#34;argo\u0026#34;: RBAC: role.rbac.authorization.k8s.io \u0026#34;argo-workflow\u0026#34; not found Confusing, possibly erroneous RBAC warnings (\u0026#34;Failed to get pod\u0026#34;) 可见: argo-workflows Issues\nETCD # 因为k8s状态都在etcd集群中，所以需要关注一下大量workflow会不会占用过多的容量资源\nETCDCTL_API=3 etcdctl --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/healthcheck-client.crt --key /etc/kubernetes/pki/etcd/healthcheck-client.key --write-out=table endpoint status +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | 127.0.0.1:2379 | 871f72e4ab5a28e8 | 3.5.0 | 104 MB | true | false | 35 | 348058564 | 348058564 | | +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 根据提供的信息，可以看到以下解释：\nENDPOINT: etcd集群的地址为127.0.0.1:2379。 ID: etcd集群的唯一标识为871f72e4ab5a28e8。 VERSION: etcd的版本为3.5.0。 DB SIZE: etcd数据库当前占用的空间大小为104 MB。 IS LEADER: 当前节点是否为etcd集群的Leader节点，这里显示为true。 IS LEARNER: 当前节点是否为etcd集群的Learner节点，这里显示为false。 RAFT TERM: 当前etcd集群的Raft Term为35。 RAFT INDEX: 当前etcd集群的Raft Index为348058564。 RAFT APPLIED INDEX: 当前etcd集群已应用的Raft Index为348058564。 ERRORS: 没有显示任何错误信息。 总体上，这些信息展示了etcd集群的状态，包括节点角色、版本、数据库大小等。 大量Workflows优化建议 # You have at least 230 completed workflows. Reducing the total number of workflows will reduce your costs. Learn more at https://argoproj.github.io/argo-workflows/cost-optimisation/\n创建时缺少安全上下文问题 # This workflow does not have security context set. You can run your workflow pods more securely by setting it. Learn more at https://argoproj.github.io/argo-workflows/workflow-pod-security-context/\n修改执行器 # "},{"id":100,"href":"/docs/programmer/cloudnative/middleware/kafka-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","title":"Kafka 安装和使用","section":"中间件","content":" 常用命令 # 创建topic # sh kafka-console-producer.sh --create --topic scanner_device_log --bootstrap-server localhost:9092 --partitions 0 --replication-factor 1 发送接收测试 # sh kafka-console-producer.sh --broker-list localhost:9092 --topic test sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 单机部署 # 本文链接🔗 Kafka是一个开源的分布式消息引擎/消息中间件，同时Kafka也是一个流处理平台。Kakfa支持以发布/订阅的方式在应用间传递消息，同时并基于消息功能添加了Kafka Connect、Kafka Streams以支持连接其他系统的数据(Elasticsearch、Hadoop等) Kafka在生产环境下使用通常是集群化部署的，同时也要依赖ZooKeeper集群，这对开发测试环境来说比较重，不过我们可以通过Docker便捷Kafka单机的方式，节省部署时间以及机器资源\n1、本文主要内容 # 通过Docker手动部署ZooKeeper\u0026amp;Kafka 通过Docker Compose快捷部署ZooKeeper\u0026amp;Kafka Kafka发送、接收消息测试 2、本文环境信息 # 工具 说明 适配 Docker Docker CE 23.0.5 Docker CE Docker Desktop 4.19.0 4.0.x ZooKeeper zookeeper:3.8（Docker Image ） zookeeper:3.x（Docker Image ） Kafka wurstmeister/kafka:2.13-2.8.1（Docker Image） wurstmeister/kafka:2.x（Docker Image） 二、手动部署Kafka # 1、拉取镜像 # 先通过docker pull 命令把镜像拉取下来，方便后续操作\ndocker pull zookeeper:3.8 docker pull wurstmeister/kafka:2.13-2.8.1 2、创建数据卷 # 创建数据卷，方便数据持久化\ndocker volume create zookeeper_vol docker volume create kafka_vol 3、创建ZooKeeper容器 # 创建zookeeper-test容器，同时挂载数据卷和并指定端口映射（2181）\ndocker run -d --name zookeeper-test -p 2181:2181 \\ --env ZOO_MY_ID=1 \\ -v zookeeper_vol:/data \\ -v zookeeper_vol:/datalog \\ -v zookeeper_vol:/logs \\ zookeeper 4、创建Kafka容器 # 创建kafka-test容器，同时挂载数据卷和并指定端口映射（9092），并将zookeeper-test链接到该容器，使Kafka可以成功访问到zookeeper-test，Kafka相关参数通过环境变量（—env）设置\ndocker run -d --name kafka-test -p 9092:9092 \\ --link zookeeper-test \\ --env KAFKA_ZOOKEEPER_CONNECT=zookeeper-test:2181 \\ --env KAFKA_ADVERTISED_HOST_NAME=localhost \\ --env KAFKA_ADVERTISED_PORT=9092 \\ --env KAFKA_LOG_DIRS=/kafka/logs \\ -v kafka_vol:/kafka \\ wurstmeister/kafka 通过这种方式可以掌握整个部署过程，也可以达成ZooKeeper的复用，不过稍显繁琐\n三、Docker Compose部署Kafka # 1、创建Docker Compose配置文件 # 使用Docker Compose可以将一系列创建及映射资源（网络、数据卷等）操作放在配置文件中，并且可以通过depends_on参数指定容器的启动顺序，通过environment参数指定Kafka需要的基本参数信息 创建kafka-group.yml，保存以下信息\nversion: \u0026#39;3\u0026#39; name: kafka-group services: zookeeper-test: image: zookeeper ports: - \u0026#34;2181:2181\u0026#34; volumes: - zookeeper_vol:/data - zookeeper_vol:/datalog - zookeeper_vol:/logs container_name: zookeeper-test kafka-test: image: wurstmeister/kafka ports: - \u0026#34;9092:9092\u0026#34; environment: KAFKA_ADVERTISED_HOST_NAME: \u0026#34;localhost\u0026#34; KAFKA_ZOOKEEPER_CONNECT: \u0026#34;zookeeper-test:2181\u0026#34; KAFKA_LOG_DIRS: \u0026#34;/kafka/logs\u0026#34; volumes: - kafka_vol:/kafka depends_on: - zookeeper-test container_name: kafka-test volumes: zookeeper_vol: {} kafka_vol: {} 2、启动容器组 # # 启动Kafka容器组 docker compose -f kafa-group.yml up -d # 输出示例 ✔ Network kafka-group_default Created ✔ Volume \u0026#34;kafka-group_zookeeper_vol\u0026#34; Created ✔ Volume \u0026#34;kafka-group_kafka_vol\u0026#34; Created ✔ Container zookeeper-test Started ✔ Container kafka-test Started 四、Kafka消息测试 # 1、启动Kafka Producer # 新开一个命令后窗口，然后执行以下命令，启动Kafka Producer，准备往topic:test发送消息\n# 进入容器 docker exec -it kafka-test /bin/bash # 进入Kafka bin目录 cd /opt/kafka/bin # 启动Producer sh kafka-console-producer.sh --broker-list localhost:9092 --topic test 2、启动Kafka Consumer # 新开一个命令后窗口，然后执行以下命令，启动Kafka Consumer，订阅来自topic:test的消息\n# 进入容器 docker exec -it kafka-test /bin/bash # 进入Kafka bin目录 cd /opt/kafka/bin # 启动Consumer sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 3、收发消息测试 # 在Producer命令行窗口输入内容，然后回车即可发送消息 然后再Consumer命令行窗口可以看到收到的消息\n![[kafka测试效果图.png]]\n五、备注 # 1、可能碰到的问题 # 如果你碰到ZooKeeper、Kafka容器无法正常启动，可以删除数据卷以及容器后进行创建\n# 停用\u0026amp;删除容器 docker stop zookeeper-test kafka-test docker rm zookeeper-test kafka-test # 删除数据卷 docker volume rm zookeeper_vol kafka_vol docker volume rm kafka-group_kafka_vol kafka-group_zookeeper_vol 2、相关阅读 # https://ken.io/note/zookeeper-cluster-deploy-guide https://ken.io/note/kafka-cluster-deploy-guide https://hub.docker.com/_/zookeeper https://hub.docker.com/r/wurstmeister/kafka 六、端到端延迟 # 来自: 一文理解kafka端到端的延迟\n理解到端的延迟(end-to-end latency) # 端到端延时是指应用逻辑调用KafkaProducer.send()生产消息到该消息被应用逻辑通过KafkaConsumer.poll()消费到之间的时间。\n因此，端到端的延迟主要会由以下几个部分组成: # Produce time: 内部Kafka producer处理消息并将消息打包的时间 Publish time: producer发送到broker并写入到leader副本log的时间 Commit time: follower副本备份消息的时间 Catch-up time: 消费者追赶消费进度，消费到该消息位移值前所花费的时间 Fetch time: 从broker读取该消息的时间 ![[kafka端到端.webp]]\n![[端到端延迟图.jpg]]\n"},{"id":101,"href":"/docs/programmer/cloudnative/sonar-%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E6%A3%80%E6%9F%A5/","title":"Sonar 代码静态检查","section":"云原生","content":"平台地址 需要自建\n在平台新建项目，新建token后可以自动生成扫描命令(拉代码, cd进去后在项目代码/路径下执行)：\nsonar-scanner \\ -Dsonar.projectKey=scancenter \\ -Dsonar.sources=. \\ -Dsonar.host.url=https://sonar-xa.inone.nsfocus.com \\ -Dsonar.login=3e569f7abcfd8a64067d790f038c57a6a6b73207 如果使用的是他人的token，需要给授权。\n"},{"id":102,"href":"/docs/programmer/gui/example/hidden/","title":"Hidden","section":"Blog 构建","content":" This page is hidden in menu # Quondam non pater est dignior ille Eurotas # Latent te facies # Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\nPater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor Cum honorum Latona # O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); } Fronde cetera dextrae sequens pennis voce muneris # Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "},{"id":103,"href":"/docs/programmer/gui/example/shortcodes/","title":"Shortcodes","section":"Blog 构建","content":" Button # Columnns # Details # Expand # Hints # Tabs # "},{"id":104,"href":"/docs/programmer/gui/example/shortcodes/buttons/","title":"Buttons","section":"Shortcodes","content":" Buttons # Buttons are styled links that can lead to local page or external link.\nExample # {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}} Get Home Contribute "},{"id":105,"href":"/docs/programmer/gui/example/shortcodes/columns/","title":"Columns","section":"Shortcodes","content":" Columns # Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example # Left Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nMid Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!\nRight Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":106,"href":"/docs/programmer/gui/example/shortcodes/details/","title":"Details","section":"Shortcodes","content":" Details # Details shortcode is a helper for details html5 element. It is going to replace expand shortcode.\nExample # {{\u0026lt; details \u0026#34;Title\u0026#34; [open] \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} {{\u0026lt; details title=\u0026#34;Title\u0026#34; open=true \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} Title Markdown content # Lorem markdownum insigne\u0026hellip;\n"},{"id":107,"href":"/docs/programmer/gui/example/shortcodes/expand/","title":"Expand","section":"Shortcodes","content":" Expand # Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample # Default # {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}} Expand ↕ Markdown content # Lorem markdownum insigne\u0026hellip;\nWith Custom Label # {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}} Custom Label ... Markdown content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":108,"href":"/docs/programmer/gui/example/shortcodes/hints/","title":"Hints","section":"Shortcodes","content":" Hints # Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example # Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa "},{"id":109,"href":"/docs/programmer/gui/example/shortcodes/section/","title":"Section","section":"Shortcodes","content":" Section # Section renders pages in section as definition list, using title and description.\nExample # {{\u0026lt; section \u0026gt;}} First Page First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Second Page Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. "},{"id":110,"href":"/docs/programmer/gui/example/shortcodes/section/first-page/","title":"First Page","section":"Section","content":" First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"},{"id":111,"href":"/docs/programmer/gui/example/shortcodes/section/second-page/","title":"Second Page","section":"Section","content":" Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"},{"id":112,"href":"/docs/programmer/gui/example/shortcodes/tabs/","title":"Tabs","section":"Shortcodes","content":" Tabs # Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example # MacOS MacOS # This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux # This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows # This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":113,"href":"/docs/programmer/hardware/raspberrypi/","title":"Raspberry Pi","section":"硬件","content":" 树莓派 # 详细文档 # 参考Cloud Atlas\n很详细的罗列了树莓派各个版本的参数以及IO\u0026amp;其他参数的汇总，属于对官方文档的翻译以及补充，基于实践的补充，很有用。\n"},{"id":114,"href":"/docs/programmer/hardware/screen/","title":"Screen","section":"硬件","content":" 便携屏幕 # 某日入得4K便携屏幕一个, 甚是欢喜。无论手机、NS、PC用之皆爽.然NS 1080P 缩放至 4k 略糊，只可远观。\n某日因压了个键盘和书，搬，屏幕裂，屏花之。方知平时屏幕擦灰时，稍加用力就会破碎感不是虚妄，而是确实。可见质量甚是不行，弃。\n"},{"id":115,"href":"/docs/programmer/langs/python/paramiko-%E4%BD%BF%E7%94%A8-sshsftp/","title":"Paramiko 使用 Ssh\u0026sftp","section":"Python","content":" 基础用法-ssh 和 sftp文件传输 # import os import gzip import shutil import paramiko import multiprocessing from pathlib import Path from loguru import logger from config import globalconf class SSHConnection(object): def __init__(self, host=None, port=None, username=None, pwd=None, pk_path=None): \u0026#34;\u0026#34;\u0026#34; :param host: 服务器ip :param port: 接口 :param username: 登录名 :param pwd: 密码 \u0026#34;\u0026#34;\u0026#34; self.host = host self.port = port self.username = username self.pwd = pwd self.pk_path = pk_path def __enter__(self): self.connect() return self def __exit__(self, exc_type, exc_val, exc_tb): self.close() return True def connect(self): transport = paramiko.Transport((self.host, self.port)) # transport.connect(username=self.username, password=self.pwd) pk = paramiko.RSAKey.from_private_key_file(self.pk_path) transport.connect(username=self.username, pkey=pk) self.__transport = transport self.sftp = paramiko.SFTPClient.from_transport(self.__transport) def close(self): self.__transport.close() self.sftp.close() def upload(self, local_path, target_path): self.sftp.put(local_path, target_path) def download(self, remote_path, local_path): sftp = paramiko.SFTPClient.from_transport(self.__transport) sftp.get(remote_path, local_path) def listdir(self, path): return self.sftp.listdir(path=path) def listdir_attr(self, path): return self.sftp.listdir_attr(path=path) def download_slowly(self, remote_path, local_path): sftp = paramiko.SFTPClient.from_transport(self.__transport) # # 旧方法下载大文件会出现Server connection dropped # sftp.get(remote_path, local_path) # 新方法下载大文件成功 # 这将避免Paramiko预取缓存，并允许您下载文件，即使它不是很快 with sftp.open(remote_path, \u0026#39;rb\u0026#39;) as fp: shutil.copyfileobj(fp, open(local_path, \u0026#39;wb\u0026#39;)) def cmd(self, command): ssh = paramiko.SSHClient() # 执行命令 stdin, stdout, stderr = ssh.exec_command(command) # 获取命令结果 result = stdout.read() result = str(result, encoding=\u0026#39;utf-8\u0026#39;) return result class SSHConnectionManager(object): def __init__(self, host, port, username, pwd, pk_path): self.ssh_args = { \u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port, \u0026#34;username\u0026#34;: username, \u0026#34;pk_path\u0026#34;: pk_path, \u0026#34;pwd\u0026#34;: pwd } def __enter__(self): self.ssh = SSHConnection(**self.ssh_args) self.ssh.connect() return self.ssh def __exit__(self, exc_type, exc_val, exc_tb): self.ssh.close() return True def clear_dir(path): \u0026#34;\u0026#34;\u0026#34; 清空文件夹：如果文件夹不存在就创建，如果文件存在就清空！ :param path: 文件夹路径 :return: \u0026#34;\u0026#34;\u0026#34; import os import shutil try: if not os.path.exists(path): os.makedirs(path) else: shutil.rmtree(path) os.makedirs(path) return True except: return False def decompress_gz(gz_file): with gzip.GzipFile(gz_file) as file: for i in file: yield i def get_file_sftp(tar_path): temp_path = os.path.join(globalconf.SFTP_TEMP_PATH, os.path.split(tar_path)[-1]) try: with SSHConnection( host=globalconf.SFTP_SERVER_HOST, port=globalconf.SFTP_SERVER_PORT, username=globalconf.SFTP_USERNAME, pwd=\u0026#34;\u0026#34;, pk_path=globalconf.SFTP_KEY_PATH ) as sftp: sftp.download_slowly(tar_path, temp_path) except Exception as err: logger.error(f\u0026#34;sftp 下载文件出错: {err}\u0026#34;) return temp_path def format_file_list(file_list): root_dir = os.path.dirname(file_list[0]) sub_files = set([os.path.basename(file) for file in file_list]) return root_dir, sub_files def is_sftp_file_exists(task_id, path): exists = False if isinstance(path, str) and path: path = [path] rootdir, _ = format_file_list(path) try: with SSHConnection( host=globalconf.SFTP_SERVER_HOST, port=globalconf.SFTP_SERVER_PORT, username=globalconf.SFTP_USERNAME, pwd=\u0026#34;\u0026#34;, pk_path=globalconf.SFTP_KEY_PATH ) as sftp: list_file_names = sftp.listdir(rootdir) if str(task_id) in str(list_file_names): exists = True except Exception as err: logger.error(f\u0026#34;sftp 获取文件列表错误: {err}\u0026#34;) return exists class SFTPFileManager_Tool(object): def __init__(self, host, port, username, pwd, pk_path): \u0026#34;\u0026#34;\u0026#34; init :param host: ip :param port: 端口 :param username: 用户名 :param pwd: 密码 \u0026#34;\u0026#34;\u0026#34; self.ssh_args = {\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port, \u0026#34;username\u0026#34;: username, \u0026#34;pwd\u0026#34;: pwd, \u0026#34;pk_path\u0026#34;: pk_path} def exists(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否存在 :param path: :return: \u0026#34;\u0026#34;\u0026#34; is_exists = False with SSHConnectionManager(**self.ssh_args) as ssh: result = ssh.cmd(f\u0026#34;find {path}\u0026#34;) if result: is_exists = True return is_exists def is_file(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否是文件 :param path: :return: \u0026#34;\u0026#34;\u0026#34; if self.exists(path): with SSHConnectionManager(**self.ssh_args) as ssh: prefix = ssh.cmd(f\u0026#34;ls -ld {path}\u0026#34;)[0] if prefix == \u0026#39;-\u0026#39;: return True else: return False else: return False def is_dir(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否是目录 :param path: :return: \u0026#34;\u0026#34;\u0026#34; if self.exists(path): with SSHConnectionManager(**self.ssh_args) as ssh: prefix = ssh.cmd(f\u0026#34;ls -ld {path}\u0026#34;)[0] if prefix == \u0026#39;d\u0026#39;: return True else: return False else: return False def download_file(self, remote_path, local_path): \u0026#34;\u0026#34;\u0026#34; 下载文件 :param remote_path: 远程文件路径 :param local_path: 本地文件路径 :return: \u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;正下载文件{remote_path}...\u0026#34;) with SSHConnectionManager(**self.ssh_args) as ssh: if not Path(local_path).parent.exists(): Path(local_path).parent.mkdir(parents=True) ssh.download_slowly(remote_path=remote_path, local_path=local_path) def download_folder(self, remote_folder, local_folder): \u0026#34;\u0026#34;\u0026#34; 下载文件夹 :param remote_folder: 远程文件夹目录 :param local_folder: 本地文件夹目录 :return: \u0026#34;\u0026#34;\u0026#34; with SSHConnectionManager(**self.ssh_args) as ssh: dst_folder = Path(local_folder) if not dst_folder.exists(): dst_folder.mkdir(parents=True) clear_dir(str(dst_folder)) files_list = ssh.cmd(\u0026#34;ls {}\u0026#34;.format(remote_folder)) files_list = files_list.split(\u0026#39;\\n\u0026#39;) files_list = [x for x in files_list if x] # 多进程下载文件 cpu_count = multiprocessing.cpu_count() // 2 if cpu_count == 0: cpu_count = 1 pool = multiprocessing.Pool(cpu_count) for file in files_list: remote_path = remote_folder + \u0026#34;/\u0026#34; + file local_path = dst_folder.joinpath(file) pool.apply_async(func=self.download_file, args=(remote_path, local_path)) pool.close() pool.join() # 主进程下载文件 # for file in files_list: # remote_path = remote_folder + \u0026#34;/\u0026#34; + file # local_path = dst_folder.joinpath(file) # print(f\u0026#34;正下载{remote_path}...\u0026#34;) # ssh.download_slowly(remote_path=remote_path, local_path=local_path) if __name__ == \u0026#34;__main__\u0026#34;: a = SFTPFileManager_Tool(host=\u0026#34;1.1.1.1\u0026#34;, port=5050, username=\u0026#34;sftpuser\u0026#34;, pwd=\u0026#34;\u0026#34;, pk_path=\u0026#34;/root/.ssh/id_rsa\u0026#34;) b = a.is_dir(\u0026#34;/hello/\u0026#34;) print(b) 端口映射 # 将远程机器上的端口转发到本机 # import socket import select from socket import AF_INET, SOCK_STREAM import paramiko ssh_client = paramiko.SSHClient() ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) ssh_client.connect(\u0026#34;{remote_host}\u0026#34;,port={remote_port}}, username=\u0026#34;{username}\u0026#34;,password=\u0026#34;{passwd}\u0026#34;, look_for_keys=False, allow_agent=False) transport = ssh_client.get_transport() channel = transport.open_channel(\u0026#39;direct-tcpip\u0026#39;, (\u0026#34;{remote_host}\u0026#34;, {remote_port}), (\u0026#34;localhost\u0026#34;, {local_port})) local_socket = socket.socket(AF_INET, SOCK_STREAM) local_socket.bind((\u0026#39;localhost\u0026#39;, 5555)) local_socket.listen(1) client_socket, client_address = local_socket.accept() while True: # 使用select来监控socket是否有数据可读 r, w, e = select.select([client_socket, channel], [], []) if client_socket in r: data = client_socket.recv(4096) if not data: break channel.send(data) if channel in r: data = channel.recv(4096) if not data: break client_socket.send(data) "},{"id":116,"href":"/excalidraw/hello-drawing-2024-04-25-16.45.19/","title":"Hello Drawing 2024 04 25 16.45.19","section":"Excalidraws","content":"==⚠ Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠==\nText Elements # %%\nDrawing # { \u0026#34;type\u0026#34;: \u0026#34;excalidraw\u0026#34;, \u0026#34;version\u0026#34;: 2, \u0026#34;source\u0026#34;: \u0026#34;https://github.com/zsviczian/obsidian-excalidraw-plugin/releases/tag/2.1.6\u0026#34;, \u0026#34;elements\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 13, \u0026#34;versionNonce\u0026#34;: 1245203698, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;u1jPM8UifU2dBaIDVmGcI\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -697.75, \u0026#34;y\u0026#34;: 691.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 21, \u0026#34;height\u0026#34;: 27, \u0026#34;seed\u0026#34;: 1090511178, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0, 0.5 ], [ 0, 1 ], [ 0, 5.5 ], [ -3.5, 10 ], [ -9, 16.5 ], [ -15.5, 22.5 ], [ -21, 27 ], [ -21, 27 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.1447928547859192, 0.14517433941364288, 0.14517433941364288, 0.1444266438484192, 0.12252994626760483, 0.0796368345618248, 0.011474784463644028, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 15, \u0026#34;versionNonce\u0026#34;: 1307882286, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;jzQyjYxa-e4ohqXOq3uM3\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -709.75, \u0026#34;y\u0026#34;: 716.484375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 4.5, \u0026#34;height\u0026#34;: 24.5, \u0026#34;seed\u0026#34;: 1585491146, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0.5, 0 ], [ 1.5, 0 ], [ 2.5, 0.5 ], [ 3.5, 4 ], [ 4.5, 8.5 ], [ 4.5, 13.5 ], [ 3.5, 18.5 ], [ 1.5, 23.5 ], [ 0.5, 24.5 ], [ 0.5, 24.5 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.07551690191030502, 0.10849164426326752, 0.1421988308429718, 0.15429922938346863, 0.1597619652748108, 0.1570153385400772, 0.1273975670337677, 0.037140458822250366, 0.0009765774011611938, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 51, \u0026#34;versionNonce\u0026#34;: 1061543602, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;KJ0D8NQz0c076KGRb68DR\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -673.75, \u0026#34;y\u0026#34;: 688.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 51.5, \u0026#34;height\u0026#34;: 56, \u0026#34;seed\u0026#34;: 725290442, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 1.5, -1 ], [ 3, -2 ], [ 3.5, -2 ], [ 3.5, -1.5 ], [ 1, 2.5 ], [ -4, 7 ], [ -8.5, 11 ], [ -11.5, 13.5 ], [ -12.5, 15 ], [ -11, 15 ], [ -8, 14.5 ], [ 1, 11 ], [ 8.5, 8.5 ], [ 16.5, 6 ], [ 20, 5.5 ], [ 24.5, 4.5 ], [ 25.5, 5.5 ], [ 24.5, 8.5 ], [ 22, 11.5 ], [ 19, 15.5 ], [ 13, 20.5 ], [ 10.5, 22 ], [ 9, 22 ], [ 7.5, 20.5 ], [ 7, 19 ], [ 7, 18.5 ], [ 7, 19 ], [ 7.5, 20.5 ], [ 8, 25.5 ], [ 8.5, 30 ], [ 8.5, 35.5 ], [ 8, 40.5 ], [ 7.5, 43.5 ], [ 6.5, 44.5 ], [ 3.5, 44 ], [ -1, 42 ], [ -5, 39 ], [ -9, 35 ], [ -10, 34.5 ], [ -10, 35 ], [ -10, 37.5 ], [ -13.5, 44 ], [ -19, 49 ], [ -24, 53 ], [ -26, 54 ], [ -26, 54 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.09900053590536118, 0.10817120969295502, 0.11374074965715408, 0.11407645046710968, 0.10370030999183655, 0.09350728988647461, 0.09350728988647461, 0.09350728988647461, 0.08934157341718674, 0.09170672297477722, 0.09654383361339569, 0.11441214382648468, 0.1253070831298828, 0.1270466148853302, 0.12495613098144531, 0.10817120969295502, 0.10370030999183655, 0.09111162275075912, 0.0801861584186554, 0.05592431500554085, 0.020187685266137123, 0.013794155791401863, 0.007736324332654476, 0.02859540656208992, 0.08413824439048767, 0.1111009418964386, 0.13379110395908356, 0.13923858106136322, 0.1421988308429718, 0.14517433941364288, 0.15161363780498505, 0.15161363780498505, 0.1280994862318039, 0.09381246566772461, 0.012222476303577423, 0.012222476303577423, 0.003082322422415018, 0.027450980618596077, 0.06918440759181976, 0.11340504884719849, 0.11944762617349625, 0.11340504884719849, 0.09837491065263748, 0.06890974193811417, 0.0023651483934372663, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 13, \u0026#34;versionNonce\u0026#34;: 663887214, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;qGIhFg6MQyCLnE0wmopzt\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -668.25, \u0026#34;y\u0026#34;: 728.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 39.5, \u0026#34;height\u0026#34;: 11, \u0026#34;seed\u0026#34;: 1585811914, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 1, 0 ], [ 3.5, -0.5 ], [ 14, -2 ], [ 28, -1.5 ], [ 33.5, 2 ], [ 38, 6.5 ], [ 39.5, 9 ], [ 39.5, 9 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.08642710000276566, 0.10817120969295502, 0.1574120670557022, 0.19926756620407104, 0.19621576368808746, 0.08671702444553375, 0.0013122758828103542, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 21, \u0026#34;versionNonce\u0026#34;: 1748711538, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;tkLtaZZ9elghcrgTezozF\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -570.25, \u0026#34;y\u0026#34;: 674.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 30.5, \u0026#34;height\u0026#34;: 47.5, \u0026#34;seed\u0026#34;: 478540106, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0.5, 0 ], [ 0.5, -0.5 ], [ 0, 1 ], [ -3, 4.5 ], [ -8, 10 ], [ -12.5, 15 ], [ -16, 22.5 ], [ -15, 26 ], [ -12, 28.5 ], [ -7.5, 31.5 ], [ 1.5, 36.5 ], [ 6.5, 40 ], [ 10.5, 43.5 ], [ 13, 46 ], [ 14.5, 47 ], [ 14.5, 47 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.11944762617349625, 0.13093766570091248, 0.1270466148853302, 0.1111009418964386, 0.09869535267353058, 0.09869535267353058, 0.10559242963790894, 0.11944762617349625, 0.1418173462152481, 0.16932936012744904, 0.18252842128276825, 0.18252842128276825, 0.1425650417804718, 0.08242923766374588, 0.0010070954449474812, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 14, \u0026#34;versionNonce\u0026#34;: 914898862, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;LGSPphzKSM10F8Q0mNgzA\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -558.75, \u0026#34;y\u0026#34;: 702.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 30, \u0026#34;height\u0026#34;: 24, \u0026#34;seed\u0026#34;: 1039258314, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.5, 0 ], [ -0.5, -0.5 ], [ -2, -0.5 ], [ -5, 1 ], [ -9.5, 5.5 ], [ -15.5, 12 ], [ -22, 17.5 ], [ -30, 23.5 ], [ -30, 23.5 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.12184329330921173, 0.1425650417804718, 0.14743266999721527, 0.1418173462152481, 0.13669031858444214, 0.12184329330921173, 0.09111162275075912, 0.0120088504627347, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 12, \u0026#34;versionNonce\u0026#34;: 81746482, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;Hewyqe3H3M7ZWFQg54651\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -605.75, \u0026#34;y\u0026#34;: 707.484375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 36.5, \u0026#34;height\u0026#34;: 11, \u0026#34;seed\u0026#34;: 1398826250, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0, -0.5 ], [ 2, -1.5 ], [ 6.5, -4 ], [ 13, -6.5 ], [ 21.5, -8.5 ], [ 36.5, -11 ], [ 36.5, -11 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.09170672297477722, 0.11340504884719849, 0.11979857832193375, 0.11911192536354065, 0.11641107499599457, 0.003524834057316184, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 34, \u0026#34;versionNonce\u0026#34;: 1056971246, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;05q113RV-Z_XZPDjvOCk4\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -546.25, \u0026#34;y\u0026#34;: 684.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 18.5, \u0026#34;height\u0026#34;: 49.5, \u0026#34;seed\u0026#34;: 1358645706, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.5, -1 ], [ 0, -3 ], [ 1.5, -4 ], [ 6, -5.5 ], [ 10.5, -6.5 ], [ 15, -7 ], [ 17, -7 ], [ 18, -7 ], [ 17, -6.5 ], [ 14, -5 ], [ 11.5, -3.5 ], [ 10.5, -3 ], [ 10, -1 ], [ 11.5, -0.5 ], [ 13.5, 0.5 ], [ 15.5, 2.5 ], [ 17, 8 ], [ 17.5, 13 ], [ 17.5, 19 ], [ 18, 25 ], [ 18, 30.5 ], [ 17.5, 37.5 ], [ 16.5, 40.5 ], [ 15, 42 ], [ 13.5, 42.5 ], [ 9, 41 ], [ 5.5, 38.5 ], [ 4, 36.5 ], [ 4, 36.5 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.043442435562610626, 0.059464409947395325, 0.07551690191030502, 0.09320210665464401, 0.09654383361339569, 0.09350728988647461, 0.06559853255748749, 0.05339131876826286, 0.03434805944561958, 0.02859540656208992, 0.0313267707824707, 0.0316624715924263, 0.03289845213294029, 0.035828184336423874, 0.04303044080734253, 0.051590751856565475, 0.062867172062397, 0.06509498506784439, 0.061142899096012115, 0.06535439193248749, 0.07364004105329514, 0.08876173198223114, 0.10054169595241547, 0.1114366352558136, 0.10849164426326752, 0.06970321387052536, 0.017868313938379288, 0, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 14, \u0026#34;versionNonce\u0026#34;: 1142506482, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;qL1ERJpzu7sSWIX1gi0v9\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -547.75, \u0026#34;y\u0026#34;: 701.984375, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 48.5, \u0026#34;height\u0026#34;: 9.5, \u0026#34;seed\u0026#34;: 1253217034, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 2, -1 ], [ 6, -2.5 ], [ 12.5, -3 ], [ 25.5, -4.5 ], [ 33, -6 ], [ 40, -7.5 ], [ 46, -9.5 ], [ 48.5, -9.5 ], [ 48.5, -9.5 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0, 0.06890974193811417, 0.09837491065263748, 0.11340504884719849, 0.11641107499599457, 0.10882734507322311, 0.05545128509402275, 0.008270390331745148, 0.0007782101165503263, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 30, \u0026#34;versionNonce\u0026#34;: 402828334, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;WAJWdzheRT8_nINwPWsrP\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -769.1329867867925, \u0026#34;y\u0026#34;: 800.8721458770551, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 53.408205136530114, \u0026#34;height\u0026#34;: 106.93125967739161, \u0026#34;seed\u0026#34;: 1634857433, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.9652247719864135, 1.2952284342079565 ], [ -2.5902883221559705, 4.207152592510056 ], [ -5.881778657549376, 9.482729840439333 ], [ -21.80655475211711, 31.27972702817658 ], [ -36.29864798035919, 50.38351361592947 ], [ -45.67397419535621, 62.47228589657391 ], [ -50.087506725760136, 66.91925007333543 ], [ -50.82533284980582, 68.29680839821742 ], [ -46.066974500802985, 66.11367826733226 ], [ -37.776074921421355, 61.64359350951918 ], [ -29.427522606698858, 56.31289172014624 ], [ -22.116501409421176, 51.05924531496396 ], [ -16.04321454278454, 47.97020878105957 ], [ -13.295642816768577, 46.59776633088711 ], [ -12.567493230933223, 46.83876765344314 ], [ -14.705710740822042, 51.49453090265126 ], [ -20.820816908863208, 59.974430326194806 ], [ -28.992673256389935, 71.45013045851044 ], [ -37.27104092563047, 82.9988012068377 ], [ -44.58626586491755, 92.0515992819602 ], [ -50.61595873717863, 98.41110744121124 ], [ -53.408205136530114, 103.1286181084248 ], [ -51.92482950394526, 106.16177659995947 ], [ -49.50519922708952, 106.93125967739161 ], [ -49.50519922708952, 106.93125967739161 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6630000472068787, 0.6630000472068787, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6630000472068787, 0.6800000667572021, 0.6630000472068787, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6630000472068787, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 14, \u0026#34;versionNonce\u0026#34;: 1609561522, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;vP-i4iDHY0aHOazObFwhj\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -799.1661357629309, \u0026#34;y\u0026#34;: 902.1927979999593, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 4.950520914157551, \u0026#34;height\u0026#34;: 49.835163231367574, \u0026#34;seed\u0026#34;: 1497586041, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.4889626141937242, 0 ], [ -0.6303233537446431, 0.6303233537446431 ], [ -0.9668408331833689, 3.183977650606721 ], [ -1.605066032167315, 13.582488721992945 ], [ -3.2393996266264367, 29.565829684601454 ], [ -4.577765988859596, 41.551332680411974 ], [ -4.950520914157551, 49.53027296185769 ], [ -4.950520914157551, 49.835163231367574 ], [ -4.950520914157551, 49.835163231367574 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6290000081062317, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6630000472068787, 0.6460000276565552, 0.6460000276565552, 0.6630000472068787, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 92, \u0026#34;versionNonce\u0026#34;: 1333327470, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;bR5Dw4li_gbYfCkRBLIlC\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -752.9612705926319, \u0026#34;y\u0026#34;: 828.5950709279261, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 41.41873634637113, \u0026#34;height\u0026#34;: 50.769266432204404, \u0026#34;seed\u0026#34;: 419125017, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 1.604005182179094, -1.5809242590711392 ], [ 3.2357510958257762, -3.2357709247976345 ], [ 6.129789521616317, -5.827933084783126 ], [ 18.607011358692716, -14.513696892955409 ], [ 29.612685544828537, -17.76580689046864 ], [ 37.60177825980634, -15.671748500649983 ], [ 41.41873634637113, -10.232304630242197 ], [ 40.977442580245906, -1.388702207001188 ], [ 36.51128395883791, 9.155988044069431 ], [ 30.698837300985474, 19.242668705835968 ], [ 24.68835870234261, 28.959578702551994 ], [ 22.442331073090827, 33.003459541735765 ], [ 22.442331073090827, 33.003459541735765 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.5950000286102295, 0.5950000286102295, 0.6290000081062317, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 21, \u0026#34;versionNonce\u0026#34;: 965373810, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;atasocP0lxRDGvWWkGAe-\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -746.6906160557581, \u0026#34;y\u0026#34;: 843.4466138414269, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 18.28861755942637, \u0026#34;height\u0026#34;: 38.26011995062288, \u0026#34;seed\u0026#34;: 887518265, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0, -0.41232363840958897 ], [ 0.6358556368608106, -0.9658692135679985 ], [ 2.2380167246678866, -1.9561280623790935 ], [ 5.181012881690208, -2.3102734976968122 ], [ 11.81533076031792, -1.3943732929193402 ], [ 17.652504145932994, 1.8592437064462501 ], [ 17.55052374426225, 7.0259995574537015 ], [ 14.347054214433001, 15.174517205239681 ], [ 9.15083251141641, 24.332805410031256 ], [ 4.140229812879738, 31.122047044881697 ], [ 0.7685312867885159, 34.54524141058755 ], [ -0.6361134134933764, 35.94984645292607 ], [ -0.04852149385339999, 34.42063615215886 ], [ 4.671646255573592, 27.46566397148615 ], [ 8.580908205598803, 22.112317496383525 ], [ 8.580908205598803, 22.112317496383525 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.612000048160553, 0.612000048160553, 0.578000009059906, 0.5950000286102295, 0.612000048160553, 0.612000048160553, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 36, \u0026#34;versionNonce\u0026#34;: 1311504558, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;jFml7yXhOJTaVgF_lzmh0\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -747.350702696088, \u0026#34;y\u0026#34;: 847.4070543675191, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 92.40970059714039, \u0026#34;height\u0026#34;: 114.5219883500663, \u0026#34;seed\u0026#34;: 365946873, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.29975456582849347, 0.9295425373361468 ], [ -2.2098397558220313, 4.16491688269889 ], [ -4.828037355705305, 9.680583320484061 ], [ -14.180371877967104, 35.30651529371846 ], [ -19.650243305513413, 57.936408610519834 ], [ -21.122207364860515, 74.0034674918245 ], [ -19.879486047826276, 86.33462912304697 ], [ -16.325955850858122, 93.85417178716682 ], [ -12.671347470433602, 96.95217101629873 ], [ -8.767161737174433, 96.44994282000948 ], [ -2.890687329566049, 90.7050138109397 ], [ 4.008109374160654, 79.06167955151454 ], [ 13.186127405835805, 63.93391906164322 ], [ 21.810619691324177, 49.01793198997984 ], [ 26.893439504946514, 39.87035142992909 ], [ 29.303472559478905, 35.736605690809256 ], [ 29.727019395894672, 34.983659975810156 ], [ 25.91478060460463, 38.13650614078131 ], [ 19.40883548903662, 44.617883160360634 ], [ 10.888227186506128, 51.868663941485124 ], [ 3.238209888321876, 57.58555478451137 ], [ -0.8579996072899121, 61.280762984578246 ], [ -1.6501670283952308, 64.55345545476007 ], [ 2.37939729319055, 69.04638318802029 ], [ 11.169382176840372, 77.50629500804746 ], [ 24.213395342198964, 86.75167205673131 ], [ 38.96660638482979, 95.67970624165105 ], [ 54.80709943500676, 104.57839354839223 ], [ 70.50405055874114, 114.03229206391813 ], [ 71.28749323227987, 114.5219883500663 ], [ 71.28749323227987, 114.5219883500663 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.5100000500679016, 0.5100000500679016, 0.5100000500679016, 0.5270000100135803, 0.5440000295639038, 0.578000009059906, 0.578000009059906, 0.578000009059906, 0.5950000286102295, 0.5610000491142273, 0.5440000295639038, 0.5610000491142273, 0.5610000491142273, 0.5610000491142273, 0.5440000295639038, 0.5100000500679016, 0.5100000500679016, 0.5270000100135803, 0.5100000500679016, 0.4930000305175781, 0.5270000100135803, 0.5610000491142273, 0.578000009059906, 0.5950000286102295, 0.5950000286102295, 0.5950000286102295, 0.612000048160553, 0.612000048160553, 0.578000009059906, 0.578000009059906, 0.5950000286102295, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 13, \u0026#34;versionNonce\u0026#34;: 1966059826, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;9Uh28vijL439zgP-6gUhb\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -664.1819672014187, \u0026#34;y\u0026#34;: 855.9879229151745, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 44.554688227417955, \u0026#34;height\u0026#34;: 20.462110810044805, \u0026#34;seed\u0026#34;: 53730521, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0.3110967376651388, -0.33003340567904615 ], [ 2.5164749748452095, -1.2581879149933002 ], [ 10.908829488146466, -3.756043485372402 ], [ 24.23205440460856, -8.068646549608047 ], [ 35.54216279390414, -13.63297328404883 ], [ 44.235521098253685, -20.142983338824024 ], [ 44.554688227417955, -20.462110810044805 ], [ 44.554688227417955, -20.462110810044805 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6290000081062317, 0.612000048160553, 0.612000048160553, 0.612000048160553, 0.612000048160553, 0.5950000286102295, 0.5950000286102295, 0.612000048160553, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 22, \u0026#34;versionNonce\u0026#34;: 2076488430, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;e_c40gmlFXTH4hSqfnKX4\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -631.8385348130976, \u0026#34;y\u0026#34;: 812.0933213280864, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 34.60351875853826, \u0026#34;height\u0026#34;: 111.2217732671063, \u0026#34;seed\u0026#34;: 308040089, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ -0.49506993749025696, 0 ], [ -1.2930869052596563, -0.6330200939014503 ], [ -2.5857375731410457, -0.6601064693015815 ], [ -4.206220630838061, 0.5758333393968087 ], [ -5.8473059901753, 4.402705911832754 ], [ -12.321465264040398, 20.79265976898921 ], [ -17.343806713848608, 36.396355238619435 ], [ -19.091909033679258, 51.89888329442044 ], [ -18.530788791315217, 66.12997768210437 ], [ -15.966982060921168, 79.6971980958557 ], [ -11.756914609565001, 90.67820504114411 ], [ -6.179520582746022, 98.71845650321711 ], [ 0.6918328240892606, 105.03699800684853 ], [ 7.950227930362871, 109.44624747935609 ], [ 15.2221067374212, 110.56166679780472 ], [ 15.511609724859, 110.56166679780472 ], [ 15.511609724859, 110.56166679780472 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.6630000472068787, 0.6630000472068787, 0.6630000472068787, 0.6630000472068787, 0.6630000472068787, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.612000048160553, 0.5950000286102295, 0.578000009059906, 0.578000009059906, 0.5950000286102295, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 14, \u0026#34;versionNonce\u0026#34;: 373734130, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;ct_Oe4tGwupE9yKvYF3yT\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -610.7163373627229, \u0026#34;y\u0026#34;: 878.4302738172371, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 54.45573005573294, \u0026#34;height\u0026#34;: 68.97729905047004, \u0026#34;seed\u0026#34;: 1704073785, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0, 0.49501045057502324 ], [ -0.9675150182226844, 1.9124250086590564 ], [ -3.512841146952951, 6.1060939003842805 ], [ -13.254795134979304, 21.190190994479053 ], [ -29.450365582145878, 45.38899221347572 ], [ -44.32471181315054, 62.44864976225699 ], [ -52.276367429478796, 68.8445242556835 ], [ -54.45573005573294, 68.97729905047004 ], [ -54.45573005573294, 68.97729905047004 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.5270000100135803, 0.5440000295639038, 0.5610000491142273, 0.578000009059906, 0.578000009059906, 0.5950000286102295, 0.578000009059906, 0.5610000491142273, 0.578000009059906, 0 ] }, { \u0026#34;type\u0026#34;: \u0026#34;freedraw\u0026#34;, \u0026#34;version\u0026#34;: 38, \u0026#34;versionNonce\u0026#34;: 1657546030, \u0026#34;isDeleted\u0026#34;: false, \u0026#34;id\u0026#34;: \u0026#34;vRKUz8mw6V_Yo2EmZzCj9\u0026#34;, \u0026#34;fillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;strokeWidth\u0026#34;: 2, \u0026#34;strokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;roughness\u0026#34;: 1, \u0026#34;opacity\u0026#34;: 100, \u0026#34;angle\u0026#34;: 0, \u0026#34;x\u0026#34;: -612.696557625769, \u0026#34;y\u0026#34;: 818.694029099611, \u0026#34;strokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;backgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;width\u0026#34;: 79.53838786117149, \u0026#34;height\u0026#34;: 99.57621816284609, \u0026#34;seed\u0026#34;: 1855721433, \u0026#34;groupIds\u0026#34;: [], \u0026#34;frameId\u0026#34;: null, \u0026#34;roundness\u0026#34;: null, \u0026#34;boundElements\u0026#34;: [], \u0026#34;updated\u0026#34;: 1722333884462, \u0026#34;link\u0026#34;: null, \u0026#34;locked\u0026#34;: false, \u0026#34;points\u0026#34;: [ [ 0, 0 ], [ 0.6288163518922829, -1.8864093977331322 ], [ 1.899476690111328, -4.1828026152104485 ], [ 4.184448419865021, -6.191160189158836 ], [ 7.752870174611644, -7.562849138404999 ], [ 19.03666551840513, -9.87383647908473 ], [ 26.129845632121715, -7.424561889474262 ], [ 31.492630697773734, -2.5283128709753555 ], [ 34.878308648943175, 4.6607601500870715 ], [ 36.5800310038685, 11.888261718386161 ], [ 36.00098537104941, 18.237260522613838 ], [ 35.67099162331385, 24.50730036136349 ], [ 35.313752868404436, 29.44261245419466 ], [ 35.93947590070479, 35.33475174947944 ], [ 37.545226032397295, 42.28579779374718 ], [ 39.499093591997735, 49.850034960174185 ], [ 40.872289543096485, 57.469912221310096 ], [ 42.21831980290813, 65.36334997660299 ], [ 41.63554632340151, 73.59522862159372 ], [ 38.738652525680095, 81.87969369964503 ], [ 34.49112814670275, 87.29165461521791 ], [ 29.221777195900586, 89.70238168376136 ], [ 22.670007326636096, 87.88025781241674 ], [ 16.05966267484473, 82.06648261345754 ], [ 9.79105052206046, 73.55370675476536 ], [ 4.7791391113887585, 65.92617551053684 ], [ 2.353560143010327, 58.96267687201498 ], [ 5.7588291182612465, 50.79076103757302 ], [ 17.260981098881075, 40.07649342016214 ], [ 32.58171714174853, 29.524188843942625 ], [ 50.83499947353016, 22.32139417443443 ], [ 70.24022608970972, 22.343404333068406 ], [ 79.53838786117149, 26.732824833833774 ], [ 79.53838786117149, 26.732824833833774 ] ], \u0026#34;lastCommittedPoint\u0026#34;: null, \u0026#34;simulatePressure\u0026#34;: false, \u0026#34;pressures\u0026#34;: [ 0.578000009059906, 0.612000048160553, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6290000081062317, 0.612000048160553, 0.612000048160553, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6290000081062317, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0.6460000276565552, 0 ] } ], \u0026#34;appState\u0026#34;: { \u0026#34;theme\u0026#34;: \u0026#34;light\u0026#34;, \u0026#34;viewBackgroundColor\u0026#34;: \u0026#34;#ffffff\u0026#34;, \u0026#34;currentItemStrokeColor\u0026#34;: \u0026#34;#1e1e1e\u0026#34;, \u0026#34;currentItemBackgroundColor\u0026#34;: \u0026#34;transparent\u0026#34;, \u0026#34;currentItemFillStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;currentItemStrokeWidth\u0026#34;: 2, \u0026#34;currentItemStrokeStyle\u0026#34;: \u0026#34;solid\u0026#34;, \u0026#34;currentItemRoughness\u0026#34;: 1, \u0026#34;currentItemOpacity\u0026#34;: 100, \u0026#34;currentItemFontFamily\u0026#34;: 1, \u0026#34;currentItemFontSize\u0026#34;: 20, \u0026#34;currentItemTextAlign\u0026#34;: \u0026#34;left\u0026#34;, \u0026#34;currentItemStartArrowhead\u0026#34;: null, \u0026#34;currentItemEndArrowhead\u0026#34;: \u0026#34;arrow\u0026#34;, \u0026#34;scrollX\u0026#34;: 900.0205959616612, \u0026#34;scrollY\u0026#34;: -645.6988963587927, \u0026#34;zoom\u0026#34;: { \u0026#34;value\u0026#34;: 2 }, \u0026#34;currentItemRoundness\u0026#34;: \u0026#34;round\u0026#34;, \u0026#34;gridSize\u0026#34;: null, \u0026#34;gridColor\u0026#34;: { \u0026#34;Bold\u0026#34;: \u0026#34;#C9C9C9FF\u0026#34;, \u0026#34;Regular\u0026#34;: \u0026#34;#EDEDEDFF\u0026#34; }, \u0026#34;currentStrokeOptions\u0026#34;: null, \u0026#34;previousGridSize\u0026#34;: null, \u0026#34;frameRendering\u0026#34;: { \u0026#34;enabled\u0026#34;: true, \u0026#34;clip\u0026#34;: true, \u0026#34;name\u0026#34;: true, \u0026#34;outline\u0026#34;: true }, \u0026#34;objectsSnapModeEnabled\u0026#34;: false }, \u0026#34;files\u0026#34;: {} } %%\n"},{"id":117,"href":"/posts/capital-incasion/","title":"Capital Incasion","section":"Blog","content":" 谈资本入侵 # 资本并非单指金钱，而是包含技术、资金、教育、媒体宣传、价值观念乃至社会架构以及运行体系的综合产物。\n资本会流动，会向最有利可图的地方大规模聚集。而它的源头，就是资本过剩地方。\n资本涌入当地，使用即已成型的技术建厂，从本源地转来过剩的产品。同时开动政治资本、话语资本(媒体)为招工、销售铺平道路。\n它们其实无需在意开出的工资。于是给出极具诱惑的薪酬，并逐步渗入教育、最大化利用当地资源为自己下游产业生产线培养专科人才。\n资源资本化 # 当人在一处聚集，有了可观的收入、暴富所产生的消费欲快速膨胀。无论是被动的还是主动的，快消品、奢饰品、追求感官刺激的体验消费，完全颠覆以往生活所形成的认知观念。而这些消费为资本带来第一轮的先期收割外，还将被话语媒体资本的助力下充斥到各处欠资本地区，吸纳更多的人前来。\n而我们去了，首先要做对的就是接受管理。他们会告诉我们什么叫做“高效”，“先进”，诸如此类词汇，但无一例外的都是将管理成本向劳动者转嫁。\n“进城打工潮”一旦形成，各地为了促进当地发展以及挽留劳动力，不得不实施“亲资本”的政策。从政策面鼓励，以低廉的方式划出工业用地。（由此，城市中土地政策宽松，乡村土地使用政策收紧。资本周边大面积征用农民土地、拆迁问题一定会出现。借贷和税收政策也一定会在两地之间形成差异）\u0026ndash;外来资本完成对当地人力资源、政府资源、土地资源的廉价征用，全部服务于本资本在“买全球、卖全球”的产品制造。\n资源捆绑化 # 当资本输入地原住民分批得利消费理念逐步冷静\u0026ndash;当然这并非个体绝对。积蓄开始随时间累积，劳动密集型的产业带来的工伤密集冲击着劳动者身体素质。\n时间跨度逐步拉长，原住民对于蓬勃发展的“城市”的长久繁荣的信心也在累积。医疗、教育和住房需求开始浮现。积蓄变得重要，理财也变得重要。\n这将是资本的第二轮攻势。凭借“主场优势”，其更易于治疗其所带来的工伤。资本的培养体系也更容易为自己体系内部培养人力资本。借此优势将教育与医疗资源集中，边缘化输入地原有医疗和教育体系，形成越好更好，越差更差的趋向。几乎理所当然的大规模大比例占用社会资金，完成了人力资本培养，人力资本修复的代价向外转嫁，且代价也在为自己提供收益。\n摘取果实 # 如果说创造就业是播下了种子，快消、奢侈、体验型消费满足了种子各种各样的幻想。医疗和教育的捆绑无时无刻在滋养着种子成长。那胜利的果实就是房地产和坚固的金融。\n自古以来，累积积蓄、购置田产是繁荣社会中必然进行的活动。但在公有制下乡村之中，地是集体的，且在前已经说过：乡村中土地政策是必然收紧的。所以替代物它必须出现，在资本的操纵下，它必然出现在城市。两个一辈子在乡村务农的老农，其儿女生养在乡村，但成婚前必须在城中买房，为什么？\n因为城中房自资本兴建的一开始，就绝不是以解决入城人住宿问题而产生的。它自一开始就裹挟着各项资源和特权。当“新增人口永不分地”写入法律，一面是先行者得利，一面是铜墙铁壁。大势所趋。\n不是风险厌恶型的资本不是好资本 # 用自己的钱去建房，风险全是自己的\u0026ndash;这肯定不行；拉银行一起，“坏账”风险是银行的\u0026ndash;这稍微进步了一点；再把购房者拉上，先收一波回款\u0026ndash;风险到这儿基本分担完了；但收得是全款，花是慢慢花，那把闲的钱再去撬动更多资金呢？\u0026ndash;这简直绝佳。\n银行也是好资本。“坏账”风险一定要转嫁出去\u0026ndash;包装成“金融产品”交由社会上的“闲钱”共力承担。\n在这样的体系中，由资本一开始推动的巨轮滚滚向前。资本已经无需再投入，在社会承担所有风险的保证下，在社会的过往劳动（积蓄）、现实劳动、未来劳动（负债）中大口大口获取剩余。而这个社会终将走向无力消费，资本终将再无剩余可以榨取，它们必须奔向向另外一片沃土。而那个地方，在现在或许已经进化成无需是一个现实存在的地方。\n逃不走的人怎么办 # 留下的人\u0026ndash;被抛弃的人只剩下两个选项：\n想方设法无论如何也要寻求资本的认同，乞求带上他一起玩 承担资本流出后转嫁在自己身上的风险 第一个不讨论，有一个收编流程已经运行了数千年，可惜近代被废了。\n那资本撤出一定会导致风险爆发吗？ # 这个问题不对，或者是说反了。在资本已经不限于压榨现有劳动剩余，对人力资源进行过往、未来尽数压榨的机制下，市场已经再无潜力和活力。资本已预料到会有风险爆发，所以才主动撤出，去寻求新的地方。否则新兴资本家必然会反制传统资本家，一如一开始它们涌入此地时所做的那样。当资本所带来的就业行业转入生产过剩，资本带来的核心技术转移或断供。而为资本中间环节培养、而非为当地社会培养人成为无用之才。早期既得利益者也无力完成产业升级，还要忙着第1条线路。\n工人下岗，左脚踏右脚一飞冲天的最原始驱动力无力抵抗一环扣一环的风险所带来的阻力。\n"},{"id":118,"href":"/docs/programmer/platforms/android/adb/","title":"adb","section":"平台","content":" 常规 # adb connect 127.0.0.1:34534 adb devices adb -s 192.168.240.112:5555 shell\napp操作 # 查看已经安装的app # adb shell pm list packages\n打开某app # adb shell monkey -p com.example.myapp -c android.intent.category.LAUNCHER 1 通过adb输入文字 # 在界面选中的输入框内输入文字\ninput text \u0026#34;{输入文字}\u0026#34; "},{"id":119,"href":"/docs/programmer/ml/yolo/","title":"Demo Test项目中的一些东西","section":"机器学习","content":"\nyolov5 # 使用自己的素材进行目标识别训练\n之前使用个位数样本识别Vmon结果败的一塌糊涂 现在用来检测卡片倒是得心应手 9个训练卡片,准确率可以到50多,自我感觉还行 使用方法: 在此\n"},{"id":120,"href":"/docs/programmer/langs/python/fastapi/","title":"FastAPI","section":"Python","content":" FastAPI 使用笔记 # 上传文件 # pip install python-multipart from fastapi import FastAPI, UploadFile, File import pandas as pd from io import StringIO from pydantic import BaseModel app = FastAPI() # 定义响应模型 class RespAction(BaseModel): status: dict # 解析上传的文件 # 解析上传的文件 async def __parse_file(file: UploadFile): contents = await file.read() # 将字节内容转换为字符串 data = StringIO(contents.decode(\u0026#39;utf-8\u0026#39;)) # 根据文件类型选择解析方式 if file.filename.endswith(\u0026#39;.csv\u0026#39;): df = pd.read_csv(data) elif file.filename.endswith(\u0026#39;.txt\u0026#39;): df = pd.read_csv(data, delimiter=\u0026#39;\\t\u0026#39;) # 假设 TXT 文件以制表符分隔 else: raise ValueError(\u0026#34;Unsupported file type. Please upload a CSV or TXT file.\u0026#34;) return df # 上传账号的路由 @app.post(\u0026#34;/upload/accounts/\u0026#34;, description=\u0026#34;上传账号csv/txt文件进行解析入库存储\u0026#34;) async def upload_accounts(file: UploadFile = File(...)) -\u0026gt; RespAction: rst = RespAction(status={\u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;\u0026#34;}) try: # 解析文件 df = await parse_file(file) pass except: pass return rst "},{"id":121,"href":"/docs/programmer/platforms/git/","title":"Git","section":"平台","content":" Git # 1. 同步远端放弃本地 # git fetch --all git reset --hard origin/master git pull Windows下问题 # [[Problem of Windows#Windows下Git问题]]\n2. git 项目由 Ext4 -\u0026gt; NTFS 复制后 # 文件权限发生变化, Git追踪文件权限的话会标记所有文件都需要修改 因为在Linux 下文件权限为 -rw-r--r--（所有者可读写，其他用户只读）,但是Linux下挂载NTFS文件权限为 -rwxr-xr-x（所有者可读、写、执行，其他用户可读、执行）就很难受\ngit config core.filemode false # 关闭github监控文件权限 # git config core.filemode false --global 自己的小仓库 - Gogs 简介 # Gogs (Go Git Service) 是一个用 Go 语言编写的自托管 Git 服务，类似于 GitHub Gitlab Gitee。它轻量、快速且易于安装，适合个人或小团队使用。Gogs 提供了基本的 Git 仓库管理功能，包括代码托管、问题跟踪、Pull Request 等。\n源码安装 # 安装依赖：\n确保已安装 Go 语言环境（1.13 或更高版本）。 安装 Git 和 MySQL/PostgreSQL/SQLite3 数据库。 下载源码：\ngit clone https://github.com/gogs/gogs.git cd gogs 编译并运行：\ngo build -o gogs ./gogs web 访问并配置： 打开浏览器访问 http://localhost:3000，按照提示完成初始配置。 Docker 安装 # 拉取镜像：\ndocker pull gogs/gogs 运行容器：\ndocker run -d --name=gogs -p 10022:22 -p 10080:3000 -v /var/gogs:/data gogs/gogs 访问并配置：\n打开浏览器访问 http://localhost:10080，按照提示完成初始配置。 参考链接 # Gogs 官方文档 Gogs GitHub 仓库 "},{"id":122,"href":"/docs/programmer/ml/python-%E5%9B%BE%E8%A1%A8/","title":"Python 图表","section":"机器学习","content":" Python 图表 # 主要用: matplotlib import matplotlib.pyplot as plt\n堆叠图 # summery_one_offer_dict_by_install_date, install_datas_by_install_date_dict = await rc.calculate_offer_do_status(offer_id=offer_id) # 计算需要的行数和列数（每行4个图表） num_offers = len(summery_one_offer_dict_by_install_date.keys()) num_cols = 3 num_rows = math.ceil(num_offers / num_cols) # 创建一个图形和子图数组 fig, axs = plt.subplots(num_rows, num_cols, figsize=(45, num_rows * 3)) if num_offers == 1: axs = [axs] # Flatten the axs array for easy iteration else: axs = axs.flatten() for ax, (install_date, data) in zip(axs, summery_one_offer_dict_by_install_date.items()): # 排序和处理数据 data = data.list_reten_info data.sort(key=lambda x: x.doreten_day) dates = [f\u0026#34;{entry.reten_day}/{entry.expect_rate}\u0026#34; for entry in data] reten_counts = [entry.count for entry in data] wait_counts = [entry.waitcount for entry in data] # 绘制堆叠条形图 ax.bar(dates, reten_counts, label=\u0026#39;Done\u0026amp;Run\u0026#39;) ax.bar(dates, wait_counts, bottom=reten_counts, label=\u0026#39;Wait\u0026#39;) # 设置标题和标签 ax.set_title(f\u0026#39;Reten for {install_date.strftime(\u0026#34;%Y-%m-%d\u0026#34;)}\u0026#39;) ax.set_xlabel(\u0026#39;Need Count\u0026#39;) ax.set_ylabel(\u0026#39;Plan Count\u0026#39;) ax.legend() # 调整x轴标签间距 ticks = range(len(dates)) # 根据实际的刻度位置生成刻度列表 ax.set_xticks(ticks) ax.set_xticklabels(dates, rotation=60, ha=\u0026#39;right\u0026#39;) # 设置x轴标签并旋转 # # 自动格式化x轴日期标签 # fig.autofmt_xdate() # 隐藏多余的子图（如果有） for i in range(num_offers, len(axs)): axs[i].axis(\u0026#39;off\u0026#39;) # 调整布局 plt.tight_layout() img_path = f\u0026#34;reten_status_{offer_id}_plot.png\u0026#34; plt.savefig(img_path, dpi=300) plt.close() logger.info(f\u0026#34;img save to {img_path}\u0026#34;) "},{"id":123,"href":"/docs/programmer/langs/python/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%9A%E8%BF%9B%E7%A8%8B/","title":"Python 多线程多进程","section":"Python","content":" 一个协程示例： import asyncio async def my_coroutine(): # 这里是协程的代码 await asyncio.sleep(1) print(\u0026#34;Coroutine is done\u0026#34;) async def main(): # 创建一个任务对象 task = asyncio.create_task(my_coroutine()) # 等待任务完成 await task # 运行主协程 asyncio.run(main()) 一个线程示例： import threading # 定义一个函数，用于在线程中执行 def thread_function(name): print(f\u0026#34;Thread {name}: starting\u0026#34;) # 在这里执行一些操作 print(f\u0026#34;Thread {name}: finishing\u0026#34;) # 创建线程的实例 thread = threading.Thread(target=thread_function, args=(1,)) # 启动线程 thread.start() # 等待线程结束 thread.join() print(\u0026#34;Main thread is done\u0026#34;) 一个loop tip： self.loop = asyncio.get_event_loop() self.queue.set_loop(loop=self.loop) await self.af.set_loop(loop=self.loop) await self.adjust.set_loop(loop=self.loop) 为什么这里使用同一个loop ? --- 在 Python 的 `asyncio` 框架中，事件循环（event loop）是处理异步任务的核心。每个异步应用程序通常只需要一个事件循环，所有的异步任务都应该在这个事件循环中运行。使用同一个事件循环的好处包括： 1. **统一管理**：所有异步任务都在同一个事件循环中运行，这样可以更方便地管理和监控它们。 2. **避免冲突**：如果为不同的任务创建多个事件循环，可能会导致资源竞争或冲突，尤其是在共享资源或执行I/O操作时。 3. **保持上下文一致性**：使用同一个事件循环可以确保所有任务都在相同的上下文中运行，这有助于维护状态的一致性。 在你提供的代码片段中，这样做的目的是确保所有这些组件都在同一个事件循环中运行，以便它们可以正确地协同工作。 如果这些组件是异步的，并且需要与事件循环交互，那么它们需要知道使用哪个事件循环。通过这种方式设置事件循环，可以确保组件在执行异步操作时能够正确地在事件循环中注册和处理。 总之，使用同一个事件循环有助于保持代码的整洁和协调，避免潜在的问题，并确保整个应用程序的异步操作能够顺利地进行。 多进程 # 多进程通信打日志 # from multiprocessing import Process, Queue from loguru import logger import sys import time # 配置日志处理函数 def configure_logger(queue): logger.remove() # 移除默认日志处理 logger.add(sys.stdout, format=\u0026#34;{message}\u0026#34;) logger.add(\u0026#34;logfile.log\u0026#34;, format=\u0026#34;{message}\u0026#34;, rotation=\u0026#34;1 MB\u0026#34;) while True: try: record = queue.get() if record is None: break # None 表示日志记录结束 # 使用 log 方法记录日志 logger.log(record[\u0026#34;level\u0026#34;], record[\u0026#34;message\u0026#34;]) except Exception: logger.exception(\u0026#34;Failed to process log record\u0026#34;) # 配置工作进程 def worker_process(name, queue): logger.remove() # 移除默认日志处理 def enqueue_log_message(message): # print(\u0026#39;message.record[\u0026#34;level\u0026#34;].name:\u0026#39;, message.record[\u0026#34;level\u0026#34;].name) # print(\u0026#39;message.record[\u0026#34;function\u0026#34;]:\u0026#39;, message.record[\u0026#34;function\u0026#34;]) # print(\u0026#39;message.record[\u0026#34;line\u0026#34;]:\u0026#39;, message.record[\u0026#34;line\u0026#34;]) # print(\u0026#39;message.record.keys:\u0026#39;, message.record.keys()) queue.put({ \u0026#34;line\u0026#34;: message.record[\u0026#34;line\u0026#34;], \u0026#34;function\u0026#34;: message.record[\u0026#34;function\u0026#34;], \u0026#34;level\u0026#34;: message.record[\u0026#34;level\u0026#34;].name, \u0026#34;message\u0026#34;: message.strip() }) logger.add(enqueue_log_message) for i in range(5): time.sleep(0.01) logger.info(f\u0026#34;Worker {name} is logging iteration {i}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: log_queue = Queue() # 启动日志处理进程 log_process = Process(target=configure_logger, args=(log_queue,)) log_process.start() # 启动工作进程 processes = [] for i in range(5): process = Process(target=worker_process, args=(f\u0026#34;Process-{i}\u0026#34;, log_queue)) processes.append(process) process.start() # 等待所有工作进程完成 for process in processes: process.join() # 终止日志处理进程 log_queue.put(None) log_process.join() "},{"id":124,"href":"/docs/programmer/langs/python/notespython/","title":"Python 常用库","section":"Python","content":"\npydantic # 来自类 # from pydantic import BaseModel class User(BaseModel): name: str age: int class Config: from_attributes = True # 假设我们有一个普通的 Python 对象，它具有与模型字段相同的属性名 class OrdinaryObject: def __init__(self, name, age): self.name = name self.age = age # 创建一个 OrdinaryObject 实例 ordinary_object = OrdinaryObject(name=\u0026#39;Alice\u0026#39;, age=30) # 现在我们可以直接将 ordinary_object 传递给 User 模型的构造函数 user_model = User(ordinary_object) # 输出模型的字段值 print(user_model.dict()) # 输出: {\u0026#39;name\u0026#39;: \u0026#39;Alice\u0026#39;, \u0026#39;age\u0026#39;: 30} 自定义字段 # class User(BaseModel): id: int is_active: bool wx_infos: List[str] = [] class Config: arbitrary_types_allowed = True # 允许任意类型 Tuple定义问题 # from typing import List, Tuple class Task(BaseModel): launch_count_today: int launch_groups: List[Tuple[str, ...]] @property def launch_groups_count(self) -\u0026gt; int: return len(self.launch_groups) wrong tuple length, expected 1 (type=value_error.tuple.length; actual_length=5; expected_length=1) # from typing import List, Tuple class Task(BaseModel): launch_count_today: int launch_groups: List[Tuple[str]] # 这样定义就会tuple限制长度 @property def launch_groups_count(self) -\u0026gt; int: return len(self.launch_groups) random # 有权重的随机 # import random # 假设有一个字典 my_dict = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3} # 将字典的键和值分别保存在两个列表中 keys = list(my_dict.keys()) weights = list(my_dict.values()) # 使用 random.choices() 函数进行带有权重的随机选择 取12个值 random_choice = random.choices(keys, weights, k=12) print(\u0026#34;随机选择的键:\u0026#34;, random_choice) loguru # from multiprocessing import Process, Queue from loguru import logger import sys import time # 配置日志处理函数 def configure_logger(queue): logger.remove() # 移除默认日志处理 logger.add(sys.stdout, format=\u0026#34;{message}\u0026#34;) logger.add(\u0026#34;logfile.log\u0026#34;, format=\u0026#34;{message}\u0026#34;, rotation=\u0026#34;1 MB\u0026#34;) while True: try: record = queue.get() if record is None: break # None 表示日志记录结束 # 使用 log 方法记录日志 logger.log(record[\u0026#34;level\u0026#34;], record[\u0026#34;message\u0026#34;]) except Exception: logger.exception(\u0026#34;Failed to process log record\u0026#34;) # 配置工作进程 def worker_process(name, queue): logger.remove() # 移除默认日志处理 def enqueue_log_message(message): # print(\u0026#39;message.record[\u0026#34;level\u0026#34;].name:\u0026#39;, message.record[\u0026#34;level\u0026#34;].name) # print(\u0026#39;message.record[\u0026#34;function\u0026#34;]:\u0026#39;, message.record[\u0026#34;function\u0026#34;]) # print(\u0026#39;message.record[\u0026#34;line\u0026#34;]:\u0026#39;, message.record[\u0026#34;line\u0026#34;]) # print(\u0026#39;message.record.keys:\u0026#39;, message.record.keys()) queue.put({ \u0026#34;line\u0026#34;: message.record[\u0026#34;line\u0026#34;], \u0026#34;function\u0026#34;: message.record[\u0026#34;function\u0026#34;], \u0026#34;level\u0026#34;: message.record[\u0026#34;level\u0026#34;].name, \u0026#34;message\u0026#34;: message.strip() }) logger.add(enqueue_log_message) for i in range(5): time.sleep(0.01) logger.info(f\u0026#34;Worker {name} is logging iteration {i}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: log_queue = Queue() # 启动日志处理进程 log_process = Process(target=configure_logger, args=(log_queue,)) log_process.start() # 启动工作进程 processes = [] for i in range(5): process = Process(target=worker_process, args=(f\u0026#34;Process-{i}\u0026#34;, log_queue)) processes.append(process) process.start() # 等待所有工作进程完成 for process in processes: process.join() # 终止日志处理进程 log_queue.put(None) log_process.join() "},{"id":125,"href":"/docs/programmer/langs/python/notespython/","title":"Python 笔记","section":"Python","content":"\npip cache 目录 # echo $PIP_CACHE_DIR 特殊函数调用 property # 使用字段的方式调用函数\nfrom datetime import datetime from pydantic import BaseModel class InstallCountInfo(BaseModel): count: int total: int @property def done_rate(self): return round(self.count / self.total, 4) class InstallCount(BaseModel): pass_day: int install_day: datetime info: InstallCountInfo 彻底摆脱to_dict和from_dict # 使用 pydantic # BaseModel类型支持:\nb = BattleAxiePositionInfo.parse_obj(DICT_DATA) b.json() b.dict() parse_file parse_raw from pydantic import BaseModel class PositionInfo(BaseModel): error: int = -1 # 收集错误 none: int = 0 # 还没开始 clicked: int = 1 # 在client 赋此值 done: int = 2 # 在server 赋此值 xy: List[int] = [0, 0] status: int = 0 # clicked or done or none or error class BattleAxiePositionInfo(BaseModel): our: List[PositionInfo] = [PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo()] enemy: List[PositionInfo] = [PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo()] pp = BattleAxiePositionInfo() print(f\u0026#34;pp json: {pp.json()}\u0026#34;) dict_pp = pp.dict() pp = BattleAxiePositionInfo.parse_obj(dict_pp) pp json: {\u0026ldquo;our\u0026rdquo;: [{\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}], \u0026ldquo;enemy\u0026rdquo;: [{\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}]}\n多个类属性一次赋值 # No:\nself.a = a self.b = b Yes:\nself.__dict__.update({\u0026#34;a\u0026#34;: a, \u0026#34;b\u0026#34;: b}) 列表表达式 二维数组边一维 取字典内变一维 # knowninfo = {\u0026#39;axie_id3\u0026#39;: {\u0026#39;init_cards\u0026#39;: [\u0026#39;Sunder Claw\u0026#39;, \u0026#39;October Treat\u0026#39;, \u0026#39;Gas Unleash\u0026#39;, \u0026#39;Disguise\u0026#39;], \u0026#39;sort\u0026#39;: 4}} [vv for _,v in knowninfo.items() for vv in v[\u0026#34;init_cards\u0026#34;]] # [\u0026#39;Sunder Claw\u0026#39;, \u0026#39;October Treat\u0026#39;, \u0026#39;Gas Unleash\u0026#39;, \u0026#39;Disguise\u0026#39;] PiP Not Found Issue # 使用pip安装某包时， 提示让更新， 按提示操作更新没效果没反应再用就提示ModuleNotFoundError: No module named 'pip' (ˉ▽ˉ；)\u0026hellip;\nModuleNotFoundError: No module named \u0026lsquo;pip\u0026rsquo; # 升级PiP时出现问题可由下方命令修复 # python -m ensurepip python -m pip install --upgrade pip SSL校验 # 安装EasyOCR时, reader = easyocr.Reader(['ch_sim','en']) 下载到接近90,结果报错了\u0026hellip;. 估计是SSL问题加入以下两条,不知如何.\nimport ssl ssl._create_default_https_context = ssl._create_unverified_context from http.client To revert to the previous, unverified, behavior ssl._create_unverified_context() can be passed to the context parameter.\n使用国内镜像下载Python # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) # 一键更新pip 包资源(利用管道grep传输查询到的需要更新包名，传输到install命令) pip3 freeze --local | grep -v \u0026#39;^\\-e\u0026#39; | cut -d = -f 1 | xargs -n1 pip3 install -U # 权限不够的话就在`pip3 install` 之前加`sudo`反正我不习惯用`root` 声明参数类型 # python3 在定义函数的时候可以声明函数类型啦：虽然不做限制，但作为label还是蛮好的。\nimport io def add(x:int, y:int) -\u0026gt; int: return x + y def write(f: io.BytesIO, data: bytes) -\u0026gt; bool: try: f.write(data) except IOError: return False else: return True 终于不会之后写的忘了，要调用函数还得看半天这个函数应该怎么用…\n时间处理 # 以下可以做周、月的加减处理 relativedelta examples Let’s begin our trip:\nfrom datetime import *; from dateutil.relativedelta import * import calendar Store some values: # NOW = datetime.now() TODAY = date.today() NOW datetime.datetime(2003, 9, 17, 20, 54, 47, 282310)\nTODAY datetime.date(2003, 9, 17)\nNext month # NOW+relativedelta(months=+1)\ndatetime.datetime(2003, 10, 17, 20, 54, 47, 282310) 合并字典 # a = {} b = {\u0026#39;a\u0026#39;: 1} c = {**a, **b} key重复b中覆盖a, 否则单纯合并。\n聊胜于无的小玩意 preety tools # 彩色输出 # 模块名儿忘了，以后贴2019.03.01 03:08 one minute later: pip3 install ansicolors\nfrom colors import red, green, blue print(red(\u0026#39;This is red\u0026#39;)) print(green(\u0026#39;This is green\u0026#39;)) print(blue(\u0026#39;This is blue\u0026#39;)) from colors import color for i in range(256): print(color(\u0026#39;Color #%d\u0026#39; % i, fg=i)) 以上程序只能写在.py文件中,运行，而不能在…‘偷懒模式‘中。\nPython3 ThreadPoolExecutor 线程池内库 # 在python3之后不久，有关线程池的使用就被集成到内库之中。 from concurrent.futures import ThreadPoolExecutor 使用方法：\nThreadPoolExecutor(max_workers=12) # 设置线程池大小 .submit(func_name, (para)) # 提交任务 .done() # 查看任务是否完成 .cancel() # 没有被放入线程池中才能生效 .result() # 获取该任务返回值 from concurrent.futures import as_completed # 用于取出所有任务结果，省去一直用.done去查看的繁琐。但该方法 # 是一个生成器，所以任务未完成会阻塞。 还有 wait map 等用法就去看文档吧。 安装错误？ # 居然有pip3 install XX的错误…这也是因为有旧版pip3存留。需要\n$bash -d pip3 $bash -r pip3 来清理shell中旧版pip缓存。\nIDE? # 其实要不要IDE都无所为，因为本就是脚本，要IDE只能说打开一个陌生项目查看时能够跳转函数。至于vim大概不能跳转吧，毕竟跳转需要把文件都加载才能实现。emm 来来，IDE的话就PyCharm除了编程页面颜色难看之外其他功能都不错，另外不支持中文路径，不过应该不是由于Python语言造成的，因为蟒蛇脚本是可以在中文路径下运行didate:2018年5月28日17点16分\nprint语句： 含有自动换行，所以要想不换行的话需要在结尾加一个\u0026quot;,\u0026ldquo;如： # for i in range(0,5): print i, 而Python3版本则应该也可以 print(a,b,c);然而Python2.7不行\n根据字典中值大小排列： # sorted(dict2.iteritems(),key=lambda item:item[1],reverse=True) # item[0]即根据键来排列[1]为根据对应值 format：如: # print('my name is{0},and my age is{1}'.format('song',18)) or: # url = 'http://www.google.com/page={}/' newsurl = url.format(i) # 旋即其后内容则代替{}位置 另，在{a}{b}{c}可通過format(a=1,b=2,c=3)來賦值\nBeautifulSoup # select语句：在内容前加\u0026rsquo;#\u0026lsquo;可以获得其内容，如： # soup.select('artibodyTitle')[0].text select().contents \u0026quot;\u0026quot;\u0026quot; 把标签变成不同list，同List中的不同元素 然后用[0]可取得第一个元素内容，而不与后方的内容合到一起 *.strip()可将取出的‘\\t\\t’移除 \u0026quot;\u0026quot;\u0026quot; .select('time-source span a') # 从time-source中的\u0026lt;span下\u0026lt;a下取得内容e .select('.productPrice')[0].text # 獲取class=\u0026quot;productPrice\u0026quot;下價格內容 零碎 # 字符串处理 # startswith .isdecimal() datetime字符串转时间 时间转字符串: # from datetime import datetime dt = datetime.strptime(timesource,'%Y年%m月%d日%H:%M')(****年*月*日*22:03) dt.strftime('%Y-%m-%d') 保存數據到xlsx，sqlite3、csv： # .to_excel('name.xlsx')：输出为excle文件 import sqlite3 #保存到数据库 with sqlite3.connect('name.sqlite') as db: df.to_sql('name',con = db) 从数据库取出 # with sqlite3.connect('name.sqlite') as db: df2 = pandas.read_sql_query('SELECT' * FROM name',con = db) 類型錯誤 TypeError: a bytes-like object is required, not \u0026lsquo;str\u0026rsquo; # csv_file = open(\u0026quot;rent.csv\u0026quot;,\u0026quot;wb\u0026quot;) csv_writer = csv.writer(csv_file, delimiter=',') #创建writer对象，指定文件与分隔符 writer.writerow(['title', 'summary', 'year', 'id', 'count', 'link']) Python2.7 轉到 3.5下時提示由此錯誤，代碼爲\n原因，解決方法： # 因爲Python3.5 對於str與bytes類型區分變得敏感，所以原本在2.7下正常的代碼不能正常運行。 雖然，利用str.encode() 或者 str = bytes(str, encoding = 'utf-8')可以轉換格式 然而錯誤依然有……解決辦法則是放棄論壇裏的說法，找到官網Demo 更改如下： # csvfile = open(\u0026#39;goodsList.csv\u0026#39;, \u0026#39;w\u0026#39;, newline=\u0026#39;\u0026#39;) spamwriter = csv.writer(csvfile, delimiter=\u0026#39;,\u0026#39;) spamwriter.writerow([productTitle, productPrice, productShop]) 細節在於，在打開文件的時候去除wb裏面的b即不用二進制模式打開。\n图片信息： # 获取图像分辨率：\nim = Image.open(0.0) width = im.size[0] height = im.size[1] Pandas: # box = pd.read_csv(\u0026#34;filename.csv, index_col=\u0026#34;Date\u0026#34;, parse_dates=Ture) #读入文件，讲Date作为日期 box.columns = [\u0026#39;\u0026#39;,\u0026#39;\u0026#39;] # 更改列名 box[\u0026#39;new\u0026#39;] = box[\u0026#39;1\u0026#39;]+box[\u0026#39;2\u0026#39;] # 新增一列为1与2之和 box.resample(\u0026#39;d\u0026#39;, \u0026#39;sum\u0026#39;) # 重新按照‘d’:每天，进行采样 方式为取和(\u0026#39;w\u0026#39;,\u0026#39;sum\u0026#39;)所有数据在一周内进行取和 闲语： # while True与while 1的区别： # 在Python2 中，循环判断一亿次，我的小电脑的执行速度是\nwhile one: 9.97739481926 while_true: 18.8063299656 while 1 以压倒性胜利。 到了Python3中，则成了\nwhile one: 16.101972927001043 while_true: 16.25536527499935 嗯，不错，不分伯仲——个鬼啊。整体变差了好吧。0.0 原因待明。\nPython 小记 📖 # 先贴一个客观的教程文档网站http://www.runoob.com/python/python-tutorial.html\nWindows 下添加环境变量，CMD中Python2 与Python3 共存 # Windows 下 把python2 路径加入到环境变量中，再修改python2.exe可以和python3区分方便在CMD中调用，但代价就是经常命令报错……\n不过也可以使用py -2来区分，所以还是不改名字了吧 Windows 下 用py -2 -m pip install ***以及py -3 -m pip install ***来区分安装到python2 或者 python3.\n变量 # 类下直接定义的变量可以继承，然而并不能被自己的函数所调用，意义不明…\n被继承的类可以调用继承类中定义的self.* 变量，俺认为这是因为它们在实例时都被当成了self 本身。另外，优先调用自己中的self变量，没有，才会去被继承类中去查找（先后顺序可得前方解答）。\n变换数据类型 # Python 在从服务器接收或者发送数据时需要字符类型转换，\u0026lsquo;\u0026lsquo;\u0026lsquo;struct\u0026rsquo;\u0026lsquo;\u0026lsquo;便是为此而工作\nstruct.pack # import struct a = 20 b = 400 str = struct.pack(\u0026#34;ii\u0026#34;, a, b) #转换后的str虽然是字符串类型，但相当于其他语言中的字节流（字节数组），可以在网络 #上传输 print \u0026#39;length:\u0026#39;, len(str) print str print repr(str) \u0026mdash;- result length: 8\n\u0026mdash;-这里是乱码 # \u0026lsquo;/x14/x00/x00/x00/x90/x01/x00/x00\u0026rsquo;\n格式符”i”表示转换为int，’ii’表示有两个int变量。进行转换后的结果长度为8个字节（int类型占用4个字节，两个int为8个字节），可以看到输出的结果是乱码，因为结果是二进制数据，所以显示为乱码。可以使用python的内置函数repr来获取可识别的字符串，其中十六进制的0x00000014, 0x00001009分别表示20和400。\nstruct.unpack # str = struct.pack(\u0026#34;ii\u0026#34;, 20, 400) a1, a2 = struct.unpack(\u0026#34;ii\u0026#34;, str) print \u0026#39;a1:\u0026#39;, a1 print \u0026#39;a2:\u0026#39;, a2 \u0026mdash;- result: a1: 20 a2: 400\nstruct.unpack做的工作刚好与struct.pack相反，用于将字节流转换成python数据类型。它的函数原型为：struct.unpack(fmt, string)，该函数返回一个元组。\nstruct.calcsize # struct.calcsize(\u0026#39;i\u0026#39;) struct.calcsize(\u0026#39;ii\u0026#39;) struct.calcsize(\u0026#39;iic\u0026#39;) struct.calcsize(\u0026#39;iicd\u0026#39;) 4 8 9 24\nstruct.calcsize用于计算格式字符串所对应的结果的长度，如：struct.calcsize(‘ii’)，返回8。因为两个int类型所占用的长度是8个字节。\nstruct.pack_into, struct.unpack_from # import struct from ctypes import create_string_buffer buf = create_string_buffer(12) print repr(buf.raw) struct.pack_into(\u0026#34;iii\u0026#34;, buf, 0, 1, 2, -1) print repr(buf.raw) print struct.unpack_from(\u0026#39;iii\u0026#39;, buf, 0) \u0026mdash;- result \u0026rsquo;/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00\u0026rsquo; \u0026rsquo;/x01/x00/x00/x00/x02/x00/x00/x00/xff/xff/xff/xff\u0026rsquo; (1, 2, -1)\nPython3 # 在Python3中，转换字符串时，不能直接pack('8s', 'i am str'), 需要将字符串转换成二进制所以在语法中标记pack('8s', b'i am str')使用'b'来进行标记\n以上来自Darkbull 这是转贴地址，不知道为什么我看的转贴挂的原帖地址失效了 😰\n一不小心发现的语法 # py2.7\nwhile 'a' in a or b: break # 没错，意思就是如果a或者是b包含‘a’的话… * 与 ** 方法: # 呃，原来*在MarkDown里面是斜体的意思啊——需要斜体显示的前后各一个星号\ndef a(* a, **b): balabala 这里的*a， a在函数中被赋值为一个元组，b被赋值为一个字典。所以在调用的时候嘞，只能把能往一个元组里塞的放在前面，而能够生成字典的放在后面\na(1,2,3,4,5,6,7,8,9,a:'a',b:1,c:'nihao') 就像这么一样来调用。 另外，def a()函数中还能在前方再新加一个输入\ndef aa(jiushishuowo, *a, **b): pass 这样的话，那么在调用的时候第一个逗号前面的内容会赋值给它。over，回去拿快递了~~~\n🐶 年假前再来补充一下：约定名*args, **kwargs\n获取文件路径 # path = os.path.abspath(os.path.dirname(__file__)) # 获取当前运行文件的路径。需在本地有此文件，在命令行中出错 for root, subdirs, files in os.walk(path): # 遍历所有path下文件 path为要遍历的路径 同获取路径 # os.path.abspath('./') os.path.abspath('Deskop') os.path.abspath('Deskop') + os.path.sep \u0026lsquo;C:\\Users\\Administrator\u0026rsquo;\n\u0026lsquo;C:\\Users\\Administrator\\Deskop\u0026rsquo;\n\u0026lsquo;C:\\Users\\Administrator\\Deskop\\\u0026rsquo;\n获取指定目录下所有文件名列表 # os.listdir('D\\IFData') _dict_ # class Province: country = 'China' def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print 'func' print Province.__dict__ # 类输出 obj1 = Province('HuBei', 100) print obj1.__dict__ # 对象1 obj2 = Province('hulala', 3888) print obj2.__dict__ # 对象2 {'country': 'China', '__module__': '__main__', 'func': \u0026lt;function func at 0x049EF470\u0026gt;, '__init__': \u0026lt;function __init__ at 0x049EF4F0\u0026gt;, '__doc__': None}\n{'count': 100, 'name': 'HuBei'}\n{'count': 3888, 'name': 'hulala'}\n类输出的是全局的函数，变量等信息。 对象输出的只是对象拥有的普通变量而已\n呃(⊙﹏⊙)，等下再去拿吧… 差点忘了说，这个__dict__与字典相配合来回赋值简直舒服… 步骤为：将某个变量=一个类（数据类（就是能够a.b这么调用的数值））然后这个变量就能a.b的这么使用了。 而后也能通过a.dict（这是一个字典）再将所需要的数值取出来，转赋值为别的东西。 反正我是用到了… 在想要实现一个函数来保存一个变量的某些属性的时候。（呃(⊙﹏⊙)用爱去理解我所描述的场合吧。）\nIF ELSE # # 执行时会将IF前面整个表达式作为判断结果后的执行对象， # 而不是仅仅替换某一个数字或者变量。 即 下方表达式运算结果 # 不是 `4` 和 `5` 而是如下所示 a = 1 + 3 if 1 == 2 else 2 + 1 a a = 1 + 3 if 1 == 1 else 2 + 1 a 3\n4\nPython 2 中的object新式类和经典类 # # 作者：邹冲 # 链接：https://www.zhihu.com/question/19754936/answer/202650790 class A: def foo(self): print('called A.foo()') class B(A): pass class C(A): def foo(self): print('called C.foo()') class D(B, C): pass if __name__ == '__main__': d = D() d.foo() B、C 是 A 的子类，D 多继承了 B、C 两个类，其中 C 重写了 A 中的 foo() 方法。\n如果 A 是经典类（如上代码），当调用 D 的实例的 foo() 方法时，Python 会按照深度优先的方法去搜索 foo() ，路径是 B-A-C ，执行的是 A 中的 foo() ；\n如果 A 是新式类，当调用 D 的实例的 foo() 方法时，Python 会按照广度优先的方法去搜索 foo() ，路径是 B-C-A ，执行的是 C 中的 foo() 。\n因为 D 是直接继承 C 的，从逻辑上说，执行 C 中的 foo() 更加合理，因此新式类对多继承的处理更为合乎逻辑。\n在 Python 3.x 中的新式类貌似已经兼容了经典类，无论 A 是否继承 object 类， D 实例中的 foo() 都会执行 C 中的 foo() 。但是在 Python 2.7 中这种差异仍然存在，因此还是推荐使用新式类，要继承 object 类。\n.items() # 一个字典 a，其a.items()为将每对对应值组为一个元组。即使键值也为一个字典也是将此字典作为元组元素。(￣▽￣)\u0026rdquo; emm\nQueue # 队列，先进先出型。可存数字、字符…嘛，Python里啥都一样。所以啥都能存。用于事件按顺序执行。示例如~：\nimport Queue mqueue = Queue.Queue(maxsize = 3) mqueue.put(10) mqueue.put(15) mqueue.put(12) # 此时如果再往里存呢，就会卡住… 持续等待有空位置 # 所以 mqueue.get() #取出第一个存入 mqueue.put('14sas4') #继续存 ## 在接触的项目中，是借用字典，来将处理函数作为Value，将Keys，put到队 列中，再进行取出执行。 如果队列中没有数值之后再get也会卡住…… 所以以下东西就显得比较重要了：\nseries和dataframe # 先贴来源：http://blog.csdn.net/ly_ysys629/article/details/54944153\n属性 # series ：.index, .values, .name, .index.name dataframe ：.columns, .index, .values series: # 一组数组（列表或元组），series除了一组数据外还包括一组索引（即只有行索引），索引可自行定义也可利用Series(),自动生成索引;\ndataframe: # 是表格型数据，既有行索引又有列索引，每列数据可以为不同类型数据（数值、字符串、布尔型值），可利用DataFrame（其他数据，dataframe属性)指定dataframe的属性创建dataframe。\n实例 # series # #创建series import pandas as pd obj_list=[1,2,3,4] obj_tuple=(4,5,6,7) obj_dict={'a':[1,2],'b':[2,3],'c':[3,4],'d':[4,5]} obj_series_list=pd.Series(obj_list)#通过列表创建series obj_series_tuple=pd.Series(obj_tuple,index=list('abcd')) #通过元组创建series obj_series_dict=pd.Series(obj_dict)#通过字典创建series #定义属性 obj_series_list.index.name='zimu' obj_series_list.name='data' print \u0026quot;#通过列表创建series\u0026quot; print obj_series_list print \u0026quot;#通过元组创建series\u0026quot; print obj_series_tuple print \u0026quot;#通过字典创建series\u0026quot; print obj_series_dict #显示series类型及属性 print type(obj_series_list),obj_series_list.dtype print obj_series_list.index,obj_series_list.index.name print obj_series_list.values,obj_series_list.name 通过列表创建series # zimu\n0 1\n1 2\n2 3\n3 4\nName: data, dtype: int64\n通过元组创建series # a 4 b 5 c 6 d 7 dtype: int32 通过字典创建series # a [1, 2] b [2, 3] c [3, 4] d [4, 5] dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt; int64 RangeIndex(start=0, stop=4, step=1, name=u'zimu') zimu [1 2 3 4] data dataframe # #创建dataframe import pandas as pd import numpy as np obj_dict={'a':[1,2],'b':[2,3],'c':[3,4],'d':[4,5]} obj_array=np.array([[1,2,3,4],[3,4,5,6]]) obj_series_1=pd.Series([11,12,13,14]) obj_series_2=pd.Series([21,22,23,24]) obj_dataframe_dict=pd.DataFrame(obj_dict) #通过字典创建dataframe obj_dataframe_array=pd.DataFrame(obj_array,index=['one','two']) #通过矩阵创建dataframe obj_dataframe_series=pd.DataFrame([obj_series_1,obj_series_2]) #通过series创建dataframe obj_dataframe_dataframe=pd.DataFrame(obj_dataframe_series,index= [0,1,'one'],columns=[0,1,2,'a']) #通过其他dataframe创建dataframe print \u0026quot;#通过字典创建dataframe\u0026quot; print obj_dataframe_dict print \u0026quot;#通过矩阵创建dataframe\u0026quot; print obj_dataframe_array print \u0026quot;#通过series创建dataframe\u0026quot; print obj_dataframe_series print \u0026quot;#通过其他dataframe创建dataframe\u0026quot; print obj_dataframe_dataframe #dataframe属性 print obj_dataframe_dataframe.dtypes print obj_dataframe_dataframe.values print obj_dataframe_dataframe.columns print obj_dataframe_dataframe.index 输出结果为： #通过字典创建dataframe a b c d 0 1 2 3 4 1 2 3 4 5 #通过矩阵创建dataframe 0 1 2 3 one 1 2 3 4 two 3 4 5 6 #通过series创建dataframe 0 1 2 3 0 11 12 13 14 1 21 22 23 24 #通过其他dataframe创建dataframe 0 1 2 a 0 11.0 12.0 13.0 NaN 1 21.0 22.0 23.0 NaN one NaN NaN NaN NaN 0 float64 1 float64 2 float64 a float64 dtype: object [[ 11. 12. 13. nan] [ 21. 22. 23. nan] [ nan nan nan nan]] Index([0, 1, 2, u\u0026rsquo;a\u0026rsquo;], dtype=\u0026lsquo;object\u0026rsquo;) Index([0, 1, u\u0026rsquo;one\u0026rsquo;], dtype=\u0026lsquo;object\u0026rsquo;) 取数据的话，便是obj_dataframe_dict['a'][0]取出数值即为1\n自命名创建方式 # df4 = pd.DataFrame(np.random.randn(6, 4), index=[u'第二', 4, 3, 2, 1, 0], columns=[u'第一',5,4,1]) #行为： 第一， 5， 4， 1 #列为：第二 -0.091305 ... # 4 ... # 3 # 2 # 1 # 0 ... 查看 # .dtypes 查看各行数据格式 .head() 查看前几行（默认5） .tail() 查看后几行 .index 查看数据框引索 .columns 查看列名 .values 数据值 .T 转置 .sort 排序 .sort(columns = '***')根据***列数据进行排序 取数据方法见上 # zip 和 数组变字典 # a = [1,2,3] b = [4,5,6] c = [4,5,6,7,8] zipped = zip(a,b) [(1, 4), (2, 5), (3, 6)]\nzip(a,c) [(1, 4), (2, 5), (3, 6)]\nzip(*zipped) [(1, 2, 3), (4, 5, 6)]\nzip 也可以二维矩阵变换（矩阵的行列互换） 因为其作用为按序号重组数组。（其英语翻译为拉链……）\n数组变字典~： # dic(zip(a, b)) # a中值为key b中值为values 字典操作 # dict= sorted(dic.items(), key=lambda d:d[0]) # 将字典按照键值升序排列 # d： 无所谓的参数 # d[0]：0为升序，1为降序 # 如果是字符型，那么‘1’‘10’‘12’… 才是‘2’’20‘，因为Python的比较是按照 # 按序提取第一个字符进行比较。所以要排序，还是得用int # 排序之后被转换为list类型。 for i in orderIDic: spamwriter.writerow(orderIDic[i]) # 变为 for i in orderIDic: spamwriter.writerow(i[1]) namedtuple # import collections person = collections.namedtuple('P', 'name age gender') # P: 类名 后面空格隔开的为变量名称 bob = person(name = 'B', age = 30, gender = 'male') jane = Person(name = 'J', age = 29, gender = 'female') for people in [bob, jane]: print (\u0026quot;%s is %d years old %s\u0026quot; % people) 元组的命名—— 命名之后可以由bob.name 来调用 （看了那个Python面向对象进阶， 老多__hahah__()函数之后，所以这明显是当成基本类的变量在用了。 emm 这么么说也不贴切 😔 果然理解程度还是跟不上的… emm 现在需要跟进的不是怎么用Python了，而是python的用法了，走起~ 继续写future笔记去了—— 这个得看的明白点儿😄）\nCSV # 读取 # import csv reader = csv.reader(open('test.csv', 'rb')) for item in reader: print item 官方是这么教你的 # #我记得我写过一次，怎么不见了… import csv with open('names.csv') as csvfile: reader = csv.DictReader(csvfilr) for row in reader: print (row['first_name'], row['last_name']) 写入 # import csv writer = csv.writer(open('test2.csv', 'wb')) writer.writerow(['col1', 'col2', 'col3']) data = [range(3) for i in range(3)] for item in data: writer.writerow(item) 官方教你这么写 # import csv with open('names.csv') as csvfile: fieldnames = ['first_name', 'last_name'] writer = csv.DictWriter(csvfile, fieldnames = fieldnames) writer.writeheader() writer.writerow('first_name' : 'Naled', 'last_name' : 'Beans') 须注意之处：writer.writerow()方法中的参数是list类型，如果你想在A1列写入\u0026rsquo;hello\u0026rsquo;，则必须是writer.writerow(\u0026lsquo;hello\u0026rsquo;)，不然\u0026rsquo;hello\u0026rsquo;会被看成是个list从而被分写入5列。写入CSV时，CSV文件的创建必须加上\u0026rsquo;b\u0026rsquo;参数，即csv.writer(open(\u0026rsquo;test.csv\u0026rsquo;, \u0026lsquo;wb\u0026rsquo;))，不然会出现隔行的现象。网上搜到的解释是：python正常写入文件的时候，每行的结束默认添加\u0026rsquo;\\n’，即0x0D，而writerow命令的结束会再增加一个0x0D0A，因此对于windows系统来说，就是两行，而采用’b\u0026rsquo;参数，用二进制进行文件写入，系统默认是不添加0x0D的。\n关闭 # csvfile.close() 值得注意的是上面的文档是覆盖型创建，即，写数据只能在关闭文档之前完成，之后再打开文件，再写就会覆盖掉之前（清空再写） 下面的txt mode = 'a' 就属于添加型写入了，再关闭之后再打开会在最后一条开始继续添加。然后将csv中的\u0026rsquo;w\u0026rsquo;替换成‘a’就行了。记得带上\u0026rsquo;b\u0026rsquo;要不会出现数据隔行…隔行显示\n官方还叫你这么写嘞 # with open('na1me.csv', 'ab') as csvfile: spamwriter = csv.writer(csvfile, delimiter = ',') spamwriter.writerow(['adasd', 'w.c.w', 'lol']) txt保存 # # 基本与CSV一致，emm其实都是保存为文档，就只有个后缀区别… def text_save(content,filename,mode='a'): # Try to save a list variable in txt file. file = open(filename,mode) file.write(str(content)+'\\n') file.close() text_save(np.mean(self.trueRange[start: ]), 'atr.txt') 关于保存路径呢，windows 下必须?用 ‘.\\.\\..’没错，当前路径（相对路径）和绝对路径都是这样用的\nmode b代表二进制模式打开，而a就有用了，表示有此文件就打开，没的话就创建。\njson # 和上述txt文件保存差不过，嗯应该说完全一样。因为我是用的是`json.dumps` dumps、loads # 这两个语句前者是将字典转化为str格式，后者是将str转换为字典。所以保 存到文件也不过是 字典 -\u0026gt; str -\u0026gt;(用`write`写入)-\u0026gt; 本地文件， 反之。 与之相对比的是`dump`和`load`这个是直接保存至文件，但`s`多好用 需注意的是`dumps`有`indent`参数可用来指明转换为`str`之后的缩进参 数。一般`4`（所以说这里说的是空格数？）。 哦，`loads`直接加载文件也 行，不用读出来`str`再去转换 Shelve # 对象的持久化存储—— 目的：Shelve模块为任意能够pickle的Python对象实现持久化存储，并提供一个类似字典的 接口。 # 列表List # 需提前定义，不能像变量一样随用随写…\n以下来自于 Python 列表(List)操作方法详解\n列表操作包含以下函数: # cmp(list1, list2) # 比较两个列表的元素 len(list) # 列表元素个数 max(list) # 返回列表元素最大值 min(list) # 返回列表元素最小值 list(seq) # 将元组转换为列表 列表操作包含以下方法: # list.append(obj) # 在列表末尾添加新的对象 list.count(obj) # 统计某个元素在列表中出现的次数 list.extend(seq) # 在列表末尾一次性 # 追加另一个序列中的多个值（用新列表扩展原来的列表） list.index(obj) # 从列表中找出某个值第一个匹配项的索引位置 list.insert(index, obj) # 将对象插入列表 list.pop(obj=list[-1]) #移除列表中的一个元素（默认最后一个元素） #，并且返回该元素的值 list.remove(obj) # 移除列表中某个值的第一个匹配项 list.reverse() # 反向列表中元素 list.sort([func]) # 对原列表进行排序 字符串连接 # 来自http://www.cnblogs.com/chenjingyi/p/5741901.html\n方法一 # website = 'python' + 'tab' + '.com' 方法二 # listStr = ['python', 'tab', '.com'] website = ''.join(listStr) 方法三 # website = '%s%s%s' % ('python', 'tab', '.com') 结论： 连接个数少使用一，个数多使用二。 推荐，使用三 ~ ，~\n手动编译Py文件 # import compileall compileall.compile_dir(目录) 时间 # datetime # from datetime import datetime a = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) a.year a.hour #int 型变量 2017\n0\n获取当前本机电脑💻时间，replace为自定义某个数值。单独调用某个信息如a.year、a.hour\ndatetime 类型变量可直接相减获得间隔日 # a = datetime.datetime.now() # datetime.datetime(2017, 10, 18, 8, 52, 27, 5000) b = datetime(2005, 2, 6) # datetime.datetime(2005, 2, 6, 0, 0) c = a - b # datetime.timedelta(4637, 31947, 5000) c.days # int 型 4637\ntimedelta # timedelta为datetime类型相减而来（datetime不能相加…），然后嘞，datetime.timedelta(1,35340)这是它的样子，前是天数，后是秒数。也就是说所有相减就是告诉你相距多少天零多少秒，都是标准单位（误）。要取出可 .days 和 `seconds``\n格式化输出当前时间 # import time print time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) 2017-08-21 10:54:31\ntime # import time time.time() # 返回当前时间的时间戳（1970纪元后经过的浮点秒数） # 返回值为float 可直接拿来运算，还是很舒服的。 线程 threading # 用于实现定时器 # import threading def hel(): print \u0026quot;so you sucsessful to kill 5 seconde\u0026quot; time = threading.Timer(5, hel) time.start() so you sucsessful to kill 5 seconde 在命令行中按下回车后消失，很有意思，并且当第二调用时time.start()时就会——\nRuntimeError: threads can only be started once\n循环调用 # 以上的不能循环调用的话就没啥价值了，所以下面有个妖艳用法为：\ndef fun(): print \u0026quot;So jian\u0026quot; global timer timer = threading.Timer(5.5, fun) timer.start() timer = threading.Timer(1, fun) timer.start() # 通过自调自的方法循环创建时间线程，另外，timer.cancel()可停止定时器工作。 # 值得注意的是，上面不循环调用的 在执行完函数之后依然会持续运行 # 所以得记得关闭。 比方说这个妖艳……呃 本来打算在调用函数里写上cancel但是…依然之后不能再次start()\n线程池 # 自实现或者使用threadpool.ThreadPool:\nimport time import threadpool def sayhello(str): print \u0026#34;Hello \u0026#34;,str time.sleep(2) name_list =[\u0026#39;dd\u0026#39;,\u0026#39;aa\u0026#39;,\u0026#39;bb\u0026#39;,\u0026#39;cc\u0026#39;] start_time = time.time() pool = threadpool.ThreadPool(10) requests = threadpool.makeRequests(sayhello, name_list) for req in requests: pool.putRequest(req) pool.wait() print \u0026#39;%d second\u0026#39;% (time.time()-start_time) Math 库 # import math 数值取整 # ceil、floor 还有一个不是此库中的round 找来翻译就是 ： 小区、地板、回合………… 好吧，是（抹灰泥装镶板、最低的，最小的、周围，围绕）\n# 使用方法为： math.ceil(3.12) math.floor(3.24) round(3.51) round(3.10999999999, 10) #取值时的参考步长，好像（😭）是10就是最大步长了，再大没意义 # 手动赋值超过9位也就是10位小数的时候在PyCharm里直接赋值调试就自己约了， # 而一般产生精度漂移都是十几位小数开外的。emm 就这么表达了，看得懂 4.0\n3.0\n4.0\n3.11\n令程序有序执行的方法 # 对象（伪类）间变量传递 # Like This：\nclass A(object): \u0026quot;\u0026quot;\u0026quot;docstring for A\u0026quot;\u0026quot;\u0026quot; def __init__(self, name): super(A, self).__init__() self.name = name self.a = 0 def da(self): print self.name print self.a a = A('I am A') a.da() class B(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(B, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() b = B(a) b.dada() class C(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(C, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() c = C(a) c.dada() I am A\n0\nI am A\n1\nI am A\n2\nB与C分别在去改变读取在A中定义的数值。 嗯，没错，这么看的画确实时Python基础……所以没有这个基础的我看起来前期还挺费劲。当然，理解很好理解，就是在实现方法上不知原理的话就很难过。最主要的是，知道了原理在自己编写的时候可以的心用手，信手拈来。嗯~ o(￣▽￣)o就是这么写意和惬意。在VN.PY中有记录，不过还是拿过来吧，毕竟python用法\n字典中建立函数映射，方便调用~ # def add(x, y): return x + y def sub(x, y): return x - y a = {'add':add, 'sub':sub} a a['add'](1, 2) a['sub'](1, 2) {\u0026lsquo;add\u0026rsquo;: \u0026lt;function add at 0x02D162B0\u0026gt;, \u0026lsquo;sub\u0026rsquo;: \u0026lt;function sub at 0x02D16530\u0026gt;}\n3\n-1\ncollections 模块 # namedtuple # 给元组元素命名（貌似写过这个笔记欸，不过现在才发现这几个都是在一个模块下的） deque # #双端队列 快速插入 以及取出 l.insert(0, v) l.pop(0) l.popleft() l.appendleft() # 数据量大时，速度优于原生list a Game: # import sys import time from collections import deque fancy_loading = deque('\u0026gt;--------------------') while True: print '\\r%s' % ''.join(fancy_loading), fancy_loading.rotate(1) sys.stdout.flush() time.sleep(0.08) Result: # 一个无尽循环的跑马灯 Counter # # 计数器 from collections import Counter s = '''A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.'''.lower() c = Counter(s) print c.most_common(5) [(\u0026rsquo; \u0026lsquo;, 54), (\u0026rsquo;e\u0026rsquo;, 32), (\u0026rsquo;s\u0026rsquo;, 25), (\u0026lsquo;a\u0026rsquo;, 24), (\u0026rsquo;t\u0026rsquo;, 24)]\nOrderDict # # 有序字典：记录了数据存入时的先后顺序 # 不过发现一个骚操作： defaultdict # # 默认字典： 当key不存在时，返回此结果 线程 # 创建线程： 使用Threading模块创建，从threading.Thread继承，然后重写__init__ 和run 方法 import threading import time exitFlag = 0 class myThread (threading.Thread): #继承父类threading.Thread def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 print \u0026#34;Starting \u0026#34; + self.name 写到这儿 print \u0026#34;Exiting \u0026#34; + self.name thread1 = myThread(1, \u0026#34;Thread - 1\u0026#34; , 1) thread1 = myThread(2, \u0026#34;Thread - 2\u0026#34; , 2) # 开启 thread1.start() thread2.start() 线程同步 # 不同线程对某个数据同时修改就很刺激，所以需要同步。（当然也可以选择不） 其实也简单，如下：\nimport threading threadingLock = threading.Lock() # 从这儿领一把锁 # 然后在 run()函数中，“写到这儿——也就是工作函数之前，写上 threadingLock.acquire() # 随后在工作函数之后 # threadingLock.release() 然后拿到小锁子的函数就能运行，运行完了把小锁子释放掉。为啥不是钥匙🔑……好吧。我就称呼它我就称呼它梭子吧——\n队列 # 线程优先级队列 Queue.qsize()\t返回队列的里站了几个 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]]) 获取队列,timeout`等待时间 Queue.get_nowait() 相当 Queue.get(False) Queue.put(item) 写入队列，timeout 等待时间 Queue.put_nowait(item) 相当 Queue.put(item, False) Queue.task_done() 在完成一项工作之后， Queue.task_done() 函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作 来段儿示例：来自这儿\n#!/usr/bin/python # -*- coding: UTF-8 -*- import Queue import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print \u0026#34;Starting \u0026#34; + self.name process_data(self.name, self.q) print \u0026#34;Exiting \u0026#34; + self.name def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print \u0026#34;%s processing %s\u0026#34; % (threadName, data) else: queueLock.release() time.sleep(1) threadList = [\u0026#34;Thread-1\u0026#34;, \u0026#34;Thread-2\u0026#34;, \u0026#34;Thread-3\u0026#34;] nameList = [\u0026#34;One\u0026#34;, \u0026#34;Two\u0026#34;, \u0026#34;Three\u0026#34;, \u0026#34;Four\u0026#34;, \u0026#34;Five\u0026#34;] queueLock = threading.Lock() workQueue = Queue.Queue(10) threads = [] threadID = 1 # 创建新线程 for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1 # 填充队列 queueLock.acquire() for word in nameList: workQueue.put(word) queueLock.release() # 等待队列清空 while not workQueue.empty(): pass # 通知线程是时候退出 exitFlag = 1 # 等待所有线程完成 for t in threads: t.join() print \u0026#34;Exiting Main Thread\u0026#34; Starting Thread-1\nStarting Thread-2\nStarting Thread-3\nThread-1 processing One\nThread-2 processing Two\nThread-3 processing Three\nThread-1 processing Four\nThread-2 processing Five\nExiting Thread-3\nExiting Thread-1\nExiting Thread-2\nExiting Main Thread\n呃， 以上就是我现知道的终极用法，当然其基础于：\nworkQueue = Queue.Queue(10) # 创建+设定队列长度（emm 小心卡死就是了） # 只要满了再往里塞绝对死，无意外……(lll￢ω￢) workQueue.put(word) # 往里塞。 基础就是塞个数字，高级就是塞个线程 workQueue.get() # 顺序往外取 # 括号里里面可以写进参数，然而，依然按照顺序往外取，插队办理啥的不存在 # 另外，队列空的话取依然会死…… 一些方法 # q = queue.Queue(maxsize=0) q.qsize() #查看队列大小 q.empty() #判断队列是否为空 q.full() #如果maxsize设置了大小(eg:2)，如果q.put()了2个元素，则返回真，反之，则为假 q.get_nowait() # 如果队列中没有元素了，只用q.get() （当然，可以设置`q.get(block=False）`）会使程序卡住，用q.get_nowait()则会报错而不卡住 q.put_nowait() # 如果maxsize设置了大小，用q.put()超过范围则会卡住（当然 # 可以设置属性q.put(block=False)）。用q.put_nowait()则会报错而不卡住 老夫的Demo # 消费生产者关系\nimport threading import queue import threadpool import time pool = threadpool.ThreadPool(2) que = queue.Queue() dataList = [1,2,3,4,5,6,7,8,9,0] dataList1 = [1,2,3,\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] dataList2 = [4,5,6] dataList3 = [7,8,9,0] printLock = threading.Lock() workList = [dataList1, dataList2, dataList3] def worker(): ## 消费者 #printLock.acquire() aaa = que.get() print(aaa) for i in aaa: print (i) #printLock.release() time.sleep(5) def geter(task): ## 生产者 print(\u0026#34;emm, put in_:\u0026#34;, task) time.sleep(1) que.put(task) a = threading.Thread(target=worker) a.start() for i in workList: geter(i) 进程 # import multiprocessing import time def worker_1(interval, lock, low): print (\u0026#34;worker_1\u0026#34;) print (time.time()) lock.acquire() time.sleep(0.1) print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print(low) print (\u0026#34;end worker_1\u0026#34;) lock.release() def worker_2(interval, lock): print (\u0026#34;worker_2\u0026#34;) print (time.time()) lock.acquire() print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print (\u0026#34;end worker_2\u0026#34;) lock.release() def worker_3(interval, lock): print (\u0026#34;worker_3\u0026#34;) print (time.time()) lock.acquire() print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print (\u0026#34;end worker_3\u0026#34;) lock.release() if __name__ == \u0026#34;__main__\u0026#34;: printLock = multiprocessing.Lock() # 🔒 来自关爱的小锁子 p1 = multiprocessing.Process(target = worker_1, args = (2, printLock, [\u0026#34;asd\u0026#34;, {\u0026#39;s\u0026#39;:1}, [1,2,3]])).start() p2 = multiprocessing.Process(target = worker_2, args = (3, printLock)).start() p3 = multiprocessing.Process(target = worker_3, args = (4, printLock)).start() w = {\u0026#39;a\u0026#39;:p1, \u0026#39;b\u0026#39;:p2, \u0026#39;c\u0026#39;:p3} # 创建三个进程去运行这三个函数 #p1.start() #p2.start() #p3.start() #for i in w: # w[i].start() # 启动进程 print(\u0026#34;The number of CPU is:\u0026#34; + str(multiprocessing.cpu_count())) for p in multiprocessing.active_children(): print(\u0026#34;child p.name:\u0026#34; + p.name + \u0026#34;\\tp.id\u0026#34; + str(p.pid)) print (\u0026#34;Main All Done\u0026#34;) # dt 2018年5月18日11点22分 worker_1 1526613489.1864893 worker_2 1526613489.1932006 The number of CPU is:4 child p.name:Process-3 p.id208 child p.name:Process-1 p.id206 child p.name:Process-2 p.id207 Main All Done worker_3 1526613489.1968668 I got the lock [\u0026lsquo;asd\u0026rsquo;, {\u0026rsquo;s\u0026rsquo;: 1}, [1, 2, 3]] end worker_1 I got the lock\nend worker_2 I got the lock end worker_3\n插一句话 线程和进程的关系，貌似与电脑双系统和系统再开虚拟机的关系emm 对于资源利用的角度上。\n没有传参的进程 # import multiprocessing def sayHello(): print(\u0026#39;hello~ I can see you\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: p1 = multiprocessing.Process(target=sayHello) p2 = multiprocessing.Process(target=sayHello) p3 = multiprocessing.Process(target=sayHello) p1.start() p2.start() p3.start() 如果只是单纯运行，这样就可以了，之所以做这个测试是因为我忌惮于那个args的传参，毕竟()里面若有元素存在就必须要有逗号… 看来没有传参的话就不需要了 一个参数a的时候: (a, )emmm🤔\n将进程定义为类 # import multiprocessing import time class ClockProcess(multiprocessing.Process): def __init__(self, interval): multiprocessing.Process.__init__(self) self.interval = interval def run(self): n = 5 while n \u0026gt; 0: print(\u0026quot;the time is {0}\u0026quot;.format(time.ctime())) time.sleep(self.interval) n -= 1 if __name__ == '__main__': p = ClockProcess(3) p.start() 以上，p.start()被调用时，自动调用run() 另外时间戳都是瞎戳的，所以… emm 这都一年之前的东西了，现在才想起来戳时间有点儿纪念意义(⊙﹏⊙) 2018年5月18日\n属性 # daemon ：是否伴随主程序结束而结束 Lock: 锁：（如下， 防止访问共享资源时冲突，如以上打印时间时出现的不连续打印😰） def worker(lock, var): try: *** finally: lock.release() lock = multiprocessing.Lock() var = '我是变量' p = multiptocessing.Process(target = worker, args = (lock, var)) 警个告 # 创建进程分支的函数选择只能隶属于__main__下或者是隶属与创建进程的函数级别相同的级别，例如今天在main下一个函数中选择目标函数为此函数的函数就不可以… 如下：\ndef a(): def c(para): pass *(target=b, args=(1,)) 🌹 *(target=c, args=(1,)) ❌ def b(para): pass emm，上述表述的很明确，但是昨天又重新犯了这个问题… 进程的执行者放到了类中的某个函数，然后又提出到__main__ 中函数，所以都不能执行，最终放到`main``外，与它同级，也就是def 前无空格。 才能“受命”。\n通过队列来存储不同进程产生的结果 # {来自}(https://blog.csdn.net/u014556057/article/details/66974452)\n# -*- coding:utf-8 -*- from multiprocessing import Process, Queue, Lock L = [1, 2, 3] def add(q, lock, a, b): lock.acquire() # 加锁避免写入时出现不可预知的错误 L1 = range(a, b) lock.release() q.put(L1) print L1 if __name__ == \u0026#39;__main__\u0026#39;: q = Queue() lock = Lock() p1 = Process(target=add, args=(q, lock, 20, 30)) p2 = Process(target=add, args=(q, lock, 30, 40)) p1.start() p2.start() p1.join() p2.join() L += q.get() + q.get() print L [20, 21, 22, 23, 24, 25, 26, 27, 28, 29] [30, 31, 32, 33, 34, 35, 36, 37, 38, 39] [1, 2, 3, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n再加一个协程 # 基础实现： # # yield def creatAor(): mylist = range(3) for i in mylist: yield i*i mygenerator = creatAor() # 生成一个生成器 print (mygenerator) for i in mygenerator: print (i) \u0026lt;generator object creatAor at 0x7f54ed368f10\u0026gt; 0 1 4\n当调用函数时，其返回并不立马执行（显示）——emm 经过十几分钟😰的观察👀说那么玄乎，.其实就是在函数执行过程中，在yield处把后面紧接的东西记录下来，之后最后生成一个可迭代的对象。 所以网上说时生成器也不可厚非，但表达真的是……不过貌似.不仅仅是记录后面紧跟的东西…\n$ vim def creatAor(): mylist = range(3) print(\u0026#34;so jia nei?\u0026#34;) for i in mylist: print(\u0026#34;pre a hou ga\u0026#34;) yield i*i print (\u0026#34;nihoua\u0026#34;) print (\u0026#34;2333333\u0026#34;) mygenerator = creatAor() print (mygenerator) for i in mygenerator: print (i) \u0026lt;generator object creatAor at 0x7fe2585a8f10\u0026gt; so jia nei? pre a hou ga 0 nihoua pre a hou ga 1 nihoua pre a hou ga 4 nihoua 2333333\n所以看这苗头像是重新执行了一次函数，但是将后面紧跟的东西也进行了记录\n应用到协程中，便是：\nimport time def consumer(): r = \u0026#39;\u0026#39; while True: n = yield r if not n: return print(\u0026#39;[CONSUMER] Consuming %s....\u0026#39; % n) time.sleep(1) r = \u0026#39;200 OK\u0026#39; def produce(c): c.next() n = 0 while n \u0026lt; 5: n = n + 1 print(\u0026#39;[PRODUCER] Producing %s...\u0026#39; % n) r = c.send(n) print(\u0026#39;[PRODUCER] Consumer return: %s\\n\u0026#39; % r) c.close() if __name__==\u0026#39;__main__\u0026#39;: c = consumer() produce(c) for i in c: print(i) [PRODUCER] Producing 1\u0026hellip; [CONSUMER] Consuming 1\u0026hellip;. [PRODUCER] Consumer return: 200 OK\n[PRODUCER] Producing 2\u0026hellip; [CONSUMER] Consuming 2\u0026hellip;. [PRODUCER] Consumer return: 200 OK\n[PRODUCER] Producing 3\u0026hellip; [CONSUMER] Consuming 3\u0026hellip;. [PRODUCER] Consumer return: 200 OK \u0026hellip; \u0026hellip;\n那么，是什么道理呢？\nsend next 方法的背后今生 # def my(): value = yield 1 value = yield value print(\u0026#39;finally: \u0026#39;, value) ge = my() print(ge.next()) print(ge.send(2)) print(ge.send(3)) \u0026gt; 1 \u0026gt; 2 \u0026gt; (\u0026#39;finally: \u0026#39;, 3) \u0026gt; Traceback (most recent call last): \u0026gt; File \u0026#34;yield_emm3.py\u0026#34;, line 8, in \u0026lt;module\u0026gt; \u0026gt; print(ge.send(3)) \u0026gt; StopIteration 可知： 当next时，yield挂起，但将之后的1返回。而后send激活了之前挂起赋值动作，但此时yield 1被替换为send来的2所以value被置为2. 再第三次调用，完成赋值动作之后，由于只被挂起两次动作，而这里调取了三次，所以报错 停止递归 。若直接递归则得到1 和 None.\n所以 next与send都是用来激活挂起动作而使用的，但send好在可以与之交互。 在send``之前需先next否则提示can\u0026rsquo;t send * to a just-started generator`(⊙﹏⊙) 我上面阐述的挂起，激活，是不是出现了什么偏差…\n2018年5月18日16点30分\n较完善方案： # # 1 import gevent def f(n): for i in range(n): print gevent.getcurrent(), i g2 = gevent.spawn(f, 5) g3 = gevent.spawn(f, 5) g1.join() g3.join() # 2 import gevent from gevent import monkey; monkey.patch_all() import urllib2 def f(url): print \u0026#39;GET: %s\u0026#39; % url resp = urllib2.urlopen(url) data = resp.read() print \u0026#39;[%d] bytes received from %s\\n\u0026#39; %(len(data), url) gevent.joinall([ gevent.spawn(f, \u0026#39;http://www.cnblogs.com/kaituorensheng/\u0026#39;), gevent.spawn(f, \u0026#39;https://www.python.org/\u0026#39;), gevent.spawn(f, \u0026#39;https://www.baidu.com\u0026#39;), ]) # 3 from gevent import monkey monkey.patch_all() import gevent from gevent import Greenlet class Task(Greenlet): def __init__(self, name): Greenlet.__init__(self) self.name = name def _run(self): print \u0026#34;Task %s: some task...\u0026#34; % self.name t1 = Task(\u0026#34;task1\u0026#34;) t2 = Task(\u0026#34;task2\u0026#34;) t1.start() t2.start() # here we are waiting all tasks gevent.joinall([t1,t2]) 和线程 进程 差不多一个用法，只不过没锁，也不需要锁。\nfutures # futures.ThreadPoolExecutor # with futures.ThreadPoolExecutor(16) as executor: executor.map(run, urls) # 这里是个爬虫，urls就是一个前方run函数的输入变量 父类中的变量与类中变量 # 在使用self.a 的时候——呃其实是实例化之后a.a时，会只在父类中寻找相关变量，而解决办法居然是将super(A, self).__init__(CtaEngine, setting)移动到变量定义之后，所以谁说这玩意放前面和放后面没有区别的！（欸?😘 这个之后有过说明，不过忘记写在哪儿了，再说一下，就是super\u0026hellip;.表示父类的初始化动作，__init__因为这个函数名子父相同不会重写，会合并。）\n列表的增删添 # append # 在最后添加一元素 extend # c.extend(a) 将列表a中元素加到c中去。可自加 + # 连接两方数组元素 c = a + c 然而创建新对象，耗内存… 所以没啥 用\ndel # 删除对应下标元素 del c[0] 删除c列表第一位元素 pop # c.pop() 删除最后一位元素 remove # 删除指定值元素，有相同值时只会删除第一位 [ : ] # 使用切片进行删除 insert # c.insert(0, 1)将1插入到c的最前方，可插列表，插入还是列表 一个函数的有效方式只在循环中执行一次 - 代码日志 # 这是原链接 emm 代码反正照着输入是不会有结果的，但感觉挺有戏先保留，以后技术提升再来看\n自己的方法 # 自己的方法很简单，很暴力，就是用字典啊—— 当执行过一次之后直接把调用关系扭到别的地方，反正只要是知道结果的判断都可以用字典来代替么。\n函数调用函数 and 语法糖 @ # import time def timehel(hell): def wrapper(): start = time.clock() hell() end =time.clock() print 'used:', end - start return wrapper @timehel def foo(): print \u0026lsquo;a ho ga\u0026rsquo;\na ho ga\nused: 0.000489465229975\n其上@timehel 和 foo = timehel(foo)等价（感谢被遗忘的博客）… 就是把下方函数当成输入，然后执行通俗来翻译就是：\n@：呼叫timehel 来执行下面这孙子。 这里是官方教你怎么用： https://wiki.python.org/moin/PythonDecoratorLibrary\n其中 函数中定义函数就类似于“父子关系”，也或者叫另辟空间。每次执行父函数时，子函数会有也尽在此时会有被执行的机会，会不会被执行，就看其在其父亲面前的表现了（他爸有没有叫他（有没有调用…））。\n变量作用域 # 因为从这个@ 这儿学到的，所以：\ndef hel(x): def inner(): print x return inner p1 = hel(1) p1 = hel(1) p1() 1\np2() 2\n闭包——如果没有inner这东西，下面绝不会输出东西，反而会报错。 直接p1,p2又不会再输出任何东西，只有在定义时会运行一次。 对比于def hel(x): print x 其中内层原因 先不深究，就脑补成外层需运行时才能去找那些变量，而其中的函数会主动去外围找所需的变量。\n应用案例 # import time def coseTime(func): print func def inner(*args, **kwargs): print args, kwargs start = time.clock() func(*args, **kwargs) end = time.clock() print args, kwargs print ('Running time: %s Seconds' % (end-start)) return inner @coseTime def hel(x): print ('hello~') hel(12) \u0026lt;function hel at 0x02BC5070\u0026gt; (12,) {} hello~ (12,) {} Running time: 0.000446197317167 Seconds\n用来无视变量来记录 函数运行所需时间的——同时输出其在运行时接入的变量\nfunctools # 就姑且放这儿吧，毕竟也算是为了有序执行而接触到的\npartial # import functools def add(a, b): print a, b return a, b addplus = functools.partial(add, 3) addplus(7) 3 7\naddplus(add, b = 6) addplus(7) 7 6\n这函数作用是 提前给定函数一个变量值…The functools module is for higher-order functions: functions that act on or return other functions. In general, any callable object can be treated as a function for the purposes of this module.\n我的接触场景是在PyQt 中信号槽循环连接时，用了partial在connect之后.connect(partial(self.start, i))去唯一化相同功能的复用。不过我之前也应该写过类似的，那时我找的解决办法时在连接调用时传参(在Python GUI里面应该会写有吧，假如两三个月前我没脑子短期性失忆的话😭)。emm那个传参是利用Qt机制 不知道孰优孰劣😄\n运气好，直接翻到： ——那里的应用场景是在鼠标点击按钮捕获点击事件click时传递的参数~ lambda # 使用方法为：\nfunc = lambda x:x*x # :前x表示函数输入，:后为返回值，x*x是这个函数收到输入后所执行的动作 w = lambda x:func(x) 网络编程 # socket # import socket # 服务端 s = socket.socket() host = socket.gethostname() port = 12345 s.bind((host, port)) s.listen(5) while True: c, addr = s.accept() print \u0026quot;link address is\u0026quot;, addr c.send('welcome here') c.close() # 客户端 s = socket.socket() host = socket.gethostname() port = 12345 s.connect((host, port)) # 此时服务端便弹出 link address is：('192.168.*.*', 64*5) print s.recv(1024) # 客户端显示welcome here select : 与Socket配合的跨平台的异步io模型 # import select import socket import Queue #create a socket server = socket.socket(socket.AF_INET,socket.SOCK_STREAM) server.setblocking(False) #set option reused server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR , 1) server_address= (\u0026#39;192.168.1.102\u0026#39;,10001) server.bind(server_address) server.listen(10) #sockets from which we except to read inputs = [server] #sockets from which we expect to write outputs = [] #Outgoing message queues (socket:Queue) message_queues = {} #A optional parameter for select is TIMEOUT timeout = 20 while inputs: print \u0026#34;waiting for next event\u0026#34; readable , writable , exceptional = select.select(inputs, outputs, inputs, timeout) # When timeout reached , select return three empty lists if not (readable or writable or exceptional) : print \u0026#34;Time out ! \u0026#34; break; for s in readable : if s is server: # A \u0026#34;readable\u0026#34; socket is ready to accept a connection connection, client_address = s.accept() print \u0026#34; connection from \u0026#34;, client_address connection.setblocking(0) inputs.append(connection) message_queues[connection] = Queue.Queue() else: data = s.recv(1024) if data : print \u0026#34; received \u0026#34; , data , \u0026#34;from \u0026#34;,s.getpeername() message_queues[s].put(data) # Add output channel for response if s not in outputs: outputs.append(s) else: #Interpret empty result as closed connection print \u0026#34; closing\u0026#34;, client_address if s in outputs : outputs.remove(s) inputs.remove(s) s.close() #remove message queue del message_queues[s] for s in writable: try: next_msg = message_queues[s].get_nowait() except Queue.Empty: print \u0026#34; \u0026#34; , s.getpeername() , \u0026#39;queue empty\u0026#39; outputs.remove(s) else: print \u0026#34; sending \u0026#34; , next_msg , \u0026#34; to \u0026#34;, s.getpeername() s.send(next_msg) for s in exceptional: print \u0026#34; exception condition on \u0026#34;, s.getpeername() #stop listening for input on the connection inputs.remove(s) if s in outputs: outputs.remove(s) s.close() #Remove message queue del message_queues[s] 糖拌咸鱼 - 记录学习的点点滴滴~\n简单来说一下select的作用： 返回值：三个列表 select方法用来监视文件描述符(当文件描述符条件不满足时，select会阻塞)，当某个文件描述符状态改变后，会返回三个列表 1、当参数1 序列中的fd满足“可读”条件时，则获取发生变化的fd并添加到fd_r_list中 2、当参数2 序列中含有fd时，则将该序列中所有的fd添加到 fd_w_list中 3、当参数3 序列中的fd发生错误时，则将该发生错误的fd添加到 fd_e_list中 4、当超时时间为空，则select会一直阻塞，直到监听的句柄发生变化 当超时时间 ＝ n(正整数)时，那么如果监听的句柄均无任何变化，则select会阻塞n秒，之后返回三个空列表，如果监听的句柄有变化，则直接执行。 epoll很好的改进了select 具体请看(深入理解python中的select模块)[http://blog.csdn.net/songfreeman/article/details/51179213]\n引用模块 # action.py中引用model.py为例\n同一文件夹下 # from model import * # or import model 其下级文件\u0026quot;here\u0026quot;下 # # 在model.py 文件中创建__init__.py空文件 from here import model # or form here.model import * 在上级文件下 # import sys sys.path.append(\u0026quot;..\u0026quot;) # 添加上级文件 路径 # import model 在上级文件的下级文件中（也就是在隔壁“wang”文件中） # # 需要创建__init__.py空文件 # 添加上级文件路径 import wang.model 解决编码问题 # import sys reload(sys) sys.setdefaultencoding('utf8') # 这段直接塞它嘴里 输出提示打印乱码 # #coding: utf-8 n=raw_input(unicode('请输入文字','utf-8').encode('gbk')) print n 内存异常占用 # import sys v = 1 sys.getsizeof(v) # 可以读出 此变量emm 或者说 对象的内存占用大小 异常 # plan1 ： # try: #正常的操作 except: #发生异常，执行这块代码 else: #如果没有异常执行这块代码(在执行完try下函数没有异常发生) 列表的坑 # 当a 为一个列表 a = [1, 2, 3] b = a c = a d = a b.append(4)\n这时，abcd四个列表都变成[1, 2, 3, 4]，emm… 所以直接以后不要把一个列表赋值给两个变量…除非不涉及修改，慎重慎重。。不过python中列表有copy一说，不过还没试过\n@staticmethod # 定义类中的的这个方法为静态方法，同理的还有`@classmethod`类方法。 常见异常 # 1.AssertionError：当assert断言条件为假的时候抛出的异常 2.AttributeError：当访问的对象属性不存在的时候抛出的异常 3.IndexError：超出对象索引的范围时抛出的异常 4.KeyError：在字典中查找一个不存在的key抛出的异常 5.NameError：访问一个不存在的变量时抛出的异常 6.OSError：操作系统产生的异常 7.SyntaxError：语法错误时会抛出此异常 8.TypeError：类型错误，通常是不通类型之间的操作会出现此异常 9.ZeroDivisionError：进行数学运算时除数为0时会出现此异常·· 事件模式中，事件篡改事故 # 在循环创建事件时，将event put到队列中，此时，被处理一半，因为不在一个线程所以下一个循环来临就将event的内容进行了修改。 杜绝此方法除了添加锁，只好将事件copy之后再传入时间引擎。如此便可暂防止事件处理一半被修改的事情发生。\n代码块注释 # Surrounding Blocks of Code with Language Constructs\nVisualStudio模式： # #region Description(说明) print \u0026quot;code here\u0026quot; #endregion NetBeans模式： # // \u0026lt;editor-fold desc=\u0026quot;Description\u0026quot;\u0026gt; code here // \u0026lt;/editor-fold\u0026gt; 类 # 以后详谈，本着一切皆对象的原则，所以对于类的了解决定了Python的认知，先记一个 def __init__(self): super(Proformance, self).__init__() #这个super表示了继承类和被继承类的 __init__调用时序，其它重名函数是覆盖，这个…… 数据类 # 用一个类来表示一个数据类型（这几天想着这个表示不同数据类型的组合方法恰类似于C中的结构体，然后Python中的数组元素存储各种东西什么类啊、数组套数组啊，字典存储啊，恰巧与C中的指针指向指针……emm ）如：\nclass A(object): def __init__(self): self.a = 'a' self.b = 'b' A().__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;}\n但是A().__dict__['a'] = 'It is a' 虽然不会报错，但之后再次调用A().__dict__显示结果还是一样，但：\na = A() a.__dict__['a'] = 'It is a' a.__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;It is a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;}\n这样我就用过一次，在不确定数据类会有几个元素甚至不知道会是什么名称的时候来创建的，毕竟：(这样的方式可以随便添加嘛)\na.__dict__['w'] = 'It is www' a.__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;It is a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;, \u0026lsquo;w\u0026rsquo;: \u0026lsquo;It is www\u0026rsquo;\n若出现docx模块pyInstaller打包问题 # 大概的解决步骤是这样的： 找到python-docx包安装路径下的一个名为default.docx的文件，我是通过everything这个强大的搜索工具全局搜索找到这个文件的，它在我本地所在的路径是：E:\\code\\env.env\\Lib\\site-packages\\docx\\templates 把找到的default.docx文件复制到我的py脚本文件所在的目录下。 修改脚本中创建Document对象的方式： 从原来的创建方式： document = Document() 修改为： import os document = Document(docx=os.path.join(os.getcwd(), \u0026lsquo;default.docx\u0026rsquo;)) 再次用pyinstaller工具打包脚本为exe文件 把default.docx文件复制到与生成的exe文件相同的路径下，再次运行exe文件，顺利运行通过，没有再出现之前的报错，问题得到解决。 作者：(m2fox)[https://www.jianshu.com/p/94ac13f6633e] 來源：简书\n拼接List字符串 # 将list中的元素拼接起来，并使用,隔开可这么来：\nimport itertools list = ['123', '567'] xlist = \u0026quot;,\u0026quot;.join(list) or ylist = \u0026quot;,\u0026quot;.join(*list) s = .join(itertools.chain(kwargs.keys())) 区别在于x为一个元素添加一个,，y为把列表中的素也拆分之后再添加\nSimpleHTTPServer # 小型的局域网嘛☺，很常用，不过在Python3中有了变化…\n$ Python2 python -m SimpleHTTPServer --- $ Python3 python -m http.server 顺带一提：-m是可以在外执行内库的操作，🦑大概是这个意思吧—— 用pdb的时候也是这么用的…\n老夫的月份生成 # # -*- coding:utf-8 -*- import datetime import copy def splitMonth(start, end): start = str2Date(start) end = str2Date(end) _delta = end - start datelist = [] if _delta.days \u0026gt; 10: # 拆分 # 按*月*拆分（10日间隔） n = 0 _start = copy.copy(start) while _delta.days \u0026gt; 0: n += 1 if _start.day \u0026lt; 10: _end = datetime.date(_start.year, _start.month, 10) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) break elif _start.day \u0026lt; 20: _end = datetime.date(_start.year, _start.month, 20) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) break else: _end = datetime.date(_start.year, _start.month, _start.day) + datetime.timedelta(15) _end = datetime.date(_end.year, _end.month, 1) - datetime.timedelta(1) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append(date2str(_start), date2str(end)) break _delta = end - _start + datetime.timedelta(1) return datelist else: return [(date2str(start), date2str(end))] def splitMouthBySE_N(start, end, n): start = str2Date(start) end = str2Date(end) _delta = end - start datelist = [] if _delta.days \u0026gt; n: # 拆分 # 按*月*拆分（10日间隔） _start = copy.copy(start) while _delta.days \u0026gt; 0: _loop = 0 for _n in range(int(30/n)): _loop = _loop + n if _start.day \u0026lt; _loop: if _start.month == 2 and _loop \u0026gt; 28: if _start.year%4: _end = datetime.date(_start.year, _start.month, 28) else: _end = datetime.date(_start.year, _start.month, 29) else: _end = datetime.date(_start.year, _start.month, _loop) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) _delta = datetime.timedelta(0) break _end = datetime.date(_start.year, _start.month, _start.day) + datetime.timedelta(15) else: continue else: _end = datetime.date(_end.year, _end.month, 1) - datetime.timedelta(1) if end \u0026gt; _end: if _start \u0026gt; _end: _delta = end - _start + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) _delta = datetime.timedelta(0) break _delta = end - _start + datetime.timedelta(1) return datelist else: return [(date2str(start), date2str(end))] def gropdate(datelist, itemNum=0, gropNum=0): #将传入datelist[(str(start1), str(end1)), (str(start2), str(end2))...] -\u0026gt; 传入为月碎片 # 打按月对月碎片进行打组。 # 传入参数 itemNum: 一个组含几个月, gropNum: 将这些碎片打为几组 _dic = collections.OrderedDict() for i in datelist: # 按月分组 keyName = i[0].split(\u0026#39;-\u0026#39;)[1] if keyName not in _dic: _dic[keyName] = [] _dic[keyName].append(i) monthList = [] groups = [] groupListTemp = [] groupList = [] for i in _dic.keys(): # 得到月份列表 monthList.append(i) #[1,2,3...,7,8,9] monthNum = len(monthList) if gropNum: itemNum = round(float(monthNum)/gropNum) itemNum = int(itemNum) if itemNum: slipNum = int(monthNum/itemNum) start = 0 end = int(itemNum) for mon in range(slipNum): groups.append(monthList[int(start):int(end)]) start = copy.copy(end) end = end + itemNum if monthNum%itemNum: groups.append(monthList[start:monthNum]) # 非整除补足 for i in groups: for ii in i: groupListTemp.append(_dic[ii]) groupList.append(groupListTemp) groupListTemp = [] return groupList else: return None # region 日期`date`格式与`str`转换处理 def date2str(_date): # datetime.date 转换为 str (有为了适配原程序的补零操作…) if _date.month \u0026lt; 10: strDate = str(_date.year) + \u0026#39;-\u0026#39; + \u0026#39;0\u0026#39;+str(_date.month) + \u0026#39;-\u0026#39; + str(_date.day) else: strDate = str(_date.year) + \u0026#39;-\u0026#39; + str(_date.month) + \u0026#39;-\u0026#39; + str(_date.day) if _date.day \u0026lt; 10: strDate = strDate[:-1] + \u0026#39;0\u0026#39;+str(_date.day) return strDate def str2Date(_str): # str 转换为 datetime.date y, m, d = _str.split(\u0026#39;-\u0026#39;) return datetime.date(int(y), int(m), int(d)) # endregion if __name__ == \u0026#39;__main__\u0026#39;: print(splitMouthBySE_N(\u0026#39;2016-01-02\u0026#39;, \u0026#39;2018-03-01\u0026#39;, 5)) Python3.6之后的奇淫技巧 # 可使用下划线将长数字隔开，便于阅读 10000=10_000 字符串操作除了 %和format之外还有f操作 $ % s = \u0026#34;%s is %d\u0026#34; % (\u0026#39;two\u0026#39;, 2) $ format s = \u0026#34;{fruit} is {color}\u0026#34;.format(fruit=\u0026#39;apple\u0026#39;, color=\u0026#39;red\u0026#39;) $ f name = \u0026#39;Bob\u0026#39; f\u0026#39;Hello, {name}!\u0026#39; ### 甚至 a = 5 b = 10 f\u0026#39;Five plus ten is {a + b} and not {2 * (a + b)}.\u0026#39; #### 精度 PI = 3.141592653 f\u0026#34;Pi is {PI:.2f}\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Pi is 3.14\u0026#39; \u0026gt;\u0026gt;\u0026gt; error = 50159747054 ##### 以16进制格式化 f\u0026#39;Programmer Error: {error:#x}\u0026#39; \u0026gt;\u0026gt;\u0026gt;\u0026#39;Programmer Error: 0xbadc0ffee\u0026#39; ##### 以二进制格式化 f\u0026#39;Programmer Error: {error:#b}\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Programmer Error: 0b101110101101110000001111111111101110\u0026#39; 3.变量注释 def my_add(a: int, b: int) -\u0026gt; int: \\n return 0 仅仅用来注释，其实传参出参并不受控制…\n魔法方法 # 假设定义类 EmmNe, EmmNe拥有self.aaa与self.aaadict、列表self.aaalist 且__init__允许两个传参\n__len__:\ndef __len__(self): return len(self.aaa) # 则在外`len`此实例化对象时，会返回这个结果 __getitem__:\ndef __getitem__(self, key) return self.aaadict[key] en = EmmNe(1, 2) print(en[`]) \u0026gt; 2 #就像上面那样。 不过还有下面的用法 def __getitem__(self, index): retrun self.aaalist[index] w = Emm(1,2) for i in w: print (i) # 则输出列表中内容 __setitem__:\ndef __setitem__(self, key, value) return self.aaadict[key] = value # 拥有此方法，则在外可将实例对象当作字典操作: enp[\u0026#39;a\u0026#39;] = \u0026#39;asd\u0026#39; # 就像这样 collectionss # 总结一句话： collections出品， 必属精品。 马上能想到的 有序字典，还有那啥都是出自此个模块之下。 今天用的 计数也是出自此处 反正之后 这个里面能实现的功能，那就放弃手写吧————😓 from collections import Counter\nFunction Annotations # Annotations are stored in the annotations attribute of the function as a dictionary and have no effect on any other part of the function. Parameter annotations are defined by a colon after the parameter name, followed by an expression evaluating to the value of the annotation. Return annotations are defined by a literal -\u0026gt;, followed by an expression, between the parameter list and the colon denoting the end of the def statement. The following example has a positional argument, a keyword argument, and the return value annotated:\n\u0026gt;\u0026gt;\u0026gt; def f(ham: str, eggs: str = \u0026#39;eggs\u0026#39;) -\u0026gt; str: print(\u0026#34;Annotations:\u0026#34;, f.__annotations__) print(\u0026#34;Arguments:\u0026#34;, ham, eggs) return ham + \u0026#39; and \u0026#39; + eggs f(\u0026#39;spam\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Annotations: {\u0026#39;ham\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;, \u0026#39;return\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;, \u0026#39;eggs\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;} \u0026gt;\u0026gt;\u0026gt; Arguments: spam eggs \u0026gt;\u0026gt;\u0026gt; \u0026#39;spam and eggs\u0026#39; Logger # 模块名： logging 上手容易，功能丰富，性能肯定也好过自己✍ 另外，懒———\nimport sys import logging import logging_error logger1 = logging.getLogger(\u0026#39;loger1\u0026#39;) logger2 = logging.getLogger(\u0026#39;loger2\u0026#39;) #实例化两个logger,默认名称为：`root` \u0026#34;\u0026#34;\u0026#34; 我居然以为root是程序执行处的名字，以为放到函数中就会显示函数名。emm 所以才有了下面多层函数嵌套…，以及调用外部`import` \u0026#34;\u0026#34;\u0026#34; formatter = logging.Formatter(\u0026#39;[%(name)s]%(asctime)s %(levelname)-8s: %(message)s\u0026#39;) #定义日志格式： \u0026#34;\u0026#34;\u0026#34; %(name)s Logger的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名| %(funcName)s 调用日志输出函数的函数名| %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用UNIX标准的表示时间的浮点数表示| %(relativeCreated)d 输出日志信息时的，自Logger创建以来的毫秒数| %(asctime)s 字符串形式的当前时间。默认格式是“2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程ID。可能没有 %(message)s 用户输出的消息 \u0026#34;\u0026#34;\u0026#34; fileHandler = logging.FileHandler(\u0026#39;loger.log\u0026#39;) fileHandler.setFormatter(formatter) consoleHandler = logging.StreamHandler(sys.stdout) consoleHandler.formatter = formatter #配置文件、终端日志处理器。可以使用不同格式，来区分处理 logger1.addHandler(fileHandler) logger2.addHandler(fileHandler) logger1.addHandler(consoleHandler) logger2.addHandler(consoleHandler) #为日志机添加处理器 logger1.setLevel(logging.INFO) #logger2.setLevel() #设置各日志机打印等级 logger1.debug(\u0026#39;debugO\u0026#39;) logger1.info(\u0026#39;info\u0026#39;) logger2.info(\u0026#39;info\u0026#39;) logger1.error(\u0026#39;error\u0026#39;) def warn_msg(): logger1.warn(\u0026#39;warn msg\u0026#39;) warn_msg2() def warn_msg2(): logger2.warn(u\u0026#39;warn 信息\u0026#39;) logging_error.error_demo() warn_msg() 当然，logger还有别的调用方法，不过这应该就够了， 具体要怎么实现，就去找官方文档了。 预防针： 多种配置方法、日志重复输出:见此\nlambda函数 # 排序 # aaa \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 1}, {\u0026#39;time\u0026#39;: 3}, {\u0026#39;time\u0026#39;: 2}] sorted(aaa, key = lambda x: x[\u0026#34;time\u0026#34;]) \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 1}, {\u0026#39;time\u0026#39;: 2}, {\u0026#39;time\u0026#39;: 3}] sorted(aaa, key = lambda x: x[\u0026#34;time\u0026#34;], reverse=True) \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 3}, {\u0026#39;time\u0026#39;: 2}, {\u0026#39;time\u0026#39;: 1}] Mock # 使用: unittest\nmock.patch.object: Mock # 一个类, 后接方法 mock.patch: Mock # 一个方法, 按路径 @mock.patch(\u0026#34;databases.wx_service.get_user_base_info\u0026#34;) @mock.patch.object(wx_service.WeChat_OAP, \u0026#34;send_template_msg\u0026#34;) def test_create_weawarning(self, mock_send_template_msg, mock_get_user_base_info): # 装饰器生效从内到外, 传入参数顺序, 从左到右 pass mock_send_template_msg.return_value = \u0026#39;\u0026#39;/{}/[]/() 皆可 设定mock返回值 mock_get_user_base_info.side_effect = [\u0026#39;\u0026#39;/{}/[]/(), \u0026#39;\u0026#39;/{}/[]/()] 设定每次调用mock函数依次返回返回值 计算 # 取整 # In [1]: import math In [2]: math.ceil(10/ 3) # 向上取整 Out[2]: 4 "},{"id":126,"href":"/docs/programmer/langs/python/py%E5%B0%8F%E5%B7%A5%E5%85%B7%E5%92%8C%E5%8A%9F%E8%83%BD%E6%80%A7%E6%96%B9%E6%B3%95/","title":"Py小工具和功能性方法","section":"Python","content":"author:Ian\n邮件 # 中文附件 # 发送邮件时携带附件 中文名称附件\ndef send_email_week_report(htm, recipients, copys, file_name, file_path): port = 465 # str_today = datetime.now().strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) str_today = datetime.now().strftime(\u0026#34;%Y-%m-%d\u0026#34;) mail_host = \u0026#34;mail.{demo}.com\u0026#34; mail_user = \u0026#34;{user name}\u0026#34; mail_pass = \u0026#34;{passwd}\u0026#34; sender = \u0026#39;{name}@{demo}.com\u0026#39; mail_from = \u0026#34;{name} \u0026lt;{name}@{demo}.com\u0026gt;\u0026#34; msg_Bcc = \u0026#39;{name}@{demo}.com\u0026#39; subject = f\u0026#34;{title}-{str_today}\u0026#34; # 标题 msg = MIMEMultipart() msg.attach(MIMEText(htm, \u0026#39;html\u0026#39;, \u0026#39;utf-8\u0026#39;)) # 这里可以传html内容 也可以传普通文字 # 创建附件 with open(file_path, \u0026#39;rb\u0026#39;) as attachment: part = MIMEBase(\u0026#39;application\u0026#39;, \u0026#39;octet-stream\u0026#39;) part.set_payload(attachment.read()) encoders.encode_base64(part) part.add_header( \u0026#39;Content-Disposition\u0026#39;, \u0026#39;attachment\u0026#39;, filename=(\u0026#34;utf-8\u0026#34;, \u0026#34;\u0026#34;, file_name), ) msg.attach(part) for root, _, files in os.walk(os.path.join(BASE_DIR, \u0026#39;{path}/images\u0026#39;)): for f in files: if f in htm: with open(os.path.join(root, f), \u0026#39;rb\u0026#39;) as fp: image = MIMEImage(fp.read()) image.add_header(\u0026#39;Content-ID\u0026#39;, f\u0026#39;\u0026lt;{f}\u0026gt;\u0026#39;) msg.attach(image) msg[\u0026#39;From\u0026#39;] = mail_from # 发件人 msg[\u0026#39;To\u0026#39;] = \u0026#34;;\u0026#34;.join(recipients) # 收件人多个逗号分隔 msg[\u0026#34;Cc\u0026#34;] = \u0026#34;;\u0026#34;.join(copys) msg[\u0026#34;Bcc\u0026#34;] = msg_Bcc subject = subject msg[\u0026#39;Subject\u0026#39;] = Header(subject) try: smtpObj = smtplib.SMTP_SSL(mail_host) if is_partner_node == 1: smtpObj = smtplib.SMTP(mail_host) smtpObj.connect(mail_host, port) smtpObj.login(mail_user, mail_pass) smtpObj.sendmail(sender, recipients + copys + [sender], msg.as_string()) return True except smtplib.SMTPException as e: return False 有限制的附件 # 这种内容插入附件会有文件名称长度限制(19好像或者16)\n# 创建附件 with open(file_path, \u0026#39;rb\u0026#39;) as attachment: part = MIMEBase(\u0026#39;application\u0026#39;, \u0026#39;octet-stream\u0026#39;) part.set_payload(attachment.read()) encoders.encode_base64(part) if len(file_name) \u0026gt; 18: file_name = file_name[:9] + file_name[-9:] part.add_header( \u0026#39;Content-Disposition\u0026#39;, f\u0026#39;attachment; filename={Header(file_name, \u0026#34;utf-8\u0026#34;).encode()}\u0026#39;, ) msg.attach(part) 最小程序照抄版 # 附件形式 # import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage # 配置 smtp_server = \u0026#39;smtp.feishu.cn\u0026#39; smtp_port = 465 username = \u0026#39;google@feishu.com\u0026#39; password = \u0026#39;g0asaddau2131823bP\u0026#39; from_addr = \u0026#39;google@feishu.com\u0026#39; to_addr = \u0026#39;google@feishu.com\u0026#39; # 创建邮件 msg = MIMEMultipart() msg[\u0026#39;Subject\u0026#39;] = \u0026#39;这里是邮件主题\u0026#39; msg[\u0026#39;From\u0026#39;] = from_addr msg[\u0026#39;To\u0026#39;] = to_addr # 添加文本内容 msg.attach(MIMEText(\u0026#39;这是邮件正文\u0026#39;, \u0026#39;plain\u0026#39;)) # 添加图片 with open(\u0026#39;path/to/image.jpg\u0026#39;, \u0026#39;rb\u0026#39;) as img_file: img = MIMEImage(img_file.read()) msg.attach(img) # 发送邮件 with smtplib.SMTP_SSL(smtp_server, smtp_port) as server: server.login(username, password) server.send_message(msg) print(\u0026#34;邮件发送成功\u0026#34;) 图片直接展示在邮件内容 - html # 邮件正文: 采用HTML格式，在正文中使用\u0026lt;img\u0026gt;标签嵌入图片。 Content-ID: 使用img.add_header('Content-ID', '\u0026lt;image1\u0026gt;')来为图片添加一个内容ID，以便在HTML import smtplib from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from email.mime.image import MIMEImage # 配置 smtp_server = \u0026#39;smtp.feishu.cn\u0026#39; smtp_port = 465 username = \u0026#39;google@feishu.com\u0026#39; password = \u0026#39;g0asaddau2131823bP\u0026#39; from_addr = \u0026#39;google@feishu.com\u0026#39; to_addr = \u0026#39;google@feishu.com\u0026#39; # 创建邮件 msg = MIMEMultipart() msg[\u0026#39;Subject\u0026#39;] = \u0026#39;这里是邮件主题\u0026#39; msg[\u0026#39;From\u0026#39;] = from_addr msg[\u0026#39;To\u0026#39;] = to_addr # 添加文本内容 text = \u0026#39;这是邮件正文，图片如下：\u0026lt;br\u0026gt;\u0026lt;img src=\u0026#34;cid:image1\u0026#34;\u0026gt;\u0026#39; msg.attach(MIMEText(text, \u0026#39;html\u0026#39;)) # 添加图片 with open(\u0026#39;path/to/image.jpg\u0026#39;, \u0026#39;rb\u0026#39;) as img_file: img = MIMEImage(img_file.read()) img.add_header(\u0026#39;Content-ID\u0026#39;, \u0026#39;\u0026lt;image1\u0026gt;\u0026#39;) msg.attach(img) # 发送邮件 with smtplib.SMTP_SSL(smtp_server, smtp_port) as server: server.login(username, password) server.send_message(msg) print(\u0026#34;邮件发送成功\u0026#34;) docx 插入附件 插入文件 # 取巧的办法 通过替换文件实现插入\n\u0026#34;\u0026#34;\u0026#34; __name__: main.py 替换掉word模板中的excel文件内容 所需文件: - demo.docx(其中已经插入了一个xlsx文件) - demo_aim.xlsx \u0026#34;\u0026#34;\u0026#34; import os import shutil import zipfile class DocxEmbeddingFile: def __init__(self, src_docx_fn, temp_path, extract_folder=\u0026#39;extrated\u0026#39;): self.src_docx_fn = src_docx_fn self.temp_path = temp_path self.extract_folder = extract_folder def unzip_docx(self): shutil.rmtree(self.extract_folder, ignore_errors=True) os.mkdir(self.extract_folder) os.chdir(self.extract_folder) with zipfile.ZipFile(self.src_docx_fn) as azip: azip.extractall() def change_ip_details_xlsx(self, path): \u0026#34;\u0026#34;\u0026#34;# 第一个插入的文件命名规则为按插入顺序递增: - Microsoft_Excel_Worksheet.xlsx - Microsoft_Excel_Worksheet1.xlsx - Microsoft_Word_Document.docx 如果要测试其他类型文件,可将docx解压后去以下路径去查看 \u0026#34;\u0026#34;\u0026#34; shutil.copy(path, os.path.join(self.temp_path, self.extract_folder, \u0026#34;word\u0026#34;, \u0026#34;embeddings\u0026#34;, \u0026#34;Microsoft_Excel_Worksheet.xlsx\u0026#34;)) return True def zip_docx(self): os.chdir(os.path.join(self.temp_path, self.extract_folder)) with zipfile.ZipFile(self.src_docx_fn, \u0026#39;w\u0026#39;) as azip: for i in os.walk(\u0026#39;.\u0026#39;): for j in i[2]: azip.write(os.path.join(i[0], j), compress_type=zipfile.ZIP_DEFLATED) if __name__ == \u0026#39;__main__\u0026#39;: temp_path = os.path.dirname(os.path.abspath(__file__)) report_path = temp_path src_docx_fn = os.path.join(report_path, \u0026#34;demo.docx\u0026#34;) docxef = DocxEmbeddingFile(src_docx_fn=src_docx_fn, temp_path=temp_path) docxef.unzip_docx() docxef.change_ip_details_xlsx(os.path.join(temp_path, \u0026#34;demo_aim.xlsx\u0026#34;)) docxef.zip_docx() word 插入文件附件 # class DocxEmbeddingFile: def __init__(self, src_docx_fn, temp_path, extract_folder=\u0026#39;extrated\u0026#39;): self.src_docx_fn = src_docx_fn self.temp_path = temp_path self.extract_folder = extract_folder def unzip_docx(self): original_dir = os.getcwd() shutil.rmtree(os.path.join(self.temp_path, self.extract_folder), ignore_errors=True) os.mkdir(os.path.join(self.temp_path, self.extract_folder)) dir_path, file_name = os.path.split(self.src_docx_fn) docx_file_path = self.src_docx_fn if file_name.endswith(\u0026#34;.zip\u0026#34;): os.chdir(self.temp_path) with zipfile.ZipFile(self.src_docx_fn) as azip: azip.extractall() file_name = file_name.replace(\u0026#34;zip\u0026#34;, \u0026#34;docx\u0026#34;) docx_file_path = os.path.join(dir_path, file_name) elif file_name.endswith(\u0026#34;docx\u0026#34;): pass else: os.chdir(original_dir) return False os.chdir(os.path.join(self.temp_path, self.extract_folder)) with zipfile.ZipFile(docx_file_path) as azip: azip.extractall() os.chdir(original_dir) return True def change_ip_details_xlsx(self, path): # 通过替换文件实现文件插入 target_path = os.path.join(self.temp_path, self.extract_folder, \u0026#34;word\u0026#34;, \u0026#34;embeddings\u0026#34;, \u0026#34;Microsoft_Excel_Worksheet.xlsx\u0026#34;) if not path or not os.path.exists(target_path): return False shutil.copy(path, target_path) return True def zip_docx(self): original_dir = os.getcwd() os.chdir(os.path.join(self.temp_path, self.extract_folder)) docx_file_path = self.src_docx_fn dir_path, file_name = os.path.split(self.src_docx_fn) if file_name.endswith(\u0026#34;.zip\u0026#34;): file_name = file_name.replace(\u0026#34;zip\u0026#34;, \u0026#34;docx\u0026#34;) docx_file_path = os.path.join(dir_path, file_name) with zipfile.ZipFile(docx_file_path, \u0026#39;w\u0026#39;) as azip: for i in os.walk(\u0026#39;.\u0026#39;): for j in i[2]: azip.write(os.path.join(i[0], j), compress_type=zipfile.ZIP_DEFLATED) os.chdir(original_dir) return docx_file_path 生成Excel文件 # class SheetGenerater: t_risky_info = \u0026#34;1_2\u0026#34; t_failed_info = u\u0026#34;key1信息\u0026#34; t_simple = \u0026#34;simple\u0026#34; def __init__(self, key, title, _type, sheeter): self.key = key self.title = title self.type = _type self.sheeter = sheeter self.dict_title = { u\u0026#34;key1信息\u0026#34;: [u\u0026#34;本周期内第三列明细如下：\u0026#34;, u\u0026#34;本周期内第三列告警详情如下：\u0026#34;], u\u0026#34;key2信息\u0026#34;: [u\u0026#34;本周期内风险主机明细如下：\u0026#34;, u\u0026#34;详情\u0026#34;] } def __get_list_dict_value(self, n, key, data): if len(data) \u0026lt;= n: return \u0026#39;\u0026#39; value = data[n][key] if isinstance(value, str) or isinstance(value, unicode): pass elif value and (isinstance(value, list) or isinstance(value, tuple)) and (isinstance(value[0], str) or isinstance(value[0], unicode)): value = u\u0026#39;,\u0026#39;.join(value) else: value = str(value) return value def full_sheet_data_failed(self, sheet_data): \u0026#34;\u0026#34;\u0026#34; key1信息 sheet信息填充 实现方式与数据长度强相关，如果需要向表格中添加数据，需要手动调整各个数值 \u0026#34;\u0026#34;\u0026#34; # set column names for sheet1 and fill in data col_names = [u\u0026#34;序号\u0026#34;, u\u0026#34;第三列\u0026#34;, u\u0026#34;第四列\u0026#34;, u\u0026#34;备注\u0026#34;] col_names_2 = [u\u0026#34;序号\u0026#34;, u\u0026#34;告警时间\u0026#34;, u\u0026#34;事件名称\u0026#34;, u\u0026#34;源IP\u0026#34;, \u0026#34;目的IP\u0026#34;] if self.dict_title.get(self.title): self.sheeter.merge_cells(\u0026#39;A1:D1\u0026#39;) self.sheeter.cell(1, 1).value = self.dict_title[self.title][0] self.sheeter.cell(1, 1).fill = PatternFill(start_color=\u0026#39;00b050\u0026#39;, end_color=\u0026#39;00b050\u0026#39;, fill_type=\u0026#39;solid\u0026#39;) self.sheeter.merge_cells(\u0026#39;F1:J1\u0026#39;) self.sheeter.cell(1, 2+len(col_names)).value = self.dict_title[self.title][-1] self.sheeter.cell(1, 2+len(col_names)).fill = PatternFill(start_color=\u0026#39;00b050\u0026#39;, end_color=\u0026#39;00b050\u0026#39;, fill_type=\u0026#39;solid\u0026#39;) self.sheeter.append(col_names + [\u0026#34;\u0026#34;] + col_names_2) # self.sheeter.append([u\u0026#34;序号\u0026#34;, u\u0026#34;状态\u0026#34;, u\u0026#34;第三列\u0026#34;, u\u0026#34;第四列\u0026#34;, u\u0026#34;备注\u0026#34;]) longer = sheet_data[\u0026#34;key1\u0026#34;] if len(sheet_data[\u0026#34;key1\u0026#34;]) \u0026gt; len(sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]) else sheet_data[\u0026#34;failed_host_warning_info\u0026#34;] for n, _ in enumerate(longer): # item[\u0026#34;loop_state\u0026#34;] # 状态列,暂时不做自动填充,此列直接删除 self.sheeter.append([ str(n+1) if self.__get_list_dict_value(n, \u0026#34;host\u0026#34;, sheet_data[\u0026#34;key1\u0026#34;]) else \u0026#39;\u0026#39;, self.__get_list_dict_value(n, \u0026#34;host\u0026#34;, sheet_data[\u0026#34;key1\u0026#34;]), self.__get_list_dict_value(n, \u0026#34;event\u0026#34;, sheet_data[\u0026#34;key1\u0026#34;]), self.__get_list_dict_value(n, \u0026#34;remark\u0026#34;, sheet_data[\u0026#34;key1\u0026#34;]), \u0026#34;\u0026#34;, str(n+1) if self.__get_list_dict_value(n, \u0026#34;datetime\u0026#34;, sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]) else \u0026#39;\u0026#39;, self.__get_list_dict_value(n, \u0026#34;datetime\u0026#34;, sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]), self.__get_list_dict_value(n, \u0026#34;event\u0026#34;, sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]), self.__get_list_dict_value(n, \u0026#34;source_ip\u0026#34;, sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]), self.__get_list_dict_value(n, \u0026#34;destined_ip\u0026#34;, sheet_data[\u0026#34;failed_host_warning_info\u0026#34;]), ]) for n, cell in enumerate(self.sheeter[2]): if n == len(col_names): continue cell.fill = openpyxl.styles.PatternFill(start_color=\u0026#34;92D050\u0026#34;, end_color=\u0026#34;92D050\u0026#34;, fill_type=\u0026#34;solid\u0026#34;) self.autosize_table() return True def full_sheet_data_risky(self, sheet_data): \u0026#34;\u0026#34;\u0026#34; key2信息 sheet信息填充 \u0026#34;\u0026#34;\u0026#34; # set column names for sheet1 and fill in data col_names = [u\u0026#34;序号\u0026#34;, u\u0026#34;风险主机\u0026#34;, u\u0026#34;第四列\u0026#34;, u\u0026#34;备注\u0026#34;] if self.dict_title.get(self.title): self.sheeter.merge_cells(start_row=1, start_column=1, end_row=1, end_column=len(col_names)) self.sheeter.cell(row=1, column=1, value=self.dict_title[self.title][0]) fill = PatternFill(fill_type=\u0026#39;solid\u0026#39;, fgColor=\u0026#34;00b050\u0026#34;) self.sheeter.cell(row=1, column=1).fill = fill self.sheeter.cell(row=1, column=1).alignment = Alignment(horizontal=\u0026#39;center\u0026#39;, vertical=\u0026#39;center\u0026#39;, wrap_text=True) if self.dict_title.get(self.title): self.sheeter.merge_cells(\u0026#39;A1:D1\u0026#39;) self.sheeter.cell(1, 1).value = self.dict_title[self.title][0] self.sheeter.cell(1, 1).fill = PatternFill(start_color=\u0026#39;00b050\u0026#39;, end_color=\u0026#39;00b050\u0026#39;, fill_type=\u0026#39;solid\u0026#39;) # self.sheeter.merge_cells(\u0026#39;F1:J1\u0026#39;) self.sheeter.cell(1, 2+len(col_names)).value = self.dict_title[self.title][-1] self.sheeter.cell(1, 2+len(col_names)).fill = PatternFill(start_color=\u0026#39;00b050\u0026#39;, end_color=\u0026#39;00b050\u0026#39;, fill_type=\u0026#39;solid\u0026#39;) self.sheeter.append(col_names) # self.sheeter.append([u\u0026#34;序号\u0026#34;, u\u0026#34;状态\u0026#34;, u\u0026#34;第三列\u0026#34;, u\u0026#34;第四列\u0026#34;, u\u0026#34;备注\u0026#34;]) sheet_data = sheet_data[\u0026#34;key2\u0026#34;] for n, _ in enumerate(sheet_data): # item[\u0026#34;loop_state\u0026#34;] # 状态列,暂时不做自动填充,此列直接删除 # self.sheeter.append([str(n+1), item[\u0026#34;host\u0026#34;], item[\u0026#34;event\u0026#34;], item[\u0026#34;remark\u0026#34;]]) self.sheeter.append([str(n+1), self.__get_list_dict_value(n, \u0026#34;host\u0026#34;, sheet_data), self.__get_list_dict_value(n, \u0026#34;event\u0026#34;, sheet_data), self.__get_list_dict_value(n, \u0026#34;remark\u0026#34;, sheet_data) ]) # set background color for column headers for n, cell in enumerate(self.sheeter[2]): if n == len(col_names): break cell.fill = openpyxl.styles.PatternFill(start_color=\u0026#34;92D050\u0026#34;, end_color=\u0026#34;92D050\u0026#34;, fill_type=\u0026#34;solid\u0026#34;) self.autosize_table() return True def full_sheet_data_simple(self, sheet_data): # set column names and fill in data for sheet3 self.sheeter.append(sheet_data[\u0026#34;column_name\u0026#34;]) for row in sheet_data[\u0026#34;table\u0026#34;]: self.sheeter.append(row) # set background color for column headers for cell in self.sheeter[1]: cell.fill = openpyxl.styles.PatternFill(start_color=\u0026#34;92D050\u0026#34;, end_color=\u0026#34;92D050\u0026#34;, fill_type=\u0026#34;solid\u0026#34;) self.autosize_table() return True def autosize_table(self): # 生效了 self.sheeter.column_dimensions[\u0026#39;B\u0026#39;].width = 20 if self.title == u\u0026#34;key3信息\u0026#34;: self.sheeter.column_dimensions[\u0026#39;C\u0026#39;].width = 40 else: self.sheeter.column_dimensions[\u0026#39;C\u0026#39;].width = 60 return # for column in self.sheeter.columns: # column_letter = get_column_letter(column[0].column) # self.sheeter.column_dimensions[column_letter].auto_size = True # self.sheeter.column_dimensions[column_letter].max_width = 500 def full_sheet(self, data): if self.type == SheetGenerater.t_risky_info: # print(\u0026#39;excel_utils -------135 {}\u0026#39;.format(data)) return self.full_sheet_data_risky(data) if self.type == SheetGenerater.t_failed_info: # print(\u0026#39;excel_utils -------138 {}\u0026#39;.format(data)) return self.full_sheet_data_failed(data) elif self.type == SheetGenerater.t_simple: # print(\u0026#39;excel_utils -------141 {}\u0026#39;.format(data)) return self.full_sheet_data_simple(data) return False def generate_excel(data, output_path): # create new workbook and worksheets workbook = openpyxl.Workbook() sheet1 = workbook.active sheet_gennerater_list = [ SheetGenerater(key=\u0026#34;key1\u0026#34;, title=u\u0026#34;key1信息\u0026#34;, _type=SheetGenerater.t_failed_info, sheeter=None), SheetGenerater(key=\u0026#34;key2\u0026#34;, title=u\u0026#34;key2信息\u0026#34;, _type=SheetGenerater.t_risky_info, sheeter=None), SheetGenerater(key=\u0026#34;key3\u0026#34;, title=u\u0026#34;key3信息\u0026#34;, _type=SheetGenerater.t_simple, sheeter=None), ] for n, sheet_gennerater in enumerate(sheet_gennerater_list): if data.get(sheet_gennerater.key) and sheet1.title == \u0026#34;Sheet\u0026#34;: sheet1.title = sheet_gennerater.title sheet_gennerater_list[n].sheeter = sheet1 elif data.get(sheet_gennerater.key): _sheet = workbook.create_sheet(sheet_gennerater.title) sheet_gennerater_list[n].sheeter = _sheet for sheet_gennerate in sheet_gennerater_list: if sheet_gennerate.sheeter: sheet_gennerate.full_sheet(data[sheet_gennerate.key]) # save workbook to output file workbook.save(output_path) 计算md5 # import hashlib def calculate_md5(input_string): md5_hash = hashlib.md5() md5_hash.update(input_string.encode(\u0026#39;utf-8\u0026#39;)) return md5_hash.hexdigest() input_string = \u0026#34;Hello, World!\u0026#34; md5_value = calculate_md5(input_string) print(\u0026#34;MD5 值为:\u0026#34;, md5_value) 定时任务 # pip install apscheduler 可以参看: 我以前写的定时任务\n坑点 # 如果需要保证定时任务执行, 需要设置coalesce 和 misfire_grace_time 两个参数\ncoalesce 参数 # coalesce 参数用于控制当任务由于某些原因错过执行时间（即“misfire”）时，是否应该合并执行。它的作用如下：\n当 coalesce 设置为 True 时：如果任务错过了多个执行时间，只执行一次。也就是说，APScheduler 会合并所有错过的执行，只触发一次执行。这适用于那些不需要为每个错过的时间点单独执行的任务。 当 coalesce 设置为 False 时：即使任务错过了多个执行时间，它也会为每个错过的时间点单独执行。这意味着，如果任务错过了多次执行，它会在下一次可以执行的时候，连续执行多次，以补上错过的执行。 例如，一个任务是每分钟执行一次，但由于某些原因，该任务在5分钟内没有执行。如果 coalesce 设置为 True，任务只会执行一次；如果设置为 False，任务会连续执行5次（假设有足够的资源）。 misfire_grace_time 参数 # misfire_grace_time：单位为秒，当某一 job 被调度时刚好线程池都被占满，调度器会选择将该 job 排队不运行，misfire_grace_time 参数则是在线程池有可用线程时会比对该 job 的应调度时间跟当前时间的差值，如果差值小于 misfire_grace_time 时，调度器会再次调度该 job；反之该 job 的执行状态为 EVENTJOBMISSED 了，即错过运行。\n"},{"id":127,"href":"/docs/programmer/platforms/os/ros/","title":"ROS机器人操作系统","section":"平台","content":" Robot OS # http://www.autolabor.com.cn/book/ROSTutorials/\n"},{"id":128,"href":"/docs/programmer/basetc/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/","title":"supervisor","section":"基础工具和配置","content":" supervisord # 安装 # pip install supervisor echo_supervisord_conf echo_supervisord_conf \u0026gt; /etc/supervisord.conf echo -e \u0026#34;[include]\\nfiles = /etc/supervisor/conf.d/*.conf\u0026#34; \u0026gt;\u0026gt; /etc/supervisord.conf mkdir -p /var/log/test mkdir -p /etc/supervisor/conf.d/ echo -e \u0026#34;[program:test] command=/data/apps/test/.venv/bin/python test.py directory=/data/apps/test/src/ user=root minfds=65535 autostart=true autorestart=true stopasgroup=true stderr_logfile=/var/log/test/test.err.log stderr_logfile_maxbytes=1000MB stderr_logfile_backups=10 stdout_logfile=/var/log/test/test.out.log stdout_logfile_maxbytes=1000MB stdout_logfile_backups=10\u0026#34; \u0026gt; /etc/supervisor/conf.d/test.conf supervisord supervisorctl update 问题 # supervisorctl status http://localhost:9001 refused connection 问题 # 首次安装, 只pip install后直接使用很可能是没有配置文件\u0026hellip; 写入配置后启动supervisord就好了 多安装问题 # 使用pip安装和apt安装的 supervisor 使用的不同路径的配置文件, 然后系统里就会跑两个supervisor, 就容易产生迷惑行为\n使用supervisor启动的程序莫名其妙有了打开文件数限制 # 起了一个go程序结果http请求给限制到了4096, 根本不够用哈 设置如下参数可以设置新值(需要设置在supervisor配置中,而非supervisor守护的app中)\n[supervisord] minfds=8192 问题链接: Github\nsystemd # 文件路径: /etc/systemd/system/{service_name}.service\nfrpc示例 # [Unit] Description=Frp Client Service After=sshd.service [Service] Type=simple User={用户} Restart=on-failure RestartSec=200s ExecStart=/{path}/frp/frpc -c /{path}/frp/frpc.ini ExecReload=/{path}/frp/frpc reload -c /{path}/frp/frpc.ini LimitNOFILE=1048576 [Install] WantedBy=multi-user.target 生效命令 # systemctl daemon-reload systemctl enable frpc.service systemctl start frpc.service systemctl status frpc.service 服务日志查看 # journalctl -u {server_name}.service 手动指定 # [Service] StandardOutput=file:/var/log/my-service.log StandardError=file:/var/log/my-service.err 这种情况下，服务的输出将存储在指定的文件中，而不是 journal。\n工作路径 # [Service] WorkingDirectory=/path/to/your/working/directory # 工作目录 "},{"id":129,"href":"/docs/programmer/platforms/os/problem-of-windows/","title":"Windows 爬坑记","section":"平台","content":" Windows下Git问题 # Linux没啥问题,但在Win下报checkout失败,路径问题 git config core.protectNTFS false Win 开机问题 # 按下Shift+F10或者是Fn+Shift+F10快捷键调出命令提示符窗口。 输入以下指令文本：OOBE\\BYPASSNRO 等待重启, 再次操作来到联网界面. \u0026ldquo;下一步\u0026quot;按钮旁会多出一个\u0026quot;我没有internet连接\u0026quot;的选项, 点击该选项 "},{"id":130,"href":"/docs/programmer/gui/notespython/","title":"图形化界面 （Python Gui）","section":"图形用户界面-GUI","content":"author:Ian\nPython GUI 💽 # pynput # 在 pynput 模块中，Win键被称为“特殊键”（Special keys），需要使用特殊的名称来表示。\n以下是可以使用的特殊键名称列表：\nhttps://pynput.readthedocs.io/en/latest/keyboard.html?highlight=%3Ccmd%3E#controlling-the-keyboard 因此，如果你想要在热键设置中使用 Win键+空格 这个热键，可以将它们分别替换为 cmd 和 space，如下所示：\nfrom pynput import keyboard def on_activate(): print(\u0026#39;Hotkey activated\u0026#39;) def on_exit(): print(\u0026#39;Hotkey exited\u0026#39;) return False with keyboard.GlobalHotKeys({\u0026#39;\u0026lt;cmd\u0026gt;+\u0026lt;space\u0026gt;\u0026#39;: on_activate}) as h: h.join(on_exit)``` 在这个例子中，我们使用 \u0026lt;cmd\u0026gt;+\u0026lt;space\u0026gt; 来表示 Win键+空格 热键，因为在Mac中，Command键（cmd）可以起到类似于Win键的作用。 ## PyQt ![qt](https://tse4-mm.cn.bing.net/th/id/OIP.J4_Nqrcc0x7slHHUFwKLSQHaI6?pid=ImgDet\u0026amp;rs=1 \u0026#34;tmp\u0026#34;) 官方说明文档：\u0026lt;http://pyqt.sourceforge.net/Docs/PyQt4/index.html\u0026gt; 照例，先贴网址： \u0026lt;http://www.qaulau.com/books/PyQt4_Tutorial/index.html\u0026gt; ## 画界面 #PyQt4使用designer.exe import os for root, dirs, files in os.walk(\u0026#39;.\u0026#39;): for file in files: if file.endswith(\u0026#39;.ui\u0026#39;): os.system(\u0026#39;pyuic4 -o ui_%s.py %s\u0026#39; % (file.rsplit(\u0026#39;.\u0026#39;, 1)[0], file)) elif file.endswith(\u0026#39;.qrc\u0026#39;): os.system(\u0026#39;pyrcc4 -o %s_rc.py %s\u0026#39; % (file.rsplit(\u0026#39;.\u0026#39;, 1)[0], file)) # 注：在Win中调用pyrcc4 可能无法识别该命令，即使添加到环境变量也不行，而是 #pyrcc.exe才能调用简直…… #### 窗口设置 resize(8, 8) setWindowTitle(u\u0026#39;标题\u0026#39;) #### 获取图标 def getIcon(filename): \u0026#34;\u0026#34;\u0026#34; 获取图标 \u0026#34;\u0026#34;\u0026#34; fileInfo = Qt.QFileInfo(filename) fileIcon = Qt.QFileIconProvider() icon = QtGui.QIcon(fileIcon.icon(fileInfo)) return icon 使用时： self.setWindowIcon(getIcon(\u0026#39;../hi/app.ico\u0026#39;)) --- ##### Dock widgetTestM, dockTestM = self.createDock(AllMarketMonitor, vtText.“dock标题”, QtCore.Qt.RightDockWidgetArea) # 方向有： `RightDockWidgetArea`,`BottomDockWidgetArea`,`LeftDockWidgetArea` # 创建dock窗口 # 可利用 self.tabifyDockWidget(dockMarketM, dockAllDataM) 来合并同一个方向上的dock # 此下还没看… dockTradeM.raise_() dockPositionM.raise_() # 连接组件之间的信号 widgetPositionM.itemDoubleClicked.connect(widgetTradingW.closePosition) # 保存默认设置 self.saveWindowSettings(\u0026#39;default\u0026#39;) 其实现函数为： \u0026#34;\u0026#34;\u0026#34;创建停靠组件\u0026#34;\u0026#34;\u0026#34; def createDock(self, widgetClass, widgetName, widgetArea): widget = widgetClass(self.mainEngine, self.eventEngine) dock = QtGui.QDockWidget(widgetName) dock.setWidget(widget) dock.setObjectName(widgetName) dock.setFeatures(dock.DockWidgetFloatable|dock.DockWidgetMovable) self.addDockWidget(widgetArea, dock) return widget, dock \u0026gt; 再本质一点的东西为： widget1 = Ha(self) dock = QtGui.QDockWidget(\u0026#39;haha\u0026#39;) dock.setObjectName(\u0026#39;ha1\u0026#39;) dock.setWidget(widget1) dock.setFeatures(dock.DockWidgetFloatable | dock.DockWidgetMovable) self.addDockWidget(QtCore.Qt.BottomDockWidgetArea, dock) #### 动作 exit = QtGui.QAction(QtGui.QIcon(\u0026#39;hello.ico\u0026#39;), \u0026#39;exit\u0026#39;, self) exit.setShortcut(\u0026#39;Ctrl+Q\u0026#39;) exit.setStatusTip(\u0026#39;Exit application\u0026#39;) # 图标、文字、快捷键、提示信息 menubar = self.menuBar() file = menubar.addMenu(\u0026#39;\u0026amp;File\u0026#39;) file.addAction(exit) # 创建目录和工具栏，将动作添加进去。工具栏同理 ### 定位布局 #### 绝对定位 label1 = QtGui.QLabel(u\u0026#39;绝对定位\u0026#39;, self) label1.move(15, 60) # 创建、移动到显示位置 #### 框布局 及 布局元素平均分布 okButton = QtGui.QPushButton(\u0026#34;OK\u0026#34;) cancelButton = QtGui.QPushButton(\u0026#34;Cancel\u0026#34;) # 创建按钮 hbox = QtGui.QHBoxLayout() hbox.addStretch(1) hbox.addWidget(okButton) # 增加组件 hbox.addWidget(cancelButton) # 创建水平栏 hbox.addStretch() # 平均分布 vbox = QtGui.QVBoxLayout() vbox.addStretch(1) # 创建竖列 vbox.addLayout(hbox) # 将水平栏插入竖列 self.setLayout(vbox) # 显示最终竖列 注意一下add时选择对类型就好了。 ### QTableWidget \u0026lt;p\u0026gt;\u0026lt;textarea cols=\u0026#34;50\u0026#34; rows=\u0026#34;15\u0026#34; name=\u0026#34;code\u0026#34; class=\u0026#34;python\u0026#34;\u0026gt;#!/usr/bin/env python #coding=utf-8 from PyQt4.QtGui import * from PyQt4.QtCore import * class MyDialog(QDialog): def __init__(self, parent=None): super(MyDialog, self).__init__(parent) self.MyTable = QTableWidget(4,3) self.MyTable.setHorizontalHeaderLabels([\u0026#39;姓名\u0026#39;,\u0026#39;身高\u0026#39;,\u0026#39;体重\u0026#39;]) newItem = QTableWidgetItem(\u0026amp;quot;松鼠\u0026amp;quot;) self.MyTable.setItem(0, 0, newItem) newItem = QTableWidgetItem(\u0026amp;quot;10cm\u0026amp;quot;) self.MyTable.setItem(0, 1, newItem) newItem = QTableWidgetItem(\u0026amp;quot;60g\u0026amp;quot;) self.MyTable.setItem(0, 2, newItem) layout = QHBoxLayout() layout.addWidget(self.MyTable) self.setLayout(layout) if __name__ == \u0026#39;__main__\u0026#39;: import sys app = QApplication(sys.argv) myWindow = MyDialog() myWindow.show() sys.exit(app.exec_()) \u0026lt;/textarea\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026amp;nbsp;\u0026lt;/p\u0026gt; 其中： \u0026lt;p\u0026gt;self.MyTable = QTableWidget(4,3)\u0026amp;nbsp; 构造了一个QTableWidget的对象，并且设置为4行，3列\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;self.MyTable.setHorizontalHeaderLabels([\u0026#39;姓名\u0026#39;,\u0026#39;身高\u0026#39;,\u0026#39;体重\u0026#39;]) 则设置表格的表头\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;newItem = QTableWidgetItem(\u0026amp;quot;松鼠\u0026amp;quot;)\u0026amp;nbsp;\u0026amp;nbsp; 则是生成了一个QTableWidgetItem的对象，并让其名为\u0026amp;ldquo;松鼠\u0026amp;rdquo;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;self.MyTable.setItem(0, 0, newItem)\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; 将刚才生成的Item加载到第0行、0列处 \u0026lt;p\u0026gt;\u0026amp;nbsp;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;这样一个简单的QTableWidget就构造完成了。\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;http://hi.csdn.net/attachment/201103/1/0_1298961912c0mN.gif\u0026#34; alt=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/p\u0026gt; 感谢[来源](view-source:blog.csdn.net/vah101/article/details/6215066) ### 以上。 之后的设置字体，底色，之类用的的时候再说。 其中： ##### 合并单元格效果的实现： self.MyTable.setSpan(0, 0, 3, 1) # 其参数为： 要改变单元格的 1行数 2列数 要合并的 3行数 4列数 ##### 表格表头的显示与隐藏 self.MyTable.verticalHeader().setVisible(False) self.MyTable.horizontalHeader().setVisible(False) # 默认显示 且标号为： 1，2，3… #### 空位填补 .addStretch() # 不过比较鸡肋，还是下面的调整窗口显示比例比较好玩 ##### 调整各部分显示比例 QVBoxLayout* layout = new QVBoxLayout; QPushButton* btn = new QPushButton; QTableWidget* tableWidget = new QTableWidget; QHBoxLayout* h_layout = new QHBoxLayout; layout.addWidget(btn); layout.addWidget(tableWidget); layout.addLayout(h_layout) layout-\u0026gt;setStretchFactor(btn, 1); layout-\u0026gt;setStretchFactor(tableWidget, 2); layout-\u0026gt;setStretchFactor(h_layout, 2); 上面是C++ 所以下面的是俺的Python： hbox1[i].addWidget(self.buttonBox[i]) hbox1[i].addWidget(self.paramMonitor[i]) hbox1[i].addWidget(self.varMonitor[i]) # 设置显示比例 hbox1[i].setStretchFactor(self.buttonBox[i], 3) hbox1[i].setStretchFactor(self.paramMonitor[i], 3) hbox1[i].setStretchFactor(self.varMonitor[i], 4) ### 列表内添加按钮 \u0026lt;p\u0026gt;1、定义添加按钮的方法\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;cnblogs_code\u0026#34;\u0026gt; \u0026lt;pre\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 列表内添加按钮\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; buttonForRow(self,id): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 3\u0026lt;/span\u0026gt; widget=\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;QWidget() \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 4\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 修改\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 5\u0026lt;/span\u0026gt; updateBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;修改\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 6\u0026lt;/span\u0026gt; updateBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 7\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : NavajoWhite; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 8\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 9\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;10\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;11\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;12\u0026lt;/span\u0026gt; updateBtn.clicked.connect(\u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;:self.updateTable(id)) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;13\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 查看\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;15\u0026lt;/span\u0026gt; viewBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;查看\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;16\u0026lt;/span\u0026gt; viewBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;17\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : DarkSeaGreen; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;18\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;19\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;20\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;21\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;22\u0026lt;/span\u0026gt; viewBtn.clicked.connect(\u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;: self.viewTable(id)) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;23\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;24\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 删除\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;25\u0026lt;/span\u0026gt; deleteBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;删除\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;26\u0026lt;/span\u0026gt; deleteBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;27\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : LightCoral; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;28\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;29\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;30\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;31\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;32\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;33\u0026lt;/span\u0026gt; hLayout =\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; QHBoxLayout() \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;34\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(updateBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;35\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(viewBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;36\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(deleteBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;37\u0026lt;/span\u0026gt; hLayout.setContentsMargins(5,2,5,2\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;38\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; widget.setLayout(hLayout) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;39\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;return\u0026lt;/span\u0026gt; widget\u0026lt;/pre\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p\u0026gt;2、在向tableWidget里添加数据时插入即可\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;cnblogs_code\u0026#34;\u0026gt; \u0026lt;pre\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; row_number, row_data \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; enumerate(rsdata): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; self.ui.tableWidget.insertRow(row_number) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;3\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt; range(len(row_data)+1\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;4\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; i\u0026amp;lt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;len(row_data): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;5\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; self.ui.tableWidget.setItem(row_number, i, QtWidgets.QTableWidgetItem(str(row_data[i]))) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;6\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 添加按钮\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;7\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; i==\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;len(row_data): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 传入当前id\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;9\u0026lt;/span\u0026gt; self.ui.tableWidget.setCellWidget(row_number, i,self.buttonForRow(str(row_data[0])))\u0026lt;/pre\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p\u0026gt;效果图\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;http://images2017.cnblogs.com/blog/896442/201709/896442-20170907222902741-300228307.png\u0026#34; alt=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; 就像以上显示的那样[来源](https://www.cnblogs.com/yuanlipu/p/7492260.html) #### 值得注意的是，再排布的时候必须只有一个表格对其进行放置（也就是说指挥它去哪儿的只能有一个人），之前我为了测试，两个hbox 对其进行排版，简直…… labelSymbol = QtGui.QLabel(self.CtaEngine.strategyTickDict[self.name]) buttonInit[i] = QtGui.QPushButton(u\u0026#39;初始化\u0026#39;) buttonStart[i] = QtGui.QPushButton(u\u0026#39;启动\u0026#39;) buttonStop[i] = QtGui.QPushButton(u\u0026#39;停止\u0026#39;) buttonUpdate[i] = QtGui.QPushButton(u\u0026#39;更新参数\u0026#39;) buttonSave[i] = QtGui.QPushButton(u\u0026#39;保存参数\u0026#39;) buttonInit[i].clicked.connect(partial(self.init, i)) buttonStart[i].clicked.connect(partial(self.start, i)) buttonStop[i].clicked.connect(partial(self.stop, i)) buttonUpdate[i].clicked.connect(partial(self.updateParams,i)) buttonSave[i].clicked.connect(partial(self.saveParams, i)) hbox1[i] = QtGui.QHBoxLayout() ##参数设置显示 hbox2[i] = QtGui.QHBoxLayout() #hbox1[i].addWidget(labelSymbol) #hbox1[i].addWidget(buttonInit[i]) #hbox1[i].addWidget(buttonStart[i]) #hbox1[i].addWidget(buttonStop[i]) #hbox1[i].addWidget(buttonUpdate[i]) #hbox1[i].addWidget(buttonSave[i]) self.buttonBox[i].setCellWidget(0, 0, buttonInit[i]) self.buttonBox[i].setCellWidget(0, 1, buttonStart[i]) self.buttonBox[i].setCellWidget(0, 2, buttonStop[i]) --- --- --- #### 组件之间连接信号 # classA(QtGui.QTableWidget): # pass classA.itemDoubleClicked.connect(classB.actionFunction) # 这样单纯调用还是可以的，但是数据传输… 就得继续研究一下了。 ##### 关闭事件退出提示 def closeEvent(self, event): reply = QtGui.QMessageBox.question(self, \u0026#39;Message\u0026#39;,\u0026#34;Are you sure to quit?\u0026#34;, QtGui.QMessageBox.Yes, QtGui.QMessageBox.No) if reply == QtGui.QMessageBox.Yes: event.accept() else: event.ignore() 函数放置位置就是主窗口类下就好。 ### QTableWidget 清除数据 def updateData(self, data): #（缩进没问题吧…🙏） \u0026#34;\u0026#34;\u0026#34;将数据更新到表格中\u0026#34;\u0026#34;\u0026#34; if self.name == u\u0026#39;RiskAlarmWidget\u0026#39;: pass if self.updateBeginAction: data = self.updateBeginAction(data) if not data: return if self.updateAction: self.updateAction(data) else: if isinstance(data, unicode) and self.dataKey: # 删除模式 key = data if key in self.dataDict: d = self.dataDict[key] row = d[self.headerList[0]].row() self.removeRow(row) del self.dataDict[key] else: # 如果设置了dataKey，则采用存量更新模式 if self.InsertMode: # 如果允许了排序功能，则插入数据前必须关闭，否则插入新的数据会变乱 if self._sorting: self.setSortingEnabled(False) newRow = 0 if self.InsertTopRow else self.rowCount() self.insertRow(newRow) for n, header in enumerate(self.headerList): content = self.getContents(data, header) cellType = self.headerDict[header][\u0026#39;cellType\u0026#39;] cell = cellType(content) if self.font: cell.setFont(self.font) if self._saveData: cell.data = data self.setItem(newRow, n, cell) # 重新打开排序 if self._sorting: self.setSortingEnabled(True) else: key = data.__getattribute__(self.dataKey) if key in self.dataDict: # 已存在数据字典中，则更新相关单元格 d = self.dataDict[key] for header in self.headerList: content = self.getContents(data, header) cell = d[header] cell.setContent(content) if self._saveData: # 如果设置了保存数据对象，则进行对象保存 cell.data = data else: # 如果允许了排序功能，则插入数据前必须关闭， #否则插入新的数据会变乱 if self._sorting: self.setSortingEnabled(False) # 不存在数据字典中，插入新行，创建此行单元格 newRow = 0 if self.InsertTopRow else self.rowCount() self.insertRow(newRow) d = {} for n, header in enumerate(self.headerList): content = self.getContents(data, header) cellType = self.headerDict[header][\u0026#39;cellType\u0026#39;] cell = cellType(content) if self.font: cell.setFont(self.font) # 如果设置了特殊字体，则进行单元格设置 if self._saveData: # 如果设置了保存数据对象，则进行对象保存 cell.data = data self.setItem(newRow, n, cell) d[header] = cell self.dataDict[key] = d # 重新打开排序 if self._sorting: self.setSortingEnabled(True) if self.updateAfterAction: self.updateAfterAction(data) 插入后数据需要清理只需`.clearContentsText()`，这样是清理数据但保留表格，方便更新内容。`.clear()`则清理数据以及表格方便\u0026lt;font color=75362109\u0026gt;重新\u0026lt;/font\u0026gt;填入新的内容 --- #### 调用Windows程序 import win32api path = \u0026#39;D:/.../dockerTrader/gateway/ctpGateway/CTP_connect.json\u0026#39; win32api.ShellExecute(0, \u0026#39;open\u0026#39;, \u0026#39;notepad.exe\u0026#39;, path, \u0026#39;\u0026#39;, 1) # 使用记事本打开此文件 --- #### Json with open(\u0026#39;D:/.../dockerTrader/gateway/ctpGateway/CTP_connect.json\u0026#39;, \u0026#39;r\u0026#39;) as f: setting = json.load(f) self.userID = str(setting[\u0026#39;userID\u0026#39;]) self.password = str(setting[\u0026#39;password\u0026#39;]) --- --- ### 信号槽（传输额外参数） 一般来说，比如一个按钮吧。 在链接点击信号与槽时`buttonInit[i].clicked.connect(partial(self.init, i))`就完事了。然而，当循环创建按钮，对应同样的槽函数，只是需要执行的变量有区别时，就需要传输额外的参数。 这时，方法有二： 环境： python2.7.8 pyqt 4.11.1 ### 一： 使用lambda表达式 \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtCore \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtGui \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-class\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;MyForm\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(QMainWindow)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;__init__\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, parent=None)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; super(MyForm, self).__init__(parent) button1 = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button 1\u0026#39;\u0026lt;/span\u0026gt;) button2 = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button 1\u0026#39;\u0026lt;/span\u0026gt;) button1.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_button(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt;)) button2.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_button(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt;)) layout = QHBoxLayout() layout.addWidget(button1) layout.addWidget(button2) main_frame = QWidget() main_frame.setLayout(layout) self.setCentralWidget(main_frame) \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;on_button\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, n)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; print(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button {0} clicked\u0026#39;\u0026lt;/span\u0026gt;.format(n)) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#34;__main__\u0026#34;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; sys app = QApplication(sys.argv) form = MyForm() form.show() app.exec_() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; \u0026lt;p\u0026gt;解释一下，on_button是怎样处理从两个按钮传来的信号。我们使用lambda传递按钮数字给槽，也可以传递任何其他东西—甚至是按钮组件本身（假如，槽打算把传递信号的按钮修改为不可用）\u0026lt;/p\u0026gt; ### 二： 使用functools里的partial函数 \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;button1.clicked.connect(partial(self.on_button, \u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt;)) button2.clicked.connect(partial(self.on_button, \u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt;)) \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; \u0026lt;p\u0026gt;《Rapid GUI Program with Python and QT》 P143例子。\u0026lt;/p\u0026gt; \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtCore \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtGui \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; functools \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; partial \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; sys \u0026lt;span class=\u0026#34;hljs-class\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;Bu1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(QWidget)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;__init__\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, parent=None)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; super(Bu1, self).__init__(parent) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#水平盒式布局 \u0026lt;/span\u0026gt; layout = QHBoxLayout() \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#显示 \u0026lt;/span\u0026gt; self.lbl = QLabel(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;no button is pressed\u0026#39;\u0026lt;/span\u0026gt;) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#循环5个按钮 \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt; range(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;5\u0026lt;/span\u0026gt;): but = QPushButton(str(i)) layout.addWidget(but) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#信号和槽连接 \u0026lt;/span\u0026gt; but.clicked.connect(self.cliked) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用封装，lambda \u0026lt;/span\u0026gt; but = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;5\u0026#39;\u0026lt;/span\u0026gt;) layout.addWidget(but) but.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_click(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;5\u0026#39;\u0026lt;/span\u0026gt;)) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用个who变量，结果不正常，显示 False is pressed \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#but.clicked.connect(lambda who=\u0026#34;5\u0026#34;: self.on_click(who)) \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用封装，partial函数 \u0026lt;/span\u0026gt; but = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;6\u0026#39;\u0026lt;/span\u0026gt;) layout.addWidget(but) but.clicked.connect(partial(self.on_click, \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;6\u0026#39;\u0026lt;/span\u0026gt;)) layout.addWidget(self.lbl) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#设置布局 \u0026lt;/span\u0026gt; self.setLayout(layout) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#传递额外参数 \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;cliked\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; bu = self.sender() \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; isinstance(bu, QPushButton): self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;%s is pressed\u0026#39;\u0026lt;/span\u0026gt; % bu.text()) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;else\u0026lt;/span\u0026gt;: self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;no effect\u0026#39;\u0026lt;/span\u0026gt;) \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;on_click\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, n)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;%s is pressed\u0026#39;\u0026lt;/span\u0026gt; % n) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;__main__\u0026#39;\u0026lt;/span\u0026gt;: app = QApplication(sys.argv) bu =Bu1() bu.show() app.exec_() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; 三：感谢[来源](http://blog.csdn.net/fengyu09/article/details/39498777) --- ### ## PyQt + echarts图表 echarts绘制图标会在本地保存一个`html`文件，所以使用`PyQt`将之作为一个网页页面加载即可： from PyQt4.QtWebKit import * from PyQt4.QtGui import * from PyQt4.QtCore import * from pyecharts import Kline, Page def creat_charts(): page = Page() chart_init = { \u0026#34;width\u0026#34;: 1600, \u0026#34;height\u0026#34;: 900, } chart = Kline(\u0026#34;K 线图\u0026#34;, **chart_init) chart.add(\u0026#34;日K\u0026#34;, [\u0026#34;2017/7/{}\u0026#34;.format(i + 1) for i in range(31)], v1) page.add(chart) return page creat_charts()_render() # 生成`render.html`文件 self.view = QWebView() self.create_charts().render() url = QUrl(\u0026#34;render.html\u0026#34;) # 需要加载`QUrl`使用字符串转化 self.view.load(url) ## addWidget 在窗口布局的时候这玩意至关重要，因为要先创建一个框架，再往里面塞东西。而塞的方法就是`addWidget`。所以简单记录一下小年这一天经常用到的环套： hbox = QtGui.QHBoxLayout() vbox = QtGui.QVBoxLayout() 可以通过`addWidget`来塞入`QtGui.QWidget`, `QtGui.QGroupBox`, `QtGui.QTableWidget` ,`QScrollArea`等 还可以`addWidget`诸如`QtGui.QPushButton`, `QtGui.QLabel`, `QtGui.QComboBox`, `QtGui.QLineEdit`等小部件 `hbox`和`vbox`可以通过`addLayout`互相添加（这两个是 框架，即页面上的“骨头”。来摆设“肌肉”-\u0026gt;“Widget”、\u0026#34;Box\u0026#34;等的） 当然最后要显示谁，需要`self.setLayout(hbox)` 而支持`setLayout`少不了有 `QWidget`,`QScrollArea`, 所以它们好像能够无限互相套下去… ### 小部件的方法 其实哪些方法也不用记…打开`QtDesigner`直接搜索拖拽，然后看右边的清单就行了，但这几个还是记录下来吧，在网上找太累了~ `QtGui.QComboBox`: `addItems`, \u0026#39;\u0026#39;\u0026#39;addItem`, `currentText` `QtGui.QSpinBox`: `setValue`, ### QString2String def QString2PyString(self, qStr): #QString，如果内容是中文，则直接使用会有问题，要转换成 python #string return unicode(qStr.toUtf8(), \u0026#39;utf-8\u0026#39;, \u0026#39;ignore\u0026#39;) ## QLineEdit 之所以放这么后面是因为我觉得这东西没什么好说的，也就是一个输入框嘛，但因为出现在后面所以说是现在发现了其中有趣的东西。那就是最近在做输入密码的时候想要限制，但在程序中去判断显然并不是什么有意思的事情。然后想起来输入的时候可以直接限制住啊。于是采用了`textChanged`去`connect`一个函数，来动态监测输入。但在调试中打开错了窗口所以以为没有用就找了其他的方法。那就是在初始化的时候直接卡死，结果没有找到设置长度的.set***但找到了现用的`setValidator`其配合正则表达式的食用方法如下： import re a = QtCore.QRegExp(\u0026#34;[A-Za-z]{0,5}[1-9][0-9]{0,5}\u0026#34;) a = QtCore.QRegExp(\u0026#34;[a-zA-Z0-9]{0,12}$\u0026#34;) self.txtPasswd.setValidator(QtGui.QRegExpValidator(a)) # emm,很显然，把a替换成limitRule就要顺眼一些了。 不过\u0026lt;font color=#ff3bffl9\u0026gt;值得注意的是：\u0026lt;/font\u0026gt;如果用`setText`将其它字符写进这个编辑小框框中的话，那么这个框框的规则就会被打破然后随便写。但要是`setText`的内容没有超出所规定的形式之外的话，那么规则照旧，依然执行。 # PyQtGraph: [Link](http://www.pyqtgraph.org/) import pyqtgraph.examples pyqtgraph.examples.run() "},{"id":131,"href":"/docs/programmer/langs/java/notesjava/","title":"愉快的Java(happy to learn the fuck java)","section":"编程语言","content":"author: Ian\nhappy to learn the fuck java 😅 # \u0026lt;微人事\u0026gt; 笔记 -\u0026gt; ψ(._. )\u0026gt; # 先贴官方文档 哦 还有官方项目地址\nJava语法 # 爪哇方法定义: # 修饰符 返回值类型 方法名(参数类型 参数名){ 方法体; return 返回值; } # 示个例 public boolean NiHou(int num){ int a = num; return turn; } // `boolean` 处 可为 public Collection\u0026lt;? extends GrantedAuthority\u0026gt; getAuthorities(){ List\u0026lt;GrantedAuthority\u0026gt; authorities = new ArrayList\u0026lt;\u0026gt;(); return authorities; } // 表泛型中可以是的`GrantedAuthority`所有子类 爪哇抽象方法(即Python父类中直接pass的函数…) # abstract\n包含抽象方法必须得是抽象类 任何子类必须重写父类抽象方法，或者声明自身为抽象类 public abstract class Employee { private String name; private int number; public abstract double computePay(); //其余 } 爪哇接口 # interface, implements\n[可见度] interface 接口名称 [extends 其他的类名] { // 声明变量 // 抽象方法 } # 示个例 /* 文件名 : NameOfInterface.java */ public interface NameOfInterface { //任何类型 final, static 字段 //抽象方法 } Interface关键字用来声明一个接口。 爪哇抽象类 # abstract classextends\n不能直接实例化 只能被继承后实例 public abstract class Employee { private String name; private String address; private int number; public Employee(String name, String address, int number) { System.out.println(\u0026#34;Constructing an Employee\u0026#34;); this.name = name; this.address = address; this.number = number; } //…… 等方法 public int getNumber() { return number; } } /* 文件名 : Salary.java */ // 用于继承上述东西 public class Salary extends Employee { private double salary; //Annual salary public Salary(String name, String address, int number, double salary) { super(name, address, number); setSalary(salary); } public void mailCheck() { System.out.println(\u0026#34;Within mailCheck of Salary class \u0026#34;); System.out.println(\u0026#34;Mailing check to \u0026#34; + getName() + \u0026#34; with salary \u0026#34; + salary); } public double getSalary() { return salary; } public void setSalary(double newSalary) { if(newSalary \u0026gt;= 0.0) { salary = newSalary; } } public double computePay() { System.out.println(\u0026#34;Computing salary pay for \u0026#34; + getName()); return salary/52; } } /* 文件名 : AbstractDemo.java */ // 用于实现继承类 public class AbstractDemo { public static void main(String [] args) { Salary s = new Salary(\u0026#34;Mohd Mohtashim\u0026#34;, \u0026#34;Ambehta, UP\u0026#34;, 3, 3600.00); Employee e = new Salary(\u0026#34;John Adams\u0026#34;, \u0026#34;Boston, MA\u0026#34;, 2, 2400.00); System.out.println(\u0026#34;Call mailCheck using Salary reference --\u0026#34;); s.mailCheck(); System.out.println(\u0026#34;\\n Call mailCheck using Employee reference--\u0026#34;); e.mailCheck(); } } 爪哇类 # class, extends\nMaven 项目标准目录结构 # str |\tmain |\tbin\t脚本库 |\tjava Java源代码文件 |\tresources 资源库，会自动复制到classes目录中 |\tfilters 资源过滤文件 |\tassembly 组建的描述配置（如何打包） |\tconfig 配置文件 |\twebapp web应用的目录。WEB-INF、css、js等 |\ttest |\tjava 单元测试Java源代码文件 |\tresorces 测试需要用到的资源库 |\tfilters 测试资源过滤库 |\tsite Site（一些文档） |\ttarget LICENSE.txt Project\u0026rsquo;s license README.txt Project\u0026rsquo;s readme\n工程根目录下就只有src和target两个目录 target是有存放项目构建后的文件和目录，jar包、war包、编译的class文件等。 target里的所有内容都是maven构建的时候生成的\n顶级目录工程的描述文件pom.xml\n摘自: https://blog.csdn.net/lengyue_wy/article/details/6718637\nsrc # java # Bean: 扮演应用程序素材的角色（其中放置了各种自定义类 如：Hr、Role、Employee、menu等数据类型）（作为service的模型库） common: 常用方法 （如字符串转换、邮件、几个查询） config: 看不懂的设置 controller: 动作执行，即受到什么请求执行什么动作。 但是我打了断点鲜有进来的。所以具体实现过程还是不清楚。 另外其url地址与网页真正输入地址有全拼简写的区别，哪里有指定也没找到还。（并且寥寥草草一个就处理完了，所以肯定是简写了💩） exception: 异常处理 mapper: 虽不觉然明厉的东西集合_20180525_其中定义了诸多做实事的接口，在.java文件中画饼，在.xml中实现，另外昨天在查资料时，还了解到有人要将.java与.xml分开来存放，解决方法是将.xml放在resources文件夹中，仿照在java文件夹中的路径，依瓢葫芦画😄的建立相同路径，如此一来在coding阶段看起来是分开的，但在building阶段编译器就是看作在同一目录下了——由此引发了虽然拆开了他们的人，却没有拆散他们的心的哲学论题😰(作为service的方法库) service: 动作逻辑服务，和controller中类似，不过详细不少（作为）\nresources # ftl: emm…… static: 静态资源 js: emm… application.properties: 各项配置 mybatis-config.xml: MySQL数据库配置\nMybatis # 头 # \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;/configuration\u0026gt; configuration中的配置信息 # 详解： https://blog.csdn.net/yqynsmile/article/details/52807815\n// 别名，假名，代称 \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Student\u0026#34; type=\u0026#34;com.mybatis3.domain.Student\u0026#34; /\u0026gt; \u0026lt;/typeAliases\u0026gt; // 声明环境变量 \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; /* 声明数据源，数据源的类型有NOPOOLED ，POOLED ，还有JIDN. 在数据量少的话用ONPOOLED，测试和开发过程一般用POOLED，实际运行使用JIDN */ \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; // \u0026lt;mappers\u0026gt;：声明我们定义的一个个Mapper类，或者说是关联 \u0026lt;mapper resource=\u0026#34;com/mybatis3/mappers/StudentMapper.xml\u0026#34; /\u0026gt; // \u0026lt;property\u0026gt;：jdbc连接的一些属性 \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/test\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;admin\u0026#34; /\u0026gt; /* 这些东西貌似也可以写在其他地方：application中 \u0026lt;property name=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;value\u0026gt;jdbc:mysql://localhost:3306/springmybaitis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026lt;/value\u0026gt; \u0026lt;!--springmybaitis是我的数据库 --\u0026gt; \u0026lt;/property\u0026gt; 或 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/vhr?useUnicode=true\u0026amp;characterEncoding=UTF-8 两种写法而已 */ // \u0026lt;mapper\u0026gt;：声明Mapper的路径 // 默认setting配置 \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt;//是否使用缓存 \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt;//是否是懒记载 \u0026lt;setting name=\u0026#34;multipleResultSetsEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;useColumnLabel\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;useGeneratedKeys\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;autoMappingBehavior\u0026#34; value=\u0026#34;PARTIAL\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;defaultExecutorType\u0026#34; value=\u0026#34;SIMPLE\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;defaultStatementTimeout\u0026#34; value=\u0026#34;25000\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;safeRowBoundsEnabled\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;localCacheScope\u0026#34; value=\u0026#34;SESSION\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;jdbcTypeForNull\u0026#34; value=\u0026#34;OTHER\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadTriggerMethods\u0026#34; value=\u0026#34;equals,clone,hashCode ,toString\u0026#34; /\u0026gt; 还有 \u0026lt;Settings\u0026gt;:声明一些全局变量、\u0026lt;typeHandlers\u0026gt;: 自定义我们的传入参数类型处理器、\u0026lt;properties\u0026gt;: 声明属性文件的key和value，但使用.properties文件将会被覆盖。\n注: 在要使用指定日志工具时，需要在\u0026lt;Settings\u0026gt;里指定\u0026lt;setting name=\u0026quot;logImpl\u0026quot; value=\u0026quot;LOG4J\u0026quot;/\u0026gt;\nequals 与 == # equals 对比两者是否类型一致，内容一致 ==\t则会由于 不同对象而False\nString str1=new String(\u0026#34;hello\u0026#34;); String str2=new String(\u0026#34;hello\u0026#34;); str1==str2 输出：false,因为不同对象 int1.equals(int2) 输出：TRUE // 无论 整形 or 字符串等 爪洼调用Python # 爪哇语有个通用调用方式，就是通过Runtime，也就是通过命令行执行，然后通过BufferedReader捕获命令行（内存）中的信息。但数据传输只能通过字符串，另外，python回传数据也只能通过print来回传，所以……基本没啥用.\n"},{"id":132,"href":"/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%BA%93%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","title":"机器学习库","section":"机器学习","content":" Python 机器学习库 👽 # Plotly # 与matplotlib 都是绘图工具，不过效果炫一些，我也没画过，所以只放链接，不放实例了 Plotly Python Library : https://plot.ly/python/\nmatplotlib # import matplotlib.pyplot as plt 参数等太多，链接最可靠 # pyplot参数\n还是粘一些常用的： marker 属性（下面写在分号里呦） o . v ^ \u0026lt; \u0026gt; 1 2 3 4 8 s p * h H + x D d | _ 之类\n画出一些“花儿”\n绘图 # plt.plot(x, y) # 在y之后可添加参数，例如常用的label = ‘IamLabel’之类 # 线的样式、颜色 ：b: blue g: green r: red c: cyan m: magenta y: yellow k: black w: white '-' : solid , '--' : dashed, '-.' : dashdot ':' : dotted ' '', ' ' ': None # 粗细 lw=3 更改数字 # 数值折点显示样式 marker = ‘o’ plot.show() 绘制图表 # 1 # plt.figure(1) 绘图 plt.figure(2) 绘图 2（未测试） # plt.figure(1) # 创建图表1 plt.figure(2) # 创建图表2 hi1 = plt.subplot(211) # 在图表2中创建子图1 hi2 = plt.subplot(212) # 在图表2中创建子图2 一表多图 # pCapital = plt.subplot(4, 1, 1) pCapital.set_ylabel(\u0026quot;capital\u0026quot;) pCapital.plot(d['capitalList'], color='r', lw=0.8) plt.show() 标注点 # eg1 # for w, m in enumerate(self.lowestPrice): if w % 120*10 == 0: plt.plot([w, w], [m, self.highestPrice[w]], linestyle = '--') #plt.scatter(self.dealPoints,color = 'c') for i in self.dealPoints: plt.scatter([i[0]], [i[1]], color = 'c') for ii in self.ydealPoints: plt.scatter([ii[0]], [ii[1]], color = 'm') plt.title('Tick \u0026amp; TradePoint') plt.legend() plt.show() plt.legend() # show() 之前不加这句是不会显示出标注的呦\neg2(还不晓得咋回事儿) # import numpy as np t = 2 * np.pi / 3 plt.plot([t, t], [0, np.cos(t)], color=\u0026#39;blue\u0026#39;, linewidth=2.5, linestyle=\u0026#34;--\u0026#34;) plt.scatter([t, ], [np.cos(t), ], 50, color=\u0026#39;blue\u0026#39;) plt.annotate(r\u0026#39;$sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$\u0026#39;, xy=(t, np.sin(t)), xycoords=\u0026#39;data\u0026#39;, xytext=(+10, +30), textcoords=\u0026#39;offset points\u0026#39;, fontsize=16, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, connectionstyle=\u0026#34;arc3,rad=.2\u0026#34;)) plt.plot([t, t],[0, np.sin(t)], color=\u0026#39;red\u0026#39;, linewidth=2.5, linestyle=\u0026#34;--\u0026#34;) plt.scatter([t, ],[np.sin(t), ], 50, color=\u0026#39;red\u0026#39;) plt.annotate(r\u0026#39;$cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$\u0026#39;, xy=(t, np.cos(t)), xycoords=\u0026#39;data\u0026#39;, xytext=(-90, -50), textcoords=\u0026#39;offset points\u0026#39;, fontsize=16, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, connectionstyle=\u0026#34;arc3,rad=.2\u0026#34;)) 坐标标签显示方案 # plt.setp(plt.gca().get_xticklabels(), rotation=20, horizontalalignment=\u0026#39;right\u0026#39;) # 貌似除了角度和right，没有了修改内容 来画一个动态图吧（感觉没啥作用所以就小标题了） # import matplotlib.pyplot as plt from matplotlib.patches import Circle import numpy as np import math plt.close() #clf() # 清图 cla() # 清坐标轴 close() # 关窗口 fig=plt.figure() ax=fig.add_subplot(1,1,1) ax.axis(\u0026#34;equal\u0026#34;) #设置图像显示的时候XY轴比例 plt.grid(True) #添加网格 plt.ion() #interactive mode on打开交互模式 而不是plt.show() IniObsX=0000 IniObsY=4000 IniObsAngle=135 IniObsSpeed=10*math.sqrt(2) #米/秒 print(\u0026#39;开始仿真\u0026#39;) try: for t in range(180): #障碍物船只轨迹 obsX=IniObsX+IniObsSpeed*math.sin(IniObsAngle/180*math.pi)*t obsY=IniObsY+IniObsSpeed*math.cos(IniObsAngle/180*math.pi)*t ax.scatter(obsX,obsY,c=\u0026#39;b\u0026#39;,marker=\u0026#39;.\u0026#39;) #散点图 #ax.lines.pop(1) 删除轨迹 #下面的图,两船的距离 plt.pause(0.1) except Exception as err: print(err) pandas # DataFrame # import pandas as pd import numpy as np a = {\u0026#39;a\u0026#39;:[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;b\u0026#39;:[1,2,3], \u0026#39;c\u0026#39;:[\u0026#39;lo\u0026#39;, \u0026#39;hel\u0026#39;, \u0026#39;hi\u0026#39;], \u0026#39;d\u0026#39;:[7,8,9]} df = pd.DataFrame(a) # 字典转换为dataFrame（每一个Key 和 Value构成一列，key为列标） df = df.set_index(\u0026#39;a\u0026#39;) # 将‘a‘列设置为行标 sr = pd.Series(a) sr2 = df[\u0026#39;b\u0026#39;] df[[\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;]].to_records()[1][\u0026#39;b\u0026#39;] df[[\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;]] columns index # 列，参数(行) 取用方法 # dfValue.loc[indexKey][colKey] 一个将DataFrame字符串化之后重新解析的程序😓 # def parseSTR(self, _str, indexKey, colKey, setIndexNum=0, setColNum=0): \u0026#34;\u0026#34;\u0026#34; 通过setIndexNum来确定第几列数据为行标题， setColNum确定使用第几行数据作为列标题 返回通过indexKey行标题 与 colKey列标题 确定的结果 \u0026#34;\u0026#34;\u0026#34; rows = _str.split(\u0026#39;\\n\u0026#39;) columns = rows[0].split(\u0026#39;,\u0026#39;)[1:] tempRow = [] index = [] for row in rows[1:]: if len(row): index.append(row.split(\u0026#39;,\u0026#39;)[setIndexNum]) tempRow.append(row.split(\u0026#39;,\u0026#39;)[1:]) dfValue = pd.DataFrame(tempRow, index=index, columns=columns) try: return dfValue.loc[indexKey][colKey] except: print u\u0026#39;【error:】信息不全\u0026#39; return None Emm,有点儿… 嗯… 嗯…\nnumpy # random # random.seed(int类型) # 理解可以为设定开始随机的开始，也就是说每次设定之后再开始取值就会得到相同的随机数() 即 np.random.seed(1)\nnp.random.random(1)\nnp.random.seed(1) np.random.random(1) array([ 0.417022])\narray([ 0.417022])\n标准差 # a = np.arange(10) np.std(a) a.std() 样本标准差 # a.std(ddof = 1) np.std(a, ddof = 1) 以上 a.std 只有当a为\u0026lt;type \u0026rsquo;numpy.ndarray\u0026rsquo;\u0026gt; 即用numpy生成的矩阵，array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])才可有，如果是python的列表list 则只能用np.std 来算\nscikit-learn # OpenCV # Insatll # caffe：\nsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler sudo apt-get install --no-install-recommends libboost-all-dev sudo apt-get install libatlas-base-dev sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 缺少 libGL.so.1 # File \u0026#34;/data/apps/env/lib/python3.10/site-packages/cv2/__init__.py\u0026#34;, line 181, in \u0026lt;module\u0026gt; bootstrap() File \u0026#34;/data/apps/env/lib/python3.10/site-packages/cv2/__init__.py\u0026#34;, line 153, in bootstrap native_module = importlib.import_module(\u0026#34;cv2\u0026#34;) File \u0026#34;/usr/lib/python3.10/importlib/__init__.py\u0026#34;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) ImportError: libGL.so.1: cannot open shared object file: No such file or directory 安装缺失库\nsudo apt-get install -y libgl1-mesa-glx PIL # his = im.histogram() values = {}\nfor i in range(256): values[i] = his[i]\nfor j,k in sorted(values.items(),key=lambda x:x[1],reverse = True)[:10]: print j,k\n爬虫 # 先链接 为实例视频教程，貌似不错，还没看。\n问题 # 虽然, 以前已经积累了一些东西, 知道\nheaders cookie 啥的, 但今天突然碰到了这个报错: Caused by SSLError(SSLError(\u0026ldquo;bad handshake: Error([(\u0026lsquo;SSL routines\u0026rsquo;, \u0026rsquo;tls_process_server_certificate\u0026rsquo;, \u0026lsquo;certificate verify failed\u0026rsquo;)])\n没见过, 之后碰到其余, 统一汇总在此.\nSSLError HTTPS # 有人指点到: 因用https的缘故, 其中报 verify failed 所以可以通过\nrequests.get(url, verify=False) 将verify关闭可通过.\nSelenium # 从网页粘来的，下方有作者以及来源链接，格式就保留原有不改了… # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.taobao.com/')\n显示等待10s # wait = WebDriverWait(browser, 10)\n等待直到元素加载出 # input = wait.until(EC.presence_of_element_located((By.ID, \u0026lsquo;q\u0026rsquo;)))\n等待直到元素可点击 # button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \u0026lsquo;.btn-search\u0026rsquo;))) print(input, button) from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait\n创建一个浏览器对象 # browser = webdriver.Chrome() try: # 开启一个浏览器并访问https://www.baidu.com browser.get(\u0026lsquo;https://www.baidu.com\u0026rsquo;) # 在打开的网页响应中根据id查找元素 获取到查询框 input = browser.find_element_by_id(\u0026lsquo;kw\u0026rsquo;) # 向查询框中输入Python input.send_keys(\u0026lsquo;Python\u0026rsquo;) # 模拟回车 input.send_keys(Keys.ENTER) # 显示等待， 等待10秒 wait = WebDriverWait(browser, 10) # 显式等待指定某个条件，然后设置最长等待时间。如果在这个时间还没有找到元素，那么便会抛出异常 wait.until(EC.presence_of_element_located((By.ID,\u0026lsquo;content_left\u0026rsquo;))) # 输出当前的url print(browser.current_url) # 输出Cookies print(browser.get_cookies()) # 输出页面响应内容 print(browser.page_source) finally: pass # 关闭浏览器 browser.close()\n\u0026lt;h2\u0026gt;2、Selenium声明浏览器对象\u0026lt;/h2\u0026gt;\u0026lt;div class=\u0026#34;highlight\u0026#34;\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-text\u0026#34;\u0026gt;\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;from selenium import webdriver browser = webdriver.Chrome() browser = webdriver.Firefox() browser = webdriver.Edge() browser = webdriver.PhantomJS() browser = webdriver.Safari() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;p\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;3、查找元素\u0026lt;/h2\u0026gt;\u0026lt;h2\u0026gt;3.1、查找单个元素\u0026lt;/h2\u0026gt;\u0026lt;div class=\u0026#34;highlight\u0026#34;\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-text\u0026#34;\u0026gt;\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;from selenium import webdriver #### 申明一个浏览器对象 browser = webdriver.Chrome() #### 使用浏览器访问淘宝 browser.get(\u0026#39;https://www.taobao.com\u0026#39;) #### 在响应结果中通过id查找元素 input_first = browser.find_element_by_id(\u0026#39;q\u0026#39;) #### 在响应结果中通过css选择器查找元素 input_second = browser.find_element_by_css_selector(\u0026#39;#q\u0026#39;) #### 在响应结果中通过xpath查找元素 input_third = browser.find_element_by_xpath(\u0026#39;//*[@id=\u0026#34;q\u0026#34;]\u0026#39;) print(input_first) print(input_second) print(input_third) browser.close() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;find_element_by_name 通过name查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_xpath 通过xpath查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_link_text 通过链接查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_partial_link_text 通过部分链接查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_tag_name 通过标签名称查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_class_name 通过类名查找\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_element_by_css_selector 通过css选择武器查找\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;div class=\u0026#34;highlight\u0026#34;\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-text\u0026#34;\u0026gt;\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;from selenium import webdriver from selenium.webdriver.common.by import By #### 申明一个浏览器对象 browser = webdriver.Chrome() #### 使用浏览器访问淘宝 browser.get(\u0026#39;https://www.taobao.com\u0026#39;) #### 第二种方式，通过使用By.xxx指定查找方式 input = browser.find_element(By.ID,\u0026#39;q\u0026#39;) print(input) browser.close() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;h2\u0026gt;3.2、多个元素\u0026lt;/h2\u0026gt;\u0026lt;div class=\u0026#34;highlight\u0026#34;\u0026gt;\u0026lt;pre\u0026gt;\u0026lt;code class=\u0026#34;language-text\u0026#34;\u0026gt;\u0026lt;span\u0026gt;\u0026lt;/span\u0026gt;from selenium import webdriver from selenium.webdriver.common.by import By #### 申明一个浏览器对象 browser = webdriver.Chrome() #### 使用浏览器访问淘宝 browser.get(\u0026#39;https://www.taobao.com\u0026#39;) #### 根据选择查找多个元素 input_first = browser.find_elements_by_css_selector(\u0026#39;.service-bd li\u0026#39;) input_second = browser.find_elements(By.CSS_SELECTOR,\u0026#39;.service-bd li\u0026#39;) print(input_first) print(input_second) browser.close() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;find_elements_by_name\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_xpath\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_link_text\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_partial_link_text\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_tag_name\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_class_name\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;find_elements_by_css_selector\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt; ## 4、元素交互操作 \u0026lt;blockquote\u0026gt;对获取的元素调用交互方法 \u0026lt;/blockquote\u0026gt; ```python import time from selenium import webdriver from selenium.webdriver.common.by import By #### 申明一个浏览器对象 browser = webdriver.Chrome() #### 使用浏览器访问淘宝 browser.get(\u0026#39;https://www.taobao.com\u0026#39;) #### 根据ID查找元素 input_search = browser.find_element(By.ID,\u0026#39;q\u0026#39;) #### 模拟输入PSV到输入框 input_search.send_keys(\u0026#39;PSV\u0026#39;) time.sleep(2) #### 清空输入 input_search.clear() input_search.send_keys(\u0026#39;3DS\u0026#39;) button = browser.find_element(By.CLASS_NAME,\u0026#39;btn-search\u0026#39;) #### 模拟点击 button.click() browser = webdriver.Chrome() url = \u0026lsquo;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable' browser.get(url)\n切换id为iframeResult的frame # browser.switch_to.frame(\u0026lsquo;iframeResult\u0026rsquo;) source = browser.find_element_by_css_selector(\u0026rsquo;#draggable\u0026rsquo;) target = browser.find_element_by_css_selector(\u0026rsquo;#droppable\u0026rsquo;) actions = ActionChains(browser) actions.drag_and_drop(source, target) actions.perform() 更多操作http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains6、执行JavaScriptfrom selenium import webdriver\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore')\n执行JavaScript脚本 # browser.execute_script(\u0026lsquo;window.scrollTo(0, document.body.scrollHeight)\u0026rsquo;) browser.execute_script(\u0026lsquo;alert(\u0026ldquo;To Bottom\u0026rdquo;)\u0026rsquo;) 7、获取元素信息7.1、获取属性from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') logo = browser.find_element(By.ID,\u0026lsquo;zh-top-link-logo\u0026rsquo;)\n获取属性 # print(logo.get_attribute(\u0026lsquo;class\u0026rsquo;)) print(logo) browser.close() 7.2、获取文本值from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') submit = browser.find_element(By.ID,\u0026lsquo;zu-top-add-question\u0026rsquo;)\n获取文本值 # print(submit.text) print(submit) browser.close() 7.3、获取ID、位置、标签名、大小from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') submit = browser.find_element(By.ID,\u0026lsquo;zu-top-add-question\u0026rsquo;)\n获取id 0.04584255991652042-1 # print(submit.id)\n获取位置 {\u0026lsquo;y\u0026rsquo;: 7, \u0026lsquo;x\u0026rsquo;: 675} # print(submit.location)\n获取标签名称 button # print(submit.tag_name)\n获取大小 {\u0026lsquo;width\u0026rsquo;: 66, \u0026lsquo;height\u0026rsquo;: 32} # print(submit.size) browser.close() 8、Framefrom selenium import webdriver from selenium.common.exceptions import NoSuchElementException\nbrowser = webdriver.Chrome() url = \u0026lsquo;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable' browser.get(url)\n将操作的响应数据换成iframeResult # browser.switch_to.frame(\u0026lsquo;iframeResult\u0026rsquo;) source = browser.find_element_by_css_selector(\u0026rsquo;#draggable\u0026rsquo;) print(source) try: logo = browser.find_element_by_class_name(\u0026rsquo;logo\u0026rsquo;) except NoSuchElementException: print(\u0026lsquo;NO LOGO\u0026rsquo;)\n切换成父元素 # browser.switch_to.parent_frame() logo = browser.find_element_by_class_name(\u0026rsquo;logo\u0026rsquo;) print(logo) print(logo.text) 9、等待9.1、隐式等待当使用了隐式等待执行测试的时候，如果 WebDriver没有在 DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常, 换句话说，当查找元素或元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0from selenium import webdriver\nbrowser = webdriver.Chrome()\n等待10秒 # browser.implicitly_wait(10) browser.get(\u0026lsquo;https://www.zhihu.com/explore') input = browser.find_element_by_class_name(\u0026lsquo;zu-top-add-question\u0026rsquo;) print(input) 9.2、显示等待显式等待指定某个条件，然后设置最长等待时间。如果在这个时间还没有找到元素，那么便会抛出异常了。 from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.taobao.com/')\n显示等待10s # wait = WebDriverWait(browser, 10)\n等待直到元素加载出 # input = wait.until(EC.presence_of_element_located((By.ID, \u0026lsquo;q\u0026rsquo;)))\n等待直到元素可点击 # button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \u0026lsquo;.btn-search\u0026rsquo;))) print(input, button) title_is 标题是某内容title_contains 标题包含某内容presence_of_element_located 元素加载出，传入定位元组，如(By.ID, \u0026lsquo;p\u0026rsquo;)visibility_of_element_located 元素可见，传入定位元组visibility_of 可见，传入元素对象presence_of_all_elements_located 所有元素加载出text_to_be_present_in_element 某个元素文本包含某文字text_to_be_present_in_element_value 某个元素值包含某文字frame_to_be_available_and_switch_to_it frame加载并切换invisibility_of_element_located 元素不可见element_to_be_clickable 元素可点击staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新element_to_be_selected 元素可选择，传元素对象element_located_to_be_selected 元素可选择，传入定位元组element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回Falseelement_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回Falsealert_is_present 是否出现Alert更多操作http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions10、前进后退import time from selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.baidu.com/') browser.get(\u0026lsquo;https://www.taobao.com/') browser.get(\u0026lsquo;https://www.python.org/') browser.back() time.sleep(1) browser.forward() browser.close() 11、Cookiesfrom selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore')\n获得cookies # print(browser.get_cookies())\n添加cookie # browser.add_cookie({\u0026rsquo;name\u0026rsquo;: \u0026rsquo;name\u0026rsquo;, \u0026lsquo;domain\u0026rsquo;: \u0026lsquo;www.zhihu.com\u0026rsquo;, \u0026lsquo;value\u0026rsquo;: \u0026lsquo;germey\u0026rsquo;}) print(browser.get_cookies())\n删除所有cookies # browser.delete_all_cookies() print(browser.get_cookies()) 12、选项卡管理import time from selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.baidu.com\u0026rsquo;)\n打开一个选项卡 # browser.execute_script(\u0026lsquo;window.open()\u0026rsquo;) print(browser.window_handles)\n选择第二个选项卡 # browser.switch_to_window(browser.window_handles[1]) browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;) time.sleep(1) browser.switch_to_window(browser.window_handles[0]) browser.get(\u0026lsquo;https://python.org\u0026rsquo;) 13、异常处理\nfrom selenium import webdriver from selenium.common.exceptions import TimeoutException, NoSuchElementException browser = webdriver.Chrome() try: browser.get(\u0026#39;https://www.baidu.com\u0026#39;) except TimeoutException: print(\u0026#39;Time Out\u0026#39;) try: browser.find_element_by_id(\u0026#39;hello\u0026#39;) except NoSuchElementException: print(\u0026#39;No Element\u0026#39;) finally: browser.close() TensorFlow # Variable # 必须用到: ```init = tf.initialize_all_variables() # 初始化全部变量\n随后即可: ```sess.run(init)\nTensorflow 笔记 # 這是在對照官網學習時的前期入門筆記，其實和官網基本沒有區別，好吧，真的沒有區別。因爲官網真的寫的太好了。 至於我爲什麼要寫出來，是因爲我之前寫在了紙上，對於邏輯的把握很給力，所以在寫一邊。\n不過TensorFlow 變動真的很大，版本更迭也很快，所以，下方只是理清邏輯，具體的東西還是去官網比較好。只不過我這兒網謎之很難等上去…\n總而言之一句話，先搭好架子再選擇填充材料。就是它的核心邏輯了。而改進也是在架子基礎上去優化優化器。嗯…現在理解就是這樣。\n1 # 导入 # import tensorflow as tf 步骤：①构建计算图 ②运行计算图\n2 # Build a simple computational Graph # node1 = tf.contant(3.0, dtype = tf.float32) node2 = tf.contant(4.0) #also tf.float32 impicitly print (node1, node2) 输出为： # Tensor (\u0026quot;Cast: 0\u0026quot;, shape = (), dtype = float) Tensor (\u0026quot;Cast_1: 0\u0026quot;, shape = (), dtype = float) 打印并不输出值3.0，4.0，而在评估时分别产生3.0和4.0节点。欲实际评估节点，We must run the computational graph within a session. A seesion encapsulation the control and state of the tensorflow runtime.\n3 # Creates a session object , 然后调用run方法运行足够的computational graph to envlute node1 and node2 # sess = tf.Session() print (sess.run([node1, node2])) 输出为： # [3.0, 4.0] #可见预期值 4 # We can build more complicated computations by combining Tensor nodes with operations # node3 = tf.add(node1, node2) print (\u0026quot;node3: \u0026quot;, node3) print (\u0026quot;sess.run(node3):\u0026quot;, sess.run(node3)) 输出为： # node3: Tensor(\u0026quot;Add:0\u0026quot;, shape = (1,dtype = float32)) sess.run(node3): 7.0 5 # 更进一步的，A graph can be parameterized. To accept external input , 称为placeholders # a = tf.placeholder(tf.float32) b = tf.placeholder(tf.float32) adder_note = a + b #provide a shortcut for tf.add(a, b) and can with multiple input by using print (sess.run(add_note, {a:3, b:4.5})) print (sess.run(add_note, {a:[1, 3], b:[2, 4]})) 输出为： # 7.5 [3. 7.] 5.1 # more complex by adding anther aperation. for example: # add_and_triple = adder_note * 3 print (sess.run(add_and_triple, {a:3, b:4.5})) 输出为： # 22.5 In TensorBoard(Tensorflow圖形化界面): 图片.jpg 是下面a+b```` 然后连接到adder_node ,随后再连接到y(add_and_triple)```\n5.2 # That a model that can take arbitary inputs:To mode the modeel trainable,need to modify the graph to get new a outputs with the some input : Variables allow us: # w = tf.Variables([ .3], dtype = tf.float32) b = tf.Variables([ - .3], dtype = tf.float32) x = tf.placeholder(tf.float32) linear_model = w * x + b #线性模型 6 # 使用tf.constant :调用、初始化常数 用tf.Vaiables :變量不被初始化，調用欲初始化所有變量，必須calll a special operation: # init = tf.global_variables_initializer() sess.run(init) 7 # x is a placeholder, we can evaluate lnear_model for several values of x simultaneausly as follow: # print (sess.run(linear_model, {x:[1,2,3,4]})) 輸出爲： # [0. 0.30000001 0.60000002 0.90000004] 8 # 有以上結果並不知好壞，因此編寫損失函數： # y = tf.placeholder(tf.float32) squared_deltas = tf.square(linear_model - y) #平方（下方差和） loss = tf.reduce_sum(squred_deltas) #差和（上方平方） print (sess.run)loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]}) 輸出爲： # 23.66 #損失值：差平方和 8.1 # We could improve this manually W,b to perfact values of -1 and 1. A variable is initializef to the value provided to tf.Variable but can be charged using operation like tf.assign # W = -1 and b = 1 are optimal parameters:(最優參數) # fixW = tf.assign(W, [-1. ]) fixb = tf.assign(b,[1. ]) sess.run(fixW, fixb) print(sess.run(loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]})) 輸出爲： # 0, 0 # The final print shows the loss now is zero ! 9 # 模型保存与加载： # 保存： # saver = tf.train.Saver() # 生成saver with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 先对模型初始化 # 然后将数据丢入模型进行训练blablabla # 训练完以后，使用saver.save 来保存 saver.save(sess, \u0026quot;save_path/file_name\u0026quot;) #file_name如果不存在的话，会自动创建 加载： # saver = tf.train.Saver() with tf.Session() as sess: #参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的值给覆盖 sess.run(tf.global_variables_initializer()) saver.restore(sess, \u0026quot;save_path/file_name\u0026quot;) #会将已经保存的变量值resotre到 变量中。 10 # 图形化操作： # \u0026gt;http://blog.csdn.net/u014595019/article/details/53912710 这篇写的还不错，等之后用过之后再写。\nVariable # 必须用到: init = tf.initialize_all_variables()\t# 初始化全部变量 随后即可: sess.run(init)\nTensorflow 笔记 # 這是在對照官網學習時的前期入門筆記，其實和官網基本沒有區別，好吧，真的沒有區別。因爲官網真的寫的太好了。 至於我爲什麼要寫出來，是因爲我之前寫在了紙上，對於邏輯的把握很給力，所以在寫一邊。\n不過TensorFlow 變動真的很大，版本更迭也很快，所以，下方只是理清邏輯，具體的東西還是去官網比較好。只不過我這兒網謎之很難等上去…\n總而言之一句話，先搭好架子再選擇填充材料。就是它的核心邏輯了。而改進也是在架子基礎上去優化優化器。嗯…現在理解就是這樣。\n1 # 导入 # import tensorflow as tf 步骤：①构建计算图\t②运行计算图\n2 # Build a simple computational Graph # node1 = tf.contant(3.0, dtype = tf.float32) node2 = tf.contant(4.0)\t#also tf.float32 impicitly print (node1, node2) 输出为： # Tensor (\u0026quot;Cast: 0\u0026quot;, shape = (), dtype = float) Tensor (\u0026quot;Cast_1: 0\u0026quot;, shape = (), dtype = float) 打印并不输出值3.0，4.0，而在评估时分别产生3.0和4.0节点。欲实际评估节点，We must run the computational graph within a session. A seesion encapsulation the control and state of the tensorflow runtime.\n3 # Creates a session object , 然后调用run方法运行足够的computational graph to envlute node1 and node2 # sess = tf.Session() print (sess.run([node1, node2])) 输出为： # [3.0, 4.0]\t#可见预期值 4 # We can build more complicated computations by combining Tensor nodes with operations # node3 = tf.add(node1, node2) print (\u0026quot;node3: \u0026quot;, node3) print (\u0026quot;sess.run(node3):\u0026quot;, sess.run(node3)) 输出为： # node3: Tensor(\u0026quot;Add:0\u0026quot;, shape = (1,dtype = float32)) sess.run(node3): 7.0 5 # 更进一步的，A graph can be parameterized. To accept external input , 称为placeholders # a = tf.placeholder(tf.float32) b = tf.placeholder(tf.float32) adder_note = a + b\t#provide a shortcut for tf.add(a, b) and can with multiple input by using print (sess.run(add_note, {a:3, b:4.5})) print (sess.run(add_note, {a:[1, 3], b:[2, 4]})) 输出为： # 7.5 [3. 7.] 5.1 # more complex by adding anther aperation. for example: # add_and_triple = adder_note * 3 print (sess.run(add_and_triple, {a:3, b:4.5})) 输出为： # 22.5 In TensorBoard(Tensorflow圖形化界面): 图片.jpg\t是下面a+b```` 然后连接到adder_node ,随后再连接到y(add_and_triple)```\n5.2 # That a model that can take arbitary inputs:To mode the modeel trainable,need to modify the graph to get new a outputs with the some input : Variables allow us: # w = tf.Variables([ .3], dtype = tf.float32) b = tf.Variables([ - .3], dtype = tf.float32) x = tf.placeholder(tf.float32) linear_model = w * x + b\t#线性模型 6 # 使用tf.constant :调用、初始化常数 用tf.Vaiables :變量不被初始化，調用欲初始化所有變量，必須calll a special operation: # init = tf.global_variables_initializer() sess.run(init) 7 # x is a placeholder, we can evaluate lnear_model for several values of x simultaneausly as follow: # print (sess.run(linear_model, {x:[1,2,3,4]})) 輸出爲： # [0. 0.30000001 0.60000002 0.90000004] 8 # 有以上結果並不知好壞，因此編寫損失函數： # y = tf.placeholder(tf.float32) squared_deltas = tf.square(linear_model - y)\t#平方（下方差和） loss = tf.reduce_sum(squred_deltas)\t#差和（上方平方） print (sess.run)loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]}) 輸出爲： # 23.66\t#損失值：差平方和 8.1 # We could improve this manually W,b to perfact values of -1 and 1. A variable is initializef to the value provided to tf.Variable but can be charged using operation like tf.assign # W = -1 and b = 1 are optimal parameters:(最優參數) # fixW = tf.assign(W, [-1. ]) fixb = tf.assign(b,[1. ]) sess.run(fixW, fixb) print(sess.run(loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]})) 輸出爲： # 0, 0 # The final print shows the loss now is zero ! 9 # 模型保存与加载： # 保存： # saver = tf.train.Saver()\t# 生成saver with tf.Session() as sess: sess.run(tf.global_variables_initializer())\t# 先对模型初始化 # 然后将数据丢入模型进行训练blablabla # 训练完以后，使用saver.save 来保存 saver.save(sess, \u0026quot;save_path/file_name\u0026quot;)\t#file_name如果不存在的话，会自动创建 加载： # saver = tf.train.Saver() with tf.Session() as sess:\t#参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的值给覆盖 sess.run(tf.global_variables_initializer()) saver.restore(sess, \u0026quot;save_path/file_name\u0026quot;)\t#会将已经保存的变量值resotre到 变量中。 10 # 图形化操作： # \u0026lt;http://blog.csdn.net/u014595019/article/details/53912710\u0026gt; 这篇写的还不错，等之后用过之后再写。\n"},{"id":133,"href":"/docs/programmer/langs/note-for-algo/","title":"算法","section":"编程语言","content":" 算法图解 # 在线书: https://www.hello-algo.com\n单向链表实现和反转 # # 单向链表实现和反转 \u0026#34;\u0026#34;\u0026#34; # 当前值, 下一个值 # 循环 # 将当前值赋值为下一个的值, 下一个节点值为当前节点值 # 当前节点next赋 \u0026#34;\u0026#34;\u0026#34; class A: def __init__(self, v): self.v = v self.next = None class LA: def __init__(self): self.head = None def add(self, v): node = A(v) node.next = self.head self.head = node def print(self): cur = self.head while cur and cur.v != None: print(f\u0026#34;linkdata node v: {cur.v}\u0026#34;) cur = cur.next def revert(self, node: A=None, head=None): if not head: cache = self.head.next else: cache = node.next if cache: pass # print(f\u0026#34;cache: {cache.v}\u0026#34;) else: self.head = node self.head.next = head return if head == None: node = self.head node.next = None self.revert(cache, node) else: node.next = head self.revert(cache, node) if __name__ == \u0026#34;__main__\u0026#34;: # 1234 # 234 ldata = LA() for i in (1, 2, 3, 4): ldata.add(i) ldata.print() print(\u0026#34;---\u0026#34;*10) ldata.revert() ldata.print() \u0026#34;\u0026#34;\u0026#34; \u0026gt;\u0026gt;\u0026gt;运行输出: linkdata node v: 4 linkdata node v: 3 linkdata node v: 2 linkdata node v: 1 ------------------------------ linkdata node v: 1 linkdata node v: 2 linkdata node v: 3 linkdata node v: 4 \u0026#34;\u0026#34;\u0026#34; 其他 # "},{"id":134,"href":"/docs/programmer/langs/python/notespython/","title":"解决问题","section":"Python","content":"\nPiP Not Found Issue # 使用pip安装某包时， 提示让更新， 按提示操作更新没效果没反应再用就提示ModuleNotFoundError: No module named 'pip' (ˉ▽ˉ；)\u0026hellip;\nModuleNotFoundError: No module named \u0026lsquo;pip\u0026rsquo; # 升级PiP时出现问题可由下方命令修复 # python -m ensurepip python -m pip install --upgrade pip SSL校验 # 安装EasyOCR时, reader = easyocr.Reader(['ch_sim','en']) 下载到接近90,结果报错了\u0026hellip;. 估计是SSL问题加入以下两条,不知如何.\nimport ssl ssl._create_default_https_context = ssl._create_unverified_context from http.client To revert to the previous, unverified, behavior ssl._create_unverified_context() can be passed to the context parameter.\n使用国内镜像下载Python # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) # 一键更新pip 包资源(利用管道grep传输查询到的需要更新包名，传输到install命令) pip3 freeze --local | grep -v \u0026#39;^\\-e\u0026#39; | cut -d = -f 1 | xargs -n1 pip3 install -U # 权限不够的话就在`pip3 install` 之前加`sudo`反正我不习惯用`root` 安装错误？ # 居然有pip3 install XX的错误…这也是因为有旧版pip3存留。需要\n$bash -d pip3 $bash -r pip3 来清理shell中旧版pip缓存。\npip提示ModuleNotFoundError: No module named \u0026lsquo;pkg_resources\u0026rsquo; # pip下载python包一直提示ModuleNotFoundError: No module named \u0026lsquo;pkg_resources\u0026rsquo;，如下图： python -m pip install --upgrade pip setuptools wheel即可解决问题。\nPython 无处安放的野生列表 # -async def _gen_login_task_for_phone(_package_name: str, phone: CloudPhoneInfo, _used_accountid_list: List[int]=[]) -\u0026gt; TaskData: +async def _gen_login_task_for_phone(_package_name: str, phone: CloudPhoneInfo) -\u0026gt; TaskData: __time_func_start = time.time() lock_id = await PackageAccountBindInfo.acquire_restock_account_lock() __time_done_get_lock = time.time() # 查询账号前申请锁 if not lock_id: return None - using_accountid_list = await GoogleAccounts._get_using_accountid_list() + _used_accountid_list = await GoogleAccounts._get_using_accountid_list() __time_done_get_using_account = time.time() - _used_accountid_list.extend(using_accountid_list) if phone.responsible_for == 0: # 跟随最大包的切换频率 - 登陆新账号保证所有包可用 2 _account_list = await GoogleAccounts._fetch_new_acoount_by(_used_accountid_list=_used_accountid_list) @@ -85,8 +84,9 @@ async def _gen_login_task_for_phone(_package_name: str, phone: CloudPhoneInfo, _ \u0026#34;获取账号耗时\u0026#34;: __time_done_get_account - __time_done_get_using_account, \u0026#34;刷新账号使用缓存耗时\u0026#34;: __time_done_cache_history - __time_done_get_account, \u0026#34;缓存账号使用耗时\u0026#34;: __time_done_release_lock - __time_done_cache_history, + \u0026#34;长度\u0026#34;: len(_used_accountid_list), } async def _gen_login_task_for_phone(_package_name: str, phone: CloudPhoneInfo) -\u0026gt; TaskData: __time_func_start = time.time() lock_id = await PackageAccountBindInfo.acquire_restock_account_lock() __time_done_get_lock = time.time() # 查询账号前申请锁 if not lock_id: return None _used_accountid_list = await GoogleAccounts._get_using_accountid_list() __time_done_get_using_account = time.time() if phone.responsible_for == 0: # 跟随最大包的切换频率 - 登陆新账号保证所有包可用 2 _account_list = await GoogleAccounts._fetch_new_acoount_by(_used_accountid_list=_used_accountid_list) else: _account_list = await GoogleAccounts._restock_query_accounts_by( cloud_phone=phone.cloud_phone, package_name=_package_name, _used_accountid_list=_used_accountid_list, responsible_for=phone.responsible_for ) __time_done_get_account = time.time() _account = (_account_list and random.choice(_account_list)) or None return task_data 以前方法有个 _used_accountid_list 入参, 但是外面调用没有给它传值; 一直执行这个方法的话 这个列表就会无限递增起来\u0026hellip;\u0026hellip;..超级牛逼\n"},{"id":135,"href":"/docs/programmer/platforms/tips-of-problems/","title":"解决问题记录笔记","section":"平台","content":"\n各种一键问题解决方案 # Windows下Git问题 # Linux没啥问题,但在Win下报checkout失败,路径问题 git config core.protectNTFS false docker - supervisord 禁用日志文件或使用 logfile=/dev/stdout # from: https://www.coder.work/article/100835 标签 docker supervisord\n[supervisord] nodaemon=true logfile=/dev/stdout pidfile=/var/run/supervisord.pid childlogdir=/var/log/supervisor 当我这样做时，这个主管会崩溃，因为它无法在/dev/stdout 中寻找\n如何禁用 supervisord 在我的 docker 容器中创建任何日志文件？\n最佳答案\n对于主主管，nodaemon 将导致日志转到 stdout\n[supervisord] nodaemon=true logfile=/dev/null logfile_maxbytes=0 然后将每个托管进程的日志发送到标准输出文件描述符/dev/fd/1\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 redirect_stderr=true 或者，如果您希望将 stderr 保留在不同的流上:\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 stderr_logfile=/dev/fd/2 stderr_logfile_maxbytes=0 关于docker - supervisord 禁用日志文件或使用 logfile=/dev/stdout，我们在Stack Overflow上找到一个类似的问题： https://stackoverflow.com/questions/45645758/\ndocker中执行sed报Device or resource busy错误的处理原因及方式 转载 # kuSorZ 博主文章分类：Linux 文章标签: docker | sed 文章分类: Docker 原文出处： https://www.cnblogs.com/xuxinkun/p/7116737.html错误现象\n在docker容器中想要修改/etc/resolv.conf中的namesever，使用sed命令进行执行时遇到错误：\n/ # sed -i \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf sed: can\u0026rsquo;t move \u0026lsquo;/etc/resolv.conf73UqmG\u0026rsquo; to \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n但是可以通过vi/vim直接修改这个文件/etc/resolv.conf这个文件的内容。 问题原因\nsed命令的实质并不是修改文件，而是产生一个新的文件替换原有的文件。这里我们做了一个实验。\n我先创建了一个test.txt的文件，文件内容是123。然后我使用sed命令对文件内容进行了替换。再次查看test.txt。\n/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 265 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:28:35.000000000Modify: 2017-07-04 06:28:17.000000000Change: 2017-07-04 06:29:03.000000000/ # cat test.txt 123/ # sed -i \u0026rsquo;s/123/321/g\u0026rsquo; test.txt/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 266 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:29:31.000000000Modify: 2017-07-04 06:29:31.000000000Change: 2017-07-04 06:29:31.000000000/ # cat test.txt321\n可以看到文件内容被正确修改了，但是同时，文件的inode也修改了。说明了实质上是新生成的文件替换了原有的文件。但是vim/vi是在原文件基础上修改的，所以inode没有变化。\n在docker中，/etc/resolv.conf是通过挂载入容器的。所以当你想去删除这个挂载文件，也就是挂载点时，自然就会报Device or resource busy。\n这个跟是不是特权privilege没有关系。即使是privilege的容器，也会有这个问题。 / # rm /etc/resolv.conf rm: can\u0026rsquo;t remove \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n其实不仅仅/etc/resolv.conf，还有/etc/hostname，/etc/hosts等文件都是通过挂载方式挂载到容器中来的。所以想要用sed对他们进行修改，都会遇到这样的问题。我们可以通过df -h查看容器内的挂载情况。\n/ # df -h Filesystem Size Used Available Use% Mounted on/dev/mapper/docker-253:2-807144231-37acfcd86387ddcbc52ef8dac69d919283fc5d9d8ab5f55fd23d1c782e3b1c70 10.0G 33.8M 10.0G 0% /tmpfs 15.4G 0 15.4G 0% /devtmpfs 15.4G 0 15.4G 0% /sys/fs/cgroup/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /run/secrets/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /dev/termination-log/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/resolv.conf/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostname/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostsshm 64.0M 0 64.0M 0% /dev/shmtmpfs 15.4G 0 15.4G 0% /proc/kcoretmpfs 15.4G 0 15.4G 0% /proc/timer_stats\n如何解决\n使用vi固然可以，但是对于批量操作就不是很合适了。可以通过sed和echo的组合命令echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf 即可实现替换。\n/ # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.1options ndots:5/ # echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf / # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.254options ndots:5\n这里如果使用sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf \u0026gt; /etc/resolv.conf是无效的。最终会导致/etc/resolv.conf内容为空。\n示例 # Dockerfile # CMD mkdir -p /var/log/scancenter \\ \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \\ \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini --log-master k8s yaml # spec: containers: - command: - /bin/sh - -c - mkdir -p /var/log/scancenter \u0026amp;\u0026amp; echo -e \u0026#34;10.120.16.12\\tapi.s.com\\n10.5.25.5\\tpp.api.com\u0026#34; \u0026gt;\u0026gt; /etc/hosts \u0026amp;\u0026amp; echo \u0026#34;$(sed \u0026#39;s/^-e //g\u0026#39; /etc/hosts)\u0026#34; \u0026gt; /etc/hosts \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP "}]