[{"id":0,"href":"/docs/programmer/","title":"程序员笔记","section":"Docs","content":" 简介 # 包含基本知识、后端、前端、网络等，还有一些交叉领域。\n"},{"id":1,"href":"/docs/example/","title":"Example Site","section":"Docs","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret Est simul fameque tauri qua ad # Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol # Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo; Trepident sitimque # Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"},{"id":2,"href":"/docs/example/table-of-contents/with-toc/","title":"With ToC","section":"Table of Contents","content":" Caput vino delphine in tamen vias # Cognita laeva illo fracta # Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\nTe at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit Natus quaerere # Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\nPhrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\nLimitibus misere sit # Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua # Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta # Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"},{"id":3,"href":"/docs/example/table-of-contents/without-toc/","title":"Without ToC","section":"Table of Contents","content":" At me ipso nepotibus nunc celebratior genus # Tanto oblite # Lorem markdownum pectora novis patenti igne sua opus aurae feras materiaque illic demersit imago et aristas questaque posset. Vomit quoque suo inhaesuro clara. Esse cumque, per referri triste. Ut exponit solisque communis in tendens vincetis agisque iamque huic bene ante vetat omina Thebae rates. Aeacus servat admonitu concidit, ad resimas vultus et rugas vultu dignamque Siphnon.\nQuam iugulum regia simulacra, plus meruit humo pecorumque haesit, ab discedunt dixit: ritu pharetramque. Exul Laurenti orantem modo, per densum missisque labor manibus non colla unum, obiectat. Tu pervia collo, fessus quae Cretenque Myconon crate! Tegumenque quae invisi sudore per vocari quaque plus ventis fluidos. Nodo perque, fugisse pectora sorores.\nSumme promissa supple vadit lenius # Quibus largis latebris aethera versato est, ait sentiat faciemque. Aequata alis nec Caeneus exululat inclite corpus est, ire tibi ostendens et tibi. Rigent et vires dique possent lumina; eadem dixit poma funeribus paret et felix reddebant ventis utile lignum.\nRemansit notam Stygia feroxque Et dabit materna Vipereas Phrygiaeque umbram sollicito cruore conlucere suus Quarum Elis corniger Nec ieiunia dixit Vertitur mos ortu ramosam contudit dumque; placabat ac lumen. Coniunx Amoris spatium poenamque cavernis Thebae Pleiadasque ponunt, rapiare cum quae parum nimium rima.\nQuidem resupinus inducto solebat una facinus quae # Credulitas iniqua praepetibus paruit prospexit, voce poena, sub rupit sinuatur, quin suum ventorumque arcadiae priori. Soporiferam erat formamque, fecit, invergens, nymphae mutat fessas ait finge.\nBaculum mandataque ne addere capiti violentior Altera duas quam hoc ille tenues inquit Sicula sidereus latrantis domoque ratae polluit comites Possit oro clausura namque se nunc iuvenisque Faciem posuit Quodque cum ponunt novercae nata vestrae aratra Ite extrema Phrygiis, patre dentibus, tonso perculit, enim blanda, manibus fide quos caput armis, posse! Nocendo fas Alcyonae lacertis structa ferarum manus fulmen dubius, saxa caelum effuge extremis fixum tumor adfecit bella, potentes? Dum nec insidiosa tempora tegit spirarunt. Per lupi pars foliis, porreximus humum negant sunt subposuere Sidone steterant auro. Memoraverit sine: ferrum idem Orion caelum heres gerebat fixis?\n"},{"id":4,"href":"/docs/example/table-of-contents/","title":"Table of Contents","section":"Example Site","content":" Ubi loqui # Mentem genus facietque salire tempus bracchia # Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice # Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); Placabilis coactis nega ingemuit ignoscat nimia non # Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; } Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":5,"href":"/docs/programmer/gui/","title":"Gui","section":"程序员笔记","content":" 桌面应用开发 # Qt PyQt(PySide) "},{"id":6,"href":"/docs/programmer/hardware/","title":"Hardware","section":"程序员笔记","content":" 桌面应用开发 # Qt PyQt(PySide) "},{"id":7,"href":"/docs/programmer/software/","title":"Software","section":"程序员笔记","content":" 桌面应用开发 # Qt PyQt(PySide) "},{"id":8,"href":"/docs/programmer/base/k8s-%E9%85%8D%E5%A5%97%E8%AF%B4%E6%98%8E/","title":"k8s 配套说明","section":"Base","content":" ctr # 如果定义了 -n 应该是namesplace 那么每个命令都得跟上\nload镜像 # sudo ctr -n=k8s.io images import ${imageTarFile}\n保存文件 # sudo ctr -n k8s.io images export \u0026ndash;platform=linux/amd64 hi.tar 101.32.1.4:30002/web-docker/worker:2121\n切换tag # sudo ctr -n k8s.io images tag \u0026ndash;force repos.x.com/web-docker/worker:2121 101.32.1.4:30002/web-docker/worker:2121\n推送镜像 # sudo ctr -n k8s.io images push -k -u admin:fat213asfdFS2W \u0026ndash;plain-http 101.32.1.4:30002/web-docker/worker:2121\n拉取 # sudo ctr -n k8s.io images pull -k -u admin:fat1239ASD124W \u0026ndash;plain-http 101.32.1.4:30002/web-docker/worker:2121\nDocker # [[noteOfdocker]] 好像并没有整理docker命令\u0026hellip; 后续补吧\n加载镜像 # docker load -i .\\hi.tar\n保存为本地文件 # docker save repos.x.com/web-docker/worker:2121 -o hi.tar\n"},{"id":9,"href":"/docs/programmer/base/k8s-%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/","title":"k8s技术分享","section":"Base","content":" k8s技术分享 # 工作负载资源 # 一、pod # 1. 概要 # 可创建管理、最小的可部署计算单元，是可以在主机上运行的容器的集合 我们的服务都在其中运行。如我们的服务是nginx，则最内层是我们的服务 nginx，运行在 container 容器当中。container (容器) 的本质是进程，而 pod 是管理这一组进程的资源 所以pod可视为一个极为轻量化、没插网线的电脑，如果所需任务无需交互，那么用pod就很合适。例如给它挂载一个文件来训练模型、生成报表，可以根据场景使用 Job 或者 CronJob 或者其它 图示关系如下 # ![[k8s-pod-insert.png]]\n2. pod网络 # 当然，pod 可以管理多个 container，又因为container (容器) 的本质是进程，如果有本地网络通信需求(使用 localhost 或者 Socket 文件进行本地通信)，在这些场景中使用 pod 管理多个 container 就非常的推荐。\n如下图展示了Pod网络所依赖的3个网络设备\n1. eth0是节点主机上的网卡，支持该节点流量出入的设备、也是支持集群节点间IP寻址和互通的设备；\n2. docker0是一个虚拟网桥，可以简单理解为一个虚拟交换机，支持该节点上的Pod之间进行IP寻址和互通的设备；\n3. veth0则是Pod1的虚拟网卡，支持该Pod内容器互通和对外访问的虚拟设备；\n4. docker0网桥和veth0网卡，都是linux支持和创建的虚拟网络设备；\n5. pause属于特殊容器，其运行的唯一目的是为Pod建立共享的veth0网络接口\n![[k8s-nginx-pod.png]]\n二、deployment、StatefulSet # 1. 概要 # Deployment 使得 Pod 和 ReplicaSet 能够进行声明式更新\nStatefulSet 表示一组具有一致身份的 Pod：\n1. 身份定义为：\n- 网络：一个稳定的 DNS 和主机名。\n- 存储：根据要求提供尽可能多的 VolumeClaim。\nStatefulSet 保证给定的网络身份将始终映射到相同的存储身份。\n虽然pod完全具备在生产环境中部署独立的单体服务的能力，但在生产环境中，我们基本上不会直接管理 pod，我们会使用deployment 代为控管。延续上面的比喻就是将 deployment 视为一个好用的机房管理员：帮助我们进货，对pod进行开关机，对pod做系统升级和重装系统以实现功能升级和回滚。 StatefulSet 也相同，只不过每次它会保证一致性，而不像deployment 每次重启都是随机分配\n2. 滚动升级 # 至于为什么需要 deployment 协助我们管理，可以参考下图了解一下滚动升级的流程，并想象一下自己手动操作pod的复杂度（使用 kubectl get pods --watch 可在终端中查看pod变化）： ![[k8s-pod-rollupdate.png]]\n3. 分界线 # 了解完以上信息就已经足够覆盖大多数开发需求，就如去网吧玩游戏、来公司上班，我们都不会去关注网络，而只关心游戏是否流畅输赢，工作进度是否顺畅。因为各个服务间的网络依赖就应该长久保持稳定，不宜做高频调整。除非出现问题，或者恰好我们需要重头搭建这部分，那么我们首先需要考虑的就是网络关系。\nService资源 # Service、Ingress # 1. 概要 # Service 是软件服务（例如 mysql）的命名抽象，包含代理要侦听的本地端口（例如 3306）和一个选择算符，选择算符用来确定哪些 Pod 将响应通过代理发送的请求。 Ingress 是允许入站连接到达后端定义的端点的规则集合。Ingress 是允许入站连接到达后端定义的端点的规则集合。 Service 就相当于给上述pod组成的服务插上了一条稳定的网线（当然不仅如此），使之可以通过网络通信，而 Ingress 则负责对外，相当于之前的web部署方案中 nginx 扮演的角色，将外部调用通过规则，将请求转发到相应的 Service 上。\n2. Service网络原理 # 首先我们熟悉DNS，再者我们知道通过 deployment 管理的pod每次重启都是重新生成、重新分配网络的，最后我们知道k8s是有一个\n配置和存储资源 # ConfigMap、Secret、Volume\n身份认证资源 # ServiceAccount\n鉴权资源 # ClusterRole、ClusterRoleBinding\n其他 # LimitRange、NetworkPolicy\nNode、Namespace\n网络 # 深入理解k8s 网络：https://www.jianshu.com/p/80eb2e9e32db\n示意图 # 来源https://github.com/guangzhengli/k8s-tutorials\nkubectl get pods # NAME READY STATUS RESTARTS AGE # hellok8s-deployment-5d5545b69c-24lw5 1/1 Running 0 27m # hellok8s-deployment-5d5545b69c-9g94t 1/1 Running 0 27m # hellok8s-deployment-5d5545b69c-9gm8r 1/1 Running 0 27m # nginx 1/1 Running 0 41m kubectl get service # NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE # service-hellok8s-clusterip ClusterIP 10.104.96.153 \u0026lt;none\u0026gt; 3000/TCP 10s kubectl exec -it nginx-pod /bin/bash # root@nginx-pod:/# curl 10.104.96.153:3000 # [v3] Hello, Kubernetes!, From host: hellok8s-deployment-5d5545b69c-9gm8r # root@nginx-pod:/# curl 10.104.96.153:3000 #[v3] Hello, Kubernetes!, From host: hellok8s-deployment-5d5545b69c-9g94t 可以看到，我们多次 curl 10.104.96.153:3000 访问 hellok8s Service IP 地址，返回的 hellok8s:v3 hostname 不一样，说明 Service 可以接收请求并将它们传递给它后面的所有 pod，还可以自动负载均衡。你也可以试试增加或者减少 hellok8s:v3 pod 副本数量，观察 Service 的请求是否会动态变更。调用过程如下图所示：\nNodePort (负载均衡(略)) # 我们知道kubernetes 集群并不是单机运行，它管理着多台节点即 Node，可以通过每个节点上的 IP 和静态端口（NodePort）暴露服务。如下图所示，如果集群内有两台 Node 运行着 hellok8s:v3，我们创建一个 NodePort 类型的 Service，将 hellok8s:v3 的 3000 端口映射到 Node 机器的 30000 端口 (在 30000-32767 范围内)，就可以通过访问 http://node1-ip:30000 或者 http://node2-ip:30000 访问到服务。 ![[k8s-svc-nodeport.png]]\nIngress ![[k8s-ingress.png]]\n"},{"id":10,"href":"/docs/programmer/net/uwsgi-%E5%A4%84%E7%90%86%E8%AE%B0%E5%BD%95/","title":"uwsgi 处理记录","section":"Net","content":" 日志输出到终端 # uwsgi.ini文件中配置\nlog-master = true ; logto=/var/log/uwsgi.log 同时这行不能有 启动命令: uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini --log-master\n隔一段时间卡死,重启不能 # 当作为纯后端API使用时, 使用 http-socket 不使用 http\n使用supervisor管理uwsgi # #daemonize=/var/log/uwsgi8011.log # 守护进程一定要注释掉(关键)\n查看性能数据 # 安装 uwsgitop 查看 uwsgi stats写入位置 查看 pip install uwsgitop cat /opt/trunk/textcheck/3rd/uwsgi/config.ini | grep stats # \u0026gt; stats=/var/run/uwsgi/uwsgi.status uwsgitop /var/run/uwsgi/uwsgi.status # \u0026gt; uwsgi-2.0.19.1 - Wed Oct 18 18:13:48 2023 - req: 113 - RPS: 0 - lq: 0 - tx: 75.1K node: app-58d8477f4-26fzb - cwd: /app - uid: 0 - gid: 0 - masterpid: 8 WID % PID REQ RPS EXC SIG STATUS AVG RSS VSZ TX ReSpwn HC RunT LastSpwn 1 28.3 132942 32 0 0 0 idle 19161ms 0 0 15.2K 1 0 155394.03 17:34:42 2 28.3 132950 32 0 0 0 idle 1781ms 0 0 20.1K 1 0 126123.093 17:34:42 3 22.1 132958 25 0 0 0 idle 5982ms 0 0 16.9K 1 0 127199.778 17:34:42 4 21.2 132963 24 0 0 0 idle 15274ms 0 0 22.8K 1 0 144018.093 17:34:42\n"},{"id":11,"href":"/docs/programmer/base/k8s%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/","title":"k8s学习-常用命令和配置文件","section":"Base","content":"\nk8s学习 # 常用命令 # kubectl apply -f rcm_log_monut_k8s_pod.yaml kubectl get pod -A kubectl get pod -all-namespaces kubectl get node kubectl get deploy 持久卷 - PersistentVolume kubectl get persistentvolume kubectl describe persistentvolume example-pv kubectl **delete** persistentvolume example-pv 从kubectl cp -n \u0026lt;命名空间\u0026gt; -c :xxx.json xxx.json configmap / secret 存储文件内容 # sftpkey 为名称\n新建 # kubectl create secret generic sftpkey --from-file=/etc/id_rsa # kubectl create -n {NAMESPACE} secret generic sftpkey --from-file=/etc/id_rsa 删除 # kubectl delete secret sftpkey\n常用字段 # 下面是一些 Kubernetes 中常用的配置字段：\napiVersion： Kubernetes API 的版本，用于定义资源的 API 版本号。 kind： 资源的类型，比如 Pod、Deployment、Service 等。 metadata： 元数据字段，用于存储 Kubernetes 对象的名称、命名空间、标签等信息。 spec： 对象的规格，用于定义对象的期望状态，如 Pod 的容器、Service 的端口等。 status： 对象的状态，用于记录对象的实际状态，如 Pod 的运行状态、Service 的访问地址等。 另外还有一些常用的子字段，如：\ncontainers： Pod 中的容器定义，包括容器名称、镜像、命令、参数等。 ports： Service 中的端口定义，包括端口名称、协议、端口号、目标端口号等。 selector： Service 中用于选择后端 Pod 的标签选择器。 replicas： Deployment 中期望的副本数。 template： Deployment 中用于创建 Pod 的 PodTemplateSpec 定义。 其他 # 在 Kubernetes 中，annotations 字段是资源对象中的一个元数据字段，用于存储一些非标准化的元数据信息。与 metadata 字段中的标准化信息不同，annotations 字段中存储的信息往往是自定义的、不易归类的数据，比如代码库的提交 ID、配置文件的 MD5 校验值、外部系统的关联信息等等。\nannotations # 字段的格式为一个 key-value 对的列表，其中 key 表示注解的名称，value 表示注解的值。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod annotations: commit-id: abc123 spec: containers: - name: my-container image: my-image 在这个示例中，我们在 Pod 的 metadata 中添加了一个自定义注解 commit-id，并将其值设置为 abc123。这个注解表示当前 Pod 对应的代码库的提交 ID。\n需要注意的是，由于 annotations 字段是用于存储自定义元数据信息的，因此在使用时需要注意避免与其他标准化的字段发生冲突，以免产生意外的后果。同时，由于注解的值可以是任意字符串，因此需要对注解的内容进行适当的验证和转义，以避免安全风险\nownerReferences 字段 # 在 Kubernetes 中，ownerReferences 字段是资源对象中的一个元数据字段，用于指定当前对象的所有者（owner）。这个字段可以用来建立资源对象之间的父子关系，便于管理和垃圾回收。在一个资源对象中，可以同时指定多个父对象（owner）。\nownerReferences 字段的格式为一个包含多个 ownerReference 对象的列表。每个 ownerReference 对象表示一个父对象的引用，其中包含了父对象的 API 版本、资源类型、名称和 UID。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod ownerReferences: - apiVersion: apps/v1 kind: Deployment name: my-deployment uid: abc123 - apiVersion: apps/v1 kind: ReplicaSet name: my-replicaset uid: def456 spec: containers: - name: my-container image: my-image 这段 YAML 文件描述了一个名为 my-pod 的 Pod 对象，它有两个父对象，分别是一个 Deployment 和一个 ReplicaSet。其中，Deployment 的名称为 my-deployment，UID 为 abc123，ReplicaSet 的名称为 my-replicaset，UID 为 def456。 该 Pod 中只包含一个容器，名称为 my-container，使用镜像为 my-image。 需要注意的是，这个 Pod 对象的 ownerReferences 字段表示它是 Deployment 和 ReplicaSet 的子对象，当这两个父对象被删除时，该 Pod 对象也会被自动删除。另外，这个 Pod 对象和其父对象都属于同一个命名空间，因为没有在 metadata 中指定 namespace 字段 在这个示例中，我们在 Pod 的 metadata 中添加了两个父对象，分别是一个 Deployment 和一个 ReplicaSet。这些信息可以帮助 Kubernetes 更好地管理这些对象之间的依赖关系，便于进行垃圾回收和版本控制。\n需要注意的是，ownerReferences 字段中的对象必须是同一个命名空间中的资源对象，否则会引发错误。另外，在使用 ownerReferences 字段时需要注意避免循环引用的问题，以免产生意外的后果。\nownerReferences 中的name和该pod name相同有什么作用？ # 在 Kubernetes 中，如果一个资源对象的 ownerReferences 中的 name 字段与当前对象的 metadata 中的 name 字段相同，表示当前对象是父对象（owner）自己创建的。这种情况下，父对象的控制器不会对这个对象进行垃圾回收，因为这个对象本身就是父对象的一部分。\n例如，在一个 Deployment 中创建了一个 Pod，并且将 Pod 的 ownerReferences 中的 name 字段设置为 Pod 的名称。这样一来，当 Deployment 被删除时，由于 Pod 依赖于 Deployment，Kubernetes 会先删除 Deployment，然后再删除 Pod。在删除 Pod 时，由于 Pod 的 ownerReferences 中的 name 字段与 Pod 的 metadata 中的 name 字段相同，所以控制器不会对 Pod 进行垃圾回收，而是保留下来作为 Deployment 的一部分。\n通过这种方式，我们可以在 Kubernetes 中建立资源对象之间更加复杂的关系，实现更高级别的控制和管理。例如，可以通过设置 ownerReferences 字段来建立 Deployment 和 Service 的关系，从而实现负载均衡和服务发现。\nenv 环境变量 # spec: containers: - env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_OWN_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: POD_OWN_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace 这段 YAML 文件描述了一个 Pod 中的三个环境变量。这些环境变量的值是从 Kubernetes 中获取的，而不是直接在 Pod 中指定的。\n其中，POD_IP_ADDRESS 环境变量的值使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的状态中获取 podIP 字段的值。POD_IP_ADDRESS 环境变量的值就是当前 Pod 的 IP 地址。\nPOD_OWN_NAME 和 POD_OWN_NAMESPACE 环境变量的值也使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的元数据中获取 name 和 namespace 字段的值。POD_OWN_NAME 环境变量的值就是当前 Pod 的名称，POD_OWN_NAMESPACE 环境变量的值就是当前 Pod 所属的命名空间。\n这种方式可以让我们在定义 Pod 时，动态地获取 Pod 自身的元数据和状态信息，并将这些信息作为环境变量传递给 Pod 中的容器。在容器中，我们可以通过读取这些环境变量的值，来获取当前 Pod 的一些重要信息\ninitContainers # dnsPolicy: ClusterFirst enableServiceLinks: true initContainers: - command: - sh - -c - until nc -zvw3 hello-redis-svc.hello-prod.svc.cluster.local 6379; do echo Waiting hello-redis; sleep 5; done; image: xxxx.docker.io/hello-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-redis resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true - command: - sh - -c - until nc -zvw3 hello-mongodb-svc.hello.svc.cluster.local 27017; do echo Waiting hello-mongodb; sleep 5; done; image: xxxx.docker.io/hello-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-mongodb resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true 这段 YAML 配置是关于 Kubernetes 中的初始化容器（initContainers）的。 初始化容器是在 Pod 中所有容器启动之前运行的容器，用于预处理或准备容器的某些方面。 在这个 YAML 配置中，定义了两个初始化容器 init-redis 和 init-mongodb，分别检查 hello-redis 和 hello-mongodb 是否准备就绪。具体地，这两个初始化容器在容器内运行了一个 until 循环，每 5 秒尝试连接 hello-redis 或 hello-mongodb 服务，并打印 Waiting hello-redis 或 Waiting hello-mongodb 的日志信息。如果连接成功，则退出循环，容器初始化成功。初始化容器的镜像是 xxxx.docker.io/hello-docker/busybox:1.28.1，使用 IfNotPresent 策略拉取镜像。其中 resources 字段定义了该容器的资源限制和请求，volumeMounts 字段定义了将哪些存储卷挂载到该容器的哪些路径。 一些杂项 # nodeName: Pod所要调度的节点名称。 nodeSelector: 用于指定Pod所需的标签，使Pod只能被具有特定标签的节点调度。 preemptionPolicy: Pod优先级抢占策略。如果当前节点资源不足，可以抢占优先级低的Pod来为优先级高的Pod腾出资源。PreemptLowerPriority表示低优先级的Pod可以被抢占。 priority: Pod的优先级，数值越高表示优先级越高。 restartPolicy: Pod的重启策略，可以是Always、OnFailure或Never。Always表示Pod一旦终止就会自动重启，OnFailure表示只有在非0退出码时才会重启，Never表示不会自动重启。 schedulerName: 指定Pod使用的调度器。 securityContext: Pod的安全上下文。 serviceAccount: 默认使用的服务账户。 serviceAccountName: 指定使用的服务账户名称。 terminationGracePeriodSeconds: Pod终止的优雅期，即Pod终止时等待多长时间后强制终止。默认为30秒 其余一些状态信息 status : podIPs phase: Running phase initContainerStatuses containerStatuses containerStatuses conditions 持久卷 - PersistentVolume # 需要注意的是，PersistentVolume 是一个集群级别的资源，不属于任何一个命名空间，但可以通过在 metadata 字段中指定 namespace 字段来将其关联到某个命名空间中。这个关联只是用来方便查找和管理资源，不会对 PersistentVolume 对象本身产生影响。\n知识问答 # 1. nodeSelector 和 nodeSelectorTerms 有什么区别？ # ChatGPT:\n在 Kubernetes 中，nodeSelector 和 nodeSelectorTerms 都是用来选择哪些节点可以运行 Pod 的。 nodeSelector 是 PodSpec 中的一个字段，它用于指定一个键值对，只有运行在具有指定标签的节点上的 Pod 才会被调度到该节点上。例如： apiVersion: v1 kind: Pod metadata: name: my-pod spec: nodeSelector: kubernetes.io/hostname: node-1 containers: - name: my-container image: my-image 在上面的示例中，nodeSelector 字段指定了 Pod 只能调度到具有标签 kubernetes.io/hostname=node-1 的节点上。 而 nodeSelectorTerms 是一个更高级别的机制，它允许在一个 Pod 中指定多个选择条件。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod spec: nodeSelector: matchExpressions: - {key: zone, operator: In, values: [east, west]} - {key: region, operator: NotIn, values: [us-east-1]} matchLabels: environment: production containers: - name: my-container image: my-image 在上面的示例中，nodeSelector 字段指定了多个选择条件。其中 matchExpressions 指定了两个表达式，一个是 zone 标签的值必须是 east 或 west，另一个是 region 标签的值不能是 us-east-1。而 matchLabels 指定了 environment 标签的值必须是 production。\n因此，nodeSelector 只能指定一个选择条件，而 nodeSelectorTerms 可以指定多个选择条件。\\\n常用命令 # kubectl apply -f rcm_log_monut_k8s_pod.yaml 持久卷 - PersistentVolume kubectl get persistentvolume kubectl describe persistentvolume example-pv kubectl **delete** persistentvolume example-pv 常用字段 # 下面是一些 Kubernetes 中常用的配置字段：\napiVersion： Kubernetes API 的版本，用于定义资源的 API 版本号。 kind： 资源的类型，比如 Pod、Deployment、Service 等。 metadata： 元数据字段，用于存储 Kubernetes 对象的名称、命名空间、标签等信息。 spec： 对象的规格，用于定义对象的期望状态，如 Pod 的容器、Service 的端口等。 status： 对象的状态，用于记录对象的实际状态，如 Pod 的运行状态、Service 的访问地址等。 另外还有一些常用的子字段，如：\ncontainers： Pod 中的容器定义，包括容器名称、镜像、命令、参数等。 ports： Service 中的端口定义，包括端口名称、协议、端口号、目标端口号等。 selector： Service 中用于选择后端 Pod 的标签选择器。 replicas： Deployment 中期望的副本数。 template： Deployment 中用于创建 Pod 的 PodTemplateSpec 定义。 其他 # 在 Kubernetes 中，annotations 字段是资源对象中的一个元数据字段，用于存储一些非标准化的元数据信息。与 metadata 字段中的标准化信息不同，annotations 字段中存储的信息往往是自定义的、不易归类的数据，比如代码库的提交 ID、配置文件的 MD5 校验值、外部系统的关联信息等等。\nannotations # 字段的格式为一个 key-value 对的列表，其中 key 表示注解的名称，value 表示注解的值。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod annotations: commit-id: abc123 spec: containers: - name: my-container image: my-image 在这个示例中，我们在 Pod 的 metadata 中添加了一个自定义注解 commit-id，并将其值设置为 abc123。这个注解表示当前 Pod 对应的代码库的提交 ID。\n需要注意的是，由于 annotations 字段是用于存储自定义元数据信息的，因此在使用时需要注意避免与其他标准化的字段发生冲突，以免产生意外的后果。同时，由于注解的值可以是任意字符串，因此需要对注解的内容进行适当的验证和转义，以避免安全风险\nownerReferences 字段 # 在 Kubernetes 中，ownerReferences 字段是资源对象中的一个元数据字段，用于指定当前对象的所有者（owner）。这个字段可以用来建立资源对象之间的父子关系，便于管理和垃圾回收。在一个资源对象中，可以同时指定多个父对象（owner）。\nownerReferences 字段的格式为一个包含多个 ownerReference 对象的列表。每个 ownerReference 对象表示一个父对象的引用，其中包含了父对象的 API 版本、资源类型、名称和 UID。例如：\napiVersion: v1 kind: Pod metadata: name: my-pod ownerReferences: - apiVersion: apps/v1 kind: Deployment name: my-deployment uid: abc123 - apiVersion: apps/v1 kind: ReplicaSet name: my-replicaset uid: def456 spec: containers: - name: my-container image: my-image 这段 YAML 文件描述了一个名为 my-pod 的 Pod 对象，它有两个父对象，分别是一个 Deployment 和一个 ReplicaSet。其中，Deployment 的名称为 my-deployment，UID 为 abc123，ReplicaSet 的名称为 my-replicaset，UID 为 def456。 该 Pod 中只包含一个容器，名称为 my-container，使用镜像为 my-image。 需要注意的是，这个 Pod 对象的 ownerReferences 字段表示它是 Deployment 和 ReplicaSet 的子对象，当这两个父对象被删除时，该 Pod 对象也会被自动删除。另外，这个 Pod 对象和其父对象都属于同一个命名空间，因为没有在 metadata 中指定 namespace 字段 在这个示例中，我们在 Pod 的 metadata 中添加了两个父对象，分别是一个 Deployment 和一个 ReplicaSet。这些信息可以帮助 Kubernetes 更好地管理这些对象之间的依赖关系，便于进行垃圾回收和版本控制。\n需要注意的是，ownerReferences 字段中的对象必须是同一个命名空间中的资源对象，否则会引发错误。另外，在使用 ownerReferences 字段时需要注意避免循环引用的问题，以免产生意外的后果。\nownerReferences 中的name和该pod name相同有什么作用？ # 在 Kubernetes 中，如果一个资源对象的 ownerReferences 中的 name 字段与当前对象的 metadata 中的 name 字段相同，表示当前对象是父对象（owner）自己创建的。这种情况下，父对象的控制器不会对这个对象进行垃圾回收，因为这个对象本身就是父对象的一部分。\n例如，在一个 Deployment 中创建了一个 Pod，并且将 Pod 的 ownerReferences 中的 name 字段设置为 Pod 的名称。这样一来，当 Deployment 被删除时，由于 Pod 依赖于 Deployment，Kubernetes 会先删除 Deployment，然后再删除 Pod。在删除 Pod 时，由于 Pod 的 ownerReferences 中的 name 字段与 Pod 的 metadata 中的 name 字段相同，所以控制器不会对 Pod 进行垃圾回收，而是保留下来作为 Deployment 的一部分。\n通过这种方式，我们可以在 Kubernetes 中建立资源对象之间更加复杂的关系，实现更高级别的控制和管理。例如，可以通过设置 ownerReferences 字段来建立 Deployment 和 Service 的关系，从而实现负载均衡和服务发现。\nenv 环境变量 # spec: containers: - env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP - name: POD_OWN_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.name - name: POD_OWN_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace 这段 YAML 文件描述了一个 Pod 中的三个环境变量。这些环境变量的值是从 Kubernetes 中获取的，而不是直接在 Pod 中指定的。\n其中，POD_IP_ADDRESS 环境变量的值使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的状态中获取 podIP 字段的值。POD_IP_ADDRESS 环境变量的值就是当前 Pod 的 IP 地址。\nPOD_OWN_NAME 和 POD_OWN_NAMESPACE 环境变量的值也使用了 valueFrom 字段，并指定了一个 fieldRef，用于从当前 Pod 的元数据中获取 name 和 namespace 字段的值。POD_OWN_NAME 环境变量的值就是当前 Pod 的名称，POD_OWN_NAMESPACE 环境变量的值就是当前 Pod 所属的命名空间。\n这种方式可以让我们在定义 Pod 时，动态地获取 Pod 自身的元数据和状态信息，并将这些信息作为环境变量传递给 Pod 中的容器。在容器中，我们可以通过读取这些环境变量的值，来获取当前 Pod 的一些重要信息\ninitContainers # dnsPolicy: ClusterFirst enableServiceLinks: true initContainers: - command: - sh - -c - until nc -zvw3 bsa-redis-svc.bsa-prod.svc.cluster.local 6379; do echo Waiting BSA-redis; sleep 5; done; image: repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-redis resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true - command: - sh - -c - until nc -zvw3 bsa-mongodb-svc.bsa-paas.svc.cluster.local 27017; do echo Waiting BSA-mongodb; sleep 5; done; image: repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1 imagePullPolicy: IfNotPresent name: init-mongodb resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-pp4tg readOnly: true 这段 YAML 配置是关于 Kubernetes 中的初始化容器（initContainers）的。 初始化容器是在 Pod 中所有容器启动之前运行的容器，用于预处理或准备容器的某些方面。 在这个 YAML 配置中，定义了两个初始化容器 init-redis 和 init-mongodb，分别检查 BSA-redis 和 BSA-mongodb 是否准备就绪。具体地，这两个初始化容器在容器内运行了一个 until 循环，每 5 秒尝试连接 BSA-redis 或 BSA-mongodb 服务，并打印 Waiting BSA-redis 或 Waiting BSA-mongodb 的日志信息。如果连接成功，则退出循环，容器初始化成功。初始化容器的镜像是 repos-wh.inone.nsfocus.com/bsa-3rd-docker/busybox:1.28.1，使用 IfNotPresent 策略拉取镜像。其中 resources 字段定义了该容器的资源限制和请求，volumeMounts 字段定义了将哪些存储卷挂载到该容器的哪些路径。 scancenter - init项目\n一些杂项 # nodeName: Pod所要调度的节点名称。 nodeSelector: 用于指定Pod所需的标签，使Pod只能被具有特定标签的节点调度。 preemptionPolicy: Pod优先级抢占策略。如果当前节点资源不足，可以抢占优先级低的Pod来为优先级高的Pod腾出资源。PreemptLowerPriority表示低优先级的Pod可以被抢占。 priority: Pod的优先级，数值越高表示优先级越高。 restartPolicy: Pod的重启策略，可以是Always、OnFailure或Never。Always表示Pod一旦终止就会自动重启，OnFailure表示只有在非0退出码时才会重启，Never表示不会自动重启。 schedulerName: 指定Pod使用的调度器。 securityContext: Pod的安全上下文。 serviceAccount: 默认使用的服务账户。 serviceAccountName: 指定使用的服务账户名称。 terminationGracePeriodSeconds: Pod终止的优雅期，即Pod终止时等待多长时间后强制终止。默认为30秒 其余一些状态信息 status : podIPs phase: Running phase initContainerStatuses containerStatuses containerStatuses conditions 持久卷 - PersistentVolume # 需要注意的是，PersistentVolume 是一个集群级别的资源，不属于任何一个命名空间，但可以通过在 metadata 字段中指定 namespace 字段来将其关联到某个命名空间中。这个关联只是用来方便查找和管理资源，不会对 PersistentVolume 对象本身产生影响。\nservice # k8s 路由解析 # \u0026ldquo;host\u0026rdquo;: \u0026ldquo;choi-wan-rabbitmq.nscloud.svc.cluster.local\u0026rdquo; 解释这段k8s配置\n4/24/2023, 5:36:06 PM\n这段 Kubernetes（k8s）配置中的 \u0026ldquo;host\u0026rdquo;: \u0026ldquo;choi-wan-rabbitmq.nscloud.svc.cluster.local\u0026rdquo; 是一个应用程序连接到 RabbitMQ 消息代理服务的主机地址。具体来说，它是一个 Kubernetes 集群内部的服务地址，该服务被命名为 choi-wan-rabbitmq，并位于 nscloud 命名空间的 svc（Service）资源中。\n如果应用程序需要连接到 scan.rabbitmq.ros.nsfocus.com 上运行的 RabbitMQ 服务，则需要在 Kubernetes 中创建一个外部服务或使用 Kubernetes 的 DNS 解析功能将该主机名映射到 RabbitMQ 服务的 IP 地址。\n4/24/2023, 5:54:22 PM\nsvc.cluster.local 分别代表什么？\n4/24/2023, 5:54:40 PM\n在 Kubernetes 中，svc.cluster.local 是一个特殊的域名后缀，用于将服务名称解析为集群内部的 IP 地址。具体来说，svc 代表 Kubernetes 中的 Service 资源类型，cluster.local 是 Kubernetes 集群的默认域名后缀。因此，当应用程序需要连接到 Kubernetes 集群中的服务时，可以使用该服务的名称作为主机名，并在末尾添加 svc.cluster.local 后缀来获得服务的 IP 地址。例如，在上述例子中，choi-wan-rabbitmq.nscloud.svc.cluster.local 是 choi-wan-rabbitmq 服务的完整域名，它将被解析为 RabbitMQ 消息代理服务的 IP 地址，从而使应用程序能够与该服务进行通信。\n配置一个rabbitmq给大家用 # 在k8s 新建一个公共rabbitmq供所有pod使用应该如何操作？\n4/24/2023, 5:34:27 PM\n在 Kubernetes 中创建一个共享的 RabbitMQ 服务供所有 Pod 使用，需要以下步骤：\n创建 RabbitMQ 镜像：可以使用 Dockerfile 或者从 Docker Hub 下载现成的 RabbitMQ 镜像。 配置 RabbitMQ：修改 RabbitMQ 的配置文件，包括默认用户名和密码、端口号、虚拟主机等。 创建 Kubernetes Service：使用 Kubernetes 的 Service 资源类型来创建一个 RabbitMQ 服务，这个服务会为 RabbitMQ 提供一个稳定的 IP 地址和端口。可以选择 ClusterIP、LoadBalancer 或者 NodePort 类型的服务。 创建 Kubernetes Deployment：创建一个 RabbitMQ 的 Deployment 资源，用于实例化 RabbitMQ 的容器，并且将这个资源归属到刚才创建的 Service 上，确保所有的 Pod 都可以访问到 RabbitMQ 服务。 验证 RabbitMQ 是否可用：使用 Kubernetes Dashboard 或者 kubectl 命令行工具，连接到 RabbitMQ 服务进行验证，确保它能够正常工作。 在其他的 Kubernetes Pod 中使用 RabbitMQ：在其他的 Pod 中安装 RabbitMQ 客户端，并使用 Service 的 IP 和端口访问 RabbitMQ 服务，实现 Pod 之间的消息传递。 总体来说，创建共享的 RabbitMQ 服务需要在 Kubernetes 中创建一个带有自动伸缩功能的 Deployment，并将它绑定到一个稳定的 Service 上，然后在其他的 Pod 中使用 RabbitMQ 客户端来连接该服务。\n4/24/2023, 5:34:49 PM\n请提供一下上述所需的示例yaml文件内容\n4/24/2023, 5:35:52 PM\n以下是创建共享的 RabbitMQ 服务所需的示例 YAML 文件内容：\nRabbitMQ 镜像的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-pod spec: containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http 注意，这里使用的是 Docker Hub 上的默认 RabbitMQ 镜像，也可以根据需要自定义 Dockerfile 来构建。\nRabbitMQ 配置文件的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: ConfigMap metadata: name: rabbitmq-config data: rabbitmq.conf: | loopback_users.guest = false listeners.tcp.default = 5672 management.listener.port = 15672 enabled_plugins: | [rabbitmq_management]. 这里使用 ConfigMap 来存储 RabbitMQ 的配置信息。配置文件中禁用了默认用户 guest，开启了 TCP 监听端口和管理界面端口，并且启用了 RabbitMQ 管理插件。\nRabbitMQ Service 的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Service metadata: name: rabbitmq-service spec: selector: app: rabbitmq ports: - name: amqp port: 5672 targetPort: amqp - name: http port: 15672 targetPort: http type: ClusterIP 这里创建的是 ClusterIP 类型的 Service，它会为 RabbitMQ 提供一个稳定的 IP 地址和端口。\nRabbitMQ Deployment 的 YAML 文件内容如下： 复制代码 apiVersion: apps/v1 kind: Deployment metadata: name: rabbitmq-deployment spec: selector: matchLabels: app: rabbitmq replicas: 1 template: metadata: labels: app: rabbitmq spec: volumes: - name: rabbitmq-config-volume configMap: name: rabbitmq-config containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http volumeMounts: - name: rabbitmq-config-volume mountPath: /etc/rabbitmq/ 这里创建了一个带有自动伸缩功能的 Deployment，并将其绑定到刚才创建的 Service 上。Deployment 中指定了 Pod 的标签，通过 ConfigMap 挂载了 RabbitMQ 的配置文件，确保所有的 Pod 都可以访问到 RabbitMQ 服务。\n验证 RabbitMQ 是否可用的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-client-pod spec: containers: 4/24/2023, 5:36:17 PM\n继续\n4/24/2023, 5:37:21 PM\n以下是创建共享的 RabbitMQ 服务所需的示例 YAML 文件内容：\nRabbitMQ 镜像的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-pod spec: containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http 注意，这里使用的是 Docker Hub 上的默认 RabbitMQ 镜像，也可以根据需要自定义 Dockerfile 来构建。\nRabbitMQ 配置文件的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: ConfigMap metadata: name: rabbitmq-config data: rabbitmq.conf: | loopback_users.guest = false listeners.tcp.default = 5672 management.listener.port = 15672 enabled_plugins: | [rabbitmq_management]. 这里使用 ConfigMap 来存储 RabbitMQ 的配置信息。配置文件中禁用了默认用户 guest，开启了 TCP 监听端口和管理界面端口，并且启用了 RabbitMQ 管理插件。\nRabbitMQ Service 的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Service metadata: name: rabbitmq-service spec: selector: app: rabbitmq ports: - name: amqp port: 5672 targetPort: amqp - name: http port: 15672 targetPort: http type: ClusterIP 这里创建的是 ClusterIP 类型的 Service，它会为 RabbitMQ 提供一个稳定的 IP 地址和端口。\nRabbitMQ Deployment 的 YAML 文件内容如下： 复制代码 apiVersion: apps/v1 kind: Deployment metadata: name: rabbitmq-deployment spec: selector: matchLabels: app: rabbitmq replicas: 1 template: metadata: labels: app: rabbitmq spec: volumes: - name: rabbitmq-config-volume configMap: name: rabbitmq-config containers: - name: rabbitmq image: rabbitmq ports: - containerPort: 5672 name: amqp - containerPort: 15672 name: http volumeMounts: - name: rabbitmq-config-volume mountPath: /etc/rabbitmq/ 这里创建了一个带有自动伸缩功能的 Deployment，并将其绑定到刚才创建的 Service 上。Deployment 中指定了 Pod 的标签，通过 ConfigMap 挂载了 RabbitMQ 的配置文件，确保所有的 Pod 都可以访问到 RabbitMQ 服务。\n验证 RabbitMQ 是否可用的 YAML 文件内容如下： 复制代码 apiVersion: v1 kind: Pod metadata: name: rabbitmq-client-pod spec: containers: - name: rabbitmq-client image: rabbitmq command: [\u0026#34;rabbitmqctl\u0026#34;, \u0026#34;list_users\u0026#34;] 这里创建了一个 Pod 来验证 RabbitMQ 是否可用，使用 rabbitmqctl 命令列出用户列表来检查服务是否正常工作。\ningress # 配置 # k8s kind ingress 是什么，有什么用途？ K8s Ingress 是 Kubernetes 集群中的一个资源对象，定义了一系列路由转发规则（或反向代理规则），规定了外部进来的 HTTP/HTTPS 请求应该被转发到哪个 Service 上。Ingress Controller 相当于是一个反向代理程序，负责解析 Ingress 的反向代理规则，并实时感知 Ingress 转发规则的变化。一旦 Ingress 规则有变化，Ingress Controller 会及时更新自己相应的转发规则，并根据这些规则，将接收到的请求转发到对应的 Service。12\nIngress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管等功能。\n举例说明。假设k8s中有一个服务A需要访问k8s中另一个服务B应该如何通过ingress 来实现 假设你的 Kubernetes 集群中有一个服务 A，需要访问另一个服务 B，可以通过 Ingress 来实现。首先，你需要创建一个 Ingress 资源对象，定义外部对集群内服务的访问路由。例如：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: minimal-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - http: paths: - path: /testpath pathType: Prefix backend: service: name: test port: number: 80 这个 Ingress 对象将会把 /testpath 的请求转发到名为 test 的 Service 上。这个 Service 可以是服务 B。1\n希望这些信息能够帮助你理解如何通过 Ingress 实现服务 A 访问服务 B。如果你还有其他问题，请随时问我。\n环境变量在k8s # k8s设定环境变量\n根据搜索结果，k8s设定环境变量的方法有以下几种12：\n在Pod的yaml文件中，使用env字段为容器指定环境变量，例如： apiVersion: v1 kind: Pod metadata: name: envar-demo spec: containers: - name: envar-demo-container image: nginx env: - name: DEMO_GREETING value: \u0026#34;Hello from the environment\u0026#34; - name: DEMO_FAREWELL value: \u0026#34;Such a sweet sorrow\u0026#34; 使用ConfigMap或Secret对象来存储环境变量的值，然后在Pod的yaml文件中，使用envFrom字段或valueFrom字段来引用这些对象，例如： apiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: k8s.gcr.io/busybox command: [ \u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;env\u0026#34; ] env: # Define the environment variable - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: # The ConfigMap containing the value you want to assign to SPECIAL_LEVEL_KEY name: special-config # Specify the key associated with the value key: special.how 使用env字段为容器指定环境变量 和 使用ConfigMap或Secret对象来存储环境变量 有什么区别？\n根据搜索结果，使用env字段为容器指定环境变量和使用ConfigMap或Secret对象来存储环境变量的区别主要有以下几点123：\n使用env字段时，需要为每个容器指定每个环境变量的值，而使用ConfigMap或Secret对象时，可以一次性引用所有的键值对作为环境变量 使用env字段时，环境变量的值是直接写在Pod的yaml文件中的，而使用ConfigMap或Secret对象时，环境变量的值是存储在Etcd中的，这样可以更好地管理和保护配置信息 使用env字段时，如果需要修改环境变量的值，需要重新创建Pod，而使用ConfigMap或Secret对象时，可以动态更新环境变量的值，不需要重启Pod ConfigMap # ConfigMap对象是一个存储配置数据的API对象\nvolumes: - configMap: defaultMode: 420 items: - key: env.json path: env.json name: env-config name: env-config 在这个配置中，k8s挂载的不是物理机的env.json文件，而是ConfigMap对象的env.json键的值。ConfigMap对象是一个存储配置数据的API对象，它可以被Pod或其他对象引用 。你可以使用kubectl命令来创建或查看ConfigMap对象。例如：\nkubectl create configmap env-config --from-file=env.json kubectl get configmap env-config -o yaml 这些命令会创建一个名为env-config的ConfigMap对象，它包含了一个键为env.json，值为文件内容的键值对。然后你可以在volume中引用这个ConfigMap对象，就像你的配置那样。\n升级单个服务流程(node namespace label) # 打包build docker image 保存服务docker镜像: docker save -o fizz_worker-2123.tar repos-xa.inone.nsfocus.com/websafe-docker/fizz_worker:2123 查看当前集群中node: kubectl get node -o wide --show-labels 并找出控制节点 如含有: run-package-node,worker k8s-worker1 是控制节点名称 通过node名查看其上所部署的pod是否是目标服务: kubectl get pod -A -o wide | grep k8s-worker1 查看当前服务运行所处node: kubectl get pod -n websafe -o wide 查看服务node 择选器: kubectl get deploy master-fizz-daemon -n websafe -o yaml | grep nodeSelector -9 一个 kv 给目标节点创建label kubectl label nodes k8s-worker1 app-select=websafe-rcmlog 查看是否成功 kubectl get node -n websafe -o wide --show-labels | grep \u0026quot;k8s-worker1\\\\|rcmlog” 上传镜像到harbor 修改deploy yaml文件(镜像版本、挂载目录、nodeSelector 其他(若有))，保存退出生效 hostPath 挂载\nvolumeMounts: - mountPath: /mnt/NPAI name: rcmlog-claim volumes: - hostPath: path: /opt/nsfocus/NPAI/data/sftp/bsa/rcm_log type: \u0026#34;\u0026#34; name: rcmlog-claim nodeSelector\nspec: nodeSelector: app-select: websafe-rcmlog 修改版本号为目标版本：2123（image: [repos-xa.inone.nsfocus.com/websafe-docker/fizz_daemon:](\u0026lt;http://repos-xa.inone.nsfocus.com/websafe-docker/fizz_daemon:1979\u0026gt;)2123)\nDocker Network # 创建网络 websafe-network 使用 IPv4Address 进行连接\ninit_mysql: docker run -p 3306:3306 \\\\ -e MYSQL_ROOT_PASSWORD=123456 \\\\ -e character-set-server=utf8mb4 \\\\ -e collation-server=utf8mb4_unicode_ci \\\\ --network websafe-network -v /x/Code/websafe_online_svn/mysql/conf:/etc/mysql/conf.d \\\\ -v /x/Code/websafe_online_svn/mysql/logs:/logs \\\\ -v /x/Code/websafe_online_svn/mysql/db:/var/lib/mysql \\\\ -v /c/Windows/System32/drivers/etc/HOSTS:/etc/hosts \\\\ --name mysql56 mysql:5.6 init_redis: docker run -p 6379:6379 \\\\ --network websafe-network \\\\ --name redislatest redis:latest --requirepass 3b21d032a7fd8eb51fa7bd8a2e812b78b7b3a36f join_network: docker network connect websafe-network mysql56 docker network connect websafe-network daemon-xxx init_network: docker network create websafe-network check_network: docker network inspect websafe-network docker network inspect websafe-network | findStr IPv4Address run: docker run --name $(CONTAINER_NAME) -p 8888:80 \\\\ -e POD_OWN_NAME=\u0026#34;master-xxxxxx\u0026#34; \\\\ --network websafe-network \\\\ -v /x/Code/websafe_online_svn/env.json:/etc/env.json \\\\ registry.nscloud:5000/kunkka/websafe/scancenter:latest Docker 限制内存/CPU占用 # 运行docker时如何限制其内存占用？\n运行docker时可以使用**–memory或-m**选项来限制其内存占用123。例如：\ndocker run -m 512m nginx 这个命令会限制nginx容器使用不超过512MB的内存。你还可以使用**–memory-reservation**选项来设置一个软限制，当主机内存不足时，docker会尽量保证容器的内存需求2。例如：\ndocker run -m 512m --memory-reservation=256m nginx 这个命令会保证nginx容器至少有256MB的内存，但最多不超过512MB。\n如何限制cpu占用呢？\n运行docker时可以使用**–cpus或–cpu-quota**选项来限制其CPU占用123456。例如：\ndocker run --cpus=2 nginx 这个命令会限制nginx容器使用不超过2个CPU的资源。你还可以使用**–cpu-shares**选项来设置容器的CPU优先级45。例如：\ndocker run --cpus=2 --cpu-shares=2000 nginx 这个命令会给nginx容器分配更高的CPU优先级，相对于默认值1024。\nDocker 在 k8s # 使用k8s 加载 docker镜像时，dockerfile中的CMD为什么没有执行？\n根据搜索结果12，k8s中的command和args会覆盖dockerfile中的entrypoint和cmd，所以如果您在k8s配置文件中设置了command或args，那么dockerfile中的cmd可能就不会执行。请检查您的k8s配置文件是否有这样的设置。\n另外，dockerfile中的cmd也可能被容器启动时附加的指令忽略3，请检查您是否在启动容器时指定了其他命令。\nDocker CMD 和 K8s Command # 如果在k8s配置中没有指定command，那么容器启动时会执行dockerfile中指定的CMD命令作为默认命令。如果dockerfile中也没有指定CMD命令，则容器启动时不会执行任何命令，只是启动一个空的容器。因此，如果想要在k8s中保留dockerfile中指定的CMD命令，可以不指定command，或者在指定command时将CMD命令包含在内。 启动命令应该写在k8s配置中的command中，因为这样可以灵活地控制容器启动时执行的命令，而不受dockerfile中的CMD命令的限制。此外，将启动命令写在k8s配置中也可以方便地进行配置管理和版本控制，便于维护和更新。当然，如果dockerfile中的CMD命令已经满足需求，也可以直接使用默认命令，不需要在k8s配置中指定command。 "},{"id":12,"href":"/docs/programmer/langs/cmake/","title":"CMake 使用Tips","section":"Langs","content":" 在编译时将编译产物放在build # 据网友所知，cmake文档中没有记录，仅出于兼容性原因或内部使用而保留：\n-B和-H标志 # cmake -Hpath/to/source -Bpath/to/build 甚至从源目录 -B # 重要：-B后没有空格\n该命令会自动创建build目录 之后cd到build下去make即可 cmake . -Bbuild 样例记录 # OpenCV # CMakeLists.txt 文件tree -L 1 |-- CMakeLists.txt |-- DisplayImage.cpp |-- DisplayImage.out |-- cmake_install.cmake |-- CMakeCache.txt |-- CMakeFiles |-- Makefile cmake_minimum_required(VERSION 2.8) project( DisplayImageExample ) find_package( OpenCV REQUIRED ) include_directories( ${OpenCV_INCLUDE_DIRS} ) add_executable( DisplayImage.out DisplayImage.cpp ) target_link_libraries( DisplayImage.out ${OpenCV_LIBS} ) Qt # "},{"id":13,"href":"/docs/programmer/game_and_simulation/blender/","title":"Blender","section":"Game and Simulation","content":" 快捷键 # 切换为四视图 | Ctrl+Alt+q 复制并移动(进入Grab模式) ｜ Shift+d(+x|y|x 选择移动轴) 线/面挤出 ｜ e(+x|y|x 选择挤出方向轴) 上一步的操作应用到当前选择 ｜ Shift+r 打开模型右侧的小工具栏(位置插件功能等调整) ｜ n 填充(两点连成线,线圈填成面) ｜ n 备忘 # 合并物体时,谁被最后选择\u0026ndash;是Active状态,将作为母体合并 "},{"id":14,"href":"/docs/programmer/base/pypi/","title":"PyPi","section":"Base","content":"\n示例项目 # py-muti-scrcpy\n配置文件 # pyproject\n工具介绍 # poetry\n增加安装包 # 直接修改pyproject.toml文件并不能生效, 因为还依赖于poetry.lock\n可使用poetry add {xxx}进行添加\n注意事项 # 需要链接外网 # HTTPSConnectionPool(host=\u0026#39;files.pythonhosted.org\u0026#39;, port=443): Max retries exceeded with url: /packages/17/61/32c3ab8951142e061587d957226b5683d1387fb22d95b4f69186d92616d1/typing_extensions-4.0.0-py3-none-any.whl (Caused by ProxyError(\u0026#39;Cannot connect to proxy.\u0026#39;, ConnectionResetError(54, \u0026#39;Connection reset by peer\u0026#39;))) HTTPSConnectionPool(host=\u0026#39;pypi.org\u0026#39;, port=443): Max retries exceeded with url: /pypi/colorama/0.4.4/json (Caused by ProxyError(\u0026#39;Cannot connect to proxy.\u0026#39;, ConnectionResetError(54, \u0026#39;Connection reset by peer\u0026#39;))) 需要安装ssl # SSLError HTTPSConnectionPool(host=\u0026#39;pypi.org\u0026#39;, port=443): Max retries exceeded with url: /pypi/importlib-metadata/4.2.0/json (Caused by SSLError(SSLEOFError(8, \u0026#39;EOF occurred in violation of protocol (_ssl.c:1129)\u0026#39;))) 该问题可通过安装openssl解决:\npip install ndg-httpsclient pip install pyopenssl pip install pyasn1 CI WorkFlows # workflows\npypi token # 注册pypi账号 进入账号管理中心这里 找见API tokens创建新token或者使用旧的，随个人 在GitHub项目配置中找到Action secrets管理这里 Repository secrets 中加入PYPI_TOKEN 因为WorkFlows中使用的是PYPI_TOKEN 见POETRY_PYPI_TOKEN_PYPI: ${{ secrets.PYPI_TOKEN }} "},{"id":15,"href":"/docs/programmer/ml/tensorflow/","title":"Tensorflow","section":"Ml","content":"\nv2兼容v1 API # import tensorflow.compat.v1 as tf tf.disable_v2_behavior() "},{"id":16,"href":"/docs/programmer/gui/pyinstaller/","title":"python打包","section":"Gui","content":" 打包 # pyinstaller\npip install pyinstaller pyinstaller /path/to/yourscript.py pyinstaller -key yourpasswd -F /path/to/yourscript.py 解包 # 解包工具 # pyinstxtractor.py\nhex编辑器 # 010Editor 下载地址\n步骤 # 将pyinstxtractor.py与exe放置在一个文件夹内，打开cmd，输入下列指令生成一个文件夹\npython pyinstxtractor.py xxx.exe 使用010Editor打开文件夹中的main和struct，将struct中E3前面的字节复制粘贴到010Editor的E3前 修改main文件后缀为main.pyc 使用在线工具https://tool.lu/pyc/ 将main.pyc反编译为py文件\n应对增加key之后的解包 # 暂无\n安装程序 # 先将程序打包exe(以多文件模式, 但文件运行起来每次都需要解压再运行很慢，大文件的话多次运行还会挤压C盘空间) 将打包好的目录压缩打包zip 编写本质为mv lnk的脚本 把脚本打包成exe 执行脚本exe 具体代码可以看这里 "},{"id":17,"href":"/docs/programmer/gui/qt/","title":"Qt/PySide","section":"Gui","content":"\n绘制界面和使用 # 安装Qt本体后可以使用Design绘制图形化界面.而后保存为xxx.ui文件.\n转换为py # 注意版本 pyside6-uic xxx.ui -o ui_xxx.py 不过信号槽就不要在Design中去标了, 放在py中手动创建和管理目前看来更为直观方便.\n"},{"id":18,"href":"/docs/programmer/install_some/","title":"安装问题","section":"程序员笔记","content":" 记录一些安装问题 # Debian 使用 apt-add-repository(ppa) # sudo apt update sudo apt install software-properties-common FreeBSD桌面 # 换源 pkg install xorg xfce echo \u0026lsquo;dbus_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf echo \u0026ldquo;/usr/local/etc/xdg/xfce4/xinitrc\u0026rdquo; \u0026gt; ~/.xinitrc startx 登录界面 # pkg install slim slim-themes echo \u0026lsquo;slim_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf vbox(没测试) # pkg install virtualbox-ose-additions 向/etc/rc.conf写入 vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; 仅供参考看这里 因为vbox显卡太弱安装了vmware后就一直没用回过vbox,我还没测试过\nvmware # pkg install open-vm-tools xf86-video-vmware xf86-input-vmmouse 继续向/etc/rc.conf中写入 hald_enable=\u0026#34;YES\u0026#34; moused_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmblock_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmhgfs_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmmemctl_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmxnet_enable=\u0026#34;YES\u0026#34; # vmware_guest_enable=\u0026#34;YES\u0026#34; 下面注释掉的是因为在测试中如果打开的话会有各种问题\u0026hellip;.尤其鼠标 其他可见这里参考 仅供参考, 这里面的东西很多都是有问题的.\nClash(樹莓派4 cli版) # 下載對應版本地址 注意不要選擇1.9.0版本,我用的1.8.0,9多人反映(以及我)有問題 我是樹莓派4 用的armv8 樹莓派3 據說用armv7 解壓給運行權限 從無論某處拿到配置文件 大多給訂閱地址, 但這裏使用需要我們手動下載好 配置systemd或其他(手動啓動的話注意需要root,或者給相應用戶配置端口權限) [Unit] Description=clash daemon [Service] Type=simple User=root ExecStart=/home/pi/apps/clash-linux-armv8-v1.8.0/clash-linux-armv8-v1.8.0 -f /home/pi/.config/clash/config.yaml Restart=on-failure [Install] WantedBy=multi-user.target 啓用 sudo systemctl enable clash sudo systemctl start clash sudo systemctl status clash Windows下wsl2 安装 npm \u0026amp;\u0026amp; nodejs # 摘抄自微软说明文档\n安装nvm (Node 版本管理器) 国内网可能有问题, 下载下保存直接bash install.sh就可安装. curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash command -v nvm验证是否安装成功,它会自行添加.bashrc需重启bash nvm ls查看Node版本 nvm install --lts即可安装lts版, nvm install node安装最新版 会安装这么多东西 -\u0026gt; v16.13.2 default -\u0026gt; lts/* (-\u0026gt; v16.13.2) iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v16.13.2) (default) stable -\u0026gt; 16.13 (-\u0026gt; v16.13.2) (default) lts/* -\u0026gt; lts/gallium (-\u0026gt; v16.13.2) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.9 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.18.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.13.2 可以了 或者官网下载不过在wsl2里node好使唤,npm无效(只有0K)\u0026hellip; Dgraph # 问题见: 这里\n"},{"id":19,"href":"/docs/programmer/database/dgraph/","title":"Dgraph使用小记","section":"Database","content":"\n概念 # 以下参考自: 这里 Console # Mutate: 突变, 结构/数据变化的时候用 Query: 查询, Emmmm查询的时候用 所以看来没有getset了???? Schema # 管理字段(Predicate, Type, list,lang,index等)\n突变 # set # 内容较多, 下面单独罗列\ndelete # 根据UID 删除指定predicate_name\n{ delete { \u0026lt;UID\u0026gt; \u0026lt;predicate_name\u0026gt; * . } } set # 创建 # 直接json给出结构和数据,即可完成创建.只不过如果有用到@lang时就需要去Schema里更新一下字段 - 类型 ???? (Schema-Type)的支持项\n{ \u0026#34;set\u0026#34;: [ { \u0026#34;food_name\u0026#34;: \u0026#34;Sushi\u0026#34;, \u0026#34;review\u0026#34;: [ { \u0026#34;comment\u0026#34;: \u0026#34;Tastes very good\u0026#34;, \u0026#34;comment@jp\u0026#34;: \u0026#34;とても美味しい\u0026#34;, \u0026#34;comment@ru\u0026#34;: \u0026#34;очень вкусно\u0026#34; } ], \u0026#34;origin\u0026#34;: [ { \u0026#34;country\u0026#34;: \u0026#34;Japan\u0026#34; } ] } ] } 更新 # 使用和创建差不多,不过目前我已知的更新只能用UID否则都会直接创建一个相同内容的新数据出来\n{ \u0026#34;set\u0026#34;:[ { \u0026#34;uid\u0026#34;: \u0026#34;{UID}\u0026#34;, \u0026#34;age\u0026#34;: 41 } ] } 查询 # has # 直接json 返回值也会按照这个格式给出,层级深浅可随意自定\n{ good_name(func: has(food_name)) { food_name review } } { good_name(func: has(food_name)) { food_name review{ comment } } } uid # 除了上述的has还有很多查询内置方法,不过深度的话除了手动罗列也可通过recurse - depth来确定,写多了也不会多返回\n{ find_follower(func: uid({UID})) @recurse(depth: 4) { name age follows } } eq\u0026amp;索引 # 需要设置hash索引, 如下为查询Sushi的review *为统配 可指定lang, 什么都不加默认无指定lang的数据\n{ food_review(func: eq(food_name,\u0026#34;Sushi\u0026#34;)) { food_name review { comment@* } } } \u0026lt;\u0026gt;= # func 说明 eq 等于 lt 小于 le 小于等于 gt 大于 ge 大于等于 { authors_and_ratings(func: ge(rating, 4.0)) { uid author_name rating published { title content dislikes } } } 索引 # hash 可等查询(eq), 但不支持字符串比较大小 exact 唯一允许字符串比较(ge,gt,le,lt)查询的索引(很牛逼的样子) term 带有任意一个(anyofterms), 同时拥有(allofterms), 相等(eq) // 多个关键字(术语)使用空格隔开即可. // 查询大小写不敏感 // dgraph 优化机制是将全文转换为token 查询使用查询token 所以多个查询关键词会进行重排列 获取唯一token后去全文中对比. 由此查询词的顺序无关紧要 // 也就是说anyofterms\u0026amp;allofterms的 `1 2 3 == 3 2 1 == 2 1 3` (结果相同是理所当然的, 消耗和内部逻辑也是相同) { find_tweets(func: anyofterms(tweet, \u0026#34;Go GraphQL\u0026#34;)) { tweet } } "},{"id":20,"href":"/docs/programmer/database/noteofdocker/","title":"notes Of docker","section":"Database","content":" Docker # 教程手册 # 好用的使用教程\nInstall # 略过~ 😁\n常见问题和模板 # 用户sudo问题 # debian增加docker用户组,优化每次sudo问题 或\nsudo groupadd docker # 安装完docker.io之后一般都会自动创建所以这一步其实没啥用 sudo gpasswd -a $USERNAME docker newgrp docker # 更新 Docker Mysql编码 # version: \u0026#34;2.2\u0026#34; services: redis: image: \u0026#34;redis\u0026#34; # ports: # - 6379:6379 command: redis-server --appendonly yes #一个容器启动时要运行的命令 restart: always # 自动重启 myserver: image: mainName/myserver restart: always # 自动重启 mainServer: image: mainName/mainServer # container_name: mainServerv1.0.0 depends_on: - redis ports: - 9001:9001 restart: always volumes: - \u0026#34;./logs:/src/build/logs\u0026#34; links: - redis - myserver mysql 编码问题|单条: docker run --name predix_mysql -e MYSQL_ROOT_PASSWORD=predix123predix -p 33061:3306 -e LANG=C.UTF-8 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci\n时间修改 # FROM alpine:3.14 RUN apk add -U tzdata \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone ENV TZ=Asia/Shanghai \\ GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ PROGRAM_ENV=pro WORKDIR /src/build # 复制构建应用程序所需的代码 COPY ./build . EXPOSE 8088 CMD [\u0026#34;./main\u0026#34;] bash进入某App内 # docker exec -it webserver bash webserver 为APP名称\nSwarm # Docker Compose Docker Machine: Mac、Windows区别预先安装。 Linux直接安装 Win10 Hyper-V 发布镜像 镜像充当已部署容器，填写必要信息：username、repo、tag dockers-compose.yml 副本\n其实以上在官方教程有很好说明在这里，但毕竟高级应用，暂且记下。\n创建虚拟机来试验一下 # $ docker-machine create --driver virtualbox myvm1 $ docker-machine create --driver virtualbox myvm2 第一个管理节点：docker swarm init，第二个工作节点`docker swarm join``\nshould like this show: # $ docker-machine ssh myvm1 \u0026#34;docker swarm init\u0026#34; Swarm initialized: current node \u0026lt;node ID\u0026gt; is now a manager. To add a worker to this swarm, run the following command: docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt; 通过运行 docker-machine ls 来复制 myvm1 的 IP 地址，然后使用 该 IP 地址并通过 \u0026ndash;advertise-addr 指定端口 2377（用于 swarm join 的端口）， 以便再次运行 docker swarm init 命令。例如：\ndocker-machine ssh myvm1 \u0026#34;docker swarm init --advertise-addr 192.168.99.100:2377\u0026#34; 复制此命令，然后通过 docker-machine ssh 将其发送给 myvm2，从而让 myvm2 加入 # $ docker-machine ssh myvm2 \u0026#34;docker swarm join \\ --token \u0026lt;token\u0026gt; \\ \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;\u0026#34; This node joined a swarm as a worker. 至此， 创建swarm完成。 # 连接 # 使用ssh连接docker-machine ssh myvm1,运行docker node ls查看此中节点。\nMybe like this. # docker@myvm1:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS brtu9urxwfd5j0zrmkubhpkbd myvm2 Ready Active rihwohkh3ph38fhillhhb84sk * myvm1 Ready Active Leader mybe not you are ture. 😂\n之后，其余东西z有用到再去官网查看吧。 记录与否，取决于俺。\n"},{"id":21,"href":"/docs/programmer/net/tipsofgrpc/","title":"gRpc使用小记","section":"Net","content":"\ngRpc HelloWorld # helloWorld # quickstart\nprotoc --go_out=. --go_opt=paths=source_relative \\ --go-grpc_out=. --go-grpc_opt=paths=source_relative \\ helloworld/helloworld.proto MacOS下问题 # 原本protobuf中没有mac的gen-go和gen-go-grpc,所以需要额外运行安装. 除了使用brew用go get应该也是可以的,就是有路径问题,所以还是使用brew吧 brew install protobuf brew install protoc-gen-go brew install protoc-gen-go-grpc "},{"id":22,"href":"/docs/programmer/langs/noteofgoexp/","title":"Golang进阶笔记","section":"Langs","content":" Golang进阶笔记 # 路径问题 # test_test.go # package main import \u0026#34;testing\u0026#34; func TestHelloWorld(t *testing.T) { // t.Fatal(\u0026#34;not implemented\u0026#34;) path := getCurrentPath() t.Log(\u0026#34;getCurrentPath: \u0026#34;, path) } test.go # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(\u0026#34;getTmpDir（当前系统临时目录） = \u0026#34;, getTmpDir()) fmt.Println(\u0026#34;getCurrentAbPathByExecutable（仅支持go build） = \u0026#34;, getCurrentAbPathByExecutable()) fmt.Println(\u0026#34;getCurrentAbPathByCaller（仅支持go run） = \u0026#34;, getCurrentAbPathByCaller()) fmt.Println(\u0026#34;getCurrentAbPath（最终方案-全兼容） = \u0026#34;, getCurrentAbPath()) fmt.Println(\u0026#34;getCurrentPath（runtime.Caller1） = \u0026#34;, getCurrentPath()) } // 最终方案-全兼容 func getCurrentAbPath() string { dir := getCurrentAbPathByExecutable() if strings.Contains(dir, getTmpDir()) { return getCurrentAbPathByCaller() } return dir } func getCurrentPath() string { _, filename, _, _ := runtime.Caller(1) return path.Dir(filename) } // 获取系统临时目录，兼容go run func getTmpDir() string { dir := os.Getenv(\u0026#34;TEMP\u0026#34;) if dir == \u0026#34;\u0026#34; { dir = os.Getenv(\u0026#34;TMP\u0026#34;) } res, _ := filepath.EvalSymlinks(dir) return res } // 获取当前执行文件绝对路径 func getCurrentAbPathByExecutable() string { exePath, err := os.Executable() if err != nil { log.Fatal(err) } res, _ := filepath.EvalSymlinks(filepath.Dir(exePath)) return res } // 获取当前执行文件绝对路径（go run） func getCurrentAbPathByCaller() string { var abPath string _, filename, _, ok := runtime.Caller(0) if ok { abPath = path.Dir(filename) } return abPath } 输出 # ian@ianDebian:~$ ./test getTmpDir（当前系统临时目录） = . getCurrentAbPathByExecutable（仅支持go build） = /home/ian getCurrentAbPathByCaller（仅支持go run） = /home/ian getCurrentAbPath（最终方案-全兼容） = /home/ian getCurrentPath（runtime.Caller1） = /home/ian ian@ianDebian:~$ ian@ianDebian:~$ go run test.go getTmpDir（当前系统临时目录） = . getCurrentAbPathByExecutable（仅支持go build） = /tmp/go-build3048077768/b001/exe getCurrentAbPathByCaller（仅支持go run） = /home/ian getCurrentAbPath（最终方案-全兼容） = /tmp/go-build3048077768/b001/exe getCurrentPath（runtime.Caller1） = /home/ian ian@ianDebian:~$ ian@ianDebian:~$ go test test_test.go test.go -v === RUN TestHelloWorld test_test.go:8: getCurrentPath: /home/ian --- PASS: TestHelloWorld (0.00s) PASS ok command-line-arguments\t0.002s Docker问题 # Docker Mysql编码 # version: \u0026#34;2.2\u0026#34; services: redis: image: \u0026#34;redis\u0026#34; # ports: # - 6379:6379 command: redis-server --appendonly yes #一个容器启动时要运行的命令 restart: always # 自动重启 myserver: image: mainName/myserver restart: always # 自动重启 mainServer: image: mainName/mainServer # container_name: mainServerv1.0.0 depends_on: - redis ports: - 9001:9001 restart: always volumes: - \u0026#34;./logs:/src/build/logs\u0026#34; links: - redis - myserver mysql 编码问题|单条: docker run --name predix_mysql -e MYSQL_ROOT_PASSWORD=predix123predix -p 33061:3306 -e LANG=C.UTF-8 -d mysql:5.7 --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci\n时间修改 # FROM alpine:3.14 RUN apk add -U tzdata \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone ENV TZ=Asia/Shanghai \\ GO111MODULE=on \\ CGO_ENABLED=0 \\ GOOS=linux \\ GOARCH=amd64 \\ PROGRAM_ENV=pro WORKDIR /src/build # 复制构建应用程序所需的代码 COPY ./build . EXPOSE 8088 CMD [\u0026#34;./main\u0026#34;] Golang 私有仓库 # xxx替换为具体地址\nexport GOPRIVATE=github.com/xxx/xxx 修改~/.gitconfig让go get始终通过ssh而非http\n[url \u0026#34;git@github.com:\u0026#34;] insteadOf = https://github.com/ [url \u0026#34;git@gitlab.com:\u0026#34;] insteadOf = https://gitlab.com/ -和_不同的分隔符引发的包导入错误 # 适用于Github仓库名为xxxxx-xxxxx但包名为xxxxx_xxxxx, 因为go mod 不支持-分隔.\nmodule example.com go 1.16 replace github.com/xxx-xx/xxxxx_xxxxx =\u0026gt; github.com/xxx-xx/xxxxx-xxxxx v0.0.1 // indirect require github.com/xxx-xx/xxxxx_xxxxx v0.0.1 非硬性结束服务 # http.Server.Shutdown # http.Server结构体有一个终止服务的方法Shutdown\n首先关闭所有开启的监听器 关闭所有闲置连接 等待活跃的连接均闲置了才终止服务 长链接 # 对诸如WebSocket等的长连接，Shutdown不会尝试关闭也不会等待这些连接。若需要，需调用者分开额外处理（诸如通知诸长连接或等待它们关闭，使用RegisterOnShutdown注册终止通知函数）\nsignal.Notify # 可指定信号类型/all incoming signals will be relayed to c\n综上 # Demo1 # srv := http.Server{ Addr: *addr, Handler: handler, } // make sure idle connections returned processed := make(chan struct{}) go func() { c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) \u0026lt;-c ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second) defer cancel() if err := srv.Shutdown(ctx); nil != err { log.Fatalf(\u0026#34;server shutdown failed, err: %v\\n\u0026#34;, err) } log.Println(\u0026#34;server gracefully shutdown\u0026#34;) close(processed) }() // serve err := srv.ListenAndServe() if http.ErrServerClosed != err { log.Fatalf(\u0026#34;server not gracefully shutdown, err :%v\\n\u0026#34;, err) } // waiting for goroutine above processed \u0026lt;-processed } Demo2 # func main() { c := make(chan os.Signal) // 监听信号 signal.Notify(c, syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2) go func() { for s := range c { switch s { case syscall.SIGHUP, syscall.SIGINT, syscall.SIGTERM: fmt.Println(\u0026#34;退出:\u0026#34;, s) ExitFunc() case syscall.SIGUSR1: fmt.Println(\u0026#34;usr1\u0026#34;, s) case syscall.SIGUSR2: fmt.Println(\u0026#34;usr2\u0026#34;, s) default: fmt.Println(\u0026#34;其他信号:\u0026#34;, s) } } }() fmt.Println(\u0026#34;启动了程序\u0026#34;) sum := 0 for { sum++ fmt.Println(\u0026#34;休眠了:\u0026#34;, sum, \u0026#34;秒\u0026#34;) time.Sleep(1 * time.Second) } } func ExitFunc() { fmt.Println(\u0026#34;开始退出...\u0026#34;) fmt.Println(\u0026#34;执行清理...\u0026#34;) fmt.Println(\u0026#34;结束退出...\u0026#34;) os.Exit(0) } Demo3 # package main import ( \u0026#34;log\u0026#34; \u0026#34;io\u0026#34; \u0026#34;time\u0026#34; \u0026#34;net/http\u0026#34; ) func startHttpServer() *http.Server { srv := \u0026amp;http.Server{Addr: \u0026#34;:8080\u0026#34;} http.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { io.WriteString(w, \u0026#34;hello world\\n\u0026#34;) }) go func() { if err := srv.ListenAndServe(); err != nil { // cannot panic, because this probably is an intentional close log.Printf(\u0026#34;Httpserver: ListenAndServe() error: %s\u0026#34;, err) } }() // returning reference so caller can call Shutdown() return srv } func main() { log.Printf(\u0026#34;main: starting HTTP server\u0026#34;) srv := startHttpServer() log.Printf(\u0026#34;main: serving for 10 seconds\u0026#34;) time.Sleep(10 * time.Second) log.Printf(\u0026#34;main: stopping HTTP server\u0026#34;) // now close the server gracefully (\u0026#34;shutdown\u0026#34;) // timeout could be given instead of nil as a https://golang.org/pkg/context/ if err := srv.Shutdown(nil); err != nil { panic(err) // failure/timeout shutting down the server gracefully } log.Printf(\u0026#34;main: done. exiting\u0026#34;) } "},{"id":23,"href":"/docs/programmer/game_and_simulation/noteofue4/","title":"UE4 笔记","section":"Game and Simulation","content":" UE4 笔记 # 手机 # 路径必须不能用汉字, 一律全英文(神奇\u0026hellip;以前习惯就是全英,以为这问题是上世纪的了,测试时不知怎么就把顺手的英文换成中文了,结果就莫名中枪了) java8 (ue4.26.2, 之前4.25也是, 反正就找个稳定版java一直使吧, 这语言太amazing了.) 虽然对java版本有一定要求, 不过按照我这次的测试和使用, 觉得折腾那么久完全是汉字项目名不支持\u0026hellip;所以java版本要求应该不是很严重 动画 # 事件图表\u0026amp;动画图表 # 事件图表: 收集动画-\u0026gt;存储在变量中 动画图表: 驱动所有动作 事件图表 # isValid # 蓝图不知道被哪个实例持有(通用)\n朝向 # 主角本地坐标X轴正方向表正前方\nGetVelocity\nRotationFromXVector\nGetControlRotaion\n2,3求Delta.\n输出 # 速度 方向 总步骤 # 向量长度获取Speed 向量方向-控制器方向获取Direction 以上2保存为变量, 交由动画图表 动画图表 # Params-Blend-Result:\n获取速度,方向(看情况可多可少) 将1输入动画混合空间 输出姿势 State Machine # 在以上一组动作中加入状态细分\nState Machine - State1-(rule)-State2\u0026hellip;StateN State - (Params-Blend-Result) 生效 # 角色 网格体(骨骼网格体) 动画-动画类-动画蓝图 "},{"id":24,"href":"/docs/programmer/base/tipsofweb/","title":"Nginx高可用","section":"Base","content":" Keepalived+Nginx实现高可用 # Nginx 关键字 # IO多路复用epoll(IO复用) 轻量,插件: Nginx仅保留了HTTP CPU亲和: 每个worker进程固定在一个CPU Nginx配置 # 代理 # 动静分离 # 动态页面和静态页面交给不同的服务器来解析\n负载均衡 # upstream balanceServer { server 10.1.22.33:12345; server 10.1.22.34:12345; server 10.1.22.35:12345; } server { server_name fe.server.com; listen 80; location /api { proxy_pass http://balanceServer; } } 机制 # 默认: 轮询, 单机卡顿, 影响分配在这台服务器下的用户 默认: 权重轮询, 宕机Nginx会自动剔除出队列, ip_hash-来源IP分配分配给同个服务器 fair: 根据相应时间均衡分配, 默认不支持. 需安装upstream_fair, url_hash类ip_hash同样需要安装Nginx的hash软件包. Keepalived 配置 # 粘贴自: 这里\n概览 # VIP IP 主机名 Nginx端口 默认主从 192.168.50.130 192.168.50.133 liuyazhuang133 88 MASTER 192.168.50.130 192.168.50.134 liuyazhuang134 88 BACKUP 主机器配置 # vi /etc/keepalived/keepalived.conf # 主要 global_defs { ## keepalived 自带的邮件提醒需要开启 sendmail 服务。 建议用独立的监控或第三方 SMTP router_id liuyazhuang133 ## 标识本节点的字条串，通常为 hostname } ## keepalived 会定时执行脚本并对脚本执行的结果进行分析，动态调整 vrrp_instance 的优先级。如果脚本执行结果为 0，并且 weight 配置的值大于 0，则优先级相应的增加。如果脚本执行结果非 0，并且 weight配置的值小于 0，则优先级相应的减少。其他情况，维持原本配置的优先级，即配置文件中 priority 对应的值。 vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/nginx_check.sh\u0026#34; ## 检测 nginx 状态的脚本路径 interval 2 ## 检测时间间隔 weight -20 ## 如果条件成立，权重-20 } ## 定义虚拟路由， VI_1 为虚拟路由的标示符，自己定义名称 vrrp_instance VI_1 { state MASTER ## 主节点为 MASTER， 对应的备份节点为 BACKUP interface eth0 ## 绑定虚拟 IP 的网络接口，与本机 IP 地址所在的网络接口相同， 我的是 eth0 virtual_router_id 33 ## 虚拟路由的 ID 号， 两个节点设置必须一样， 可选 IP 最后一段使用, 相同的 VRID 为一个组，他将决定多播的 MAC 地址 mcast_src_ip 192.168.50.133 ## 本机 IP 地址 priority 100 ## 节点优先级， 值范围 0-254， MASTER 要比 BACKUP 高 nopreempt ## 优先级高的设置 nopreempt 解决异常恢复后再次抢占的问题 advert_int 1 ## 组播信息发送间隔，两个节点设置必须一样， 默认 1s ## 设置验证信息，两个节点必须一致 authentication { auth_type PASS auth_pass 1111 ## 真实生产，按需求对应该过来 } ## 将 track_script 块加入 instance 配置块 track_script { chk_nginx ## 执行 Nginx 监控的服务 } # # 虚拟 IP 池, 两个节点设置必须一样 virtual_ipaddress { 192.168.50.130 ## 虚拟 ip，可以定义多个 } } 备份机配置 # vi /etc/keepalived/keepalived.conf # 备份 ! Configuration File for keepalived global_defs { router_id liuyazhuang134 } vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/nginx_check.sh\u0026#34; interval 2 weight -20 } vrrp_instance VI_1 { state BACKUP interface eth1 virtual_router_id 33 mcast_src_ip 192.168.50.134 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } track_script { chk_nginx } virtual_ipaddress { 192.168.50.130 } } Nginx 运维命令 # # 快速关闭Nginx，可能不保存相关信息，并迅速终止web服务 nginx -s stop # 平稳关闭Nginx，保存相关信息，有安排的结束web服务 nginx -s quit # 因改变了Nginx相关配置，需要重新加载配置而重载 nginx -s reload # 重新打开日志文件 nginx -s reopen # 为 Nginx 指定一个配置文件，来代替缺省的 nginx -c filename # 不运行，而仅仅测试配置文件。nginx 将检查配置文件的语法的正确性，并尝试打开配置文件中所引用到的文件 nginx -t # 显示 nginx 的版本 nginx -v # 显示 nginx 的版本，编译器版本和配置参数 nginx -V # 格式换显示 nginx 配置参数 2\u0026gt;\u0026amp;1 nginx -V | xargs -n1 2\u0026gt;\u0026amp;1 nginx -V | xargs -n1 | grep lua "},{"id":25,"href":"/docs/programmer/ml/opencv/","title":"OpenCV","section":"Ml","content":"\n问题(libSM.so.6 缺失) # 运行opencv的代码时，报以下错误： # Traceback (most recent call last): File \u0026#34;data_generator.py\u0026#34;, line 24, in \u0026lt;module\u0026gt; import cv2 File \u0026#34;/usr/local/lib/python3.5/dist-packages/cv2/__init__.py\u0026#34;, line 3, in \u0026lt;module\u0026gt; from .cv2 import * ImportError: libSM.so.6: cannot open shared object file: No such file or directory 解决 # 原因是缺少共享文件库，解决办法如下：\n安装apt-file $ apt-get update $ apt-get install apt-file $ apt-file update\n寻找依赖库 $ apt-file search libSM.so.6\nlibsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6 libsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1\n根据提示，安装合适的依赖库 $ apt-get install libsm6\n其余文件缺失类似, 即可解决问题。 "},{"id":26,"href":"/docs/programmer/base/for_china/","title":"各个软件换源","section":"Base","content":"\n在国内用原源都会很慢, 所以总结一下各个软件(?吧)换源方法.\nQt # 使用Maintain管理kit时，可以在Settings中设置Repositories，设置地址可从Qt Downloads页面查询.\napt # 可解决版本升级时的问题,即使用了国内源,最后一个文件不知道为什么还是从国外拉取\u0026hellip;\n# sudo touch /etc/apt/apt.conf sudo vim /etc/apt/apt.conf -\u0026gt; Acquire::http::Proxy \u0026ldquo;http://127.0.0.1:8001\u0026rdquo;;\nFreeBSD # mkdir -p /usr/local/etc/pkg/repos vim /usr/local/etc/pkg/repos/bjtu.conf\nbjtu: { url: \u0026#34;pkg+http://mirror.bjtu.edu.cn/reverse/freebsd-pkg/${ABI}/quarterly\u0026#34;, mirror_type: \u0026#34;srv\u0026#34;, signature_type: \u0026#34;none\u0026#34;, fingerprints: \u0026#34;/usr/share/keys/pkg\u0026#34;, enabled: yes } FreeBSD: { enabled: no } pkg update\nQt # 源 # 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/ 清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/ 北京理工大学：http://mirror.bit.edu.cn/qtproject/ 中国互联网络信息中心：https://mirrors.cnnic.cn/qt/ Python Pip # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) 源 # 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ Nodejs Npm # 不过好像换了会有问题.Npm各个包依赖混乱不堪,不忍直视.\nnpm install --registry=https://registry.npm.taobao.org Ubuntu # 地址: /etc/apt/sources.list\n注意备份, sudo 权限\n文件内容如下, 原源部分没有粘贴完全 # 20.04 Focal Fossa # # 国内源 # Ali deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse # QH # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse # See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to # newer versions of the distribution. deb http://archive.ubuntu.com/ubuntu/ focal main restricted # deb-src http://archive.ubuntu.com/ubuntu/ focal main restricted ## Major bug fix updates produced after the final release of the ## distribution. deb http://archive.ubuntu.com/ubuntu/ focal-updates main restricted # deb-src http://archive.ubuntu.com/ubuntu/ focal-updates main restricted # 原源(以下可保存也可不保存吧, 以上可选其一也可全部都放着, 目前没啥问题) ## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu ## team. Also, please note that software in universe WILL NOT receive any ## review or updates from the Ubuntu security team. Pi # 同debian\n"},{"id":27,"href":"/docs/programmer/net/net/","title":"网络(Computer Network)","section":"Net","content":"\nC++ \u0026amp; Epoll # 代码可见这里\n也没啥高级就是:\ncreate_socket epoll_create1 epoll_ctl(1. \u0026amp; 2.) struct epoll_event events[MAX_EPOLL_EVENTS] = {0}; while1: epoll_wait(2, \u0026amp; 4.) eventfd == sockfd accept else =\u0026gt; connfd read 所以就是:\nepoll_event -\u0026gt; 内核空间 epitem -\u0026gt; 红黑 设备事件就绪 - callback (epitem -\u0026gt; rdlist链表) emmmm\u0026hellip;有需要再继续整理吧 和select-poll区别为: 一个遍历, 一个触发式的.\n"},{"id":28,"href":"/docs/programmer/base/tipsofdebugers/","title":"tips Of Debuggers","section":"Base","content":" Clang \u0026amp;\u0026amp; lldb # 听说clang+lldb \u0026gt;= gcc + gdb, 所以一试:\nlldb基本命令 # 与GDB相同\nbreak (b) - 设置断点，也就是程序暂停的地方 run (r) - 启动目标程序，如果遇到断点则暂停 step (s) - 进入下一条指令中的函数内部 backtrace (bt) - 显示当前的有效函数 frame (f) - 默认显示当前栈的内容，可以通过 frame arg 进入特定的 frame（用作输出本地变量） next (n) - 运行当前箭头指向行 continue (c) - 继续运行程序直到遇到断点。 clang hello.c -g -o hello lldb hello # lldb b main run n p str 还有颜色 😂 可视效果确实提高了不少 而且这四个工具可以混用,也蛮好.\nGDB # First and foremost, you will need to compile your program with the flag \u0026ldquo;-g\u0026rdquo; (for debug) to run it via GDB. From there the syntax to start debugging is:\n$ gdb -tui [executable\u0026#39;s name] placing breakpoints\nbreak [line number] or b [line number] or [file name]:[line number] or [function name] And even better, can set conditional breakpoints:\nbreak [line number] if [condition] For example, can set (if have a loop)\nbreak 11 if i \u0026gt; 97 Place a \u0026ldquo;watchpoint\u0026rdquo; which will pause the program if a variable is modified:\nwatch [variable] Once our breakpoints are set, we can run the program with the \u0026ldquo;run\u0026rdquo; command, or simply:\nr [command line arguments if your program takes some] How we got to that point:\nbt Display all the local variables and their current values.\ninfo locals Of course:\np [variable] ptype [variable] step next delete [line number] continue quit Playing with fire. As well do it all the way:\nset var [variable] = [new value] "},{"id":29,"href":"/docs/programmer/base/notesdjango/","title":"Django的建站的(｡･･)ﾉﾞ","section":"Base","content":"author: Ian\nDjango 的一些东西 # 一些问题 # 使用字体 zh-cn时如果报错: # OSError: No translation files found for default language zh-cn.\nLANGUAGE_CODE = \u0026#39;zh-Hans\u0026#39; TIME_ZONE = \u0026#39;Asia/Shanghai\u0026#39; # zh-Hans是简体中文 zh-Hant是繁体中文 # 如果数据库有UTC的时间，那么可以设置： # USE_TZ = True 改为 USE_TZ = False 时区问题 # python3.8/site-packages/django/db/models/fields/init.py:1416: RuntimeWarning: DateTimeField {DATABASEMODEL}.update_time received a naive datetime (2023-09-14 21:55:56) while time zone support is active. warnings.warn(\u0026ldquo;DateTimeField %s received a naive datetime (%s)\u0026rdquo;\n这个警告是由于在使用带有时区支持的DateTimeField字段时，传入了一个没有时区信息的datetime对象。要修复这个警告，你可以将传入DateTimeField字段的datetime对象转换为带有时区信息的datetime对象。\n有两种方法可以解决这个问题：\n使用带有时区信息的datetime对象：确保在创建datetime对象时，使用正确的时区信息。你可以使用pytz库来设置时区信息，例如： from datetime import datetime import pytz # 创建带有时区信息的datetime对象 naive_datetime = datetime(2023, 9, 14, 21, 55, 56) timezone = pytz.timezone(\u0026#34;Asia/Shanghai\u0026#34;) aware_datetime = timezone.localize(naive_datetime) # 将带有时区信息的datetime对象传递给DateTimeField字段 ScannerDevice.update_time = aware_datetime 将DateTimeField字段的auto_now或auto_now_add属性设置为True：这将自动将字段的值设置为当前的带有时区信息的datetime对象。例如： from django.db import models class DATABASEMODEL(models.Model): update_time = models.DateTimeField(auto_now=True) 通过以上两种方法之一，你可以修复这个警告并确保正确处理时区信息。\ndaemon 命令 # Django 的 BaseCommand怎么使用？\nAI: 要使用 Django 的 BaseCommand，你需要按照以下步骤操作：\n创建一个新的 Python 模块或文件，例如 myapp/management/commands/mycommand.py 这里的路径很重要 在 mycommand.py 文件中导入必要的模块和类： from django.core.management.base import BaseCommand 创建一个继承自 BaseCommand 的子类，并实现 handle() 方法来定义你的命令逻辑。例如： class Command(BaseCommand): help = \u0026#39;My custom command\u0026#39; def handle(self, *args, **options): # 在这里编写你的命令逻辑 self.stdout.write(\u0026#39;Hello, world!\u0026#39;) 在 Django 项目中运行你的命令。使用以下命令格式： python manage.py mycommand 这将执行你在 handle() 方法中定义的逻辑。 你还可以在 handle() 方法中使用 self.stdout.write() 方法来输出信息到命令行。\n示例如下: # from django.core.management.base import BaseCommand class Command(BaseCommand): def add_arguments(self, parser): parser.add_argument(\u0026#39;-s\u0026#39;, \u0026#34;--start\u0026#34;, required=True) parser.add_argument(\u0026#39;-e\u0026#39;, \u0026#34;--end\u0026#34;, required=True) def handle(self, **options): try: start_timed = datetime.datetime.strptime(options.get(\u0026#39;start\u0026#39;, None), \u0026#34;%Y-%m-%d\u0026#34;) end_timed = datetime.datetime.strptime(options.get(\u0026#39;end\u0026#39;, None), \u0026#34;%Y-%m-%d\u0026#34;) run(start_timed, end_timed) except Exception: print(traceback.print_exc()) 如此就可以使用如下命令执行:\npython manage.py {pyfilename} --start 2023-04-01 --end 2023-05-01 利用nginxfd反向代理解决跨域问题 # 纠结了很久的跨域问题。。。。。。一直配置Django。。。。。问题重重，从配置方面这条路还没找到解决方案，如以后确认无误后就再放在这儿。告慰前面付出的种种艰辛 😓😀\n来自(这儿)[https://www.jb51.net/article/105786.htm]\n方法是： 打开nginx默认配置文件/etc/nginx/sites-available/default 更改如下：\n## demo listen 5017 proxy 5000 and 5001 ## server { listen 5017; server_name a.xxx.com; access_log /var/log/nginx/a.access.log; error_log /var/log/nginx/a.error.log; root html; index index.html index.htm index.php; ## send request back to flask ## location / { proxy_pass http://127.0.0.1:5000/ ; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; } location /proxy { rewrite ^.+proxy/?(.*)$ /$1 break; proxy_pass http://127.0.0.1:5001/ ; #Proxy Settings proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; } } ## End a.xxx.com ## 很显然，这种解决方法仅仅适用于同服务器，架设两个网站。进行跨域访问。 所以这种东西……就很欠缺。 或者nginx也支持多服务器“并联”？\n但这种解决方案依然不能解决两个“严格无关”的网站通信。\n摒弃java后的\u0026rsquo;欢乐\u0026rsquo;?时光? # Django 的前端相关 # [^_^]虽然我前端不用这个吧，但就一记录。届时估计还是回来翻Django官方文档的。 摘一个看一个牛逼哄哄的东西： Removing hardcoded URLs in templates Remember, when we wrote the link to a question in the polls/index.html template, the link was partially hardcoded like this\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;/polls/{{ question.id }}/\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; The problem with this hardcoded, tightly-coupled approach is that it becomes challenging to change URLs on projects with a lot of templates. However, since you defined the name argument in the path() functions in the polls.urls module, you can remove a reliance on specific URL paths defined in your url configurations by using the \\{\\% url \\%\\} template tag: The problem with this hardcoded, tightly-coupled approach is that it becomes challenging to change URLs on projects with a lot of templates. However, since you defined the name argument in the path() functions in the polls.urls module, you can remove a reliance on specific URL paths defined in your url configurations by using the \\{\\% url \\%\\} template tag:\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; The way this works is by looking up the URL definition as specified in the polls.urls module. You can see exactly where the URL name of ‘detail’ is defined below:\n# the \u0026#39;name\u0026#39; value as called by the {% url %} template tag path(\u0026#39;\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), If you want to change the URL of the polls detail view to something else, perhaps to something like polls/specifics/12/ instead of doing it in the template (or templates) you would change it in polls/urls.py:\n# added the word \u0026#39;specifics\u0026#39; path(\u0026#39;specifics/\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), Namespacing URL names # The answer is to add namespaces to your URLconf. In the polls/urls.py file, go ahead and add an app_name to set the application namespace:\nfrom django.urls import path from . import views app_name = \u0026#39;polls\u0026#39; urlpatterns = [ path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/\u0026#39;, views.detail, name=\u0026#39;detail\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/results/\u0026#39;, views.results, name=\u0026#39;results\u0026#39;), path(\u0026#39;\u0026lt;int:question_id\u0026gt;/vote/\u0026#39;, views.vote, name=\u0026#39;vote\u0026#39;), ] Change your polls/index.html template from: polls/templates/polls/index.html¶\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; to point at the namespaced detail view: polls/templates/polls/index.html¶\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{% url \u0026#39;polls:detail\u0026#39; question.id %}\u0026#34;\u0026gt;{{ question.question_text }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; 版本 # 其中，很令人头疼的便是版本。 如果遇到什么莫名其妙的错，请查看是否是版本的原因。 这里的版本原因并不☞一些人说的库依赖严重，好像开发者版本更迭不考虑兼容——或者说居然勤奋的接口重换那般严重。 此处仅仅☞在运行新版本时否个方法时，或许会莫名其妙引发一个早已摒弃的函数错误。这时候就可能是在折腾版本是导致有的不同版本有文件残留。在运行时莫名其妙的被import了然后它有调取其他东西，但是找不到的…\n这时候轻则pip uninstall 重则环境重建。所以可见虚拟环境还是挺有用的嘛——\nMVC # 全名： Model 、View、Controller。模型，视图，控制器这种功能分离的软件设计规范。所以它是通用的…不要和爪哇捆绑，搞得和某个神奇技术一般… (⊙﹏⊙)\n简介 # 在安装之后，使用django-admin startproject +名字来初始化一个工程。 对比到python中就是创建好了文档目录，还在文件中写入相关框架代码，以此支持运行。\n试一下? # python manage.py runserver 便可开启服务器，这时候访问相应端口，就一个欢迎界面，提示嗯~ o(￣▽￣)o，你能开跑了。\n再试一下？ # 在11版本中有\\admin地址可以访问，访问之后便是一个登陆界面.但,并不知道用户名和密码啊~ emm… 不过好处是能看到这个页面至少保证了django在render一个.html页面时是正常的。而之前说的老版本残留就会导致render时出错。\n结构 # 根目录下，\u0026lsquo;项目名文件\u0026rsquo;是项目容器😰 manage.py 命令行工具，emm 类似于python click库的命令行程序，使用参数干不同的事情。 进入到项目容器中，其中settings.py顾名思义 urls.py同上，管理各个url通往哪里 wsgl.py某个兼容啥，现在不用管…\n得知结构之后 # 然后就能\n在urls.py里愉快的添加各个功能url。这里面就一个urlpatterns列表，使用djangol.conf.urls.url方法来配置。 不过其对应的执行函数都需要一个request来接受请求数据。 return回一个页面~ 现在用到的有django,shortcuts.render 及 render_to_response出来的，以及django.http.HttpResponse出来的东西。\n嗯…… ulr 链接的执行方法详情就放在新创建的view.py中管理。\n而在view中需要渲染的html文件则放置在根目录新创建的templates文件夹中。通过在setting.py中的\u0026rsquo;TEMPLATES\u0026rsquo;列表中的不知名字典(因为它确实没取名啊😔)deDIRS元素来指路。\n这下可以很厉害了 # 进而进行数据库配置—— 还在setting.py中的\u0026rsquo;DATABASES\u0026rsquo;来指路。 但Django规定要使用模型，就要创建一个爱怕怕app：\ndjango-admin startapp TestModel 🦑 再将此爱怕怕领到setting.py中NSTALLED_APPS中签一下到。 随后在TestModel下的models中创建继承于django.db.models.Model的数据类，然后使用隶属于models下的方法来制定数据类型eg:\nname = models.CharField(max_length=20) 毕竟不能直接通过Python的自由类嘛… 然后也肯定不能通过python的制定类型… 毕竟python数据类型和MySQL天差地别。\n最后 再回到命令行中使用\npython manage.py migrate //创建表结构 python manage.py makemigrations //通知更改 python manage.py testModel // 创建表结构 😲❓ 正式拉入编制之后就能用了。 2019年1月23日\n- Change your models(in *models.py*) - Run *python manage.py makemigrations* to create migration for those changes - Run *python manage.py migrate* to apply those changes to the database Of courses, If Null Run python manage.py migrate can make a models.py whitch has nothings.\n那么这个数据库怎么操作呢？ # 自然是到urls.py中添加🔗链接到方法的路 再到容器里面添加testdb.py来说明方法详细。\n增删改查 # 实例化类 直接.save()即保存 未实例化类，all标识查找全部 .objects.filter(填写删选条件) .objects.get(获取) .order_by(排序条件) 更改则是将查出来的东西直接修改.update(修改东西) 再.save保存 删除便是.delete() ``. 差不多了 之后的详细再随情况更新。 ### 那么数据库表多了怎么一键生成对应类呢？ ```shell python manage.py inspectdb //自动生成models模型文件 python manage.py inspectdb \u0026gt; app/models.py //假设有了名为\u0026#39;app\u0026#39;的爱怕怕 // 老一套 python manage.py makemigrations python manage.py migrate 但是会将之前models.py中的东西删掉… 还会把数据库中的表名重命名… 按它的规矩来生成，嗯…其实也🆗的。\n我爱Java 2018年6月24日16点40分的我由衷的写到 # 在MySQL中读取blob存储的字段时，使用BinaryField不可使用其逆向生成的模型读取方式。当然，对照表如下\n\u0026#39;AutoField\u0026#39;: \u0026#39;integer AUTO_INCREMENT\u0026#39;, \u0026#39;BigAutoField\u0026#39;: \u0026#39;bigint AUTO_INCREMENT\u0026#39;, \u0026#39;BinaryField\u0026#39;: \u0026#39;longblob\u0026#39;, \u0026#39;BooleanField\u0026#39;: \u0026#39;bool\u0026#39;, \u0026#39;CharField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;CommaSeparatedIntegerField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;DateField\u0026#39;: \u0026#39;date\u0026#39;, \u0026#39;DateTimeField\u0026#39;: \u0026#39;datetime\u0026#39;, \u0026#39;DecimalField\u0026#39;: \u0026#39;numeric(%(max_digits)s, %(decimal_places)s)\u0026#39;, \u0026#39;DurationField\u0026#39;: \u0026#39;bigint\u0026#39;, \u0026#39;FileField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;FilePathField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;FloatField\u0026#39;: \u0026#39;double precision\u0026#39;, \u0026#39;IntegerField\u0026#39;: \u0026#39;integer\u0026#39;, \u0026#39;BigIntegerField\u0026#39;: \u0026#39;bigint\u0026#39;, \u0026#39;IPAddressField\u0026#39;: \u0026#39;char(15)\u0026#39;, \u0026#39;GenericIPAddressField\u0026#39;: \u0026#39;char(39)\u0026#39;, \u0026#39;NullBooleanField\u0026#39;: \u0026#39;bool\u0026#39;, \u0026#39;OneToOneField\u0026#39;: \u0026#39;integer\u0026#39;, \u0026#39;PositiveIntegerField\u0026#39;: \u0026#39;integer UNSIGNED\u0026#39;, \u0026#39;PositiveSmallIntegerField\u0026#39;: \u0026#39;smallint UNSIGNED\u0026#39;, \u0026#39;SlugField\u0026#39;: \u0026#39;varchar(%(max_length)s)\u0026#39;, \u0026#39;SmallIntegerField\u0026#39;: \u0026#39;smallint\u0026#39;, \u0026#39;TextField\u0026#39;: \u0026#39;longtext\u0026#39;, \u0026#39;TimeField\u0026#39;: \u0026#39;time\u0026#39;, \u0026#39;UUIDField\u0026#39;: \u0026#39;char(32)\u0026#39;, 以上是一部分，具体点这里\n模型字段名称 # 在逆向生成时，我遇到过一次将数据库名修改的先例，不过后来似乎没有修改过。 然后就是驼峰命名法的字段可能emm也是因为此我才开始写这些信息，就是，驼峰命名法的字段可能在模型字段中为全小写。 还有就是Django莫名其妙的的编码错误，真的是一分钟编程，一小时修改编码…而且调试起来真的…我目前的调试方式极为原始，所以感觉真的不想编程嗯…\nDjango 返回文件下载 # def readFile(fn, buf_size=262144): # 大文件下载，设定缓存大小 f = open(fn, \u0026#34;rb\u0026#34;) while True: # 循环读取 c = f.read(buf_size) if c: yield c else: break f.close() response = HttpResponse(readFile(filePath), content_type=\u0026#39;APPLICATION/OCTET-STREAM\u0026#39;) # 设定文件头，这种设定可以让任意文件都能正确下载，而且已知文本文件不是本地打开 fileName = \u0026#39;haya\u0026#39; fileType = \u0026#39;.docx\u0026#39; response[\u0026#39;Content-Disposition\u0026#39;] = \u0026#39;attachment; filename=\u0026#39; + fileName.encode(\u0026#39;utf-8\u0026#39;) + fileType.encode(\u0026#39;utf-8\u0026#39;) # 设定传输给客户端的文件名称 response[\u0026#39;Content-Length\u0026#39;] = os.path.getsize(filePath) # 传输给客户端的文件大小 return response Python Docx编辑 # 替换 # 在`.docx`文件中将需要替换的位置 使用变量站位，写法{{ placheholdParaName }} 使用文件时，只能写做{{placheholdParaName}}不能有空格…另外docx使用docx中的Document读入即可\ntpl = DocxTemplate(self.prjRootPath + \u0026#39;/word_template/\u0026#39; + \u0026#34;word_template.docx\u0026#34;) sub1 = tpl.new_subdoc() sub1.subdocx = Document(temPath + \u0026#39;sub1_bond.docx\u0026#39;) subContext[\u0026#39;sub1\u0026#39;] = sub1 上述中，只能写作……难道是因为使用{{someThing}}这种写法而隐藏了？！！ 那么，今后写彩带注释岂不是不需要使用^_^而直接使用双花括号的写法就能直接隐藏了么(⊙o⊙ ) 凄い Py中：\nfrom docxtpl import DocxTemplate, InlineImage from docx.shared import Mm, Inches, Pt doc = DocxTemplate(\u0026#34;my_word_template.docx\u0026#34;) myimage = InlineImage(doc, \u0026#39;C:/Users/GuPengxiang/Pictures/ha.jpg\u0026#39;,width=Mm(20)) context = { \u0026#39;fundName\u0026#39; : u\u0026#39;这里是基金名称\u0026#39;, \u0026#39;stars\u0026#39;:u\u0026#39;五星级琉璃六\u0026#39;, \u0026#39; bench\u0026#39;: u\u0026#39;对比基金\u0026#39;, \u0026#39;income\u0026#39;: u\u0026#39;12\u0026#39;, \u0026#39;bb\u0026#39;: u\u0026#39;0.1%\u0026#39;, \u0026#39;image0\u0026#39; : myimage} doc.render(context) doc.save(\u0026#34;generated_doc.docx\u0026#34;) 生成echarts图表图片 # 环境 # # 更新软件列表 \u0026amp; 更新软件 sudo apt-get update sudo apt-get upgrade # 下载包 pip install pyecharts-snapshot wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.5.0-beta-linux-ubuntu-xenial-x86_64.tar.gz # 解压 tar -xzvf phantomjs-2.5.0-beta-linux-ubuntu-xenial-x86_64.tar.gz # 进入路径 cd phantomjs-2.5.0-beta-ubuntu-xenial/bin # 赋予权限 chmod +x phantomjs # 查看版本号 phantomjs -v # 若显示版本号，如 2.1.1 则生效 生成图片 # from pyecharts import Line, Pie, Grid from pyecharts_snapshot.main import make_a_snapshot attr = [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;] v1 = [5, 20, 36, 10, 10, 100] v2 = [55, 60, 16, 20, 15, 80] line = Line(\u0026#34;折线图示例\u0026#34;) line.add(\u0026#34;商家A\u0026#34;, attr, v1, mark_point=[\u0026#34;average\u0026#34;]) line.add(\u0026#34;商家B\u0026#34;, attr, v2, is_smooth=True, mark_line=[\u0026#34;max\u0026#34;, \u0026#34;average\u0026#34;]) line.render(\u0026#39;test.html\u0026#39;) make_a_snapshot(\u0026#39;test.html\u0026#39;, \u0026#39;test.pdf\u0026#39;) # 或者直接生成 line.render(\u0026#39;test.png\u0026#39;) 在生成图片时，插件包文件源码中有Log，但却是print出来的，而在部署环境中不允许出现print，所以…… 得在包源码中将之屏蔽\n连续生成图片 # 用以上方法来生成图片是…很慢的🐢⬅这个速度。但可以通过使用为渲染创建一个默认配置环境来避免多次生成环境配置。所以—— 具体来看pyecharts中的高级说明🕶\nfrom pyecharts import Bar, Line from pyecharts.engine import create_default_environment bar = Bar(\u0026#34;我的第一个图表\u0026#34;, \u0026#34;这里是副标题\u0026#34;) bar.add(\u0026#34;服装\u0026#34;, [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;], [5, 20, 36, 10, 75, 90]) line = Line(\u0026#34;我的第一个图表\u0026#34;, \u0026#34;这里是副标题\u0026#34;) line.add(\u0026#34;服装\u0026#34;, [\u0026#34;衬衫\u0026#34;, \u0026#34;羊毛衫\u0026#34;, \u0026#34;雪纺衫\u0026#34;, \u0026#34;裤子\u0026#34;, \u0026#34;高跟鞋\u0026#34;, \u0026#34;袜子\u0026#34;], [5, 20, 36, 10, 75, 90]) env = create_default_environment(\u0026#34;html\u0026#34;) # 为渲染创建一个默认配置环境 # create_default_environment(filet_ype) # file_type: \u0026#39;html\u0026#39;, \u0026#39;svg\u0026#39;, \u0026#39;png\u0026#39;, \u0026#39;jpeg\u0026#39;, \u0026#39;gif\u0026#39; or \u0026#39;pdf\u0026#39; env.render_chart_to_file(bar, path=\u0026#39;bar.html\u0026#39;) env.render_chart_to_file(line, path=\u0026#39;line.html\u0026#39;) (￣▽￣)o 如上\n注意 # 在生成报表时， 由于采用的是浏览器截图的方式，在使用`phantomjs`时会自动判断图片是否加载完成（echarts在显示图表之前是有一段动画的……）然后再`pyecharts`中并没有关闭动画的接口，而echarts是有的。 但毕竟`echarts`是在做翻译，所以只要在\u0026quot;Chart\u0026quot;基类中，将`animation=False`就可以了。 我改的时候在`chart.py`文件的29行，def __init__中。 SSl加密，https配置 # 虽然就配置过之后显得操作很简单，而且也很明显，但就配置之初着实还是费了一些功夫的。或许是因为大而全的东西懒得看，而网上搜索到的粘贴复制之词又太过片面，或许大家写的时候也就当作日记来写的，本就没准备让别人去参考。所以再加上搜索的时候俺表述词不达意，所以总是很曲折（呵，用谷歌搜外文网就不存在这问题，前面就谦虚一下🙃）\n之前写的文档 # 1 ssl加密部署步骤说明文档 一．申请ssl证书 1.生成csr文件，可使用openssl工具生成 (1)例:openssl genrsa -des3 -out server.key 1024 生成服务器key文件; (2)例:openssl req -new -key server.key -out server.csr 生成服务器证书请求CSR文件; 或使用CSR文件生成工具生成(例https://www.chinassl.net/ssltools/generator-csr.html，填写信息后点击生成CSR文件即可) （CSR文件中包括组织部门、国家地区、算法、以及邮箱和域名等信息） 2.申请/购买HTTPS证书， 填写与上述相同的信息，验证类型选择DNS，CSR生成选择提供CSR(即提供第一步生成的CSR文件)（例：在阿里云或腾讯等地，本文档撰写时是通过https://freessl.org/ 免费申请而来（一年有效期，单域名，）） 二、验证域名所属关系 1.到域名管理控制台中选择云解析DNS, 选择域名，添加“记录”，记录类型选择‘TXT’，主机记录及记录值填写证书申请方提供内容。 2.等待1分钟或10分钟后，等待生效 3.点击验证 三、证书下载 验证通过后，下载网站提供证书，含（CA证书、服务器证书、服务器私钥） 四、Apache2部署开启SSL加密 更改httpd.conf 文件设置： 1.Listen {内网IP}:80 2.开启models (1)LoadModule ssl_module modules/mod_ssl.so (2)LoadModule socache_shmcb_module modules/mod_socache_shmcb.so (3)LoadModule rewrite_module modules/mod_rewrite.so (4)ServerName {与域名相同}（未测试是否必须相同） 3.http跳转到https: (1)RewriteEngine on (2)RewriteCond %{SERVER_PORT} !^443$ (3)RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] 更改extra/httpd-ssl.conf 文件设置 1.Listen 443 2.ServerName www.lejinrong.cn 3.ServerAdmin admin@lejinrong 4.SSLCertificateFile \u0026ldquo;c:/Apache24/conf/ssl/server.crt\u0026rdquo; 5.SSLCertificateKeyFile \u0026ldquo;c:/Apache24/conf/ssl/server.key\u0026rdquo; 第四步中crt文件指向服务器证书文件， 第五步中.key文件指向私钥文件 (其余部署方案或许有所不同，会使用CA证书)\n1.1 注意： 确保服务器中防火墙入站规则中添加了80端口和443端口。\n2 附： 2.1.1 本地测试方案：\n环境：wamp Apache 2.4.9 前言：wamp安装好后，默认的只有http服务，以下配置启用https服务 条件：在Apache安装目录下需要有一下文件 [Apache安装目录]/modules/ mod_ssl.so [Apache安装目录]/bin/ openssl.exe, libeay32.dll, ssleay32.dll [Apache安装目录]/conf/ openssl.cnf 步骤： 一、修改配置文件httpd.conf，去掉下面行首的#（载入ssl模块和其他配置文件） LoadModule socache_shmcb_module modules/mod_socache_shmcb.so LoadModule ssl_module modules/mod_ssl.so Include conf/extra/httpd-ssl.conf 二、认证文件生成（生成证书签发请求） 进入Apache安装目录的bin目录下，输入cmd，进入DOS窗口，输入以下命令 openssl req -new -out server.csr -config ../conf/openssl.cnf 回车后提示输入密码和确认密码，本机输入：keypasswd 后面会提示输入一系列的参数 \u0026hellip;\u0026hellip; Country Name (2 letter code) [AU]: （要求输入国家缩写，只能输入2个字母，这里输入cn） State or Province Name (full name) [Some-State]: （要求输入州名或省名，这里输入hubei） Locality Name (eg, city) []: （要求输入城市名，这里输入wuhan） Organization Name (eg, company) [Internet Widgits Pty Ltd]: （要求输入组织名或公司名，这里输入gg） Organizational Unit Name (eg, section) []: （要求输入部门名，这里输入gg） Common Name (eg, YOUR name) []: （要求输入服务器域名或IP地址） Email Address []: （要求输入邮件地址） A challenge password[]:（要求输入密码） An optional company name[]（要求输入公司别名，这里输入ggs） \u0026hellip;.. 生成私钥，在DOS窗口下的Apache的bin目录下输入命令 openssl rsa -in privkey.pem -out server.key 然后要求输入之前 privkey.pem 的密码（keypasswd) 创建证书，输入命令 openssl x509 -in server.csr -out server.crt -req -signkey server.key -days 8000 回车后，显示创建成功，有效期为 8000 天 将Apache的bin目录下的server.csr、server.crt、server.key拷贝到Apache安装目录下的conf\\ssl，若没有ssl文件则创建 打开Apache安装目录conf/extra/httpd-ssl.conf文件，设置SSLCertificateFile和SSLCertificateKeyFile SSLCertificateFile \u0026ldquo;C:/apache2.4.9/conf/ssl/server.crt\u0026rdquo; SSLCertificateKeyFile \u0026ldquo;C:/apache2.4.9/conf/ssl/server.key\u0026rdquo; 最后重启Apache服务，HTTPS服务的默认监听端口为443 随后在本机中安装server.crt至收信人的根证书颁发机构即可不再提示证书无效 注意：在重启Apache时，若Apache服务启动不起来，则在Apache安装目录的bin目录下，输入httpd –t，可以根据提示来修改你的配置文件\n附 # 现在是2018年8月25日16点01分 所以上面其实是一个月前写给别人看的文档。 在我搜的时候由于先在本地配置，尔后再网上找CA发证书，自我感觉这个步骤没有什么问题。就今天在\nApache配置双网站/https # 的时候，也是这样，先在本地通过不同端口测试，确定方案之后再在服务器上通过ServerName进行区分。 也就是启用httpd-vhosts.conf之后，再\n# Virtual Hosts # # Required modules: mod_log_config # If you want to maintain multiple domains/hostnames on your # machine you can setup VirtualHost containers for them. Most configurations # use only name-based virtual hosts so the server doesn\u0026#39;t need to worry about # IP addresses. This is indicated by the asterisks in the directives below. # # Please see the documentation at # \u0026lt;URL:http://httpd.apache.org/docs/2.4/vhosts/\u0026gt; # for further details before you try to setup virtual hosts. # # You may use the command line option \u0026#39;-S\u0026#39; to verify your virtual host # configuration. # # VirtualHost example: # Almost any Apache directive may go into a VirtualHost container. # The first VirtualHost section is used for all requests that do not # match a ServerName or ServerAlias in any \u0026lt;VirtualHost\u0026gt; block. # \u0026lt;VirtualHost 192.168.1.81:80\u0026gt; ServerName www.lejinrong.cn ServerAlias www.lejinrong.cn ServerAdmin www.lejinrong.cn #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; RewriteEngine on RewriteCond %{SERVER_PORT} !^400$ RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] ErrorLog \u0026#34;logs/dummy-host.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/dummy-host.example.com-access.log\u0026#34; common \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.81:8880\u0026gt; ServerName lejinrong.cn ServerAlias vip.lejinrong.cn ServerAdmin vip.lejinrong.cn #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; ErrorLog \u0026#34;logs/dummy-host.example.com-error.log\u0026#34; CustomLog \u0026#34;logs/dummy-host.example.com-access.log\u0026#34; common RewriteEngine on RewriteCond %{SERVER_PORT} !^443$ RewriteRule ^/?(.*)$ https://%{SERVER_NAME}/$1 [L,R] \u0026lt;/VirtualHost\u0026gt; 同理，在httpd-ssl.conf中也是通过配置不同VirtualHost进行区分\n# # This is the Apache server configuration file providing SSL support. # It contains the configuration directives to instruct the server how to # serve pages over an https connection. For detailed information about these # directives see \u0026lt;URL:http://httpd.apache.org/docs/2.4/mod/mod_ssl.html\u0026gt; # # Do NOT simply read the instructions in here without understanding # what they do. They\u0026#39;re here only as hints or reminders. If you are unsure # consult the online docs. You have been warned. # # Required modules: mod_log_config, mod_setenvif, mod_ssl, # socache_shmcb_module (for default value of SSLSessionCache) # # Pseudo Random Number Generator (PRNG): # Configure one or more sources to seed the PRNG of the SSL library. # The seed data should be of good random quality. # WARNING! On some platforms /dev/random blocks if not enough entropy # is available. This means you then cannot use the /dev/random device # because it would lead to very long connection times (as long as # it requires to make more entropy available). But usually those # platforms additionally provide a /dev/urandom device which doesn\u0026#39;t # block. So, if available, use this one instead. Read the mod_ssl User # Manual for more details. # #SSLRandomSeed startup file:/dev/random 512 #SSLRandomSeed startup file:/dev/urandom 512 #SSLRandomSeed connect file:/dev/random 512 #SSLRandomSeed connect file:/dev/urandom 512 # # When we also provide SSL we have to listen to the # standard HTTP port (see above) and to the HTTPS port # Listen 443 Listen 400 #ServerName www.lejinrong.cn ## ## SSL Global Context ## ## All SSL configuration in this context applies both to ## the main server and all SSL-enabled virtual hosts. ## # SSL Cipher Suite: # List the ciphers that the client is permitted to negotiate, # and that httpd will negotiate as the client of a proxied server. # See the OpenSSL documentation for a complete list of ciphers, and # ensure these follow appropriate best practices for this deployment. # httpd 2.2.30, 2.4.13 and later force-disable aNULL, eNULL and EXP ciphers, # while OpenSSL disabled these by default in 0.9.8zf/1.0.0r/1.0.1m/1.0.2a. SSLCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES SSLProxyCipherSuite HIGH:MEDIUM:!MD5:!RC4:!3DES # By the end of 2016, only TLSv1.2 ciphers should remain in use. # Older ciphers should be disallowed as soon as possible, while the # kRSA ciphers do not offer forward secrecy. These changes inhibit # older clients (such as IE6 SP2 or IE8 on Windows XP, or other legacy # non-browser tooling) from successfully connecting. # # To restrict mod_ssl to use only TLSv1.2 ciphers, and disable # those protocols which do not support forward secrecy, replace # the SSLCipherSuite and SSLProxyCipherSuite directives above with # the following two directives, as soon as practical. # SSLCipherSuite HIGH:MEDIUM:!SSLv3:!kRSA # SSLProxyCipherSuite HIGH:MEDIUM:!SSLv3:!kRSA # User agents such as web browsers are not configured for the user\u0026#39;s # own preference of either security or performance, therefore this # must be the prerogative of the web server administrator who manages # cpu load versus confidentiality, so enforce the server\u0026#39;s cipher order. SSLHonorCipherOrder on # SSL Protocol support: # List the protocol versions which clients are allowed to connect with. # Disable SSLv3 by default (cf. RFC 7525 3.1.1). TLSv1 (1.0) should be # disabled as quickly as practical. By the end of 2016, only the TLSv1.2 # protocol or later should remain in use. SSLProtocol all -SSLv3 SSLProxyProtocol all -SSLv3 # Pass Phrase Dialog: # Configure the pass phrase gathering process. # The filtering dialog program (`builtin\u0026#39; is an internal # terminal dialog) has to provide the pass phrase on stdout. SSLPassPhraseDialog builtin # Inter-Process Session Cache: # Configure the SSL Session Cache: First the mechanism # to use and second the expiring timeout (in seconds). #SSLSessionCache \u0026#34;dbm:c:/Apache24/logs/ssl_scache\u0026#34; SSLSessionCache \u0026#34;shmcb:c:/Apache24/logs/ssl_scache(512000)\u0026#34; SSLSessionCacheTimeout 300 # OCSP Stapling (requires OpenSSL 0.9.8h or later) # # This feature is disabled by default and requires at least # the two directives SSLUseStapling and SSLStaplingCache. # Refer to the documentation on OCSP Stapling in the SSL/TLS # How-To for more information. # # Enable stapling for all SSL-enabled servers: #SSLUseStapling On # Define a relatively small cache for OCSP Stapling using # the same mechanism that is used for the SSL session cache # above. If stapling is used with more than a few certificates, # the size may need to be increased. (AH01929 will be logged.) #SSLStaplingCache \u0026#34;shmcb:c:/Apache24/logs/ssl_stapling(32768)\u0026#34; # Seconds before valid OCSP responses are expired from the cache #SSLStaplingStandardCacheTimeout 3600 # Seconds before invalid OCSP responses are expired from the cache #SSLStaplingErrorCacheTimeout 600 ## ## SSL Virtual Host Context ## \u0026lt;VirtualHost 192.168.1.81:400\u0026gt; # General setup for the virtual host DocumentRoot \u0026#34;c:/Apache24/htdocs\u0026#34; ServerName www.lejinrong.cn ServerAdmin admin@lejinrong.cn ErrorLog \u0026#34;c:/Apache24/logs/error.log\u0026#34; TransferLog \u0026#34;c:/Apache24/logs/access.log\u0026#34; # SSL Engine Switch: # Enable/Disable SSL for this virtual host. SSLEngine on # Server Certificate: # Point SSLCertificateFile at a PEM encoded certificate. If # the certificate is encrypted, then you will be prompted for a # pass phrase. Note that a kill -HUP will prompt again. Keep # in mind that if you have both an RSA and a DSA certificate you # can configure both in parallel (to also allow the use of DSA # ciphers, etc.) # Some ECC cipher suites (http://www.ietf.org/rfc/rfc4492.txt) # require an ECC certificate which can also be configured in # parallel. SSLCertificateFile \u0026#34;c:/Apache24/conf/ssl/server.crt\u0026#34; #SSLCertificateFile \u0026#34;c:/Apache24/conf/server-dsa.crt\u0026#34; #SSLCertificateFile \u0026#34;c:/Apache24/conf/server-ecc.crt\u0026#34; # Server Private Key: # If the key is not combined with the certificate, use this # directive to point at the key file. Keep in mind that if # you\u0026#39;ve both a RSA and a DSA private key you can configure # both in parallel (to also allow the use of DSA ciphers, etc.) # ECC keys, when in use, can also be configured in parallel SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/ssl/server.key\u0026#34; #SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/server-dsa.key\u0026#34; #SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/server-ecc.key\u0026#34; # Server Certificate Chain: # Point SSLCertificateChainFile at a file containing the # concatenation of PEM encoded CA certificates which form the # certificate chain for the server certificate. Alternatively # the referenced file can be the same as SSLCertificateFile # when the CA certificates are directly appended to the server # certificate for convenience. #SSLCertificateChainFile \u0026#34;c:/Apache24/conf/server-ca.crt\u0026#34; # Certificate Authority (CA): # Set the CA certificate verification path where to find CA # certificates for client authentication or alternatively one # huge file containing all of them (file must be PEM encoded) # Note: Inside SSLCACertificatePath you need hash symlinks # to point to the certificate files. Use the provided # Makefile to update the hash symlinks after changes. #SSLCACertificatePath \u0026#34;c:/Apache24/conf/ssl.crt\u0026#34; #SSLCACertificateFile \u0026#34;c:/Apache24/conf/ssl.crt/ca-bundle.crt\u0026#34; # Certificate Revocation Lists (CRL): # Set the CA revocation path where to find CA CRLs for client # authentication or alternatively one huge file containing all # of them (file must be PEM encoded). # The CRL checking mode needs to be configured explicitly # through SSLCARevocationCheck (defaults to \u0026#34;none\u0026#34; otherwise). # Note: Inside SSLCARevocationPath you need hash symlinks # to point to the certificate files. Use the provided # Makefile to update the hash symlinks after changes. #SSLCARevocationPath \u0026#34;c:/Apache24/conf/ssl.crl\u0026#34; #SSLCARevocationFile \u0026#34;c:/Apache24/conf/ssl.crl/ca-bundle.crl\u0026#34; #SSLCARevocationCheck chain # Client Authentication (Type): # Client certificate verification type and depth. Types are # none, optional, require and optional_no_ca. Depth is a # number which specifies how deeply to verify the certificate # issuer chain before deciding the certificate is not valid. #SSLVerifyClient require #SSLVerifyDepth 10 # TLS-SRP mutual authentication: # Enable TLS-SRP and set the path to the OpenSSL SRP verifier # file (containing login information for SRP user accounts). # Requires OpenSSL 1.0.1 or newer. See the mod_ssl FAQ for # detailed instructions on creating this file. Example: # \u0026#34;openssl srp -srpvfile c:/Apache24/conf/passwd.srpv -add username\u0026#34; #SSLSRPVerifierFile \u0026#34;c:/Apache24/conf/passwd.srpv\u0026#34; # Access Control: # With SSLRequire you can do per-directory access control based # on arbitrary complex boolean expressions containing server # variable checks and other lookup directives. The syntax is a # mixture between C and Perl. See the mod_ssl documentation # for more details. #\u0026lt;Location /\u0026gt; #SSLRequire ( %{SSL_CIPHER} !~ m/^(EXP|NULL)/ \\ # and %{SSL_CLIENT_S_DN_O} eq \u0026#34;Snake Oil, Ltd.\u0026#34; \\ # and %{SSL_CLIENT_S_DN_OU} in {\u0026#34;Staff\u0026#34;, \u0026#34;CA\u0026#34;, \u0026#34;Dev\u0026#34;} \\ # and %{TIME_WDAY} \u0026gt;= 1 and %{TIME_WDAY} \u0026lt;= 5 \\ # and %{TIME_HOUR} \u0026gt;= 8 and %{TIME_HOUR} \u0026lt;= 20 ) \\ # or %{REMOTE_ADDR} =~ m/^192\\.76\\.162\\.[0-9]+$/ #\u0026lt;/Location\u0026gt; # SSL Engine Options: # Set various options for the SSL engine. # o FakeBasicAuth: # Translate the client X.509 into a Basic Authorisation. This means that # the standard Auth/DBMAuth methods can be used for access control. The # user name is the `one line\u0026#39; version of the client\u0026#39;s X.509 certificate. # Note that no password is obtained from the user. Every entry in the user # file needs this password: `xxj31ZMTZzkVA\u0026#39;. # o ExportCertData: # This exports two additional environment variables: SSL_CLIENT_CERT and # SSL_SERVER_CERT. These contain the PEM-encoded certificates of the # server (always existing) and the client (only existing when client # authentication is used). This can be used to import the certificates # into CGI scripts. # o StdEnvVars: # This exports the standard SSL/TLS related `SSL_*\u0026#39; environment variables. # Per default this exportation is switched off for performance reasons, # because the extraction step is an expensive operation and is usually # useless for serving static content. So one usually enables the # exportation for CGI and SSI requests only. # o StrictRequire: # This denies access when \u0026#34;SSLRequireSSL\u0026#34; or \u0026#34;SSLRequire\u0026#34; applied even # under a \u0026#34;Satisfy any\u0026#34; situation, i.e. when it applies access is denied # and no other module can change it. # o OptRenegotiate: # This enables optimized SSL connection renegotiation handling when SSL # directives are used in per-directory context. #SSLOptions +FakeBasicAuth +ExportCertData +StrictRequire \u0026lt;FilesMatch \u0026#34;\\.(cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory \u0026#34;c:/Apache24/cgi-bin\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; # SSL Protocol Adjustments: # The safe and default but still SSL/TLS standard compliant shutdown # approach is that mod_ssl sends the close notify alert but doesn\u0026#39;t wait for # the close notify alert from client. When you need a different shutdown # approach you can use one of the following variables: # o ssl-unclean-shutdown: # This forces an unclean shutdown when the connection is closed, i.e. no # SSL close notify alert is sent or allowed to be received. This violates # the SSL/TLS standard but is needed for some brain-dead browsers. Use # this when you receive I/O errors because of the standard approach where # mod_ssl sends the close notify alert. # o ssl-accurate-shutdown: # This forces an accurate shutdown when the connection is closed, i.e. a # SSL close notify alert is send and mod_ssl waits for the close notify # alert of the client. This is 100% SSL/TLS standard compliant, but in # practice often causes hanging connections with brain-dead browsers. Use # this only for browsers where you know that their SSL implementation # works correctly. # Notice: Most problems of broken clients are also related to the HTTP # keep-alive facility, so you usually additionally want to disable # keep-alive for those clients, too. Use variable \u0026#34;nokeepalive\u0026#34; for this. # Similarly, one has to force some clients to use HTTP/1.0 to workaround # their broken HTTP/1.1 implementation. Use variables \u0026#34;downgrade-1.0\u0026#34; and # \u0026#34;force-response-1.0\u0026#34; for this. BrowserMatch \u0026#34;MSIE [2-5]\u0026#34; \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 # Per-Server Logging: # The home of a custom SSL log file. Use this when you want a # compact non-error SSL logfile on a virtual host basis. CustomLog \u0026#34;c:/Apache24/logs/ssl_request.log\u0026#34; \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b\u0026#34; #指定myweb项目的wsgi.py配置文件路径 WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/Fund_Evaluation_System/wsgi.py #配置静态变量路径 Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.81:443\u0026gt; DocumentRoot \u0026#34;c:/Apache24/htdocs\u0026#34; ServerName www.lejinrong.cn ServerAdmin admin@lejinrong.cn ErrorLog \u0026#34;c:/Apache24/logs/error.log\u0026#34; TransferLog \u0026#34;c:/Apache24/logs/access.log\u0026#34; SSLEngine on SSLCertificateFile \u0026#34;c:/Apache24/conf/ssl/server.crt\u0026#34; SSLCertificateKeyFile \u0026#34;c:/Apache24/conf/ssl/server.key\u0026#34; \u0026lt;FilesMatch \u0026#34;\\.(cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory \u0026#34;c:/Apache24/cgi-bin\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; BrowserMatch \u0026#34;MSIE [2-5]\u0026#34; \\ nokeepalive ssl-unclean-shutdown \\ downgrade-1.0 force-response-1.0 CustomLog \u0026#34;c:/Apache24/logs/ssl_request.log\u0026#34; \\ \u0026#34;%t %h %{SSL_PROTOCOL}x %{SSL_CIPHER}x \\\u0026#34;%r\\\u0026#34; %b\u0026#34; WSGIScriptAlias / D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/Fund_Evaluation_System/wsgi.py Alias /static/ D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static/ \u0026lt;Directory D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3/static\u0026gt; Allow from all \u0026lt;/Directory\u0026gt; DocumentRoot \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34; \u0026lt;Directory \u0026#34;D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V3\u0026#34;\u0026gt; Options Indexes FollowSymLinks AllowOverride None \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; 但其实 都写了跳转，所以在httpd-vhosts.conf文件中的项目以及静态资源路径指定就不用指定了，只不过我懒得删… 还有一个坑点就是 原本有一个指定项目路径以及python环境的语句：\n#WSGIPythonPath \u0026#34;C:/Python27/Lib;C:/Python27/Lib/site-packages;C:/Python27/DLLs\u0026#34; #WSGIPythonPath D:/FundEvaluationSystem_svn1 #WSGIPythonHome \u0026#34;C:/Python27\u0026#34; 我不知道按照上下这两种为什么会出问题，但网上那些人不会。但中间那个是用来指向项目路径的一个取巧的办法。哦因为wsgi或许我已经在别处制订过了。所以只要在wsgi.py中声明sys.path.append('D:/FundEvaluationSystem_svn1/Fund_Evaluation_System_V2')就可以将项目包括进来，而不需要通过 第二句那个制定python路径的东西。而用那个，会导致资源只有声明的项目1会被加载，而项目2的资源就不会声明，而将那三句话注释，只要分别在\u0026rsquo;wsgi.py\u0026rsquo;中声明项目资源，而在.conf文件中指向\u0026rsquo;wsgi.py\u0026rsquo;文件就可以如数加载了。\n(⊙﹏⊙)语序 逻辑混乱之后不加班了再整理吧~~😭\n前端 Vue # vue的使用方式可以通过html页面直接引用，也能直接用vue-cil创建项目。 网上人称vue脚手架？晓不大得 而我这里自然说的就是 vue-cil即 通过vue init webpack \u0026lt;prjName\u0026gt;来生成的项目喽\n系统的创建以及介绍之后使用再熟一些再写，现在先记一些零散的东西。 [^_^]2018年9月18日 21点36分\n路由配置登陆访问 # 在`router/index.js`中： { path: \u0026#39;/\u0026#39;, // 首页 name: \u0026#39;Main\u0026#39;, component: Main, meta: { requireAuth: true, // 添加该字段，表示进入这个路由是需要登录的 } }, "},{"id":30,"href":"/docs/programmer/langs/noteofgolang/","title":"Golang笔记","section":"Langs","content":" Golang笔记 # 先贴一个客观的教程文档网站http://www.runoob.com/go/go-slice.html\n并发 Channel # 使用关键字go开启goroutine 轻量级线程\ngo fun_name(paras_list) # eg: go f(x, y, z) 代码\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func say(s string) { for i := 0; i \u0026lt; 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) } } func main() { go say(\u0026#34;world\u0026#34;) say(\u0026#34;hello\u0026#34;) } Channel # 用于传递数据的数据结构 可用于两个goroutine之间传递指定类型值，同步和通讯 \u0026lt;- 指定通道方向(发送or接受)，未指定则双向通道\n声明通道 # 使用chan关键字, 在使用之前，需先创建.\nch := make(chan int) 示例\npackage main import \u0026#34;fmt\u0026#34; func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c \u0026lt;- sum // 把 sum 发送到通道 c } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := \u0026lt;-c, \u0026lt;-c // 从通道 c 中接收 fmt.Println(x, y, x+y) } Cache # 在创建通道时可创建缓冲区，做压入存储\nch := make(chan int, 100) // cache size package main import \u0026#34;fmt\u0026#34; func main() { // 这里我们定义了一个可以存储整数类型的带缓冲通道 // 缓冲区大小为2 ch := make(chan int, 2) // 因为 ch 是带缓冲的通道，我们可以同时发送两个数据 // 而不用立刻需要去同步读取数据 ch \u0026lt;- 1 ch \u0026lt;- 2 // 获取这两个数据 fmt.Println(\u0026lt;-ch) fmt.Println(\u0026lt;-ch) } Vim 高亮 # emmmm，偶尔会有不支持Go高亮的情况 所以，步骤如下：\ncd ~ mkdir .vim cd .vim mkdir autoload plugged cd plugged git clone https://github.com/fatih/vim-go vim-go cd autoload wget https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 配置 .vimrc\ncat ~/.vimrc set shiftwidth=4 softtabstop=4 expandtab call plug#begin() Plug \u0026lsquo;fatih/vim-go\u0026rsquo;, { \u0026lsquo;do\u0026rsquo;: \u0026lsquo;:GoInstallBinaries\u0026rsquo; } call plug#end() let g:go_version_warning = 0 over~!\n函数定义 # func function_name([参数列表])[返回类型]{ balabala } 如：\nfunc Divide(varDividee int, varDivider int) (result int, errorMsg string) { if varDivider == 0 { dData := DivideError{ dividee: varDividee, divider: varDivider, } errorMsg = dData.Error() return } else { return varDividee / varDivider, \u0026#34;\u0026#34; } } 接口 # package main import ( \u0026#34;fmt\u0026#34; ) # 或者 直接 import \u0026#34;fmt\u0026#34; type Phone interface { call() } type NokiaPhone struct { } func (nokiaPhone NokiaPhone) call() { fmt.Println(\u0026#34;I am Nokia, I can call you!\u0026#34;) } type IPhone struct { } func (iPhone IPhone) call() { fmt.Println(\u0026#34;I am iPhone, I can call you!\u0026#34;) } func main() { var phone Phone phone = new(NokiaPhone) phone.call() phone = new(IPhone) phone.call() } 错误 # package main import ( \u0026#34;fmt\u0026#34; ) // 定义一个 DivideError 结构 type DivideError struct { dividee int divider int } // 实现 `error` 接口 func (de *DivideError) Error() string { // 以上函数中，取结构体地址是（等同于面向对象实例化对象吧，然后下方可以 // de.使用.的方式去调取结构体中定义的某变量） //错误Error()是调用接口中的函数，制定返回类型为string strFormat := ` Cannot proceed, the divider is zero. dividee: %d divider: 0 ` return fmt.Sprintf(strFormat, de.dividee) } // 定义 `int` 类型除法运算的函数 func Divide(varDividee int, varDivider int) (result int, errorMsg string) { if varDivider == 0 { dData := DivideError{ dividee: varDividee, divider: varDivider, } errorMsg = dData.Error() return } else { return varDividee / varDivider, \u0026#34;\u0026#34; } } func main() { // 正常情况 if result, errorMsg := Divide(100, 10); errorMsg == \u0026#34;\u0026#34; { fmt.Println(\u0026#34;100/10 = \u0026#34;, result) } // 当被除数为零的时候会返回错误信息 if _, errorMsg := Divide(100, 0); errorMsg != \u0026#34;\u0026#34; { fmt.Println(\u0026#34;errorMsg is: \u0026#34;, errorMsg) } } 以上总结 # 函数定义真是… 也或许刚开始接触太多。也不知道这么设计的目的 其中 功能重写见d.Data.Error。先是将d.Data定义为结构体，然后再去调用结构体下的Error，分明结构体里并没有定义，所以下面的那个函数定然是将Error,与DicideError连接的函数。\n所以Go并没有类与对象一说吧…\n生动点来说那个函数（func (de *DivideError) Error() string {...}）的定义就好像是在强行给这个地址的结构体中塞进去一个执行函数。 一个言简意骇的对象实现方法\ngo的循环 # golang 只有for while==for golang 中没有小括号包裹, 只需要用{}分隔作用域就可以 for 可以有\nfor A;B;C {} for ;B; {} for {} go的switch # 每个case自动break fallthrough 显式声明可以继续执行下一个case case 无需常量 switch {case} 可做 if-else 用 go的指针 # go的指针 没有指针运算.\n"},{"id":31,"href":"/docs/programmer/gui/noteofvn_py/","title":"Vn.Py学习笔记（Python交易平台框架）","section":"Gui","content":"author: Ian\nVn.Py笔记 ✏📔 # # 一个开源Python交易软件，主使用CTP协议。当然，还有其他协议了其源项目在http://www.vnpy.org/ 初期笔记 # 报单交易过程中， CTP使用BrokerID 从业务层面完全隔离不同经纪公司的交易、风控及结算用户的接入。 BrokerID具体取值咨询开户的经纪公司。 CTP中 UserID为操作员代码，InversterID为投资者代码； 投资者自己下单两者同为投资者代码\nCTP-API中，OrderRef和OrderAction 前者为CTP后台提供给客户端标识一笔报 单的字段，从客户端可通过（FrontID、SessionID、OrderRef）唯一确定一笔报 单；；；后者与OrderRef功能相似，提供给客户端来标识一笔撤单。 前者的数据类型为字符数组，必须为阿拉伯数字字符。 OrderRef（OrderActionRef）取值必须保证在同一会话内发送的报单 OrderRef（OrderActionRef）值大于之前的最大值，开发多线程客户端尤为需要 注意。 CTP-API库：\nerror.dtd\\error.xml 错误定义文件 ---- ThostFrfcMdApi.h 交易接口类定义文件 ——— ThostFtfcUserApiDataType.h 类型定义文件 ------ thostmduserapi.lib,thostmduserpi.dll 行情接口库文件 ----- thosttraderapi.lib,thosttraderapi.dll交易接口库文件 ----- 交易和行情接口类定义文件都包含API 和 SPI类定义，客户端使用API向CTP后台 发送请求，CTP后台则使用SPI向客户端回传响应及回报 行情Demo开发： 1.将API文件复制到工程目录；并将所有的头文件和静态、动态库连链接库 并将文件导入到项目工程中。 先继承行情接口类CThostFtdcMdspi，并实现需要实现的虚函数。 OnFrontConnectde、OnFrontDisconnected、OnPspUserLogin、 OnRspSubMarketDAta /API工作流程***/\nAPI压缩包——API含常量对应字符、类型定义、操作系统编译定义、回调函数（MdSpi）（柜台向用户端发送信息后被系统自动调用的函数）、主动函数（MdApi）（向柜台发送各种请求和指令）\nAPI工作流程： 创建MdSpi对象（回掉函数），调用MdApi类，以Create开头的静态方法，创建MdApi对象（主动函数），注册MdSpi对象指针，行情柜台前置机地址，调用MdApi对象Init方法初始化连接前置机，连接成功会通过OnFrontConnected回调通知用户，用户获得连接成功通知后，调MdApi的ReqUserLogin登陆，登陆后MdSpi的OnRsqUserLogin通知用户 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-到此登陆完成\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nMdApi：（行情相关） 使用MdApi对象的SubscribeMarketData方法，传入参数为想要订阅的“合约 代码”，订阅成功当合约有新行情通过MdApi的OnRtnDepthMarketData回调通知 用户 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-至此订阅完成\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; 当用户的某次请求发生错误时，会通过OnRspError通知用户 MdApi也含有退订合约、登出功能。 而一般退出程序则直接杀进程（不太安全便是）\nTraderApi：（交易相关） 不同于以上的有 注册TraderSpi对象的指针后需要调用TraderApi对象的 SubscribePrivateTopic和SubscribePublicTopic方法去选择公开和私有数据流的重 传方法 对于期货柜台，每一日第一次登陆需要先查询前一日的结算单，等待查询 结果返回，确认，才可进行后续操作（CTP、恒生UFT），证券（LTS）无此要求 上一步完成后，用户可以调用ReqQryInstrument的方法查询柜台上所有可 以交易的合约信息（包括代码、中文名、涨跌停、最小价位变动、合约乘数等大 量细节），一般是在这里获得合约信息列表后，再去MdApi中订阅合约；经常有 人问为什么在MdApi中找不到查询可供订阅的合约代码的函数，这里尤其要注 意，必须通过TraderApi来获取 当用户报单、成交状态发生变化时，TraderApi会自动通过OnRtnOrder、 OnRtnTrade通知，无需额外订阅 /封装API****/ 封装后API的动作： 主动函数： 调用封装API主动函数，传入Python变量作为参数—\u0026gt;封装API将Python变量转换成C++变量—\u0026gt;API调用原生API主动函数传入C++变量作为参数 回掉函数： 交易柜台通过原生API传入参数为C++变量-\u0026gt;封装API将C++变量转换为Python变量-\u0026gt;封装API调用封装后的回调函数想Python程序中推送数\n封装处理： 将回调函数Spi类和主动函数Api类封装为一个类，使用中更加方便 在API中包含一个缓冲队列，当回调函数收到新的数据信息时只是简单存入 并立即返回，而数据信息的处理和向Python中的推送则由另一个工作线程执行 鉴于Python中dict字典内的键和值的类型可以不同，所以利用此来代替 C++的结构体 处理示例： getChar()： d(Python字典对象) key(d中想要提取的数据键名) if(d.has_key(key)) 判断是否存在这个键； object o = d[key]; 提取对应值 extract\u0026lt;string\u0026gt; x(o); 生成提取 std::string类的提取器 if (x.check()) 检测能否提取出数据 string s = x(); 执行解包器，提取 string对象 const char *buffer = s.c_str(); 从s中获取字符串指针bufffer strcpy_s(value, strlen(buffer) + 1, buffer); 将字符串指针指向的字符串数组复制到结构体成员的指针上 对字符串指针赋值 必须使用strcpy_s, vs2013使用strcpy 编译通不过+1应该是因为C++字符串的结尾符号？不是特别确定，不加这个 1会出错 /事件驱动***/\n时间驱动： 定时调用 事件驱动： 新事件被推送时（如新行情、成交）则调用 初始化： 事件队列、引擎开关（标志）、事件线程、定时器、一个事件和处理函数对应字典（__handlers） 引擎运行： 循环检查引擎开关 若开则一直尝试获取事件（阻塞开，时间1s），处理事件； 若出错则pass 处理事件： 检测是否有对当前事件监听的处理函数，若有则循环调用相应处理函数对事件进行处理 计时器事件： 创建计时器事件，推入计时器事件 引擎启动： 打开引擎开关、启动事件处理线程、启动定时器（事件默认间隔1s） 停止引擎： 关闭。。。。、停止计时器、等待事件处理线程退出 注册事件处理： 尝试获取对应处理此类型函数列表（对应字典），若无则创建。 注销函数监听： 。。。。。。。。。。。。。。。。。。。。。，若无则pass，若函数存在于列表则将之移除，若函数列表为空，则引擎中移除该事件类型 put： 向事件队列中存入事件\n底层接口对接： 交易程序架构分：底层接口、中层引擎、顶层GUI， 为将某API对接到程序中需：1.将API的回调函数收到的数据—\u0026gt;中层引擎 等待处理 2.将API的主动函数进行一定的简化封装，便于中层引擎调用\n中层引擎设计： 进一步封装底层接口所暴露出的API函数，使得其更容易被上层的GUI和策略组件调用。 构造函数： 以主引擎成员变量形式创建事件驱动引擎ee，行情接口md和交易接口td的对象。 随后立即启动，当用户调用接口连接、登陆等功能、收到事件推送，ee可以立即推送到监听这些事件的组件进行处理。 LTS和CTP接口的持仓情况和账户情况不通过推送，需手动查询。Demo选择循环查询模式，不断更新。可选择不进行查询，降低占用网络带宽。 登陆成功后，查询柜台所有可交易信息，保存到dictInstrument字典中，方便后续查询 优化了一些函数方法的调用方式，将经纪商一起提供的接口登陆封装在一个函数中，减少了重复书写的次数。\n引擎之间执行过程 # 发单为例： # 设置发单按钮 -\u0026gt; 将点按动作关联sendOrder发单实现函数（从输入框获取合约代码-\u0026gt;获取合约信息对象（见下） -\u0026gt; 如果成功获取 -\u0026gt; 再获取方向价格等信息 -\u0026gt; 调用主引擎下发单实现 -\u0026gt; 主引擎转到TdApi下发单函数执行（请求编号（API管理） -\u0026gt; 将传入信息数据存入字典（合约代码、方向价格等） -\u0026gt; 报单编号（API管理） -\u0026gt; 用户id、单子属性（投机、立即发单、今日有效）等信息存入字典） -\u0026gt; self.reqOrderInsert(req（信息字典）, self.__reqid（请求编号）) -\u0026gt; 返回订单号（报单编号））\n主引擎：（负责对API的调度） # init()初始化中的动作： 创建事件驱动引擎、创建API接口、启动事件驱动引擎、循环查询持仓和账户相关（之后学习）、创建合约存储空字典，注册插入合约对象执行函数事件类型和其处理函数。 其中包含几乎所有的功能函数，包含了每个功能函数的实现方法\n事件驱动引擎： # init()初始化中的动作： 创建事件队列、创建设置事件引擎开关（关）、创建事件处理线程(目标为引擎运行)、创建计时器（将超时动作连接到__onTimer函数）、创建__handlers空字典（存储对应事件调用关系） 统筹管理事件的执行，在其中建立起事件执行队列管理向队列中插入事件，分配事件对象类型（据此注册其执行函数）和具体事件数据（时间及日志），拥有注册事件处理监听及注销监听。最终使得整个程序有序的进行。\n调用关系 # 主引擎在初始化时即启动事件驱动引擎（调用启动函数start()（将引擎开关设为启动、启动事件处理线程、启动计时器）） -\u0026gt; 事件处理线程运行目标__run()（若开关开则将从事件队列中get()到事件，放到处理函数__process()中执行） -\u0026gt; __process()处理事件函数（检查事件类型，在__handlers字典中是否有对此监听处理函数，若存在则调用字典中处理函数）\n事件启动引擎start()中启动定时器 -\u0026gt; 创建计时器事件 -\u0026gt; 向队列存入计时器事件 获取合约信息对象： # 从合约字典中读取合约信息对象有则继续执行原本程序操作（获取名称、发单撤单），无则None\n以初始化查询为例： # 主引擎初始化中注册self.ee.register(EVENT_TDLOGIN, self.initGet),EVENT_TDLOGIN为交易服务器登陆成功事件。即此事件为登录成功后开始初始化查询。 步骤：打开设定文件setting.vn，尝试读取设定字典。载入后，设定事件类型、将事件推入事件队列、查询投资者、循环查询账户和持仓。（若不存在or合约数据非今天，则发出获取合约请求。）-\u0026gt; 获取合约 -\u0026gt; 定义事件类型 -\u0026gt; 推入事件队列 -\u0026gt; API查询合约\nctpGateway 接入方法 # 考虑到现阶段大部分CTP中的ExchangeID字段返回的都是空值 vtSymbol直接使用symbol\n创建CTP价格方向交易所持仓产品等类型映射，方便调用 然后 class CtpGateway(VtGateway):CTP接口中初始化动作（继承VtGateway实例化事件引擎、设定网关名称为’CTP‘、实例化ctpMdApi，ctpTdApi、初始化行情交易连接状态，循环查询允许）\n连接过程 初始化账号密码等、连接服务器、注册服务器地址、登陆 订阅合约里有个设计为：尚未登陆就调用了订阅则保存订阅信号，则在成功登陆之后的登陆回报函数中重新订阅\n数据记录器 # drBase.py中（定义数据类型）：（数据记录器和CTA两模块共同使用） # K线数据 构造函数（定义数据类型）：vt系统代码、合约代码、交易所代码、开高低 关、bar开始时间、时间、成交量持仓量 Tick数据 构造函数（定义数据类型）：vt系统代码、合约代码、交易所代码、成交数 据、tick时间、五档行情 DrEngine数据记录引擎 # 获取当前文件绝对路径\nsettingFileName = 'DR_setting.json' path = os.path.abspath(os.path.dirname(__file__)) settingFileName = os.path.join(path, settingFileName) 初始化中动作：实例化设置主引擎、事件引擎、获取当前日期、创建主力合约代码映射字典、Tick对象字典、K线对象字典、初始化数据库插入单独线程、载入设置，订阅行情\n载入设置、订阅行情 # 打开DR_setting.json文件，以json载入，其中’working‘决定是否启动行情记录功能。随后从json文件中循环获取合约代码订阅tick和bar\n启动数据插入线程（run函数（向MongoDB中插入数据））、注册事件监听（procecssTickEvent处理行情推送（下详））\n处理行情推送 # 从事件字典中取出保存的具体事件数据、vtSymbol为tick识别信号（合约代码）、转化Tick格式、更新TIck数据（并发出日志）、更新分钟线数据\n风控模块 # 从配置json文件中读取设定信息 操作运作：1.检测风控设定值变化 2.每笔交易发单时使用风控模块决定该次发单是否允许 （其中流控计数在每次调用风控检测时计数、成交合约量在更新成交数据中加交易数值）\nCTA策略 # 直接来到改版之后：\nCTP交易托管API # 介绍 # 基于C++的类库，通过使用提供接口实现相关交易功能，含：报单与报价录入、的撤销、的挂起、的激活、的修改、的查询、成交单查询、投资者查询、 投资者持仓查询、合约查询、交易日获取等\n含文件：交易接口、API所需数据类型、业务相关数据结构i、的头文件、动态链接库、导入库\n体系结构 # 建立在TCP协议之上FTD协议与交易托管系统进行通讯 FTD通讯模式：\n对话通讯模式 - 会员端请求、接收处理、响应 私有通讯模式 - 交易所主动向特定会员发出 广播通讯模式 - 交易所主动、全员发送 接口模式 # CThostFtdeTraderApi和CThostFtdeTraderSpi，前者发送请求，后者回调响应。旗下函数方法前者以Req开头后者以OnRsp开头。请求接口第一个参数为请求的内容，不能为空。第二个参数为请求号。\n如果接收到的响应数据不止一个，则回调函数会被多次调用。第一个参数为响应的具体数据，第二个参数为处理结果，第三个参数为请求号，第四个参数为响应结束标志，表明是否是本次响应的最后一次回调。\n运行模式 # 至少两个线程，一个为应用程序主线程，一个为交易员API工作线程，其间通讯由API工作线程驱动。\n撤单 发单 # 发单为例： # 在用户点击发单之后，程序从“交易”栏的text()获取合约代码，随后从详细合约保存字典中读取其他信息，将之保存到一个字典中之后，调用主引擎对特定接口发单。\n发单完成之后，马上会收到报单响应 OnRspOrderInsert，说明交易系统已经收到报单。报单进入交易系统后，如果报单的交易状态发生变化，就会收到报单回报 OnRtnOrder。如果报单被撮(部分)成交，就会收到成交回报 OnRtnTrade。通过更新\n撤单时： # 程序从单元格中获取exchange、frontID、orderID、sessionID、symbol、gatewayName等信息，调用主引擎对特定接口撤单。撤单时调用Api函数为reqOrderAction其内容包括撤销、挂起、激活、修改，故还需一个Flag参数\nps：如果报单还停留在 Thost，Thost 可以用 Front 、SessionID、OrderRef 来定位 如果报单停留在交易所，Thost 可以用 ExchangID、OrderSysID 来定位，然后向交易 所转发撤单指令。\nTraderApi所有方法功能 # OnFrontConnected/Disconnected # 客户端与交易托管系统建立起通信连接时 OnHeartBeatWarning # 当长时间未收到报文时 OnRspUserLogin/Logout # 登陆注销响应 OnRspUserPasswordUpdate # 改密响应 OnRspTradingAccountPasswordUpdate # 当客户端发出资金账户口令更新指令后，交易托管系统返回响应时 OnRspError # 请求出错时 OnRspOrderInsert # 报单录入 OnRspOrderAction # 报单操作包括报单的撤销、报单的挂起、报单的激活、报单的修改。当客户端 发出过报单操作指令后，交易托管系统返回响应时 OnRspQueryMaxOrderVolume # 查询最大报单 OnRspSettlementInfoConfirm # 当客户端发出投资者结算结果确认指令后，交易托管系统返回响应时 等…… lol 统计无力 ？\nCTA 策略引擎 # _init_()的工作： # 加载主引擎、事件引擎；获取当前日期 设定是否在回测 保存策略实例的字典strategyDict(key为策略名称，value为策略实例)、 保存vtSymbol和策略实例映射的字典(用于推送tick数据，可能多个策略交易同一个vtSymbol因此key为vtSymbol.value为包含所有相关策略对象的list)、 保存vtOrderID和strategy对象映射的字典(用于推送order和trade数据key为vtOrderID，value为strategy对象）、 本地停止单编号计数、本地停止单字典(key为stopOrderID，value为stopOrder对象)、 持仓缓存字典(key为vtSymbol，value为PositionBuffer对象)、 成交号集合、 设置引擎类型为实盘、 注册事件监听 初始化策略 # 从数据库中读取3天的历史TICK数据、行情更新。。。。。有的话待续\n启动策略 # 从策略实例字典中取出策略实例，调用策略函数（已经初始化，没有在进行策略交易），开启进行交易标志位。\n停止策略 # 从策略实例字典中取出策略实例，调用策略函数（ 在进行策略交易），关闭策略交易标志位 -\u0026gt; 对该策略发出的所有限价单进行撤单 -\u0026gt; 发出的所有本地停止单撤单 -\u0026gt;\n保存、读取策略配置 # 触发策略状态变化事件（通常用于通知GUI更新） 获取策略的参数字典 获取策略当前的变量字典\n记录 # 报单更新、成交更新都是先检测是否有对此监听的策略 限价单成交处理：成交回报、报单回报、记录成交到列表、删除该限价单\n基础功能的策略调用 # 策略中发单时，需要在设置参数时考虑设置。 另获取持仓缓存数据，做平昨平今的选择。 策略中发单时，检查报单是否有效，赋参，撤单。 发停止单，编号，赋参，保存至字典 撤停止单，从工作停止单字典中移除\nTa-Lib # 趋势策略分为以下部分：\n趋势信号（通常是基于某几个参数计算出来的指标值超过某个阈值）、 信号过滤（和趋势信号类似）、 出场方案（固定点数/百分比的止盈和止损，移动止损）。 所以，Ta-lib是策略实现工具罢了。 此库中提供了多种技术分析的函数，有多种指标：ADX、MACD、RSI、布林轨道等 ；K线形态识别，如“黄昏之星”、“锤形线”等。\n依靠此库对数据的分析，来下达发单撤单的动作即为策略。\n策略示例： # 基于Talib模块的双指数均线策略`class TalibDoubleSmaDemo(CtaTemplate):` 就是两个指标的数据来判断当前局势罢了\n设定策略参数 策略变量 参数列表（保存参数名称） 变量列表（保存变量名称） 步骤 # 初始化策略（加载Bar数据）、启动策略、停止策略、收到行情Tick推送（计算K线）、收到Bar推送（缓存最新收盘价到列表 -\u0026gt; 数量足够后转化为Numpy数组后传入talib函数SMA中计算 -\u0026gt; 读取当前K线和上一根K线数值，用于判断均线交叉 -\u0026gt; 检测持仓状态，做出相应交易动作）\nCTA回测 # _init_()的工作 # 本地停止单编号计数 self.stopOrderCount 本地停止单字典 self.stopOrderDict And self.workingStopOrderDict 设引擎类型为回测 回测相关变量定义 当前最新数据，用于模拟成交使用 运行回测 # 载入历史数据\n根据回测模式确定要使用数据类\n初始化策略\n启动策略\n回放数据（从数据库中取得推到newBar或者newTick）\n策略获得新数据，执行相应操作\n基于最新数据撮合限价单 # 先确定会撮合成交的价格 -\u0026gt; 遍历限价单字典中所有限价单 -\u0026gt; 判断是否会成交 -\u0026gt; 发生成交推送成交数据（买入 -\u0026gt; 增加持仓 推送委托数据、从字典中删除该限价单）\n计算原理 # 改版之后程序架构 # | | | | | | | | | | | | | |:\u0026mdash;- |\u0026mdash; | \u0026mdash; | |\u0026mdash; |\u0026mdash; |\u0026mdash;- | \u0026mdash; | \u0026mdash; | \u0026mdash; |\u0026mdash; |\u0026mdash;: | | |APIs | |*** | | | | | Trader | | | | |CTP | |KSGold |*** |Common |Condig |Core|Gateway |Setting |Strategy |UI |main| |CtpMdApi、CtpTdApi | ………… | ………… |Md、Td| ……………… | ……………… |CTA、HTA、引擎、事件管理| ……………… |配置文件| ……………… | ……………… | ……………… |\n事件引擎 # 两版都一样，作为一个程序运行最外层的生成的实例，来进行各个实例之间的数据传输。因为每个实例都将数据在事件引擎中保存，调用事件引擎中的事件队列来对进行事件运行安排。\nLike This：\nclass A(object): \u0026quot;\u0026quot;\u0026quot;docstring for A\u0026quot;\u0026quot;\u0026quot; def __init__(self, name): super(A, self).__init__() self.name = name self.a = 0 def da(self): print self.name print self.a a = A('I am A') a.da() class B(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(B, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() b = B(a) b.dada() class C(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(C, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() c = C(a) c.dada() I am A\n0\nI am A\n1\nI am A\n2\nB与C分别在去改变读取在A中定义的数值。 嗯，没错，这么看的画确实时Python基础……所以没有这个基础的我看起来前期还挺费劲。当然，理解很好理解，就是在实现方法上不知原理的话就很难过。最主要的是，知道了原理在自己编写的时候可以的心用手，信手拈来。嗯~ o(￣▽￣)o就是这么写意和惬意。Indigo色在纯黑背景下不好辨识哈哈，还是换少女粉吧\nVn.Py 界面 # Icon 图标下载网: http://www.easyicon.net/\n界面设计文档 # 功能要求 # 连接、登陆，订阅，发撤单，持仓、账户信息、成交（下单时间、成交时间、备注（下单动作者））、保留交易模块、跟随鼠标点击更新交易模块中单子内容\n文档编写步骤 # 由需求确定功能，划分模块，模块关系，下分框架，框架实现\n模块 # 工具栏、行情显示、策略池、账户持仓、消息栏\n工具栏 # 连接（含各个端口） 风控、帮助、登陆状态显示\n工具功能 # 工具名称 说明 备注 连接 弹出端口列表 通过复选框选中对应端口 风控 弹出设定列表 通过文本框输入设定数值 帮助 弹出帮助窗口 策略池 # 操作位置 热点操作 策略名称单元格 鼠标指针悬停 展开操作界面 动作按钮 鼠标单击 执行选中 动作按钮 鼠标右击 展开操作界面 消息栏 # 分“成交”、“错误”、“日志”三个模块，选择相应模块显示对应内容\n日志 错误 成交 时间、内容、接口 时间、错误代码、错误信息、接口 成交编号、委托编号、合约代码、名称、方向、开平、价格、成交量、成交时间、接口 显示操作日志 显示当前操作错误信息 显示成交单信息 账户持仓信息 # 账户显示账户信息，并具备切换账户功能 当前选中账户 显示在旁label中。\n界面切换 # 记录笔记 # 照例，先贴网址： http://www.qaulau.com/books/PyQt4_Tutorial/index.html\n窗口设置 # resize(8, 8) setWindowTitle(u'标题') 获取图标 # def getIcon(filename): \u0026quot;\u0026quot;\u0026quot; 获取图标 \u0026quot;\u0026quot;\u0026quot; fileInfo = Qt.QFileInfo(filename) fileIcon = Qt.QFileIconProvider() icon = QtGui.QIcon(fileIcon.icon(fileInfo)) return icon 使用时： self.setWindowIcon(getIcon('../hi/app.ico')) Dock # widgetTestM, dockTestM = self.createDock(AllMarketMonitor, vtText.“dock 标题”, QtCore.Qt.RightDockWidgetArea) # 方向有： RightDockWidgetArea,BottomDockWidgetArea,LeftDockWidgetArea # 创建dock窗口 # 可利用 self.tabifyDockWidget(dockMarketM, dockAllDataM) 来合并同一个方向上的dock # 此下还没看… dockTradeM.raise_() dockPositionM.raise_() # 连接组件之间的信号 widgetPositionM.itemDoubleClicked.connect(widgetTradingW.closePosition) # 保存默认设置 self.saveWindowSettings('default') 其实现函数为： \u0026ldquo;\u0026ldquo;\u0026ldquo;创建停靠组件\u0026rdquo;\u0026rdquo;\u0026rdquo;\ndef createDock(self, widgetClass, widgetName, widgetArea): widget = widgetClass(self.mainEngine, self.eventEngine) dock = QtGui.QDockWidget(widgetName) dock.setWidget(widget) dock.setObjectName(widgetName) dock.setFeatures(dock.DockWidgetFloatable|dock.DockWidgetMovable) self.addDockWidget(widgetArea, dock) return widget, dock 再本质一点的东西为：\nwidget1 = Ha(self) dock = QtGui.QDockWidget('haha') dock.setObjectName('ha1') dock.setWidget(widget1) dock.setFeatures(dock.DockWidgetFloatable | dock.DockWidgetMovable) self.addDockWidget(QtCore.Qt.BottomDockWidgetArea, dock) 动作 # exit = QtGui.QAction(QtGui.QIcon('hello.ico'), 'exit', self) exit.setShortcut('Ctrl+Q') exit.setStatusTip('Exit application') # 图标、文字、快捷键、提示信息 menubar = self.menuBar() file = menubar.addMenu('\u0026amp;File') file.addAction(exit) # 创建目录和工具栏，将动作添加进去。工具栏同理 定位布局 # 绝对定位 # label1 = QtGui.QLabel(u'绝对定位', self) label1.move(15, 60) # 创建、移动到显示位置 框布局 及 布局元素平均分布 # okButton = QtGui.QPushButton(\u0026quot;OK\u0026quot;) cancelButton = QtGui.QPushButton(\u0026quot;Cancel\u0026quot;) # 创建按钮 hbox = QtGui.QHBoxLayout() hbox.addStretch(1) hbox.addWidget(okButton) # 增加组件 hbox.addWidget(cancelButton) # 创建水平栏 hbox.addStretch() # 平均分布 vbox = QtGui.QVBoxLayout() vbox.addStretch(1) # 创建竖列 vbox.addLayout(hbox) # 将水平栏插入竖列 self.setLayout(vbox) # 显示最终竖列 注意一下add时选择对类型就好了。\n组件之间连接信号 # # classA(QtGui.QTableWidget): # pass classA.itemDoubleClicked.connect(classB.actionFunction) # 这样单纯调用还是可以的，但是数据传输… 就得继续研究一下了。 调用Windows程序 # import win32api path = 'D:/vnpy- \\ master/docker/dockerTrader/gateway/ctpGateway/CTP_connect.json' win32api.ShellExecute(0, 'open', 'notepad.exe', path, '', 1) # 使用记事本打开此文件 Json # with open('D:/vnpy- \\ master/docker/dockerTrader/gateway/ctpGateway/CTP_connect.json', 'r') as f: setting = json.load(f) self.userID = str(setting['userID']) self.password = str(setting['password']) 关闭事件退出提示 # def closeEvent(self, event): reply = QtGui.QMessageBox.question(self, 'Message',\u0026quot;Are you sure to quit?\u0026quot;, QtGui.QMessageBox.Yes, QtGui.QMessageBox.No) if reply == QtGui.QMessageBox.Yes: event.accept() else: event.ignore() 函数放置位置就是主窗口类下就好。\nVS2015 快捷键 # Ctrl + k Ctrl + c # 多行注释 Ctrl + k Ctrl + u # 多行取消注释 鼠标事件 # press move release doubleClick clicked() enterEvent 鼠标移入 leaveEvent 鼠标移出 回去看看具体函数\n信号槽（传输额外参数） # 一般来说，比如一个按钮吧。 在链接点击信号与槽时buttonInit[i].clicked.connect(partial(self.init, i))就完事了。然而，当循环创建按钮，对应同样的槽函数，只是需要执行的变量有区别时，就需要传输额外的参数。 这时，方法有二：\n环境：\npython2.7.8\npyqt 4.11.1\n一： 使用lambda表达式 # 二： 使用functools里的partial函数 # 三：感谢来源\n策略管理 # 策略类，引擎，报单管理\u0026amp;\u0026amp;仓位管理\n引擎 # 引擎中将策略事件有序添加到事件引擎和主引擎中。 读取setting.json 文件对策略参数以及是否启用进行配置。设定日期。 使用策略实例字典保存策略名与实例关系—— 并将此字典在推送字典中与tick数据ID对应（ID对多实例。） 再有orderID与策略对应字典，用以推送order和trade数据 计数本地停止单 、 持仓缓存字典\n报单管理 # 成交推送处理 # 成交回调 - \u0026gt; 订单ID和策略对应字典 -\u0026gt; 计算策略持仓（根据策略方向，持仓增加交易笔数）-\u0026gt; 更新持仓缓存数据\n报单者类 # 单一合约订单缓存类——初始化buffer 存储字典_log策略日志存储\n"},{"id":32,"href":"/docs/programmer/langs/tipsofmarkdown/","title":"tips Of markdown","section":"Langs","content":" Markdown Notes 📪 # HTML锚点 - 页面内点击跳转 # 可以使用 HTML 锚点来实现点击内容跳转当前页面某标题。 具体实现方法如下：\n首先，在需要跳转到的标题前插入一个 HTML 锚点，例如： ### \u0026lt;a name=\u0026#34;section1\u0026#34;\u0026gt;Section 1\u0026lt;/a\u0026gt; 这个锚点的名称为 \u0026#34;section1\u0026#34;，可以根据需要自定义。 在需要点击跳转的内容处，使用 Markdown 的链接语法，将链接地址设置为锚点名称加上 # 符号，例如： [跳转到 Section 1](#section1) 这样，点击这个链接就会跳转到页面中的 \u0026#34;Section 1\u0026#34; 标题处。 注意事项： # 锚点名称必须是唯一的，否则链接可能会跳转到错误的位置。 如果需要跳转到其他页面的锚点，链接地址应该包括页面路径和锚点名称，例如：/path/to/page.html#section1。\n## Test 二级标题\nNow I will test the Markdown\u0026rsquo;s hobiy 二级 # Maybe is a nice way to impove my blog. 三级 # 原来标题 要# 与正文隔开一个空格… ···print “hello Markdown”··· 欸？ 怎么回事？上面的文字 莫非是用Tab能将其放到一个容器里？\n新的区块 # 你好，这是我新创建的容器。 ———好吧，只有直接在标题之下的Tab才能创建 no~，在空行下面也是可以的。 address@example.com\nMarkdown 字体颜色、流程图 # 斜体 # *文字*：前后星号斜体 就像这样？\n流程图 # st=\u0026gt;start: Start e=\u0026gt;end: End opl=\u0026gt;operation: My Operation sub1=\u0026gt;subroutine: My subroutine cond=\u0026gt;condition: Yes or No? io=\u0026gt;inputoutput: catch something\n呃 流程图我不清楚，不过\n字体颜色 # 可以内嵌html ：你好，我是红色吗?，\n你好，我是自定义色吗? 即\n\u0026lt;font color=red\u0026gt;你好，我是红色吗?\u0026lt;/font\u0026gt; \u0026lt;font color=#75362109\u0026gt;你好，我是自定义色吗?\u0026lt;/font\u0026gt; 刚开始我还在好奇怎么三色RGB怎么变成四个了，原来起作用的还是三个，只不过markdown选择性忽略了多余的字节。😰 这段话的配置如下：\n\u0026lt;font color=#ff36ff\u0026gt;骚气的颜色~\u0026lt;/font\u0026gt; 超链接 # Super Link is me? Yes , you are successful link to Google.hk\n[Super Link is me?](https://www.google.com.hk) 表格 # 1 111 a 2 222 b 3 333 c 4 444 d 6 555 e 7 666 f 序列 # 这是第一行 这是第二行 第三 Like This 另种表现 实现方式 阿门 @的用法 # @后跟随的关键字可以生成Github的搜索超链接 例如： @markdown\n注释 # [^_^]: 这里是注释：这个是在制作ppt的时候来写注释的…… 毕竟在笔记里面写注释怕是失了智… 毕竟不会被显示出来… 不过因为上面也说了是支持html语法的。所以……\n\u0026lt;!-- 这里是注释 隐藏区域--\u0026gt; 插入图片：只能插入网图… # 关于``` 痛苦的进行中 # (⊙﹏⊙)， ```这东西是用来标注代码开始的，然而在有的编辑器中，若不是以单独一行会识别为`，也就是对平常语句中的字符的修饰。但是hexo显然不这么认为，所以只好将之前使用```的地方都改成`了 【2018年5月18日 纪念我勤奋的修改史】 "},{"id":33,"href":"/docs/programmer/base/tipsofvim/","title":"tip Of vim","section":"Base","content":" Vim 使用 # 除去“简便生活”里的几条配置，在纠结是否添加到别的地方，果然还是单独给vim一个使用手册比较好……\n注释 # # 注释 1， 12s/^/#/g --- # 取消注释 1， 12s/^#//g 其实 是vim中的 :s替换命令… 下方解释\n或者，使用列编辑的模式:\nv、选择区域、ctrl q置行首、I插入#、Esc应用到全列 ctrl v、I、#、Esc 因为有的ctrl q或者ctrl v 不能用…… 取消，即使用上述方法选中行首，删除第一个字节即可了 替换 # :s/oldWords/newWords/g g : 代表当前光标所在行。\n由此可知: # ^表行首标识符。 /^/表示行首的空字符。 而取消注释中的/^#/即表示行首的#，被//空字符所替换。\n查找高亮 # set hlsearch set nohlsearch 分屏 # 实现 # 在外部使用-o or -O参数 内部split or vsplit 操作 # 移动光标 Ctrl + w hjkl 移动分区Ctrl + w HJKL 统一高度Ctrl + w = 改变高度Ctrl + w +- more and less # 阅读器~~~ 因为经常读大文件发现了这两个的无敌好处——快。\n使用命令 # cat cat -b # 查看且标注行号 -n # 同上，但也会显示空行行号 more # - space 向下翻页 # - Ctrl+F 同上 # - b back 返回一页显示 # - Ctrl+B 同上 # - Enter 向下n行,默认1 # - = 输出当前行号 # - v 调用vi/vim # - !命令 调用shell 执行命令 # - q 退出 less Vi \u0026amp;\u0026amp; Vim # 三个模式:\n命令模式 插入模式 Ex模式 para : 说明 o : 在当前行下面插入新空白行 dd : 删除当前一行。 u : 撤销一步操作 yy : 当前行-\u0026gt;缓冲区 p : 缓冲区-\u0026gt;光标之后插入 n+ y 当前及接下来n行-\u0026gt;缓冲区 r : 替换当前字符 / : 查找关键字——支持汉字呐！难得 n : 上命令下切换 next Ex下: # set number: 显示行号。（不过我已经改了配置文件，默认显示） ！+命令 代理执行系统命令。如ls cd sh 挂下编辑 显示系统命令行。 ctrl+d返回（PS:命令行下，这是关闭虚拟终端快捷键） tip:tail head 等查看命令可以和 \u0026raquo; 命令合用，将文件的首行或者结尾字添加到另一个文档～ "},{"id":34,"href":"/docs/programmer/database/noteofdbdata/","title":"db数据库","section":"Database","content":" DB数据库 🖥 📊🖥 # MongoDB笔记 # 学习网站：http://www.runoob.com/mongodb/mongodb-tutorial.html (其学习教程还挺可观，很多，不过还不清楚好不好)\n注意事项 # Mongo 数据库锁 # mongo只提供库级粒度锁，所以一个写操作锁定时，其他读写操作都等待… 所以这个导致了Mongo多线程写操作反而没有一个线程写来的快？\n前台建立索引时，Mongo需占用一个写锁（且不同上述、不会临时放弃） 为避免此问题需采用background方式\ndb.posts.ensureIndex({user_id: 1}) #此方式将引起全面战争 db.posts.ensureIndex({user_id: 1}， {background: 1}) # 这个就比较和平 操作命令简单记录 # 创建、插入 # use DATABASE_NAME #如果数据库不存在，则创建数据库，否则切换到指定数据库。 show dbs #查看所有数据库“name size” 刚创建的数据库，如没有内容则不现实在其中\ndb.runoob.insert({\u0026quot;name\u0026quot;:\u0026quot;教程\u0026quot;}) #插入数据 删除 # db.dropDatabase() #删除当前数据库，如未选择则删除test db.collection.drop() #删除集合 db.site.drop() #：如删除site集合 删除重复数据 # delete from alarm_calendar where id not in (SELECT maxid from (SELECT MAX(id) as maxid, CONCAT(user_id,time,generic_name) as nameAndCode from alarm_calendar GROUP BY nameAndCode) t); 根据user_id, time, generic_name来打包重复，将重复数据删掉, 留下max，在自增里面即：最新数据\n插入文档 # db.COLLECTION_NAME.insert(document) db.col.insert({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }) #例如这样 db.col.find() #查看已插入文档\n也可以将document=括号里要插入内容，然后插入document变量，效果一样。\n3.2版本新加 # db.collection.insertOne() #向指定集合中插入一条文档数据 db.collection.insertMany() #向指定集合中插入多条文档数据 插入单条数据 var document = db.collection.insertOne({\u0026quot;a\u0026quot;: 3}) document { \u0026ldquo;acknowledged\u0026rdquo; : true, \u0026ldquo;insertedId\u0026rdquo; : ObjectId(\u0026ldquo;571a218011a82a1d94c02333\u0026rdquo;) }\n插入多条数据 var res = db.collection.insertMany([{\u0026quot;b\u0026quot;: 3}, {'c': 4}]) res { \u0026ldquo;acknowledged\u0026rdquo; : true, \u0026ldquo;insertedIds\u0026rdquo; : [ ObjectId(\u0026ldquo;571a22a911a82a1d94c02337\u0026rdquo;), ObjectId(\u0026ldquo;571a22a911a82a1d94c02338\u0026rdquo;) ] }\n更新、添加文档 # db.col.update({'title':'MongoDB 教程'},{$set:{'title':'MongoDB'}}) #更新标题 db.collection.save( #通过传入的文档来替换已有文档 \u0026lt;document\u0026gt;, { writeConcern: \u0026lt;document\u0026gt; }) 参数说明： document : 文档数据。 writeConcern : 可选，抛出异常的级别。\neg： 实例中替换了 _id 为 56064f89ade2f21f36b03136 的文档数据：\ndb.col.save({ \u0026quot;_id\u0026quot; : ObjectId(\u0026quot;56064f89ade2f21f36b03136\u0026quot;), \u0026quot;title\u0026quot; : \u0026quot;MongoDB\u0026quot;, \u0026quot;description\u0026quot; : \u0026quot;MongoDB 是一个 Nosql 数据库\u0026quot;, \u0026quot;by\u0026quot; : \u0026quot;Runoob\u0026quot;, \u0026quot;url\u0026quot; : \u0026quot;http://www.runoob.com\u0026quot;, \u0026quot;tags\u0026quot; : [ \u0026quot;mongodb\u0026quot;, \u0026quot;NoSQL\u0026quot; ], \u0026quot;likes\u0026quot; : 110 })\n导入csv文件 # mongoimport --db Trader_1Min_Db --collection Au(T+D) --type csv --file D:\\\\IFData\\\\md_Au(T+D)_20170101_20170531\\\\md_Au(T+D)_2017010301.csv --headerline --upsert --ignoreBlanks 注意需要另开一个命令行，在其中运行。 2017-10-25T08:43:40.917+0800 E QUERY [thread1] SyntaxError: missing ; before statement @(shell):1:16 否则就是这个错误\n-d 指定把数据导入到哪一个数据库中 -c 指定把数据导入到哪一个集合中 --type 指定导入的数据类型 csv/tsv 逗号或者tab分割值 --file 指定从哪一个文件中导入数据 --headerline 仅适用于导入csv,tsv格式的数据，表示文件中的第一行作为数据头 --upsert 以新增或者更新的方式来导入数据 --f 导入字段名 --ignoreBlanks 忽略空白符 导出 # mongoexport -d test -c students -o students.dat connected to: 127.0.0.1 exported 9 records # 指明导出格式为csv mongoexport -d test -c students --csv -f classid,name,age -o students_csv.dat connected to: 127.0.0.1 exported 9 records 添加 # db.collectionName.update({}, {$set:{'key' : value}}, false, true); 改 # .update 更改字段名称 # db.CollectionName.update({}, {$rename : {\u0026quot;OldName\u0026quot; : \u0026quot;NewName\u0026quot;}}, false, true) # false为如不存在update记录，是否插入新的纪录 # ture位置为更新全部数据，如设定false 则为只更新第一条 # 另外 没有输入名称时没有输全，也会显示查找，但不会执行更改 统配 # db.CollectionName.update(\u0026lt;query\u0026gt;, \u0026lt;update\u0026gt;,{upsert : \u0026lt;boolean\u0026gt;, multi : \u0026lt;boolean\u0026gt;, writeConcern : \u0026lt;document\u0026gt;}) # query : update 查找条件，类似sql update查询内where后面的 # update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查 #\u0026gt;询内set后面的 # upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插 #\u0026gt;入，默认是false，不插入。 # multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把 #\u0026gt;按条件查出来多条记录全部更新。 # writeConcern :可选，抛出异常的级别。 eg # db.col.update({'title':'MongoDB'},{$set:{'title':'IamNewTitle'}}) 删除文档 # remove()函数是用来移除集合中的数据。\ndb.collection.remove( \u0026lt;query\u0026gt;, \u0026lt;justOne\u0026gt; ) 2.6版以后 # db.collection.remove( \u0026lt;query\u0026gt;, { justOne: \u0026lt;boolean\u0026gt;, writeConcern: \u0026lt;document\u0026gt; }) 参数说明： query :（可选）删除的文档的条件。 justOne : （可选）如果设为 true 或 1，则只删除一个文档。 writeConcern :（可选）抛出异常的级别。\ndb.col.remove({}) #删除所有 (就很恐怖) 查询文档 # 操作 格式 范例 RDBMS中的类似语句 等于 {\u0026lt;key\u0026gt;:\u0026lt;value\u0026gt;} db.col.find({\u0026quot;by\u0026quot;:\u0026quot;教程\u0026quot;}).pretty() where by = '教程' 小于 {\u0026lt;key\u0026gt;:{$lt:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$lt:50}}).pretty() where likes \u0026lt; 50 小于或等于 {\u0026lt;key\u0026gt;:{$lte:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$lte:50}}).pretty() \u0026hellip; 大于 {\u0026lt;key\u0026gt;:{$gt:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$gt:50}}).pretty() \u0026hellip; 大于或等于 {\u0026lt;key\u0026gt;:{$gte:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$gte:50}}).pretty() \u0026hellip; 不等于 {\u0026lt;key\u0026gt;:{$ne:\u0026lt;value\u0026gt;}} db.col.find({\u0026quot;likes\u0026quot;:{$ne:50}}).pretty() where likes != 50 And # find可以传入多个键(key),逗号隔开：\ndb.col.find({key1:value1, key2:value2}).pretty() db.col.find({\u0026quot;by\u0026quot;:\u0026quot;教程\u0026quot;, \u0026quot;title\u0026quot;:\u0026quot;MongoDB \u0026quot;}).pretty() #类似于 WHERE by='教程' AND title='MongoDB ' Or # db.test.find({$[{key1:value1},(key2:value2)]}).pretty() #注意小中大括号😰 db.col.find({\u0026quot;likes\u0026quot;: {$gt:50}, $or: [{\u0026quot;by\u0026quot;: \u0026quot;教程\u0026quot;},{\u0026quot;title\u0026quot;: \u0026quot;MongoDB \u0026quot;}]}) And 与 Or # db.col.find({\u0026quot;likes\u0026quot;: {$gt:50}, $or: [{\u0026quot;by\u0026quot;: \u0026quot;教程\u0026quot;},{\u0026quot;title\u0026quot;: \u0026quot;MongoDB \u0026quot;}]}) #类似于（其中pretty()是显示样式） where likes\u0026gt;50 AND (by = '教程' OR title = 'MongoDB ‘ 简写说明 # $gt \u0026mdash;\u0026mdash;\u0026ndash; greater than \u0026gt; $gte \u0026mdash;\u0026mdash;\u0026mdash; gt equal \u0026gt;= $lt \u0026mdash;\u0026mdash;\u0026ndash; less than \u0026lt; $lte \u0026mdash;\u0026mdash;\u0026mdash; lt equal \u0026lt;= $ne \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; not equal != $eq \u0026mdash;\u0026mdash;\u0026ndash; equal = Type # db.col.find({\u0026quot;title\u0026quot; : {$type : 2}}) #获取“col”集合中title为String的数据 对照表：\n类型 数字 备注 Double 1 String 2 Object 3 Array 4 Binary data 5 Undefined 6 已废弃。 Object id 7 Boolean 8 Date 9 Null 10 Regular Expression 11 JavaScript 13 Symbol 14 JavaScript (with scope) 15 32-bit integer 16 Timestamp 17 64-bit integer 18 Min key 255 Query with -1. Max key 127 Limit() Skip()方法 # db.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).limit(2) 参数说明： “title”后1为判断语句，表示是否只查询“title”内容0为否，显示这条的全部信息。_id的0亦为判断表示是否显示“_id”内容。limit为限制搜索信息条数。\ndb.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).limit(1).skip(1) skip(NUMBER) #NUMBER为阶跃，即每隔几条数据来搜索 排序 # db.COLLECTION_NAME.find().sort({KEY:1}) #KEY后数字可为1OR-1，升序OR降序 db.col.find({},{\u0026quot;title\u0026quot;:1,_id:0}).sort({\u0026quot;likes\u0026quot;:-1} #按“likes”降序排序 MongoDB 索引 （建立索引干嘛……） # ensureIndex() 方法 # db.COLLECTION_NAME.ensureIndex({KEY:1}) # Key 值为要创建的索引字段，1为指定按升序创建索引，降序-1 聚合 # aggregate()方法 # db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$sum : 1}}}]) #类似于 select by_user, count(*) from mycol group by by_user 输出结果： { \u0026ldquo;_id\u0026rdquo; : \u0026ldquo;Neo4j\u0026rdquo;, \u0026ldquo;num_tutorial\u0026rdquo; : 1 } { \u0026ldquo;_id\u0026rdquo; : \u0026ldquo;runoob.com\u0026rdquo;, \u0026ldquo;num_tutorial\u0026rdquo; : 2 } { \u0026ldquo;_id\u0026rdquo; : null, \u0026ldquo;num_tutorial\u0026rdquo; : 1 }\n参数说明：“$by_user” 即为分类依据，并打印出来（如上）。 num_tutorial 仅为显示提示，可以更改为任意提示甚至汉字。 $sum : 1 其中1为每次计数值，即重复一次加几。1+1+1+1…… ：重复一次加1；0.1+0.1+0.1……重复一次加0.1。这个意思\n计算符： # 表达式 描述 实例 $sum 计算总和。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$sum : \u0026quot;$likes\u0026quot;}}}]) $avg 计算平均值 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$avg : \u0026quot;$likes\u0026quot;}}}]) $min 获取集合中所有文档对应值得最小值。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$min : \u0026quot;$likes\u0026quot;}}}]) $max 获取集合中所有文档对应值得最大值。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, num_tutorial : {$max : \u0026quot;$likes\u0026quot;}}}]) $push 在结果文档中插入值到一个数组中。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, url : {$push: \u0026quot;$url\u0026quot;}}}]) $addToSet 在结果文档中插入值到一个数组中，但不创建副本。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, url : {$addToSet : \u0026quot;$url\u0026quot;}}}]) $first 根据资源文档的排序获取第一个文档数据。 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, first_url : {$first : \u0026quot;$url\u0026quot;}}}]) $last 根据资源文档的排序获取最后一个文档数据 db.mycol.aggregate([{$group : {_id : \u0026quot;$by_user\u0026quot;, last_url : {$last : \u0026quot;$url\u0026quot;}}}]) 条件操作符 # $gt 大于 $lt 小于 $gte 大于等于 $lte 小于等于 eg： # db.col.find({likes : {$gte : 100}}) # 查询“col”集合中\u0026quot;likes\u0026quot;大于100的数据 # 比较与 `SQL Select * from col where likes \u0026gt;=100;` 取前n条数据 # .find().limit(n) 执行顺序 # skip(), limilt(), sort()三个放在一起执行的时候，执行的顺序是先 sort(), 然后是 skip()，最后是显示的 limit()。 数据导出 # mongoexport -d *** -c *** -o *** # -d 后为 dbName -c 后为 collectionName -o 后为 outputFileName 导出文件名 名字都不用加引号，直接上的~， 然后导出格式都是json 那样，不管后缀是什么用文本打开都是一个样子——骗鬼👻\n数据导入 # mongoimport -h 127.0.0.1 -p 27017 -d Trader_1Min_Db -c ag1806 --file /home/ian/Downloads/ag1806.json Linux 下使用Robo3T错误 # 错误最后字段为：已放弃 (核心已转储)\nmkdir ~/robo-backup mv robo3t-1.1.1-linux-x86_64-*/lib/libstdc++* ~/robo-backup/robo3t-1.1.1-linux-x86_64-*/bin/robo3t 移动备份之后即可运行\nFor Python # PyMongo # from pymongo import MongoClient client = MongoClient(\u0026quot;localhost\u0026quot;, 27017) client.server_info() # 查看信息，检测是否成功连接 db = client[\u0026quot;someData\u0026quot;] collection = db.zn1801_30Min # 两种命名方式，一种是直接. 一种是使用“” 乖乖的用双引号，因为，在这里的单双引号是区分的… 我现在也懒得去管它是字符字符串的什么鬼。┏┛墓┗┓\u0026hellip;(((m -__-)m\ninsert # collection.insert( {\u0026quot;name\u0026quot;:\u0026quot;text\u0026quot; } ) find # d = {u'Volume':{'$gte':50353,'$lte':50355}} a = collection.find(d) 最小与最大，另外，find出来的东西是数据库指针，需要用for...in...来循环取出内容来\n查询库名 # from pymongo import MongoClient client = MongoClient('localhost', 27017) client.database_names() [u\u0026rsquo;Trader_1Min_Db\u0026rsquo;, u\u0026rsquo;Trader_30Min_Db\u0026rsquo;, u\u0026rsquo;Trader_Tick_Db\u0026rsquo;, u\u0026rsquo;VnTrader_Log_Db\u0026rsquo;, u\u0026rsquo;VnTrader_Position_Db\u0026rsquo;, u\u0026rsquo;admin\u0026rsquo;, u\u0026rsquo;local\u0026rsquo;, u\u0026rsquo;someData\u0026rsquo;, u\u0026rsquo;test']\n查询集合名 # collectionNames = client[dbName].collection_names() print collectionNames 使用 # 其读写速度还是可以的… 二十万条数据查询的话不到一秒，然而… 频繁多量的读取，再加上不断地往其中写入就出问题了…… 卡的极慢…简直恐怖（数个小时的延迟 怕不怕）。（当然以上情况是完全没有做任何优化的情况（直接insert 、find），不知道优化之后会怎样） 另外不知道不增加条数，去增加内容会怎样…… emm 果然还是缓存比较好用…在高速多量多频次的情况下还是用内存里面不去手动做任何保存比较好。 等积攒够量之后再去保存，就好比文件压缩不去一个个小文件传输一个道理。\nMySQL # MySQL 8.0 # 因为在更新8.0 之后更改了用户密码加密形式所以在使用客户端连接的时候会出现错误，所以需要\nALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER; #修改加密规则 ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password'; #更新用户的密码 FLUSH PRIVILEGES; #刷新权限 经此步骤，就可以将密码加密形式改为图形化客户端支持的加密形式，也或者更待客户端跟着服务端同步更新。\n另外，配置之初，windows 中配置步骤如下：\n添加系统环境变量path 为MySQL/bin 初始化 mysqld --initialize --user=mysql --console 根据初始化随机生成密码登陆 修改密码 emm 这里说的是在外部，当然也可以在修改加密形式的时候一并修改 😄 mysqladmin -u root -p password 添加系统服务 mysqld -install 启动服务 net start mysql 另外在图像化里面注意密码格式呦，还有使用navicat的话需要最新版本，否则无法设置加密格式，还得用命令行去修改……果然还是命令行永远最好用\nupdate # MySQL的update在被更新数值和更新传入数值相同时，执行速度相当的快，据说是mysql并不会执行更新动作但是它晓得更新动作的发生\nMySQL 中文乱码 # 需要在连接时就指定✱charset✲ 而不该一味纠结于在程序在存储时的数据准备 此处使用的是\ncharset='gb2312' 另外，干脆就在数据库中设置存为 blob 格式\n连接远程 win 数据库 # 开启某端口的示例： 添加防火墙例外端口 ## 导出表记录 [^_^] 2021-04-22 看了上面,深表惭愧... ```bash mysql -uuser -ppasswd -hhost -e \u0026#34;use db_name; select * from table_name where chat_id in (...);\u0026#34; \u0026gt;\u0026gt; hello2.csv 在bash中直接执行sql语句，重定向保存\n好处 # 可以规避 into outfile 的权限问题，导出的东西用csv也是可以看的，分隔符得以保留，csv可以正常阅览\n注意点 # 只不过有,时分隔符可能有些问题，全文替换了就好\n入站规则设置 # 第一步 选择 入站规则 然后 新建规则，选择 端口，然后下一步 第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如: 3306 第三步 选择允许连接 第四步 选择配置文件 第五步 输入规则名称 mysqlport\n出站规则设置 # 第一步 选择出站规则 然后 新建规则，选择 端口，然后下一步 第二步 选择TCP 选择特定端口 然后输入端口，如有多个端口需要用逗号隔开了 例如: 3306 第三步 选择允许连接 第四步 选择配置文件 第五步 输入规则名称 mysqlport（或者无特殊要求下直接关闭防火墙）\n--- --- --- # 数据迁移 因为已有从数据库中读取数据进行返回的函数，所以没有必要再去写读取数据库的步骤（也没法写，因为数据库设计混乱，分不清哪儿是哪儿只有通过其对外函数才能取对相应数据） 但对外其是将一段时间内数据全部读取并且打包为`json`返回，所以一次性的话将是极大的一个文件，所以解决方法有： - 阅读其中源码，返回相应数据库指针，以此取出一个迁移一个 - 编写分段读取函数，保证每次取出的数据不多，一段一段的迁移 反正我是采用`一段一段`了，毕竟源码太… 另外，一段一段的话打好日志，出现问题后可以分段纠正，也能间歇运行，另外下载好再迁也保证了数据emm，考虑如上 ## 简单总结 - 数据迁移程序 - 数据检验补差程序 - 断点运行机制 ```md # 初始化 1. 读取配置文件（其中保存 * 数据迁移顺序——列表（内元素为字典key为* value为相应数据库、表名， 时间起止，一次插入的时间跨度） ） 2. 根据移植顺序读取目标数据库中相应数据的最新数据日期（ * 若为空开始则开始插入） * 删除此日期的所有数据， * 根据一次插入的时间跨度以及终点生成时间区间 * 根据时间区间去移植数据 3. 当此类型数据移植完毕之后删除配置文件中列表的相应元素 # 执行动作 是 ## 日志 将每一步的重要信息都打印~ "},{"id":35,"href":"/docs/programmer/base/editer/","title":"编辑器使用","section":"Base","content":" Jupyter-Note # 局域网访问 # 方法1: 使用jupyter notebook --generate-config生成配置文件 修改配置文件中c.NotebookApp.allow_root(因为安卓用的Termux跑的,所以伪root),c.NotebookApp.ip这样就能通过局域网和Token访问了 如果想要使用密码(长期使用局域网的话),可以使用from notebook.auth import passwd;passwd()生成加密密码,配置到c.NotebookApp.password 方法2: 如果只是临时的,那传入运行命令肯定最好了,如下可以使用如下格式: jupyter-notebook --allow-root --ip=0.0.0.0 自动补全 # 安装插件: pip install jupyter_contrib_nbextensions -i https://pypi.tuna.tsinghua.edu.cn/simple(此命令包含代理) 到Nbextensions中将Disable改为Enable 开始 Vim # vim 查看日志中文乱码(2021) # .bash_profile # export LC_ALL=en_US.utf-8 .vimrc # set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 set termencoding=utf-8 set encoding=utf-8 双管齐下, 一个解决系统配置, 一个解决vim配置\n中文乱码问题(2018) # 在.bash_profile中增加\nexport LANG=zh_CN.utf8 export LC_ALL=zh_CN.utf8 即可增加中文支持。 不过，还是\nexport LANG=en_US.utf8 export LC_ALL=en_US.utf8 比较香，因为中文字体很难看… ^_^: 2019年5月5日19点46分\nvscode vs code # venv # Python # Command Palette...(Ctrl+Shift+p)\n\u0026gt;Python: Select Interpreter 然后选择就好了.\n当然不会那么安逸(.vscode/launch.json) 2022-01-18 11：34\n.vscode/launch.json配置(图形化都是骗人的) # { // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Python: Current File\u0026#34;, // 自定义名称 \u0026#34;type\u0026#34;: \u0026#34;python\u0026#34;, \u0026#34;pythonPath\u0026#34;: \u0026#34;{配置python解释器路径}\u0026#34;, //调试程序时的工作目录，一般为${workspaceRoot}即代码所在目录 \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceRoot}\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${file}\u0026#34;, // 可直接指定文件 \u0026#34;console\u0026#34;: \u0026#34;integratedTerminal\u0026#34; } ] } 三兄弟 # 查看文本 列 # awk -F \u0026#39;,\u0026#39; \u0026#39;{print $NF}\u0026#39; , 分隔符 $NF 末尾 同理也可 $1 $1, $3 表示1列+3列,并不含2列 只能使用 单引号 双引号不行的呦( \u0026quot;{print $1}\u0026quot; )\nkubectl get pod -n namespace | grep text | awk \u0026#39;{print $1}\u0026#39; find + vim 查找打开一条龙 # find * -name \u0026#34;*wd.csv\u0026#34; -exec vim {} \\; 来自find --help的解释: -exec COMMAND ; -exec COMMAND {} + -ok COMMAND ; -exec兼容多条命令, bash监控;,但find也用;中断,所以在bash运行需要转义一层\u0026hellip;.也就变成了\\;\nGrep # 排除某(些)文件(夹) # 文件: # --exclude=\n文件类型: # grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude=*.{log,} {}中貌似必须有,， 也就是说必须传入为列表， 不然不生效， 倒和Python的tuple类型有些相像。\n文件夹: # --exclude-dir=\n个: grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude-dir=log 些: grep \u0026#34;get_wx_mapping\u0026#34; . -r --exclude-dir={log,__pycache__} "},{"id":36,"href":"/docs/programmer/base/noteoflinux/","title":"Linux","section":"Base","content":"\nUbuntu22.04 依赖项整理 # vbox: libqt5opengl5 kate: konsole Qt5.12.12: mesa-common-dev, libgl1-mesa-dev OpenCV4.6.0: libgtk2.0-dev, pkg-config, libcanberra-gtk-module 如果没有安装这俩依赖不会影响编译，但是编译后会有功能损失，补充安装后不会修复； 如果想修复，只能安装后再编译一次； dpkg .deb # Install # sudo dpkg -i file.deb\nc l r P L s # -c列出内容 -l提取包信息 -r移除一个已安装的包 -P完全清除一个已安装包 -L列出安装所有文件清单 -s显示已安装包信息 WSL # wsl问题 因为后面不太喜欢这种东西了,还是上了物理机. 所以就不粘贴过来了.\nsudo apt upgrade # E: Sub-process /usr/bin/dpkg returned an error code (1)\n解决 # sudu下\n备份/var/lib/dpkg/info 新建/var/lib/dpkg/info 重新执行更新 合并/var/lib/dpkg/info 和 备份文件 完 说明 # 非原理性解决方案, 若解决不了, 另寻他法或者需要直击灵魂.\n磁盘操作 # NTFS # 一般发行版 # 在此中可以使用ntfsfix, 不过刚才看了一圈儿, 好像, 这工具就是来源于下面所介绍的\n树莓派 # 因为没有预装ntfsfix, 所以\n安装 ntfs-3g 很久远的工具: sudo apt install ntfs-3g (看3g就知道年代久远 😄) 取消挂载, sudo umount /dev/sda{N} 重新挂载, mount –t ntfs /dev/sda{n} /media/pi 就可以有读写权限了. 不然只有读的, 挺不好的.\n不过在windows放了缓存在里面的话就没办法挂载为可写了， 方法是取消Win的快速启动功能后关机，不使用休眠.\n磁盘查询命令 # fdisk -l df -h LVM概要（がいよう）\n自弁の理解：\n将零散的集合起来，再进行动态分组。 PV \u0026raquo; VG \u0026raquo; LV じゃあ作成（さくせい）： # pvcreat disk1 disk2 di3 ...　# 集合 pvs|pvdisplay vgcreat 集合name 1 2 3 ... # 集合 vgs|vgdisplay lvcreat -n name -L size 集name lvs|lvdisplay 格式化磁盘: # mkfs.ext4 /dev/集name/name # 格式化此（PS：路径为所示） 注: 不过要采用这种方法来给Linux扩容的话需要之前时就选定Linux磁盘管理为LVM，否则主目录在之后不能添加lv组，也就谈不上添加。\nLVMの削除（さくじょ）： # LV lvremove /dev/... VG vgremove 集name PV(物理卷) pvremove /dev/... disk LVの追加（ついか）： # lvexpend -L +1G /dev/集name/name # 增加了空白空间 resize2fs /dev/... 更新文件系统 使空白空间得以有身份（文件系统） disk VGの追加 # pvcreat /dev/sdd(new) vgexpend 集name /dev/sdd 网络 # SSH 远程终端控制 # ssh root(usrname)@192.168.^.^ (IP) 输入密码错误之后——就…之前解决过，然而忘了上次怎么解决的了(京东云)反正这次是等着等着突然就能连接了。 以后可得把解决方案记录到这儿ヽ(*。\u0026gt;Д\u0026lt;)o゜\n另外，ssh公钥🔑连接方式可以参考makethingseasy中的描写。\nping 测试连通 # mtr 测试网络+每个路由信息 * + IP VNC 桌面远程 # Emmmm 当时还写了这个？现在倒是用这个在链接树莓派o(∩∩)o\u0026hellip;哈哈(2021-04-22)\n壓縮打包 # tar -zxvf **.tar.gz: .tar.gz tar -jxvf **.tar.bz2: .tar.bz2 tar # tar xvzf fileName.tar.gz tar cvzf fileName.tar.gz targerName x: 解压 c : 压缩\nUbuntu 16.04 升级 Ubuntu 18.04 # ___ 经尝试真的不如备份自我资料后重装……因为太…慢…了… 更新还不稳。\n其实还好… 就是更新速度慢了点儿。早不到十点更新到了下午13点38分。不过基于是一键式的所以还是有多点儿好处的。 更新命令\nsudo do-release-upgrade # 提示是没法找到可用更新… # 所以 之后增加了 -c # 还是不行 -d # 参数完成更新 但是python被重装了！！！！ 里面的包都没了…🐎a算了，好在软件级别的东西都还在…另外pip也损坏了，apt安装也失败，后面我就用了.py脚本重新安装，所以apt卸载再重装没试，不知道行不行。 收回前面“软件级别的都还在”，其实软件级别的也待测。\n设定系统常量 # 在用户目录下profile文件中可通过export 增加(一般来说是增加路径)\nexport IAN=/mnt/c/Users/ian sourse ~/.profile 之后便可通过cd $IAN 来访问win下的用户目录。当然，这个方法是在添加GoPath时注意到的。\nemm 其实在/etc/profile 文件下才是系统王道\nps # 今年面试还碰到个问这个问题，说什么是变量\u0026hellip;.. 把我给整蒙了\u0026hellip;.. 结果一番问下才发现他想问的就是放在/etc/profile和~/.profile里有啥区别，\n啥是系统,用户,会话级变量.唉.. 有时候突然听到基本问题就觉得对方是不是有什么深意\u0026hellip;\ntmux 虚拟多终端 # 类似于vim多窗口编辑一类的东西，emm 或者说图形化ubuntu使用ctrl+alt+t叫出来的东西。这么一对比的话就是无界面化的虚拟终端——那个是界面里的虚拟终端嘛。 用于解决ssh连接远程开启应用，断开后不关闭进程的方案。因为nohup好像并不稳定的样子…… 不过用起来… 不太了解怎么这就能够持久化了…因为毕竟是虚拟窗口，间makethingseasy中，其实…好像…大概…没什么关系吧。这两者。\n最大文件数/单进程最大文件数 # bump fs.nr_open + fs.max-file to their largest possible values\ncat /proc/sys/fs/file-max cat /proc/sys/fs/nr_open 今天(2021-04-22)看epoll的时候好奇看了一下,发现我的fs/file-max居然有9223372036854775807震惊一下.\n"},{"id":37,"href":"/docs/example/hidden/","title":"Hidden","section":"Example Site","content":" This page is hidden in menu # Quondam non pater est dignior ille Eurotas # Latent te facies # Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\nPater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor Cum honorum Latona # O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); } Fronde cetera dextrae sequens pennis voce muneris # Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "},{"id":38,"href":"/docs/programmer/base/argo-workflow%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90/","title":"Argo Workflow性能测试和使用场景分析","section":"Base","content":"Github: https://github.com/argoproj\n一、简介 # Argo Workflow 是一个开源的、基于 Kubernetes 的工作流引擎，用于编排和运行容器化应用的工作流程。它使用 YAML 文件来定义工作流、依赖关系和参数。\nArgo Workflow 还支持任务的重试、跳过、并行执行和失败处理等功能。它提供了丰富的工作流控制和监控功能，可以查看工作流的状态、日志和执行历史，并支持自定义的事件触发和通知机制。\n目前Argo团队下中有如下几个子项目：\nargoproj Common project repo for all Argo Projects gitops-engine Public Democratizing GitOps argo-workflows Workflow engine for Kubernetes argo-cd Declarative continuous deployment for Kubernetes. argo-events Event-driven automation framework argo-rollouts Progressive Delivery for Kubernetes cd和rollouts一个是持续交付工具，一个是渐进式发布工具。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。这两者搭配可以设计出一个由新建任务事件触发从而启动工作流的方案。\n流程如下： ![[content/docs/programmer/base/argo_events_workfows.png]]\nsensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排示例 # 以下是一个扔硬币和打印结果的示例，借此可以熟悉一下Workflow的编排语法\napiVersion: argoproj.io/v1alpha1 kind: Workflow metadata: generateName: coinflip-recursive- spec: entrypoint: coinflip templates: - name: coinflip steps: - - name: flip-coin template: flip-coin - - name: heads template: heads when: \u0026#34;{{steps.flip-coin.outputs.result}} == heads\u0026#34; - name: tails template: coinflip when: \u0026#34;{{steps.flip-coin.outputs.result}} == tails\u0026#34; - name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = \u0026#34;heads\u0026#34; if random.randint(0,1) == 0 else \u0026#34;tails\u0026#34; print(result) - name: heads container: image: alpine:3.6 command: [sh, -c] args: [\u0026#34;echo \\\u0026#34;it was heads\\\u0026#34;\u0026#34;] 至于部署Argo的步骤网上都有，为了精简文章就不在此赘述。下面关于一些在使用中需要注意的重要问题进行一些说明。\n三、空间和性能 # ETCD占用 # 因为Argo是基于Kubernetes的，所以空间问题一般不需要怎么关注，但如果在使用场景中需要频繁创建工作流，还是需要关注一下etcd的空间情况。因为Kubernetes集群中的配置、运行状态和其他各项关键信息都存储在etcd，在频繁创建工作流、且工作流很长时，这类信息会占据大量空间：\nETCDCTL_API=3 etcdctl --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/healthcheck-client.crt --key /etc/kubernetes/pki/etcd/healthcheck-client.key --write-out=table endpoint status ENDPOINT ID VERSION DB SIZE IS LEADER IS LEARNER RAFT TERM RAFT INDEX RAFT APPLIED INDEX ERRORS 127.0.0.1:2379 871f72e4ab5a28e8 3.5.0 104 MB true false 35 348058564 348058564 根据提供的信息，可以看到以下解释：\nVERSION: etcd的版本为3.5.0。 DB SIZE: etcd数据库当前占用的空间大小为104 MB。 RAFT APPLIED INDEX: 当前etcd集群已应用的Raft Index为348058564。 ERRORS: 没有显示任何错误信息。 总体上，这些信息展示了etcd集群的状态，包括节点角色、版本、数据库大小等，经过测试，创建100个十步左右的工作流需要占用20mb空间。 性能 # 以下测试全部是通过创建一个概率性失败和重试的workflow测试而来：\n它总共包括三步(第二步和第三步并行执行) 每一步都有一定的几率失败，失败后每一步最多重试10次，一旦成功后进入下一步 可以通过调节失败几率模拟出在实际环境中各个workflow分别处于不同进度的情况 下图中第一步一共重试了四次，失败三次，第四次时成功，随后2b全部失败，2a第三步成功，整个工作流耗时4分钟 ![[三步随机出错workflow.png]] 在并发启动十五个工作流时，并且每一步都保证100%成功，整个流程花费2min左右，三个子步骤分别花费50-60秒。 ![[全部成功的树状图.png]] ![[全成功workflow耗时.png]] ![[全成功的step耗时.png]]\n在全部错误时，并且每一步都保证100%失败，总计经历11次尝试，整个流程花费10分钟左右，11个子步骤分别花费60秒左右 ![[全部失败的树状图.png]] ![[全错误workflow耗时.png]] ![[全错误的step耗时.png]]\n可见每一步成功与否，与执行花费无关。不会出现错误重试避让成功工作流的现象。\n使用argo submit retry_template.yaml -n websafe --watch 和 kubectl get pod -n {NAMESPACE} | grep workflow查看工作流运行状态，可知在工作流的每一步执行时都是实时初始化pod，所以以上花费约等于每一步初始化pod所用的时间。即以上时间是在运行逻辑之外无法优化的固定时间花费。 ![[watch_workflow.png]] ![[work_flow_pod.png]]\n总结 # 由以上信息可见Argo WorkFlow有基于 Kubernetes的简单、易用、便于迁移的优点，但同时有启动速度慢，执行工作流的每一步时都具有额外消耗的缺点。\n所以它适用于不关注实时性的业务，本身执行时间长的任务。例如AI中的模型训练，可以令每次训练都无需关注环境配置，可以做到自动资源、埋点分析和生成报表。例如在以下场景中： ![[ai_model_workflow.png]] 训练人员可以通过yaml文件自由更换训练、测试数据，选择输出模型发布方案。可以很方便的查看每一阶段信息，且不用编写代码关注运行环境。 进了工作流程中步骤之间的松耦合，并开辟了在未来工作流中重用组件的可能性。\n"},{"id":39,"href":"/docs/programmer/base/argo-%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","title":"Argo 使用记录","section":"Base","content":"Github: https://github.com/argoproj\n一、简介 # 目前Argo项目中有如下几个子项目：\nargoproj Common project repo for all Argo Projects\ngitops-engine Public Democratizing GitOps\nargo-workflows Workflow engine for Kubernetes\nargo-cd Declarative continuous deployment for Kubernetes.\nargo-events Event-driven automation framework\nargo-rollouts Progressive Delivery for Kubernetes\ncd和rollouts一个是持续交付工具，一个是渐进式发布工具，与原子能力关系不大。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。都与本次原子能力相关。\n这样，就可以设计出一个由新建扫描任务事件触发，实例化经过编排可实现扫描全流程的方案。\n流程如下：![[book_architecture/content/docs/programmer/base/argo_events_workfows.png]]\nsensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排 # name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = \u0026ldquo;heads\u0026rdquo; if random.randint(0,1) == 0 else \u0026ldquo;tails\u0026rdquo; print(result)\nname: heads container: image: alpine:3.6 command: [sh, -c] args: [\u0026ldquo;echo \u0026quot;it was heads\u0026quot;\u0026rdquo;] 三、Argo Events使用 # 定义一个webhook(名称: webhook_example)路径/webhook, 端口12000, 接收 POST 方法. apiVersion: argoproj.io/v1alpha1 kind: EventSource metadata: name: webhook spec: service: ports: - port: 12000 targetPort: 12000 webhook: webhook_example: port: \u0026#34;12000\u0026#34; endpoint: /webhook method: POST 定义Sensor 指定行为 Yaml说明: i. 定义了订阅的EventSource以及具体的Webhook(一个EventSource可以定义多个Webhook,因此指定俩参数) ii. Trigger中定义了对应Action 创建一个werkflow, workflow的spec在respirce中配置 iii. parameters定义了workfolw的参数,从event中获取,如上将整个event都作为input(只获取body部分可通过: dataKey: body.message) iv: 此时 curl -X POST -d '{\u0026quot;message\u0026quot;: \u0026quot;Hello\u0026quot;}' 127.0.0.1:12000/webhook,可见argo workflow中创建了一个实例. 如传入整个请求,获得的数据可能经由base64编码的,需要解码后使用{\u0026quot;context\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;data\u0026quot;: \u0026quot;包含header和body\u0026quot;} v: 其他用法查看: 这里\n需验证的问题 # workflow并行处理多个不同参数的相同任务效率需要验证 四、部署 # 1. 运维命令 # argo submit hello-world.yaml # submit a workflow spec to Kubernetes argo list # list current workflows argo get hello-world-xxx # get info about a specific workflow argo logs hello-world-xxx # print the logs from a workflow argo delete hello-world-xxx # delete workflow 2. 安装和启动 # kubectl create namespace argo kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml # 最全-精简安装看别的 # 查看运行状态 kubectl get pods -n argo kubectl get svc -n argo # 将svc改为nodeport方便访问Web UI kubectl edit svc -n argo argo-workflow-argo-workflows-server # 或者argo-server 名字会变但是差不多这意思 进去手动将ClusterIP改为NodePort # 查看argo server pod在哪个node上运行 端口映射到了node哪个端口 kubectl get pods -n argo -o wide # 查看该node IP kubectl get node -o wide # http//nodeip:nodePort访问 # 提交任务 argo submit https://github.com/argoproj/argo-workflows/blob/master/examples/coinflip.yaml --watch -n argo # 将yaml下载下载执行为佳 权限问题 # User \u0026#34;system:serviceaccount:argo:default\u0026#34; cannot patch resource \u0026#34;pods\u0026#34; in API group \u0026#34;\u0026#34; in the namespace \u0026#34;argo\u0026#34;: RBAC: role.rbac.authorization.k8s.io \u0026#34;argo-workflow\u0026#34; not found Confusing, possibly erroneous RBAC warnings (\u0026#34;Failed to get pod\u0026#34;) 可见: argo-workflows Issues\nETCD # 因为k8s状态都在etcd集群中，所以需要关注一下大量workflow会不会占用过多的容量资源\nETCDCTL_API=3 etcdctl --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/healthcheck-client.crt --key /etc/kubernetes/pki/etcd/healthcheck-client.key --write-out=table endpoint status +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | ENDPOINT | ID | VERSION | DB SIZE | IS LEADER | IS LEARNER | RAFT TERM | RAFT INDEX | RAFT APPLIED INDEX | ERRORS | +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ | 127.0.0.1:2379 | 871f72e4ab5a28e8 | 3.5.0 | 104 MB | true | false | 35 | 348058564 | 348058564 | | +----------------+------------------+---------+---------+-----------+------------+-----------+------------+--------------------+--------+ 根据提供的信息，可以看到以下解释：\nENDPOINT: etcd集群的地址为127.0.0.1:2379。 ID: etcd集群的唯一标识为871f72e4ab5a28e8。 VERSION: etcd的版本为3.5.0。 DB SIZE: etcd数据库当前占用的空间大小为104 MB。 IS LEADER: 当前节点是否为etcd集群的Leader节点，这里显示为true。 IS LEARNER: 当前节点是否为etcd集群的Learner节点，这里显示为false。 RAFT TERM: 当前etcd集群的Raft Term为35。 RAFT INDEX: 当前etcd集群的Raft Index为348058564。 RAFT APPLIED INDEX: 当前etcd集群已应用的Raft Index为348058564。 ERRORS: 没有显示任何错误信息。 总体上，这些信息展示了etcd集群的状态，包括节点角色、版本、数据库大小等。 大量Workflows优化建议 # You have at least 230 completed workflows. Reducing the total number of workflows will reduce your costs. Learn more at https://argoproj.github.io/argo-workflows/cost-optimisation/\n创建时缺少安全上下文问题 # This workflow does not have security context set. You can run your workflow pods more securely by setting it. Learn more at https://argoproj.github.io/argo-workflows/workflow-pod-security-context/\n修改执行器 # "},{"id":40,"href":"/docs/programmer/base/kafka-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","title":"Kafka 安装和使用","section":"Base","content":" 常用命令 # 创建topic # sh kafka-console-producer.sh --create --topic scanner_device_log --bootstrap-server localhost:9092 --partitions 0 --replication-factor 1 发送接收测试 # sh kafka-console-producer.sh --broker-list localhost:9092 --topic test sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 单机部署 # 本文链接🔗 Kafka是一个开源的分布式消息引擎/消息中间件，同时Kafka也是一个流处理平台。Kakfa支持以发布/订阅的方式在应用间传递消息，同时并基于消息功能添加了Kafka Connect、Kafka Streams以支持连接其他系统的数据(Elasticsearch、Hadoop等) Kafka在生产环境下使用通常是集群化部署的，同时也要依赖ZooKeeper集群，这对开发测试环境来说比较重，不过我们可以通过Docker便捷Kafka单机的方式，节省部署时间以及机器资源\n1、本文主要内容 # 通过Docker手动部署ZooKeeper\u0026amp;Kafka 通过Docker Compose快捷部署ZooKeeper\u0026amp;Kafka Kafka发送、接收消息测试 2、本文环境信息 # 工具 说明 适配 Docker Docker CE 23.0.5 Docker CE Docker Desktop 4.19.0 4.0.x ZooKeeper zookeeper:3.8（Docker Image ） zookeeper:3.x（Docker Image ） Kafka wurstmeister/kafka:2.13-2.8.1（Docker Image） wurstmeister/kafka:2.x（Docker Image） 二、手动部署Kafka # 1、拉取镜像 # 先通过docker pull 命令把镜像拉取下来，方便后续操作\ndocker pull zookeeper:3.8 docker pull wurstmeister/kafka:2.13-2.8.1 2、创建数据卷 # 创建数据卷，方便数据持久化\ndocker volume create zookeeper_vol docker volume create kafka_vol 3、创建ZooKeeper容器 # 创建zookeeper-test容器，同时挂载数据卷和并指定端口映射（2181）\ndocker run -d --name zookeeper-test -p 2181:2181 \\ --env ZOO_MY_ID=1 \\ -v zookeeper_vol:/data \\ -v zookeeper_vol:/datalog \\ -v zookeeper_vol:/logs \\ zookeeper 4、创建Kafka容器 # 创建kafka-test容器，同时挂载数据卷和并指定端口映射（9092），并将zookeeper-test链接到该容器，使Kafka可以成功访问到zookeeper-test，Kafka相关参数通过环境变量（—env）设置\ndocker run -d --name kafka-test -p 9092:9092 \\ --link zookeeper-test \\ --env KAFKA_ZOOKEEPER_CONNECT=zookeeper-test:2181 \\ --env KAFKA_ADVERTISED_HOST_NAME=localhost \\ --env KAFKA_ADVERTISED_PORT=9092 \\ --env KAFKA_LOG_DIRS=/kafka/logs \\ -v kafka_vol:/kafka \\ wurstmeister/kafka 通过这种方式可以掌握整个部署过程，也可以达成ZooKeeper的复用，不过稍显繁琐\n三、Docker Compose部署Kafka # 1、创建Docker Compose配置文件 # 使用Docker Compose可以将一系列创建及映射资源（网络、数据卷等）操作放在配置文件中，并且可以通过depends_on参数指定容器的启动顺序，通过environment参数指定Kafka需要的基本参数信息 创建kafka-group.yml，保存以下信息\nversion: \u0026#39;3\u0026#39; name: kafka-group services: zookeeper-test: image: zookeeper ports: - \u0026#34;2181:2181\u0026#34; volumes: - zookeeper_vol:/data - zookeeper_vol:/datalog - zookeeper_vol:/logs container_name: zookeeper-test kafka-test: image: wurstmeister/kafka ports: - \u0026#34;9092:9092\u0026#34; environment: KAFKA_ADVERTISED_HOST_NAME: \u0026#34;localhost\u0026#34; KAFKA_ZOOKEEPER_CONNECT: \u0026#34;zookeeper-test:2181\u0026#34; KAFKA_LOG_DIRS: \u0026#34;/kafka/logs\u0026#34; volumes: - kafka_vol:/kafka depends_on: - zookeeper-test container_name: kafka-test volumes: zookeeper_vol: {} kafka_vol: {} 2、启动容器组 # # 启动Kafka容器组 docker compose -f kafa-group.yml up -d # 输出示例 ✔ Network kafka-group_default Created ✔ Volume \u0026#34;kafka-group_zookeeper_vol\u0026#34; Created ✔ Volume \u0026#34;kafka-group_kafka_vol\u0026#34; Created ✔ Container zookeeper-test Started ✔ Container kafka-test Started 四、Kafka消息测试 # 1、启动Kafka Producer # 新开一个命令后窗口，然后执行以下命令，启动Kafka Producer，准备往topic:test发送消息\n# 进入容器 docker exec -it kafka-test /bin/bash # 进入Kafka bin目录 cd /opt/kafka/bin # 启动Producer sh kafka-console-producer.sh --broker-list localhost:9092 --topic test 2、启动Kafka Consumer # 新开一个命令后窗口，然后执行以下命令，启动Kafka Consumer，订阅来自topic:test的消息\n# 进入容器 docker exec -it kafka-test /bin/bash # 进入Kafka bin目录 cd /opt/kafka/bin # 启动Consumer sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 3、收发消息测试 # 在Producer命令行窗口输入内容，然后回车即可发送消息 然后再Consumer命令行窗口可以看到收到的消息\n![[kafka测试效果图.png]]\n五、备注 # 1、可能碰到的问题 # 如果你碰到ZooKeeper、Kafka容器无法正常启动，可以删除数据卷以及容器后进行创建\n# 停用\u0026amp;删除容器 docker stop zookeeper-test kafka-test docker rm zookeeper-test kafka-test # 删除数据卷 docker volume rm zookeeper_vol kafka_vol docker volume rm kafka-group_kafka_vol kafka-group_zookeeper_vol 2、相关阅读 # https://ken.io/note/zookeeper-cluster-deploy-guide https://ken.io/note/kafka-cluster-deploy-guide https://hub.docker.com/_/zookeeper https://hub.docker.com/r/wurstmeister/kafka 六、端到端延迟 # 来自: 一文理解kafka端到端的延迟\n理解到端的延迟(end-to-end latency) # 端到端延时是指应用逻辑调用KafkaProducer.send()生产消息到该消息被应用逻辑通过KafkaConsumer.poll()消费到之间的时间。\n因此，端到端的延迟主要会由以下几个部分组成: # Produce time: 内部Kafka producer处理消息并将消息打包的时间 Publish time: producer发送到broker并写入到leader副本log的时间 Commit time: follower副本备份消息的时间 Catch-up time: 消费者追赶消费进度，消费到该消息位移值前所花费的时间 Fetch time: 从broker读取该消息的时间 ![[kafka端到端.webp]]\n![[端到端延迟图.jpg]]\n"},{"id":41,"href":"/docs/programmer/base/paramiko-%E4%BD%BF%E7%94%A8-sshsftp/","title":"Paramiko 使用 Ssh\u0026sftp","section":"Base","content":"没啥好说的, 直接看代码:\nimport os import gzip import shutil import paramiko import multiprocessing from pathlib import Path from loguru import logger from config import globalconf class SSHConnection(object): def __init__(self, host=None, port=None, username=None, pwd=None, pk_path=None): \u0026#34;\u0026#34;\u0026#34; :param host: 服务器ip :param port: 接口 :param username: 登录名 :param pwd: 密码 \u0026#34;\u0026#34;\u0026#34; self.host = host self.port = port self.username = username self.pwd = pwd self.pk_path = pk_path def __enter__(self): self.connect() return self def __exit__(self, exc_type, exc_val, exc_tb): self.close() return True def connect(self): transport = paramiko.Transport((self.host, self.port)) # transport.connect(username=self.username, password=self.pwd) pk = paramiko.RSAKey.from_private_key_file(self.pk_path) transport.connect(username=self.username, pkey=pk) self.__transport = transport self.sftp = paramiko.SFTPClient.from_transport(self.__transport) def close(self): self.__transport.close() self.sftp.close() def upload(self, local_path, target_path): self.sftp.put(local_path, target_path) def download(self, remote_path, local_path): sftp = paramiko.SFTPClient.from_transport(self.__transport) sftp.get(remote_path, local_path) def listdir(self, path): return self.sftp.listdir(path=path) def listdir_attr(self, path): return self.sftp.listdir_attr(path=path) def download_slowly(self, remote_path, local_path): sftp = paramiko.SFTPClient.from_transport(self.__transport) # # 旧方法下载大文件会出现Server connection dropped # sftp.get(remote_path, local_path) # 新方法下载大文件成功 # 这将避免Paramiko预取缓存，并允许您下载文件，即使它不是很快 with sftp.open(remote_path, \u0026#39;rb\u0026#39;) as fp: shutil.copyfileobj(fp, open(local_path, \u0026#39;wb\u0026#39;)) def cmd(self, command): ssh = paramiko.SSHClient() # 执行命令 stdin, stdout, stderr = ssh.exec_command(command) # 获取命令结果 result = stdout.read() result = str(result, encoding=\u0026#39;utf-8\u0026#39;) return result class SSHConnectionManager(object): def __init__(self, host, port, username, pwd, pk_path): self.ssh_args = { \u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port, \u0026#34;username\u0026#34;: username, \u0026#34;pk_path\u0026#34;: pk_path, \u0026#34;pwd\u0026#34;: pwd } def __enter__(self): self.ssh = SSHConnection(**self.ssh_args) self.ssh.connect() return self.ssh def __exit__(self, exc_type, exc_val, exc_tb): self.ssh.close() return True def clear_dir(path): \u0026#34;\u0026#34;\u0026#34; 清空文件夹：如果文件夹不存在就创建，如果文件存在就清空！ :param path: 文件夹路径 :return: \u0026#34;\u0026#34;\u0026#34; import os import shutil try: if not os.path.exists(path): os.makedirs(path) else: shutil.rmtree(path) os.makedirs(path) return True except: return False def decompress_gz(gz_file): with gzip.GzipFile(gz_file) as file: for i in file: yield i def get_file_sftp(tar_path): temp_path = os.path.join(globalconf.SFTP_TEMP_PATH, os.path.split(tar_path)[-1]) try: with SSHConnection( host=globalconf.SFTP_SERVER_HOST, port=globalconf.SFTP_SERVER_PORT, username=globalconf.SFTP_USERNAME, pwd=\u0026#34;\u0026#34;, pk_path=globalconf.SFTP_KEY_PATH ) as sftp: sftp.download_slowly(tar_path, temp_path) except Exception as err: logger.error(f\u0026#34;sftp 下载文件出错: {err}\u0026#34;) return temp_path def format_file_list(file_list): root_dir = os.path.dirname(file_list[0]) sub_files = set([os.path.basename(file) for file in file_list]) return root_dir, sub_files def is_sftp_file_exists(task_id, path): exists = False if isinstance(path, str) and path: path = [path] rootdir, _ = format_file_list(path) try: with SSHConnection( host=globalconf.SFTP_SERVER_HOST, port=globalconf.SFTP_SERVER_PORT, username=globalconf.SFTP_USERNAME, pwd=\u0026#34;\u0026#34;, pk_path=globalconf.SFTP_KEY_PATH ) as sftp: list_file_names = sftp.listdir(rootdir) if str(task_id) in str(list_file_names): exists = True except Exception as err: logger.error(f\u0026#34;sftp 获取文件列表错误: {err}\u0026#34;) return exists class SFTPFileManager_Tool(object): def __init__(self, host, port, username, pwd, pk_path): \u0026#34;\u0026#34;\u0026#34; init :param host: ip :param port: 端口 :param username: 用户名 :param pwd: 密码 \u0026#34;\u0026#34;\u0026#34; self.ssh_args = {\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port, \u0026#34;username\u0026#34;: username, \u0026#34;pwd\u0026#34;: pwd, \u0026#34;pk_path\u0026#34;: pk_path} def exists(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否存在 :param path: :return: \u0026#34;\u0026#34;\u0026#34; is_exists = False with SSHConnectionManager(**self.ssh_args) as ssh: result = ssh.cmd(f\u0026#34;find {path}\u0026#34;) if result: is_exists = True return is_exists def is_file(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否是文件 :param path: :return: \u0026#34;\u0026#34;\u0026#34; if self.exists(path): with SSHConnectionManager(**self.ssh_args) as ssh: prefix = ssh.cmd(f\u0026#34;ls -ld {path}\u0026#34;)[0] if prefix == \u0026#39;-\u0026#39;: return True else: return False else: return False def is_dir(self, path): \u0026#34;\u0026#34;\u0026#34; 判断路径是否是目录 :param path: :return: \u0026#34;\u0026#34;\u0026#34; if self.exists(path): with SSHConnectionManager(**self.ssh_args) as ssh: prefix = ssh.cmd(f\u0026#34;ls -ld {path}\u0026#34;)[0] if prefix == \u0026#39;d\u0026#39;: return True else: return False else: return False def download_file(self, remote_path, local_path): \u0026#34;\u0026#34;\u0026#34; 下载文件 :param remote_path: 远程文件路径 :param local_path: 本地文件路径 :return: \u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;正下载文件{remote_path}...\u0026#34;) with SSHConnectionManager(**self.ssh_args) as ssh: if not Path(local_path).parent.exists(): Path(local_path).parent.mkdir(parents=True) ssh.download_slowly(remote_path=remote_path, local_path=local_path) def download_folder(self, remote_folder, local_folder): \u0026#34;\u0026#34;\u0026#34; 下载文件夹 :param remote_folder: 远程文件夹目录 :param local_folder: 本地文件夹目录 :return: \u0026#34;\u0026#34;\u0026#34; with SSHConnectionManager(**self.ssh_args) as ssh: dst_folder = Path(local_folder) if not dst_folder.exists(): dst_folder.mkdir(parents=True) clear_dir(str(dst_folder)) files_list = ssh.cmd(\u0026#34;ls {}\u0026#34;.format(remote_folder)) files_list = files_list.split(\u0026#39;\\n\u0026#39;) files_list = [x for x in files_list if x] # 多进程下载文件 cpu_count = multiprocessing.cpu_count() // 2 if cpu_count == 0: cpu_count = 1 pool = multiprocessing.Pool(cpu_count) for file in files_list: remote_path = remote_folder + \u0026#34;/\u0026#34; + file local_path = dst_folder.joinpath(file) pool.apply_async(func=self.download_file, args=(remote_path, local_path)) pool.close() pool.join() # 主进程下载文件 # for file in files_list: # remote_path = remote_folder + \u0026#34;/\u0026#34; + file # local_path = dst_folder.joinpath(file) # print(f\u0026#34;正下载{remote_path}...\u0026#34;) # ssh.download_slowly(remote_path=remote_path, local_path=local_path) if __name__ == \u0026#34;__main__\u0026#34;: a = SFTPFileManager_Tool(host=\u0026#34;1.1.1.1\u0026#34;, port=5050, username=\u0026#34;sftpuser\u0026#34;, pwd=\u0026#34;\u0026#34;, pk_path=\u0026#34;/root/.ssh/id_rsa\u0026#34;) b = a.is_dir(\u0026#34;/hello/\u0026#34;) print(b) "},{"id":42,"href":"/docs/programmer/base/pytest-%E6%B5%8B%E8%AF%95/","title":"Py Test 测试","section":"Base","content":"[TOC]\n命令 # Django 整合进 pytest测试 # pip install pytest-django pytest -s -vv .\\tests\\test_step2.py --rootdir X:\\Code\\workflows\\ --ds project.settings rootdir 指定项目根目录 ds 指向django setting.py 文件 一、为什么需要pytest # helps you write better programs\n提高阅读理解代码效率 提高debug效率 提高开发效率 保证交付代码质量 简单例子 # 入门例子:\n了解使用test文件命名格式: test_前缀 了解断言assert 了解测试输出 # content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5 输出\n$ pytest =========================== test session starts ============================ platform linux -- Python 3.x.y, pytest-7.x.y, pluggy-1.x.y rootdir: /home/sweet/project collected 1 item test_sample.py F [100%] ================================= FAILURES ================================= _______________________________ test_answer ________________________________ def test_answer(): \u0026gt; assert inc(3) == 5 E assert 4 == 5 E + where 4 = inc(3) test_sample.py:6: AssertionError ========================= short test summary info ========================== FAILED test_sample.py::test_answer - assert 4 == 5 ============================ 1 failed in 0.12s ============================= 常用命令 # 熟悉测试命令和备忘, 了解常用参数含义\npytest -s 输出print和日志 --pdb 允许pdb调试 -vv 详细输出 Django # python2 manage.py test tests/ # Django Test Allure # pytest --alluredir=./allure_report allure serve ./allure_report 安装 # 涉及到的库和依赖安装命令备忘\napt install npm apt install openjdk-11-jdk npm install -g allure-commandline --save-dev pip install pytest pip install allure-pytest # -i https://pypi.tuna.tsinghua.edu.cn/simple 二、API测试 # 批量API测试简化写法, 初步体验一下简化工作的快乐\n简单且重复的接口测试 以CSV为例 # test.csv # url body contains https://httpbin.org/post {\u0026ldquo;key\u0026rdquo;: \u0026ldquo;value\u0026rdquo;} {\u0026ldquo;url\u0026rdquo;: \u0026ldquo;https://httpbin.org/post\"} https://httpbin.org/post {\u0026ldquo;key\u0026rdquo;: \u0026ldquo;value\u0026rdquo;} {\u0026ldquo;data\u0026rdquo;: \u0026ldquo;{\u0026quot;key\u0026quot;: \u0026quot;value\u0026quot;}\u0026rdquo;} test_api.py # def readCsv(): data=list() with open(\u0026#39;test.csv\u0026#39;,\u0026#39;r\u0026#39;) as f: reader=csv.reader(f) next(reader) for item in reader: data.append(item) return data @pytest.mark.parametrize(\u0026#39;data\u0026#39;, readCsv()) def test_csv_login(data): r=requests.post( url=data[0], json=json.loads(data[1])) _temp = r.json() _temp_update = copy.deepcopy(_temp) _temp_update.update(json.loads(data[2])) assert _temp == _temp_update 输出\npytest test_api.py ==================================== test session starts ==================================== platform linux -- Python 3.9.2, pytest-7.2.1, pluggy-1.0.0 rootdir: /mnt/share/code plugins: allure-pytest-2.12.0, anyio-3.6.2 collected 2 items test_api.py .. [100%] ===================================== 2 passed in 3.12s ===================================== 三、Mock 和测试 # 了解测试中常用的小工具, 增进开发自测幸福感\n前、后端并行开发, 摆脱依赖 模拟无法访问的资源 隔离系统, 避免脏数据干扰或生产脏数据 0. Mock的方式 # i. 手动指定 mock 范围 # def test_get_sum(): mock_get_sum = mock.patch(\u0026#34;app.get_sum\u0026#34;, return_value=20) mock_get_sum.start() rst = app.get_sum(1, 3) mock_get_sum.stop() ii. 装饰器 # @mock.patch(\u0026#34;app.get_sum\u0026#34;) def test_get_sumv2(mock_get_sum): mock_get_sum.side_effect = mock_sum rst = app.get_sum(1, 3) assert rst == 10 iii. 上下文管理器 # with mock.patch(\u0026#34;app.get_sum\u0026#34;, new_callable=mock_sum) as mock_get_sum: rst = app.get_sum assert rst == 10 总结 # - 手动指定 装饰器 上下文管理器 优点 可以更精细控制mock的范围 方便mock多个对象 1 不足 需要手动start和stop 装饰器顺序和函数参数相反容易混乱 一个with只能mock一个对象 1. Mock一个方法 # from pathlib import Path def test_getssh(monkeypatch): monkeypatch.setattr(Path, \u0026#34;home\u0026#34;, mockreturn) 2. Mock一个类 # 以 requests 为例, mock get 任意url的(.json())返回值\nimport requests class App: def get_json(self, url): return requests.get(url).json() class MockResponse: @staticmethod def json(): return {\u0026#34;mock_key\u0026#34;: \u0026#34;mock_response\u0026#34;} def test_get_json(monkeypatch): def mock_get(*args, **kwargs): return MockResponse() monkeypatch.setattr(requests, \u0026#34;get\u0026#34;, mock_get) result = App().get_json(\u0026#34;https://fakeurl\u0026#34;) assert result[\u0026#34;mock_key\u0026#34;] == \u0026#34;mock_response\u0026#34; 3. 实例 # backent - Django Test # from django.test import TestCase from events.preview_service import PreviewService class MailTestCase(TestCase): def setUp(self): pass @patch(\u0026#39;events.preview_service.get_app_platform_logo\u0026#39;) @patch(\u0026#39;events.preview_service.is_master_node\u0026#39;) def test_preview_info_master(self, mock_node, mock_logo): mock_node.return_value = True base64_image = \u0026#34;R0lGODlhAQABAIAAAAUEBAAAACwAAAAAAQABAAACAkQBADs=\u0026#34; # 黑色图片 mock_logo.return_value = (2000, base64_image) cnt = PreviewService({ \u0026#34;notice_object\u0026#34;: \u0026#34;customer\u0026#34;, \u0026#34;event_object\u0026#34;: { \u0026#34;event_list\u0026#34;: [ { \u0026#34;start_time\u0026#34;: \u0026#34;2023-01-16\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2023-01-16\u0026#34;, \u0026#34;customer_name\u0026#34;: \u0026#34;6\u0026#34;, } ]} }).get_preview_info() self.assertEqual(type(cnt), dict) self.assertEqual(cnt.keys(), {\u0026#34;flag\u0026#34;: None, \u0026#34;preview_info\u0026#34;: None, \u0026#34;sender\u0026#34;: None}.keys()) self.assertEqual(cnt[\u0026#34;flag\u0026#34;], True) self.assertEqual(cnt[\u0026#34;sender\u0026#34;][\u0026#34;address\u0026#34;], \u0026#34;mdr@nsfocus.com\u0026#34;) self.assertEqual(cnt[\u0026#34;preview_info\u0026#34;][\u0026#34;email_title\u0026#34;], u\u0026#34;【绿盟科技1】MDR威胁分析服务安全事件通知\u0026#34;) MOC # from common.nscloud import NsCloudNuriClient class MockResponse: @staticmethod def json(): return {\u0026#34;results\u0026#34;: []} def test_a(monkeypatch): def mock_request(*args, **kwargs): return MockResponse() monkeypatch.setattr(NsCloudNuriClient, \u0026#34;request\u0026#34;, mock_request) # import pdb; pdb.set_trace() content = generate_daily_report_content(\u0026#34;\u0026#34;, \u0026#34;\u0026#34;) assert bool(content) 四、功能重用(pytest.fixture) # fixture一点需要考虑的是初始化与清理。\n也就是说在一个完整的测试用例中, 都必须都得有初始化与清理的部分, 这样才是一个完整的测试用例的 还有一点是fixture的函数也可以和返回值整合起来构成完整流程, 以get案例, 那么首先需要add书籍, 然后是get, 最后是del #!coding:utf-8 import pytest import requests from loguru import logger def add_book(get_token): r=requests.post( url=\u0026#39;https://www.example.org/\u0026#39;, headers={\u0026#39;Authorization\u0026#39;:\u0026#39;JWT {0}\u0026#39;.format(get_token)} ) del_book = add_book # 仅演示用 @pytest.fixture() def init(get_token): add_book(get_token) logger.info(\u0026#34;add_book in init\u0026#34;) yield del_book(get_token) logger.info(\u0026#34;del_book in init\u0026#34;) def test_get_book(init, get_token): r=requests.post( url=\u0026#39;https://www.example.org/\u0026#39;, headers={\u0026#39;Authorization\u0026#39;:\u0026#39;JWT {0}\u0026#39;.format(get_token)} ) logger.info(\u0026#34;get_book in test\u0026#34;) assert r.text fixture作用范围(scope) # @pytest.fixture()如果不写参数, 默认就是scope=\u0026quot;function\u0026quot; 它的作用范围是每个测试用例来之前运行一次, 销毁代码在测试用例运行之后运行\n详细如下:\nfunction 每一个函数或方法都会调用 class 每一个类调用一次, 一个类可以有多个方法 module 每一个.py文件调用一次, 该文件内又有多个function和class session 是多个文件调用一次, 可以跨.py文件调用, 每个.py文件就是module 输出\npytest test_api.py -s test_api.py 2023-02-07 15:38:22.906 | INFO | test_api:init:17 - add_book in init 2023-02-07 15:38:24.471 | INFO | test_api:test_get_book:27 - get_book in test 2023-02-07 15:38:25.894 | INFO | test_api:init:20 - del_book in init ================ 1 passed in 6.71s ================ 五、流程规范(Allure) # 同样以add, get, del为例 详参这里 和 这里 import allure import pytest import requests @pytest.fixture(scope=\u0026#34;session\u0026#34;) def login_setup(): return \u0026#34;token\u0026#34; @allure.feature(\u0026#34;功能模块\u0026#34;) @allure.story(\u0026#34;测试用例小模块-成功案例\u0026#34;) @allure.title(\u0026#34;测试用例名称: 流程性的用例, 添加测试步骤\u0026#34;) def test_add_goods_and_buy(login_setup): \u0026#39;\u0026#39;\u0026#39; 用例描述: 前置: 登陆 用例步骤: 1.浏览商品 2.添加购物车 3.购买 4.支付成功 \u0026#39;\u0026#39;\u0026#39; with allure.step(\u0026#34;step1: 浏览商品\u0026#34;): assert True with allure.step(\u0026#34;step2: 添加购物车\u0026#34;): assert True with allure.step(\u0026#34;step3: 生成订单\u0026#34;): # assert False assert True with allure.step(\u0026#34;step4: 支付\u0026#34;): assert True with allure.step(\u0026#34;断言\u0026#34;): assert True @allure.feature(\u0026#34;MDR服务邮件通知去绿盟云\u0026#34;) @allure.story(\u0026#34;客户安全事件邮件通知去绿盟化\u0026#34;) @allure.link(\u0026#34;https://inone.intra.nsfocus.com/jira/browse/MDR-4271\u0026#34;) @allure.title(\u0026#34;标题1\u0026#34;) def test_f1(): \u0026#39;\u0026#39;\u0026#39; 用例描述: 前置: 无 用例步骤: 1.测试1 2.测试2 \u0026#39;\u0026#39;\u0026#39; with allure.step(\u0026#34;step1\u0026#34;): assert True with allure.step(\u0026#34;step2\u0026#34;): assert True ![[pytest-demo.jpg]]\n"},{"id":43,"href":"/docs/programmer/base/sonar-%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E6%A3%80%E6%9F%A5/","title":"Sonar 代码静态检查","section":"Base","content":"平台地址 需要自建\n在平台新建项目，新建token后可以自动生成扫描命令(拉代码, cd进去后在项目代码/路径下执行)：\nsonar-scanner \\ -Dsonar.projectKey=scancenter \\ -Dsonar.sources=. \\ -Dsonar.host.url=https://sonar-xa.inone.nsfocus.com \\ -Dsonar.login=3e569f7abcfd8a64067d790f038c57a6a6b73207 如果使用的是他人的token，需要给授权。\n"},{"id":44,"href":"/docs/programmer/base/%E5%B0%8F%E5%91%BD%E4%BB%A4/","title":"小命令","section":"Base","content":"title: 小命令 date: 2023-09-24 23:03:41 categories: [小命令] tags: [小命令]\n小命令 # 1. 递归删除某些文件 # 如以.py.bak 为结尾的文件: find . -name \u0026quot;*.py.bak\u0026quot; -exec rm {} \\;\n2. 批量杀死进程 # - pkill -f uwsgi\n- ps aux | grep 关键字 | awk \u0026lsquo;{print $2}\u0026rsquo; | xargs kill\n批量删除pod - xargs 的使用 # kubectl get pod -n argo | grep workflow-template | awk \u0026#39;{print $1}\u0026#39; | xargs kubectl -n argo delete pod 3. MySQL NOW # 指定东八：update scanner_device set update_time = CONVERT_TZ(NOW(), @@session.time_zone, \u0026quot;+08:00\u0026quot;);\n4. celery worker状态 # celery -A ncelery status\n-\u0026gt; celery@scan-celery.rcmrestat.00: OK\n-\u0026gt; celery@scan-celery.vulcombine.00: OK\n-\u0026gt; celery@scan-celery.rcmstat.00: OK\n5. base64解码 # echo YWRtaW46bnNmMGN1cy5Aazhz | base64 -d 使用场景: 如在USER/.docker/config寻找到docker登陆凭证可以用此解码后login登录\n6. k8s 复制文件 # kubectl cp -n websafe -c master-fizz-daemon master-fizz-daemon-66c89f7c9c-nlgd4:rcm_vul_info.json rcm_vul_info.json\n7. 查看k8s DNS解析 # kubectl get configmap -n kube-system coredns -o yaml\n8. 关闭WSL2 # #停止LxssManager服务: net stop LxssManager #启动LxssManager服务: net start LxssManager\n9. nginx 代理 mongodb # FROM nginx RUN echo \u0026#34;stream {\\n upstream stream_mongo {\\n server mongo:27017;\\n }\\n\\n server {\\n listen 9876;\\n proxy_pass stream_mongo;\\n }\\n}\u0026#34; \u0026gt;\u0026gt; /etc/nginx/nginx.conf docker build -t nginx-proxy:v0 . docker run -p 12345:9876 --network websafe-network --name nginx-proxy nginx-proxy:v0 # 连接 12345 即可 10. MySQL删除锁修改表 # SHOW PROCESSLIST; KILL 6261330; -- 根据表所在的库名找见ID，然后删除锁 LOCK TABLES task WRITE; ALTER TABLE task ADD COLUMN module_id INT not null DEFAULT 1005 COMMENT \u0026#39;这里是SQL字段注释\u0026#39;; UNLOCK TABLES; 11. rz sz 上传下载服务器小文件 # 安装命令: apt install lrzsz 下载 sz xxx 上传 rz 12. 并行下发命令 # time parallel -N0 -j10 \u0026#34;argo submit success.yaml -n argo\u0026#34; ::: {1..100} 使用 -N 限制每行参数的个数，其中-N0表示一次只读取一个参数，且不输入这个参数（作为计数器来使用）。\nparallel -N4 echo 1={1} 2={2} 3={3} ::: A B C D E F G H 1=A 2=B 3=C // D传入了，但没接收所以下一行丢失 1=E 2=F 3=G parallel -N0 echo foo ::: 1 2 3 foo foo foo 如果要打印计数，可以使用time parallel -N1 -j10 \u0026quot;echo '[$(date)] 第 {}：次提交中...' \u0026amp; ls\u0026quot; ::: {1..10}或者不指定N1默认就是N1\n13. ffmpeg 提取视频中音频 # ffmpeg -i englishdemo.mp4 -vn -c:a copy english.aac 提取并转换为mp3格式 # ffmpeg -i englishdemo.mp4 -vn -b:a 128k -c:a mp3 english.mp3 14. Windows 休眠 # cmd 管理员模式运行\npowercfg.exe -h off powercfg.exe -h on 15. Windows刷新DNS缓存 - 修改hosts之后不生效使用 # ipconfig /flushdns "},{"id":45,"href":"/docs/programmer/database/mongodb/","title":"Mongodb","section":"Database","content":"title: Mongodb使用记录 date: 2023-09-24 23:02:41 categories: [mongodb] tags: [mongodb, docker]\n安装 # Docker 安装 4.4.12版本 # pull: docker pull mongo:4.4.13 run: docker run -itd --name mongo --restart=always \\ -v /mongodb/datadb:/data/db \\ -p 27017:27017 \\ --network websafe-network \\ --privileged=true mongo:4.4.12 进入容器docker exec -it mongo bash后:\nmongo use admin # db.createUser({user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;admin\u0026#34;, roles: [{role: \u0026#34;root\u0026#34;, db: \u0026#34;admin\u0026#34;}]}) # db.createUser({user: \u0026#34;admin\u0026#34;, pwd: \u0026#34;admin\u0026#34;, roles: [{role: \u0026#34;userAdminAnyDatabase\u0026#34;, db: \u0026#34;admin\u0026#34;}]}) # 如果能auth就不用createUser了 db.auth(\u0026#34;admin\u0026#34;, \u0026#34;admin\u0026#34;) 网上传的将 MONGO_INITDB_ROOT_PASSWORD 和 MONGO_INITDB_ROOT_USERNAME传入环境变量的方式，在mongo4.4.12 和 4.4.13上都不好使。\n"},{"id":46,"href":"/docs/programmer/hardware/android/","title":"Android","section":"Hardware","content":" 将安卓手机用于开发 # Termux # 类似于WIN端的Subsystem——其实更像Ubuntu下的虚拟终端。 不过这东西功能强大，除了将安卓里的Linux发挥出来。还有Termux API来调用手机的底层接口。\nXFCE4 # 步骤：\n安装Termux 执行pkg update 执行pkg install git \u0026amp;\u0026amp; git clone https://github.com/Yisus7u7/termux-desktop-xfce.git 执行cd termux-desktop-xfce \u0026amp;\u0026amp; bash boostrap.sh 当然，3\u0026amp;4步可以合并为一句curl -sLf https://raw.githubusercontent.com/Yisus7u7/termux-desktop-xfce/main/boostrap.sh | bash\nVNC # 默认VNC只能通过localhost:1来连接，局域网不能访问。想用大屏来看就不是很方便。\n# 先执行`vncserver`使用本机的`VNC Viewer`看看效果，主要是需要先设置一下密码 vncserver # 现在还无法通过局域网连接 # 去设置 cd ~/.vnc/ vim config # 打开最后一行注释 # 重新运行 vncserver -kill :1 vncserver 配置文件一览 # 将config文件最后一行的注释打开，即可\n## Supported server options to pass to vncserver upon invocation can be listed ## in this file. See the following manpages for more: vncserver(1) Xvnc(1). ## Several common ones are shown below. Uncomment and modify to your liking. ## # securitytypes=vncauth,tlsvnc # desktop=sandbox geometry=1280x720 # localhost # alwaysshared 将这行注释取消注释 alwaysshared # 修改成这样 现在各个版本概览 # python - 3.10 clang - 14.0.5 opencv - 4.5.5 NumPy # # pip3 install numpy 不能安装 MATHLIB=\u0026#34;m\u0026#34; pip3 install numpy # numpy 1.22.4 C++ \u0026amp; OpenCV # 现在安装opencv-python还有问题,可能问题出现在安装numpy上,但后来经过努力安装好了,但版本或者其他问题导致还是不能正常运行.但C++还是很好呀.\npkg install opencv opcv.cpp # #include \u0026lt;opencv2/opencv.hpp\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace cv; using namespace std; int main() { Mat src = imread(\u0026#34;logo-red.png\u0026#34;, IMREAD_GRAYSCALE); if (src.empty()) { printf(\u0026#34;could not find the image\\n\u0026#34;); return -1; } imwrite(\u0026#34;grayscale.png\u0026#34;, src); printf(\u0026#34;save grayscale success\\n\u0026#34;); // waitKey(0); // system(\u0026#34;path\u0026#34;); // getchar(); return 0; } 编译 \u0026amp; 运行 # g++ opcv.cpp -o opcv `pkg-config --cflags --libs opencv4` ./opcv 指定编译器版本 # opencv4 需要C++11\ng++ opcv.cpp -o opcv `pkg-config --cflags --libs opencv4` -std=c++11 ssh与手机连接 # 手机端sshpc端 # 电脑生成密匙,无视密码设置全部回车 ssh-keygen -t rsa 电脑开启sshd服务,用于手机的ssh连接到电脑, 拷贝id_rsa.pub内容 systemctl start sshd wsl: sshd re-exec requires execution with an absolute path 转去手机端操作 手机连接拷贝 $HOME/.ssh/authorized_keys -\u0026gt; 不管用什么复制，然后放到这个路径就好。 查看手机的用户名 whoami 开启服务 sshd -p 9000 pcssh手机端 # ssh u0_222@192.168.1.14 -p 9000 可能有文件权限问题 chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys 😓\n快捷键(有用的音量键？) # 显示扩展功能按键 # 方法一: 从左向右滑动,显示隐藏式导航栏,长按左下角的KEYBOARD.\n方法二: 使用Termux快捷键:音量++Q键\n常用快捷键 # Ctrl键是终端用户常用的按键 – 但大多数触摸键盘都没有这个按键。为此，Termux使用音量减小按钮来模拟Ctrl键。在触摸键盘上按音量减小+ L发送与在硬件键盘上按Ctrl + L相同的输入。 Ctrl+A -\u0026gt; 将光标移动到行首 Ctrl+C -\u0026gt; 中止当前进程 Ctrl+D -\u0026gt; 注销终端会话 Ctrl+E -\u0026gt; 将光标移动到行尾 Ctrl+K -\u0026gt; 从光标删除到行尾 Ctrl+L -\u0026gt; 清除终端 Ctrl+Z -\u0026gt; 挂起（发送SIGTSTP到）当前进程 加键也可以作为产生特定输入的特殊键. 音量加+E -\u0026gt; Esc键 音量加+T -\u0026gt; Tab键 音量加+1 -\u0026gt; F1（和音量增加+ 2→F2等） 音量加+0 -\u0026gt; F10 音量加+B -\u0026gt; Alt + B，使用readline时返回一个单词 音量加+F -\u0026gt; Alt + F，使用readline时转发一个单词 音量加+X -\u0026gt; Alt+X 音量加+W -\u0026gt; 向上箭头键 音量加+A -\u0026gt; 向左箭头键 音量加+S -\u0026gt; 向下箭头键 音量加+D -\u0026gt; 向右箭头键 音量加+L -\u0026gt; | （管道字符） 音量加+H -\u0026gt; 〜（波浪号字符） 音量加+U -\u0026gt; _ (下划线字符) 音量加+P -\u0026gt; 上一页 音量加+N -\u0026gt; 下一页 音量加+. -\u0026gt; Ctrl + \\（SIGQUIT） 音量加+V -\u0026gt; 显示音量控制 音量加+Q -\u0026gt; 显示额外的按键视图 "},{"id":47,"href":"/docs/programmer/hardware/raspberrypi/","title":"Raspberry Pi","section":"Hardware","content":" 树莓派 # 详细文档 # 参考Cloud Atlas\n很详细的罗列了树莓派各个版本的参数以及IO\u0026amp;其他参数的汇总，属于对官方文档的翻译以及补充，基于实践的补充，很有用。\n"},{"id":48,"href":"/docs/programmer/hardware/readme/","title":"Readme","section":"Hardware","content":" 硬件篇 # 这里虽说是\u0026quot;硬件篇\u0026quot;其实并不是仅有硬件该怎么配，而包括了在这些硬件上，软件应该如何部署。 当然，也会有一些硬件的使用经验。\n树莓派 安卓手机 便携屏幕 "},{"id":49,"href":"/docs/programmer/hardware/screen/","title":"Screen","section":"Hardware","content":" 便携屏幕 # 某日入得4K便携屏幕一个, 甚是欢喜。无论手机、NS、PC用之皆爽.然NS 1080P 缩放至 4k 略糊，只可远观。\n某日因压了个键盘和书，搬，屏幕裂，屏花之。方知平时屏幕擦灰时，稍加用力就会破碎感不是虚妄，而是确实。可见质量甚是不行，弃。\n"},{"id":50,"href":"/docs/programmer/ml/paddle/","title":"Paddle","section":"Ml","content":" title: Paddle date: 2022-06-08 18:58:56 modified: 2022-06-08 18:58:56 category: [note, 机器学习] tags: [Paddle] slug: # Paddle的坑 # 资源占用 # 命令示例(yml中修改了train,test样本地址,使用--gpus这里只用了一个GPU,可方便修改为多卡0,1,2,3)\npython -m paddle.distributed.launch --gpus \u0026#39;1\u0026#39; tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model=./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy.pdparams en_PP-OCRv3_rec默认性能配置在, 单卡V100上: +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ | 1 Tesla V100-SXM2\u0026hellip; On | 00000000:00:09.0 Off | 0 | | N/A 53C P0 223W / 300W | 23065MiB / 32510MiB | 100% Default | | | | N/A | +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nPaddle 多卡训练 # You may need to install \u0026rsquo;nccl2\u0026rsquo; from NVIDIA official website\nTraceback: 这种问题可以参看Github Issues\n写在坑前头 # 经测试，下面预训练模型下载地址和检测训练效果的脚本之所以报错是因为PaddleOCR项目主页的readme中链接的子readme是develop分支的。且这个分支是落后于当前release/2.5的，所以出现了以下不匹配的情况. 切换了分支之后, 匹配度还可以接受.\nPaddleOCR 预训练模型 # 百度写文档的积极性是真的低，看来这东西用的人是真的少\u0026hellip; 这是官方说明文档:\ncd PaddleOCR/ # 下载MobileNetV3的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/MobileNetV3_large_x0_5_pretrained.tar # 或，下载ResNet18_vd的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/ResNet18_vd_pretrained.tar # 或，下载ResNet50_vd的预训练模型 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/ResNet50_vd_ssld_pretrained.tar # 解压预训练模型文件，以MobileNetV3为例 tar -xf ./pretrain_models/MobileNetV3_large_x0_5_pretrained.tar ./pretrain_models/ # 注：正确解压backbone预训练权重文件后，文件夹下包含众多以网络层命名的权重文件，格式如下： ./pretrain_models/MobileNetV3_large_x0_5_pretrained/ └─ conv_last_bn_mean └─ conv_last_bn_offset └─ conv_last_bn_scale └─ conv_last_bn_variance └─ ...... 但是 # Paddle 在1.8版本后已经不用这种格式的预训练模型了！ 2022-06-07 现在已经更新到2.3.0 所以下载下来压根不能使用 wget -P ./pretrain_models/ https://paddle-imagenet-models-name.bj.bcebos.com/dygraph/ResNet18_vd_pretrained.pdparams 增加dygraph 后缀修改为pdparams 使用训练结果检测单张图片 # 应使用:\npython tools/infer_det.py --config=configs/det/det_res18_db_v2.0.yml -o Global.infer_img=\u0026#34;./train_data/icdar2015/ch4_test_images/img_4.jpg\u0026#34; Global.checkpoints=\u0026#34;./output/ch_db_res18/latest.pdparams\u0026#34; Global.use_gpu=false 而非官网所示的:\npython3 tools/infer_det.py -c configs/det/det_mv3_db_v1.1.yml -o Global.infer_img=\u0026#34;./doc/imgs_en/img_10.jpg\u0026#34; Global.checkpoints=\u0026#34;./output/det_db/best_accuracy\u0026#34; 否则会报错:\nTraceback (most recent call last): File \u0026#34;... /PaddleOCR/tools/infer_det.py\u0026#34;, line 133, in \u0026lt;module\u0026gt; config, device, logger, vdl_writer = program.preprocess() File \u0026#34;... /PaddleOCR/tools/program.py\u0026#34;, line 535, in preprocess FLAGS = ArgsParser().parse_args() File \u0026#34;... /PaddleOCR/tools/program.py\u0026#34;, line 57, in parse_args assert args.config is not None, \\ AssertionError: Please specify --config=configure_file_path. 多卡和断点续传 # 断点可能怕是不行了。。。\n多卡使用:\npython -m paddle.distributed.launch --gpus \u0026#39;1,2\u0026#39; tools/train.py -c configs/det/det_res18_db_v2.0.yml -o Global.use_gpu=true Global.checkpoints=\u0026#34;./output/ch_db_res18/latest.pdparams\u0026#34; | tee train_det.log 会出现:\n[2022/06/08 18:36:48] ppocr INFO: num_workers : 4 [2022/06/08 18:36:48] ppocr INFO: shuffle : True [2022/06/08 18:36:48] ppocr INFO: profiler_options : None [2022/06/08 18:36:48] ppocr INFO: train with paddle 2.3.0 and device Place(gpu:1) server not ready, wait 3 sec to retry... not ready endpoints:[\u0026#39;127.0.0.1:36939\u0026#39;] W0608 18:36:51.403939 745832 dynamic_loader.cc:276] You may need to install \u0026#39;nccl2\u0026#39; from NVIDIA official website: https://developer.nvidia.com/nccl/nccl-downloadbefore install PaddlePaddle. Traceback (most recent call last): File \u0026#34;tools/train.py\u0026#34;, line 191, in \u0026lt;module\u0026gt; main(config, device, logger, vdl_writer) File \u0026#34;tools/train.py\u0026#34;, line 47, in main dist.init_parallel_env() File \u0026#34;/data/anaconda3/lib/python3.8/site-packages/paddle/distributed/parallel.py\u0026#34;, line 315, in init_parallel_env parallel_helper._init_parallel_ctx() File \u0026#34;/data/anaconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel_helper.py\u0026#34;, line 42, in _init_parallel_ctx __parallel_ctx__clz__.init() RuntimeError: (PreconditionNotMet) The third-party dynamic library (libnccl.so) that Paddle depends on is not configured correctly. (error code is libnccl.so: cannot open shared object file: No such file or directory) Suggestions: 1. Check if the third-party dynamic library (e.g. CUDA, CUDNN) is installed correctly and its version is matched with paddlepaddle you installed. 2. Configure third-party dynamic library environment variables as follows: - Linux: set LD_LIBRARY_PATH by `export LD_LIBRARY_PATH=...` - Windows: set PATH by `set PATH=XXX; (at /paddle/paddle/phi/backends/dynload/dynamic_loader.cc:303) LSTM Model # import os import sys import jieba import codecs import chardet import shutil import time from tqdm import tqdm, trange from bs4 import BeautifulSoup import paddle import paddlenlp chardet.__dict__ import numpy as np from functools import partial import paddle.nn as nn import paddle.nn.functional as F import paddlenlp as ppnlp from paddlenlp.data import Pad, Stack, Tuple print(paddle.__version__, paddlenlp.__version__) # from paddlenlp.datasets import MapDatasetWrapper # 加载文件列表 import pandas as pd columns = [\u0026#39;id\u0026#39;, \u0026#39;flag\u0026#39;, \u0026#39;filename\u0026#39;, \u0026#39;url\u0026#39;] tempdf = pd.read_csv(\u0026#39;MaliciousWebpage/file_list.txt\u0026#39;, sep=\u0026#39;,\u0026#39;,skiprows=0, header=None, names=columns, skipfooter=0) tempdf[:5] # p为钓鱼页面，d为被黑页面，n为正常页面 tempdf[\u0026#39;flag\u0026#39;].unique() tempdf[\u0026#39;flag\u0026#39;].value_counts() # 查看正常页面对应的filename df1=tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;n\u0026#39;] df1.head() # 选择一个正常页面进行html内容解析 html = BeautifulSoup(open(\u0026#39;MaliciousWebpage/file1/\u0026#39;+\u0026#39;66178272dee70b26f1400bb5c2aea1ab\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;),\u0026#39;html.parser\u0026#39;, from_encoding=\u0026#39;utf-8\u0026#39;) # 获取最后20组非标签字符串，会自动去掉空白字符串，返回的是一个list list(html.stripped_strings)[-20:] # 由于在PaddleNLP进行文本分类时，我们需要构造的输入内容是一串连续的文字，因此这里要用到list和string的转化 # 将list转化为string print(\u0026#39;\u0026#39;.join(list(html.stripped_strings)[-20:])) n_page = tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;n\u0026#39;] # 对正常页面进行随机采样 n_page = n_page.sample(n=500) # 提取全部被黑页面样本 d_page = tempdf[tempdf[\u0026#39;flag\u0026#39;]==\u0026#39;d\u0026#39;] # 合并样本 train_page = pd.concat([n_page,d_page],axis=0) # 做一个乱序 train_page = train_page.sample(frac = 1) # 查看效果，确认数据集的样本准备完成 train_page.head(10) for filename in tqdm(train_page[\u0026#39;filename\u0026#39;]): # 这里要先做个判断，有的file_list里面的文件不存在 if os.path.exists(\u0026#39;MaliciousWebpage/file1/\u0026#39;+filename): # 读取文件，获取字符集 content = codecs.open(\u0026#39;MaliciousWebpage/file1/\u0026#39;+filename,\u0026#39;rb\u0026#39;).read() source_encoding = chardet.detect(content)[\u0026#39;encoding\u0026#39;] # 个别文件的source_encoding是None，这里要先进行筛选 if source_encoding is None: pass # 只对字符集是gb2312格式的文件尝试转码 elif source_encoding == \u0026#39;gb2312\u0026#39;: # 转码如果失败，就跳过该文件 try: content = content.decode(source_encoding).encode(\u0026#39;utf-8\u0026#39;) codecs.open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename,\u0026#39;wb\u0026#39;).write(content) except UnicodeDecodeError: print(filename + \u0026#34;读取失败\u0026#34;) pass # 字符集是utf-8格式的文件直接保存 elif source_encoding == \u0026#39;utf-8\u0026#39;: codecs.open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename,\u0026#39;wb\u0026#39;).write(content) else: pass else: pass for i, filename in enumerate(tqdm(train_page[\u0026#39;filename\u0026#39;])): # 这里要先做个判断，有的file_list里面的文件不存在 if os.path.exists(\u0026#39;TrainWebpage/file1/\u0026#39;+filename): # 读取文件，解析HTML页面 html = BeautifulSoup(open(\u0026#39;TrainWebpage/file1/\u0026#39;+filename, encoding=\u0026#34;utf-8\u0026#34;),\u0026#39;html.parser\u0026#39;, from_encoding=\u0026#39;utf-8\u0026#39;) text = \u0026#39;\u0026#39;.join(list(html.stripped_strings)[-20:]) # 去掉多余的换行符（部分数据最后解析结果为） text = text.replace(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;) text = text.replace(\u0026#34; \u0026#34;, \u0026#34;,\u0026#34;) # real_label = train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] if i % 5 == 0: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webtest.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webtest.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) elif i % 5 == 1: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webdev.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webdev.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) else: if train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;n\u0026#39;: with open(\u0026#34;webtrain.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;0\u0026#39; + \u0026#39;\\n\u0026#39;) elif train_page[\u0026#39;flag\u0026#39;][train_page[\u0026#39;filename\u0026#39;]==filename].values[0] == \u0026#39;d\u0026#39;: with open(\u0026#34;webtrain.txt\u0026#34;,\u0026#34;a+\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(text[-100:] + \u0026#39;\\t\u0026#39; + \u0026#39;1\u0026#39; + \u0026#39;\\n\u0026#39;) else: pass class MyDataset(paddle.io.Dataset): \u0026#34;\u0026#34;\u0026#34; 步骤一：继承 paddle.io.Dataset 类 \u0026#34;\u0026#34;\u0026#34; def __init__(self, data_path=\u0026#34;\u0026#34;, data_list=[]): \u0026#34;\u0026#34;\u0026#34; 步骤二：实现 __init__ 函数，初始化数据集，将样本和标签映射到列表中 \u0026#34;\u0026#34;\u0026#34; super().__init__() if data_list: self.data_list = data_list else: self.data_list = [] with open(data_path, encoding=\u0026#39;utf-8\u0026#39;) as f: for line in f: self.data_list.append(line.strip().split(\u0026#39;\\t\u0026#39;)) def __getitem__(self, index): \u0026#34;\u0026#34;\u0026#34; 步骤三：实现 __getitem__ 函数，定义指定 index 时如何获取数据，并返回单条数据（样本数据、对应的标签） \u0026#34;\u0026#34;\u0026#34; # 根据索引，从列表中取出一个图像 try: data = self.data_list[index] if len(data) == 2: content, label = data elif len(data) \u0026gt;= 2: label = data[-1] content = \u0026#39;\u0026#39;.join(data[0: -1]) print(f\u0026#34;fuck you: {data} index: {index}\u0026#34;) except Exception as err: print(f\u0026#34;阿西吧: {self.data_list[index]}， index: {index}\u0026#34;) label = int(label) return [content, label] def __len__(self): \u0026#34;\u0026#34;\u0026#34; 步骤四：实现 __len__ 函数，返回数据集的样本总数 \u0026#34;\u0026#34;\u0026#34; return len(self.data_list) def get_labels(self): return [0, 1] train_ds, dev_ds, test_ds = MyDataset(\u0026#39;webtrain.txt\u0026#39;), MyDataset(\u0026#39;webdev.txt\u0026#39;), MyDataset(\u0026#39;webtest.txt\u0026#39;) label_list = train_ds.get_labels() print(label_list) for i in range(10): print (train_ds[i]) import jieba dict_path = \u0026#39;webdict.txt\u0026#39; #创建数据字典，存放位置：webdict.txt。在生成之前先清空webdict.txt #在生成all_data.txt之前，首先将其清空 with open(dict_path, \u0026#39;w\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.seek(0) f.truncate() dict_set = set() train_data = open(\u0026#39;webtrain.txt\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) for data in train_data: seg = jieba.lcut(data[:-3]) for datas in seg: if datas != \u0026#34; \u0026#34;: dict_set.add(datas) dicts = open(dict_path,\u0026#39;w\u0026#39;, encoding=\u0026#34;utf-8\u0026#34;) dicts.write(\u0026#39;[PAD]\\n\u0026#39;) dicts.write(\u0026#39;[UNK]\\n\u0026#39;) for data in dict_set: dicts.write(data + \u0026#39;\\n\u0026#39;) dicts.close() # # 下载词汇表文件word_dict.txt，用于构造词-id映射关系。 # !wget https://paddlenlp.bj.bcebos.com/data/senta_word_dict.txt def load_vocab(vocab_file): \u0026#34;\u0026#34;\u0026#34;Loads a vocabulary file into a dictionary.\u0026#34;\u0026#34;\u0026#34; vocab = {} with open(vocab_file, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as reader: tokens = reader.readlines() for index, token in enumerate(tokens): token = token.rstrip(\u0026#34;\\n\u0026#34;).split(\u0026#34;\\t\u0026#34;)[0] vocab[token] = index return vocab # 加载词表 # vocab = load_vocab(\u0026#39;data/webdict.txt\u0026#39;) vocab = load_vocab(\u0026#39;./webdict.txt\u0026#39;) for k, v in vocab.items(): print(k, v) break def convert_example(example, vocab, unk_token_id=1, is_test=False): tokenizer = jieba \u0026#34;\u0026#34;\u0026#34; Builds model inputs from a sequence for sequence classification tasks. It use `jieba.cut` to tokenize text. Args: example(obj:`list[str]`): List of input data, containing text and label if it have label. vocab(obj:`dict`): The vocabulary. unk_token_id(obj:`int`, defaults to 1): The unknown token id. is_test(obj:`False`, defaults to `False`): Whether the example contains label or not. Returns: input_ids(obj:`list[int]`): The list of token ids.s valid_length(obj:`int`): The input sequence valid length. label(obj:`numpy.array`, data type of int64, optional): The input label if not is_test. \u0026#34;\u0026#34;\u0026#34; input_ids = [] # print(\u0026#34;example 是: \u0026#34;, example) if len(example) != 2: print(f\u0026#34;fuck you!: {example}\u0026#34;) for token in tokenizer.cut(example[0]): token_id = vocab.get(token, unk_token_id) input_ids.append(token_id) valid_length = np.array([len(input_ids)]) input_ids = np.array(input_ids, dtype=\u0026#34;int32\u0026#34;) if not is_test: label = np.array(example[-1], dtype=\u0026#34;int64\u0026#34;) return input_ids, valid_length, label else: return input_ids, valid_length # python中的偏函数partial，把一个函数的某些参数固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 trans_function = partial( convert_example, vocab=vocab, unk_token_id=vocab.get(\u0026#39;[UNK]\u0026#39;, 1), is_test=False) # 版本不匹配的兼容修改方式 from paddlenlp.datasets import MapDataset train_ds_new = MapDataset(train_ds) dev_ds_new = MapDataset(dev_ds) test_ds_new = MapDataset(test_ds) # train_ds_new.map(trans_function, lazy=True) def create_dataloader(dataset, trans_function=None, mode=\u0026#39;train\u0026#39;, batch_size=1, pad_token_id=0, batchify_fn=None): if trans_function: dataset = dataset.map(trans_function, lazy=True) # return_list 数据是否以list形式返回 # collate_fn 指定如何将样本列表组合为mini-batch数据。传给它参数需要是一个callable对象，需要实现对组建的batch的处理逻辑，并返回每个batch的数据。在这里传入的是`prepare_input`函数，对产生的数据进行pad操作，并返回实际长度等。 dataloader = paddle.io.DataLoader( dataset, return_list=True, batch_size=batch_size, collate_fn=batchify_fn) return dataloader # 将读入的数据batch化处理，便于模型batch化运算。 # batch中的每个句子将会padding到这个batch中的文本最大长度batch_max_seq_len。 # 当文本长度大于batch_max_seq时，将会截断到batch_max_seq_len；当文本长度小于batch_max_seq时，将会padding补齐到batch_max_seq_len. batchify_fn = lambda samples, fn=Tuple( Pad(axis=0, pad_val=vocab[\u0026#39;[PAD]\u0026#39;]), # input_ids Stack(dtype=\u0026#34;int64\u0026#34;), # seq len Stack(dtype=\u0026#34;int64\u0026#34;) # label ): [data for data in fn(samples)] train_loader = create_dataloader( train_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;train\u0026#39;, batchify_fn=batchify_fn) dev_loader = create_dataloader( dev_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;validation\u0026#39;, batchify_fn=batchify_fn) test_loader = create_dataloader( test_ds_new, trans_function=trans_function, batch_size=32, mode=\u0026#39;test\u0026#39;, batchify_fn=batchify_fn) class LSTMModel(nn.Layer): def __init__(self, vocab_size, num_classes, emb_dim=64, padding_idx=0, lstm_hidden_size=96, direction=\u0026#39;forward\u0026#39;, lstm_layers=2, dropout_rate=0, pooling_type=None, fc_hidden_size=48): super().__init__() # 首先将输入word id 查表后映射成 word embedding self.embedder = nn.Embedding( num_embeddings=vocab_size, embedding_dim=emb_dim, padding_idx=padding_idx) # 将word embedding经过LSTMEncoder变换到文本语义表征空间中 self.lstm_encoder = ppnlp.seq2vec.LSTMEncoder( emb_dim, lstm_hidden_size, num_layers=lstm_layers, direction=direction, dropout=dropout_rate, pooling_type=pooling_type) # LSTMEncoder.get_output_dim()方法可以获取经过encoder之后的文本表示hidden_size self.fc = nn.Linear(self.lstm_encoder.get_output_dim(), fc_hidden_size) # 最后的分类器 self.output_layer = nn.Linear(fc_hidden_size, num_classes) def forward(self, text, seq_len): # text shape: (batch_size, num_tokens) # print(\u0026#39;input :\u0026#39;, text.shape) # Shape: (batch_size, num_tokens, embedding_dim) embedded_text = self.embedder(text) # print(\u0026#39;after word-embeding:\u0026#39;, embedded_text.shape) # Shape: (batch_size, num_tokens, num_directions*lstm_hidden_size) # num_directions = 2 if direction is \u0026#39;bidirectional\u0026#39; else 1 text_repr = self.lstm_encoder(embedded_text, sequence_length=seq_len) # print(\u0026#39;after lstm:\u0026#39;, text_repr.shape) # Shape: (batch_size, fc_hidden_size) fc_out = paddle.tanh(self.fc(text_repr)) # print(\u0026#39;after Linear classifier:\u0026#39;, fc_out.shape) # Shape: (batch_size, num_classes) logits = self.output_layer(fc_out) # print(\u0026#39;output:\u0026#39;, logits.shape) # probs 分类概率值 probs = F.softmax(logits, axis=-1) # print(\u0026#39;output probability:\u0026#39;, probs.shape) return probs model= LSTMModel( len(vocab), len(label_list), direction=\u0026#39;bidirectional\u0026#39;, padding_idx=vocab[\u0026#39;[PAD]\u0026#39;]) model = paddle.Model(model) model optimizer = paddle.optimizer.Adam( parameters=model.parameters(), learning_rate=1e-4) loss = paddle.nn.CrossEntropyLoss() metric = paddle.metric.Accuracy() model.prepare(optimizer, loss, metric) # 设置visualdl路径 log_dir = \u0026#39;./visualdl\u0026#39; callback = paddle.callbacks.VisualDL(log_dir=log_dir) model.fit(train_loader, dev_loader, epochs=100, save_dir=\u0026#39;./checkpoints\u0026#39;, save_freq=5, callbacks=callback) results = model.evaluate(dev_loader) print(\u0026#34;Finally test acc: %.5f\u0026#34; % results[\u0026#39;acc\u0026#39;]) print(results) import random label_map = {0: \u0026#39;正常页面\u0026#39;, 1: \u0026#39;被黑页面\u0026#39;} results = model.predict(test_loader, batch_size=128)[0] predictions = [] for batch_probs in results: # 映射分类label idx = np.argmax(batch_probs, axis=-1) idx = idx.tolist() labels = [label_map[i] for i in idx] predictions.extend(labels) # 看看预测数据前5个样例分类结果 for idx, data in enumerate(test_ds.data_list[:10]): print(\u0026#39;Data: {} \\t Value: {} \\t Label: {}\u0026#39;.format(data[0], data[-1], predictions[idx])) 可视化 # python -m pip install visualdl -i https://mirror.baidu.com/pypi/simple visualdl.exe --logdir . "},{"id":51,"href":"/docs/programmer/net/elk%E5%9C%A8k8s%E4%B8%8A%E7%9A%84%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/","title":"Elk在k8s上的部署使用示例","section":"Net","content":"title: elk在k8s上的部署使用示例 date: 2023-09-24 23:01:41 categories: [k8s, elk] tags: [k8s, elk]\n--- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-config namespace: ops labels: k8s-app: filebeat data: filebeat.yml: |- filebeat.config: inputs: # Mounted `filebeat-inputs` configmap: path: ${path.config}/inputs.d/*.yml # Reload inputs configs as they change: reload.enabled: false modules: path: ${path.config}/modules.d/*.yml # Reload module configs as they change: reload.enabled: false output.elasticsearch: hosts: [\u0026#39;49.65.125.91:9200\u0026#39;] --- apiVersion: v1 kind: ConfigMap metadata: name: filebeat-inputs namespace: ops labels: k8s-app: filebeat data: kubernetes.yml: |- - type: docker containers.ids: - \u0026#34;*\u0026#34; processors: - add_kubernetes_metadata: in_cluster: true --- apiVersion: apps/v1 kind: DaemonSet metadata: name: filebeat namespace: ops labels: k8s-app: filebeat spec: selector: matchLabels: k8s-app: filebeat template: metadata: labels: k8s-app: filebeat spec: serviceAccountName: filebeat terminationGracePeriodSeconds: 30 containers: - name: filebeat image: elastic/filebeat:7.9.2 args: [ \u0026#34;-c\u0026#34;, \u0026#34;/etc/filebeat.yml\u0026#34;, \u0026#34;-e\u0026#34;, ] securityContext: runAsUser: 0 # If using Red Hat OpenShift uncomment this: #privileged: true resources: limits: memory: 200Mi requests: cpu: 100m memory: 100Mi volumeMounts: - name: config mountPath: /etc/filebeat.yml readOnly: true subPath: filebeat.yml - name: inputs mountPath: /usr/share/filebeat/inputs.d readOnly: true - name: data mountPath: /usr/share/filebeat/data - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true volumes: - name: config configMap: defaultMode: 0600 name: filebeat-config - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: inputs configMap: defaultMode: 0600 name: filebeat-inputs # data folder stores a registry of read status for all files, so we don\u0026#39;t send everything again on a Filebeat pod restart - name: data hostPath: path: /var/lib/filebeat-data type: DirectoryOrCreate --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: filebeat subjects: - kind: ServiceAccount name: filebeat namespace: ops roleRef: kind: ClusterRole name: filebeat apiGroup: rbac.authorization.k8s.io --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: filebeat labels: k8s-app: filebeat rules: - apiGroups: [\u0026#34;\u0026#34;] # \u0026#34;\u0026#34; indicates the core API group resources: - namespaces - pods verbs: - get - watch - list --- apiVersion: v1 kind: ServiceAccount metadata: name: filebeat namespace: ops labels: k8s-app: filebeat 将以上内容存储到 elk.yaml\nkubectl create namespace ops kubectl apply -f elk.yaml kubectl get pods -n ops "},{"id":52,"href":"/docs/programmer/net/nginx%E5%AE%9E%E7%94%A8%E9%85%8D%E7%BD%AE/","title":"Nginx实用配置","section":"Net","content":"title: nginx实用配置 date: 2023-09-24 23:01:41 categories: [nginx] tags: [nginx]\nfrom: 这里\nlocation / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } location /test_vul_id_1000003 { alias /home/test_vul_id_1000003; autoindex on; } location /test_vul_id_1000003 { root /home; autoindex on; } 非以上配置访问404原因 # location /test_vul_id_1000003 { root /home/test_vul_id_1000003; autoindex on; } 如以上配置, nginx 配置文件会将 root 加上 以上的 localtion , 导致访问时实际定位是 /home/test_vul_id_1000003/test_vul_id_1000003 所以就 404 了\n生效命令 # nginx -t nginx -s reload service nginx restart "},{"id":53,"href":"/docs/programmer/software/bash/","title":"Bash","section":"Software","content":" Bash # Auther: Ian\n自动补全 # linux中使用bash_completion工具进行自动不全，在某些发行版或者版本中make或者git没有Tab自动补全，这时在Github上找一个bash_completion文件放在相应位置就可以了。\nsudo cp bash_completion /usr/share/bash-completion/bash_completion source /usr/share/bash-completion/bash_completion Powershell # 命令历史存储在: C:\\Users\\{USERNAME}\\AppData\\Roaming\\Microsoft\\Windows\\PowerShell\\PSReadLine下 ConsoleHost_history.txt文件\n"},{"id":54,"href":"/docs/programmer/software/freebsd/","title":"Freebsd","section":"Software","content":" FreeBSD # 桌面 # 换源 pkg install xorg xfce echo \u0026lsquo;dbus_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf echo \u0026ldquo;/usr/local/etc/xdg/xfce4/xinitrc\u0026rdquo; \u0026gt; ~/.xinitrc startx 登录界面 # pkg install slim slim-themes echo \u0026lsquo;slim_enable=\u0026ldquo;YES\u0026rdquo;\u0026rsquo; \u0026raquo; /etc/rc.conf vbox(没测试) # pkg install virtualbox-ose-additions 向/etc/rc.conf写入 vboxguest_enable=\u0026#34;YES\u0026#34; vboxservice_enable=\u0026#34;YES\u0026#34; 仅供参考看这里 因为vbox显卡太弱安装了vmware后就一直没用回过vbox,我还没测试过\nvmware # pkg install open-vm-tools xf86-video-vmware xf86-input-vmmouse 继续向/etc/rc.conf中写入 hald_enable=\u0026#34;YES\u0026#34; moused_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmblock_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmhgfs_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmmemctl_enable=\u0026#34;YES\u0026#34; # vmware_guest_vmxnet_enable=\u0026#34;YES\u0026#34; # vmware_guest_enable=\u0026#34;YES\u0026#34; 下面注释掉的是因为在测试中如果打开的话会有各种问题\u0026hellip;.尤其鼠标 其他可见这里参考 =\u0026gt; 该Blog仅供参考, 这里面的东西很多都是有问题的.\n换源 # mkdir -p /usr/local/etc/pkg/repos vim /usr/local/etc/pkg/repos/bjtu.conf bjtu: { url: \u0026#34;pkg+http://mirror.bjtu.edu.cn/reverse/freebsd-pkg/${ABI}/quarterly\u0026#34;, mirror_type: \u0026#34;srv\u0026#34;, signature_type: \u0026#34;none\u0026#34;, fingerprints: \u0026#34;/usr/share/keys/pkg\u0026#34;, enabled: yes } FreeBSD: { enabled: no } pkg update 附录 # Ian 整理的各个软件换源Blog\n"},{"id":55,"href":"/docs/programmer/software/gitbook/","title":"Gitbook","section":"Software","content":" Gitbook # Author: Ian\n安装 # 官方文档 Github Gitbook 打造的 Gitbook 说明文档 使用npm进行安装, 安装npm (v4.0.0 and above is recommended) npm install gitbook-cli -g 需要sudo权限 实际在执行gitbook -V后才算是安装完成 问题 # TypeError: cb.apply is not a function # npm 安装软件不出点儿问题貌似都不是很合适, 该问题代码级问题是因为在适配某些可能本机上并没有安装的npm版本时写了bug，导致执行出错.\n所以注释掉相关代码即可，或者直接删除。删除的好处是不会因为编辑器的原因触发npm的某些缩进问题。\n62. // fs.stat = statFix(fs.stat) 63. // fs.fstat = statFix(fs.fstat) 64. // fs.lstat = statFix(fs.lstat) 固然可以通过安装相匹配版本进行适配，不过\u0026hellip;Ian怕导致本机上的hexo再出现版本不兼容的问题。 使用 # 功能 示例 个人使用习惯(Ian) 新建book gitbook init gitbook init gitbooks/Architecture 编译和运行服务 gitbook serve 编译 gitbook serve pdf # 参考自 码谱\n安装calibre sudo apt install calibre gitbook pdf \u0026lt;gitbook-folder-location\u0026gt; \u0026lt;pdf-location\u0026gt;.pdf 新版的gitbook，官方已经不支持导出pdf等电子书格式，官方的解读如下：\nPDF and other ebook formats exports ？ The new version of GitBook no longer supports exporting to PDF and other ebooks format. A lot of rich-content does not translate well from the Web to PDF. GitBook will expose a developer API for people to consume and extend their content. It is not excluded that someone build a PDF export tool using the API, but it will not be officially supported. See the section about offline access if this is the part you cared about. 放到Blog中 # hexo 为例\n将gitbook作为自项目添加到当前项目中 git submodule add git@github.com:IanVzs/book_architecture.git gitbooks/book_architecture build gitbook和hexo 再将两者静态文件放在一起 cd gitbooks/book_architecture/ \u0026amp;\u0026amp; gitbook build hexo build cp -r gitbooks/book_architecture/_book/ public/book_architecture 使用https://ianvzs.github.io | localhost:4000访问原Blog，增加uri/book_architecture访问gitbook "},{"id":56,"href":"/docs/programmer/software/markdown/","title":"Markdown","section":"Software","content":" Markdown # 折叠 # 文本字体速查表 # 参考自: csdn 王大雄\n高亮 # 1. 使用\u0026#34;`\u0026#34;双引, eg: `{要高亮的文本}`; 2. 使用\u0026#34;```\u0026#34; 跨行, eg:```\\n{要高亮的文本}\\n```; 3. HTML \u0026lt;mark\u0026gt;双引, eg: \u0026lt;mark\u0026gt;{要高亮的文本}\u0026lt;mark\u0026gt; 要高亮的文本 见下 要高亮的文本 要高亮的文本 "},{"id":57,"href":"/docs/programmer/software/npm/","title":"Npm","section":"Software","content":" npm # 树莓派 # 官网下载 树莓派4b 选择ARMv8之前的树莓派型号选择ARMv7 配置PATH 向/usr/local/bin/下建立node软链 export PATH=\u0026#34;~/node-v16.14.0-linux-arm64/bin:$PATH\u0026#34; #sudo ln -s ~/node-v16.14.0-linux-arm64/bin/node /usr/bin/node Windows下wsl2 安装 npm \u0026amp;\u0026amp; nodejs # 摘抄自微软说明文档\n安装nvm (Node 版本管理器) 国内网可能有问题, 下载下保存直接bash install.sh就可安装. curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash command -v nvm验证是否安装成功,它会自行添加.bashrc需重启bash nvm ls查看Node版本 nvm install --lts即可安装lts版, nvm install node安装最新版 会安装这么多东西 -\u0026gt; v16.13.2 default -\u0026gt; lts/* (-\u0026gt; v16.13.2) iojs -\u0026gt; N/A (default) unstable -\u0026gt; N/A (default) node -\u0026gt; stable (-\u0026gt; v16.13.2) (default) stable -\u0026gt; 16.13 (-\u0026gt; v16.13.2) (default) lts/* -\u0026gt; lts/gallium (-\u0026gt; v16.13.2) lts/argon -\u0026gt; v4.9.1 (-\u0026gt; N/A) lts/boron -\u0026gt; v6.17.1 (-\u0026gt; N/A) lts/carbon -\u0026gt; v8.17.0 (-\u0026gt; N/A) lts/dubnium -\u0026gt; v10.24.1 (-\u0026gt; N/A) lts/erbium -\u0026gt; v12.22.9 (-\u0026gt; N/A) lts/fermium -\u0026gt; v14.18.3 (-\u0026gt; N/A) lts/gallium -\u0026gt; v16.13.2 可以了 或者官网下载不过在wsl2里node好使唤,npm无效(只有0K)\u0026hellip; "},{"id":58,"href":"/docs/programmer/software/readme/","title":"Readme","section":"Software","content":" 软件篇 # 主要记录一些工具、软件的Initialization，或者实用插件的安装等问题\n"},{"id":59,"href":"/docs/programmer/software/vim/","title":"Vim","section":"Software","content":" Vim 使用 # Auther: Ian\n注释 # # 注释 1， 12s/^/#/g --- # 取消注释 1， 12s/^#//g 其实 是vim中的 :s替换命令… 下方解释\n或者，使用列编辑的模式:\nv、选择区域、ctrl q置行首、I插入#、Esc应用到全列 ctrl v、I、#、Esc 因为有的ctrl q或者ctrl v 不能用…… 取消，即使用上述方法选中行首，删除第一个字节即可了 替换 # :s/oldWords/newWords/g g : 代表当前光标所在行。\n由此可知: # ^表行首标识符。 /^/表示行首的空字符。 而取消注释中的/^#/即表示行首的#，被//空字符所替换。\n查找高亮 # set hlsearch set nohlsearch 分屏 # 实现 # 在外部使用-o or -O参数 内部split or vsplit 操作 # 移动光标 Ctrl + w hjkl 移动分区Ctrl + w HJKL 统一高度Ctrl + w = 改变高度Ctrl + w +- # and less 阅读器~~~ 因为经常读大文件发现了这两个的无敌好处——快。\n使用命令 # cat cat -b # 查看且标注行号 -n # 同上，但也会显示空行行号 more # - space 向下翻页 # - Ctrl+F 同上 # - b back 返回一页显示 # - Ctrl+B 同上 # - Enter 向下n行,默认1 # - = 输出当前行号 # - v 调用vi/vim # - !命令 调用shell 执行命令 # - q 退出 less Vi \u0026amp;\u0026amp; Vim # 三个模式:\n命令模式 插入模式 Ex模式 para : 说明 o : 在当前行下面插入新空白行 dd : 删除当前一行。 u : 撤销一步操作 yy : 当前行-\u0026gt;缓冲区 p : 缓冲区-\u0026gt;光标之后插入 n+ y 当前及接下来n行-\u0026gt;缓冲区 r : 替换当前字符 / : 查找关键字——支持汉字呐！难得 n : 上命令下切换 next Ex下: # set number: 显示行号。（不过我已经改了配置文件，默认显示） ！+命令 代理执行系统命令。如ls cd sh 挂下编辑 显示系统命令行。 ctrl+d返回（PS:命令行下，这是关闭虚拟终端快捷键） tip:tail head 等查看命令可以和 \u0026raquo; 命令合用，将文件的首行或者结尾字添加到另一个文档～ "},{"id":60,"href":"/docs/shortcodes/buttons/","title":"Buttons","section":"Shortcodes","content":" Buttons # Buttons are styled links that can lead to local page or external link.\nExample # {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}} Get Home Contribute "},{"id":61,"href":"/docs/shortcodes/columns/","title":"Columns","section":"Shortcodes","content":" Columns # Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example # Left Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nMid Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!\nRight Content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":62,"href":"/docs/shortcodes/details/","title":"Details","section":"Shortcodes","content":" Details # Details shortcode is a helper for details html5 element. It is going to replace expand shortcode.\nExample # {{\u0026lt; details \u0026#34;Title\u0026#34; [open] \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} {{\u0026lt; details title=\u0026#34;Title\u0026#34; open=true \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} Title Markdown content # Lorem markdownum insigne\u0026hellip;\n"},{"id":63,"href":"/docs/shortcodes/expand/","title":"Expand","section":"Shortcodes","content":" Expand # Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample # Default # {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}} Expand ↕ Markdown content # Lorem markdownum insigne\u0026hellip;\nWith Custom Label # {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}} Custom Label ... Markdown content # Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":64,"href":"/docs/shortcodes/hints/","title":"Hints","section":"Shortcodes","content":" Hints # Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example # Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa "},{"id":65,"href":"/docs/shortcodes/section/","title":"Section","section":"Shortcodes","content":" Section # Section renders pages in section as definition list, using title and description.\nExample # {{\u0026lt; section \u0026gt;}} First Page First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Second Page Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. "},{"id":66,"href":"/docs/shortcodes/section/first-page/","title":"First Page","section":"Section","content":" First page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"},{"id":67,"href":"/docs/shortcodes/section/second-page/","title":"Second Page","section":"Section","content":" Second Page # Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"},{"id":68,"href":"/docs/shortcodes/tabs/","title":"Tabs","section":"Shortcodes","content":" Tabs # Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example # MacOS MacOS # This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux # This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows # This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n"},{"id":69,"href":"/docs/programmer/demo_test_some/","title":"Demo Test项目中的一些东西","section":"程序员笔记","content":"\nyolov5 # 使用自己的素材进行目标识别训练\n之前使用个位数样本识别Vmon结果败的一塌糊涂 现在用来检测卡片倒是得心应手 9个训练卡片,准确率可以到50多,自我感觉还行 使用方法: 在此\n"},{"id":70,"href":"/docs/programmer/base/tip_dgraph/","title":"Dgraph","section":"Base","content":"\n问题 # 在新手村的时候使用dgraph/standalone 但此时(2021-12-8 18:30:23)文档使用的版本为dgraph/standalone:v21.03.2但是这个版本的Ratel UI不工作\u0026hellip;. 导致hello 不了 world很是难受\n结果换了dgraph/standalone:v20.11.3好了诶.\nsudo docker run --rm -it -p \u0026#34;8080:8080\u0026#34; -p \u0026#34;9080:9080\u0026#34; -p \u0026#34;8000:8000\u0026#34; -v ~/dgraph:/dgraph \u0026#34;dgraph/standalone:v20.11.3\u0026#34; http://127.0.0.1:8000 "},{"id":71,"href":"/docs/programmer/langs/notespython/","title":"Python笔记(notes of Python)","section":"Langs","content":"author:Ian\n彻底摆脱to_dict和from_dict # 使用 pydantic # BaseModel类型支持:\nb = BattleAxiePositionInfo.parse_obj(DICT_DATA) b.json() b.dict() parse_file parse_raw from pydantic import BaseModel class PositionInfo(BaseModel): error: int = -1 # 收集错误 none: int = 0 # 还没开始 clicked: int = 1 # 在client 赋此值 done: int = 2 # 在server 赋此值 xy: List[int] = [0, 0] status: int = 0 # clicked or done or none or error class BattleAxiePositionInfo(BaseModel): our: List[PositionInfo] = [PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo()] enemy: List[PositionInfo] = [PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo(), PositionInfo()] pp = BattleAxiePositionInfo() print(f\u0026#34;pp json: {pp.json()}\u0026#34;) dict_pp = pp.dict() pp = BattleAxiePositionInfo.parse_obj(dict_pp) pp json: {\u0026ldquo;our\u0026rdquo;: [{\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}], \u0026ldquo;enemy\u0026rdquo;: [{\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}, {\u0026ldquo;error\u0026rdquo;: -1, \u0026ldquo;none\u0026rdquo;: 0, \u0026ldquo;clicked\u0026rdquo;: 1, \u0026ldquo;done\u0026rdquo;: 2, \u0026ldquo;xy\u0026rdquo;: [0, 0], \u0026ldquo;status\u0026rdquo;: 0}]}\n多个类属性一次赋值 # No:\nself.a = a self.b = b Yes:\nself.__dict__.update({\u0026#34;a\u0026#34;: a, \u0026#34;b\u0026#34;: b}) 列表表达式 二维数组边一维 取字典内变一维 # knowninfo = {\u0026#39;axie_id3\u0026#39;: {\u0026#39;init_cards\u0026#39;: [\u0026#39;Sunder Claw\u0026#39;, \u0026#39;October Treat\u0026#39;, \u0026#39;Gas Unleash\u0026#39;, \u0026#39;Disguise\u0026#39;], \u0026#39;sort\u0026#39;: 4}} [vv for _,v in knowninfo.items() for vv in v[\u0026#34;init_cards\u0026#34;]] # [\u0026#39;Sunder Claw\u0026#39;, \u0026#39;October Treat\u0026#39;, \u0026#39;Gas Unleash\u0026#39;, \u0026#39;Disguise\u0026#39;] PiP Not Found Issue # 使用pip安装某包时， 提示让更新， 按提示操作更新没效果没反应再用就提示ModuleNotFoundError: No module named 'pip' (ˉ▽ˉ；)\u0026hellip;\nModuleNotFoundError: No module named \u0026lsquo;pip\u0026rsquo; # 升级PiP时出现问题可由下方命令修复 # python -m ensurepip python -m pip install --upgrade pip SSL校验 # 安装EasyOCR时, reader = easyocr.Reader(['ch_sim','en']) 下载到接近90,结果报错了\u0026hellip;. 估计是SSL问题加入以下两条,不知如何.\nimport ssl ssl._create_default_https_context = ssl._create_unverified_context from http.client To revert to the previous, unverified, behavior ssl._create_unverified_context() can be passed to the context parameter.\n使用国内镜像下载Python # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) # 一键更新pip 包资源(利用管道grep传输查询到的需要更新包名，传输到install命令) pip3 freeze --local | grep -v \u0026#39;^\\-e\u0026#39; | cut -d = -f 1 | xargs -n1 pip3 install -U # 权限不够的话就在`pip3 install` 之前加`sudo`反正我不习惯用`root` 声明参数类型 # python3 在定义函数的时候可以声明函数类型啦：虽然不做限制，但作为label还是蛮好的。\nimport io def add(x:int, y:int) -\u0026gt; int: return x + y def write(f: io.BytesIO, data: bytes) -\u0026gt; bool: try: f.write(data) except IOError: return False else: return True 终于不会之后写的忘了，要调用函数还得看半天这个函数应该怎么用…\n时间处理 # 以下可以做周、月的加减处理 relativedelta examples Let’s begin our trip:\nfrom datetime import *; from dateutil.relativedelta import * import calendar Store some values: # NOW = datetime.now() TODAY = date.today() NOW datetime.datetime(2003, 9, 17, 20, 54, 47, 282310)\nTODAY datetime.date(2003, 9, 17)\nNext month # NOW+relativedelta(months=+1)\ndatetime.datetime(2003, 10, 17, 20, 54, 47, 282310) 合并字典 # a = {} b = {\u0026#39;a\u0026#39;: 1} c = {**a, **b} key重复b中覆盖a, 否则单纯合并。\n聊胜于无的小玩意 preety tools # 彩色输出 # 模块名儿忘了，以后贴2019.03.01 03:08 one minute later: pip3 install ansicolors\nfrom colors import red, green, blue print(red(\u0026#39;This is red\u0026#39;)) print(green(\u0026#39;This is green\u0026#39;)) print(blue(\u0026#39;This is blue\u0026#39;)) from colors import color for i in range(256): print(color(\u0026#39;Color #%d\u0026#39; % i, fg=i)) 以上程序只能写在.py文件中,运行，而不能在…‘偷懒模式‘中。\nPython3 ThreadPoolExecutor 线程池内库 # 在python3之后不久，有关线程池的使用就被集成到内库之中。 from concurrent.futures import ThreadPoolExecutor 使用方法：\nThreadPoolExecutor(max_workers=12) # 设置线程池大小 .submit(func_name, (para)) # 提交任务 .done() # 查看任务是否完成 .cancel() # 没有被放入线程池中才能生效 .result() # 获取该任务返回值 from concurrent.futures import as_completed # 用于取出所有任务结果，省去一直用.done去查看的繁琐。但该方法 # 是一个生成器，所以任务未完成会阻塞。 还有 wait map 等用法就去看文档吧。 安装错误？ # 居然有pip3 install XX的错误…这也是因为有旧版pip3存留。需要\n$bash -d pip3 $bash -r pip3 来清理shell中旧版pip缓存。\nIDE? # 其实要不要IDE都无所为，因为本就是脚本，要IDE只能说打开一个陌生项目查看时能够跳转函数。至于vim大概不能跳转吧，毕竟跳转需要把文件都加载才能实现。emm 来来，IDE的话就PyCharm除了编程页面颜色难看之外其他功能都不错，另外不支持中文路径，不过应该不是由于Python语言造成的，因为蟒蛇脚本是可以在中文路径下运行didate:2018年5月28日17点16分\nprint语句： 含有自动换行，所以要想不换行的话需要在结尾加一个\u0026quot;,\u0026ldquo;如： # for i in range(0,5): print i, 而Python3版本则应该也可以 print(a,b,c);然而Python2.7不行\n根据字典中值大小排列： # sorted(dict2.iteritems(),key=lambda item:item[1],reverse=True) # item[0]即根据键来排列[1]为根据对应值 format：如: # print('my name is{0},and my age is{1}'.format('song',18)) or: # url = 'http://www.google.com/page={}/' newsurl = url.format(i) # 旋即其后内容则代替{}位置 另，在{a}{b}{c}可通過format(a=1,b=2,c=3)來賦值\nBeautifulSoup # select语句：在内容前加\u0026rsquo;#\u0026lsquo;可以获得其内容，如： # soup.select('artibodyTitle')[0].text select().contents \u0026quot;\u0026quot;\u0026quot; 把标签变成不同list，同List中的不同元素 然后用[0]可取得第一个元素内容，而不与后方的内容合到一起 *.strip()可将取出的‘\\t\\t’移除 \u0026quot;\u0026quot;\u0026quot; .select('time-source span a') # 从time-source中的\u0026lt;span下\u0026lt;a下取得内容e .select('.productPrice')[0].text # 獲取class=\u0026quot;productPrice\u0026quot;下價格內容 datetime字符串转时间 时间转字符串: # from datetime import datetime dt = datetime.strptime(timesource,'%Y年%m月%d日%H:%M')(****年*月*日*22:03) dt.strftime('%Y-%m-%d') 保存數據到xlsx，sqlite3、csv： # .to_excel('name.xlsx')：输出为excle文件 import sqlite3 #保存到数据库 with sqlite3.connect('name.sqlite') as db: df.to_sql('name',con = db) 从数据库取出 # with sqlite3.connect('name.sqlite') as db: df2 = pandas.read_sql_query('SELECT' * FROM name',con = db) 類型錯誤 TypeError: a bytes-like object is required, not \u0026lsquo;str\u0026rsquo; # csv_file = open(\u0026quot;rent.csv\u0026quot;,\u0026quot;wb\u0026quot;) csv_writer = csv.writer(csv_file, delimiter=',') #创建writer对象，指定文件与分隔符 writer.writerow(['title', 'summary', 'year', 'id', 'count', 'link']) Python2.7 轉到 3.5下時提示由此錯誤，代碼爲\n原因，解決方法： # 因爲Python3.5 對於str與bytes類型區分變得敏感，所以原本在2.7下正常的代碼不能正常運行。 雖然，利用str.encode() 或者 str = bytes(str, encoding = 'utf-8')可以轉換格式 然而錯誤依然有……解決辦法則是放棄論壇裏的說法，找到官網Demo 更改如下： # csvfile = open(\u0026#39;goodsList.csv\u0026#39;, \u0026#39;w\u0026#39;, newline=\u0026#39;\u0026#39;) spamwriter = csv.writer(csvfile, delimiter=\u0026#39;,\u0026#39;) spamwriter.writerow([productTitle, productPrice, productShop]) 細節在於，在打開文件的時候去除wb裏面的b即不用二進制模式打開。\nImage下： # 获取图像分辨率：\nim = Image.open(0.0) width = im.size[0] height = im.size[1] Pandas: # box = pd.read_csv(\u0026#34;filename.csv, index_col=\u0026#34;Date\u0026#34;, parse_dates=Ture) #读入文件，讲Date作为日期 box.columns = [\u0026#39;\u0026#39;,\u0026#39;\u0026#39;] # 更改列名 box[\u0026#39;new\u0026#39;] = box[\u0026#39;1\u0026#39;]+box[\u0026#39;2\u0026#39;] # 新增一列为1与2之和 box.resample(\u0026#39;d\u0026#39;, \u0026#39;sum\u0026#39;) # 重新按照‘d’:每天，进行采样 方式为取和(\u0026#39;w\u0026#39;,\u0026#39;sum\u0026#39;)所有数据在一周内进行取和 闲语： # while True与while 1的区别： # 在Python2 中，循环判断一亿次，我的小电脑的执行速度是\nwhile one: 9.97739481926 while_true: 18.8063299656 while 1 以压倒性胜利。 到了Python3中，则成了\nwhile one: 16.101972927001043 while_true: 16.25536527499935 嗯，不错，不分伯仲——个鬼啊。整体变差了好吧。0.0 原因待明。\nPython 小记 📖 # 先贴一个客观的教程文档网站http://www.runoob.com/python/python-tutorial.html\nWindows 下添加环境变量，CMD中Python2 与Python3 共存 # Windows 下 把python2 路径加入到环境变量中，再修改python2.exe可以和python3区分方便在CMD中调用，但代价就是经常命令报错……\n不过也可以使用py -2来区分，所以还是不改名字了吧 Windows 下 用py -2 -m pip install ***以及py -3 -m pip install ***来区分安装到python2 或者 python3.\n变量 # 类下直接定义的变量可以继承，然而并不能被自己的函数所调用，意义不明…\n被继承的类可以调用继承类中定义的self.* 变量，俺认为这是因为它们在实例时都被当成了self 本身。另外，优先调用自己中的self变量，没有，才会去被继承类中去查找（先后顺序可得前方解答）。\n变换数据类型 # Python 在从服务器接收或者发送数据时需要字符类型转换，\u0026lsquo;\u0026lsquo;\u0026lsquo;struct\u0026rsquo;\u0026lsquo;\u0026lsquo;便是为此而工作\nstruct.pack # import struct a = 20 b = 400 str = struct.pack(\u0026#34;ii\u0026#34;, a, b) #转换后的str虽然是字符串类型，但相当于其他语言中的字节流（字节数组），可以在网络 #上传输 print \u0026#39;length:\u0026#39;, len(str) print str print repr(str) \u0026mdash;- result length: 8 \u0026gt; #\u0026mdash;-这里是乱码 \u0026lsquo;/x14/x00/x00/x00/x90/x01/x00/x00\u0026rsquo;\n格式符”i”表示转换为int，’ii’表示有两个int变量。进行转换后的结果长度为8个字节（int类型占用4个字节，两个int为8个字节），可以看到输出的结果是乱码，因为结果是二进制数据，所以显示为乱码。可以使用python的内置函数repr来获取可识别的字符串，其中十六进制的0x00000014, 0x00001009分别表示20和400。\nstruct.unpack # str = struct.pack(\u0026#34;ii\u0026#34;, 20, 400) a1, a2 = struct.unpack(\u0026#34;ii\u0026#34;, str) print \u0026#39;a1:\u0026#39;, a1 print \u0026#39;a2:\u0026#39;, a2 \u0026mdash;- result: a1: 20 a2: 400\nstruct.unpack做的工作刚好与struct.pack相反，用于将字节流转换成python数据类型。它的函数原型为：struct.unpack(fmt, string)，该函数返回一个元组。\nstruct.calcsize # struct.calcsize(\u0026#39;i\u0026#39;) struct.calcsize(\u0026#39;ii\u0026#39;) struct.calcsize(\u0026#39;iic\u0026#39;) struct.calcsize(\u0026#39;iicd\u0026#39;) 4 8 9 24\nstruct.calcsize用于计算格式字符串所对应的结果的长度，如：struct.calcsize(‘ii’)，返回8。因为两个int类型所占用的长度是8个字节。\nstruct.pack_into, struct.unpack_from # import struct from ctypes import create_string_buffer buf = create_string_buffer(12) print repr(buf.raw) struct.pack_into(\u0026#34;iii\u0026#34;, buf, 0, 1, 2, -1) print repr(buf.raw) print struct.unpack_from(\u0026#39;iii\u0026#39;, buf, 0) \u0026mdash;- result \u0026rsquo;/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00/x00\u0026rsquo; \u0026rsquo;/x01/x00/x00/x00/x02/x00/x00/x00/xff/xff/xff/xff\u0026rsquo; (1, 2, -1)\nPython3 # 在Python3中，转换字符串时，不能直接pack('8s', 'i am str'), 需要将字符串转换成二进制所以在语法中标记pack('8s', b'i am str')使用'b'来进行标记\n以上来自Darkbull 这是转贴地址，不知道为什么我看的转贴挂的原帖地址失效了 😰\n一不小心发现的语法 # py2.7\nwhile 'a' in a or b: break # 没错，意思就是如果a或者是b包含‘a’的话… * 与 ** 方法: # 呃，原来*在MarkDown里面是斜体的意思啊——需要斜体显示的前后各一个星号\ndef a(* a, **b): balabala 这里的*a， a在函数中被赋值为一个元组，b被赋值为一个字典。所以在调用的时候嘞，只能把能往一个元组里塞的放在前面，而能够生成字典的放在后面\na(1,2,3,4,5,6,7,8,9,a:'a',b:1,c:'nihao') 就像这么一样来调用。 另外，def a()函数中还能在前方再新加一个输入\ndef aa(jiushishuowo, *a, **b): pass 这样的话，那么在调用的时候第一个逗号前面的内容会赋值给它。over，回去拿快递了~~~\n🐶 年假前再来补充一下：约定名*args, **kwargs\n获取文件路径 # path = os.path.abspath(os.path.dirname(__file__)) # 获取当前运行文件的路径。需在本地有此文件，在命令行中出错 for root, subdirs, files in os.walk(path): # 遍历所有path下文件 path为要遍历的路径 同获取路径 # os.path.abspath('./') os.path.abspath('Deskop') os.path.abspath('Deskop') + os.path.sep \u0026lsquo;C:\\Users\\Administrator\u0026rsquo;\n\u0026lsquo;C:\\Users\\Administrator\\Deskop\u0026rsquo;\n\u0026lsquo;C:\\Users\\Administrator\\Deskop\\\u0026rsquo;\n获取指定目录下所有文件名列表 # os.listdir('D\\IFData') _dict_ # class Province: country = 'China' def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print 'func' print Province.__dict__ # 类输出 obj1 = Province('HuBei', 100) print obj1.__dict__ # 对象1 obj2 = Province('hulala', 3888) print obj2.__dict__ # 对象2 {'country': 'China', '__module__': '__main__', 'func': \u0026lt;function func at 0x049EF470\u0026gt;, '__init__': \u0026lt;function __init__ at 0x049EF4F0\u0026gt;, '__doc__': None}\n{'count': 100, 'name': 'HuBei'}\n{'count': 3888, 'name': 'hulala'}\n类输出的是全局的函数，变量等信息。 对象输出的只是对象拥有的普通变量而已\n呃(⊙﹏⊙)，等下再去拿吧… 差点忘了说，这个__dict__与字典相配合来回赋值简直舒服… 步骤为：将某个变量=一个类（数据类（就是能够a.b这么调用的数值））然后这个变量就能a.b的这么使用了。 而后也能通过a.dict（这是一个字典）再将所需要的数值取出来，转赋值为别的东西。 反正我是用到了… 在想要实现一个函数来保存一个变量的某些属性的时候。（呃(⊙﹏⊙)用爱去理解我所描述的场合吧。）\nIF ELSE # # 执行时会将IF前面整个表达式作为判断结果后的执行对象， # 而不是仅仅替换某一个数字或者变量。 即 下方表达式运算结果 # 不是 `4` 和 `5` 而是如下所示 a = 1 + 3 if 1 == 2 else 2 + 1 a a = 1 + 3 if 1 == 1 else 2 + 1 a 3\n4\nPython 2 中的object新式类和经典类 # # 作者：邹冲 # 链接：https://www.zhihu.com/question/19754936/answer/202650790 class A: def foo(self): print('called A.foo()') class B(A): pass class C(A): def foo(self): print('called C.foo()') class D(B, C): pass if __name__ == '__main__': d = D() d.foo() B、C 是 A 的子类，D 多继承了 B、C 两个类，其中 C 重写了 A 中的 foo() 方法。\n如果 A 是经典类（如上代码），当调用 D 的实例的 foo() 方法时，Python 会按照深度优先的方法去搜索 foo() ，路径是 B-A-C ，执行的是 A 中的 foo() ；\n如果 A 是新式类，当调用 D 的实例的 foo() 方法时，Python 会按照广度优先的方法去搜索 foo() ，路径是 B-C-A ，执行的是 C 中的 foo() 。\n因为 D 是直接继承 C 的，从逻辑上说，执行 C 中的 foo() 更加合理，因此新式类对多继承的处理更为合乎逻辑。\n在 Python 3.x 中的新式类貌似已经兼容了经典类，无论 A 是否继承 object 类， D 实例中的 foo() 都会执行 C 中的 foo() 。但是在 Python 2.7 中这种差异仍然存在，因此还是推荐使用新式类，要继承 object 类。\n.items() # 一个字典 a，其a.items()为将每对对应值组为一个元组。即使键值也为一个字典也是将此字典作为元组元素。(￣▽￣)\u0026rdquo; emm\nQueue # 队列，先进先出型。可存数字、字符…嘛，Python里啥都一样。所以啥都能存。用于事件按顺序执行。示例如~：\nimport Queue mqueue = Queue.Queue(maxsize = 3) mqueue.put(10) mqueue.put(15) mqueue.put(12) # 此时如果再往里存呢，就会卡住… 持续等待有空位置 # 所以 mqueue.get() #取出第一个存入 mqueue.put('14sas4') #继续存 ## 在接触的项目中，是借用字典，来将处理函数作为Value，将Keys，put到队 列中，再进行取出执行。 如果队列中没有数值之后再get也会卡住…… 所以以下东西就显得比较重要了：\nseries和dataframe # 先贴来源：http://blog.csdn.net/ly_ysys629/article/details/54944153\n属性 # series ：.index, .values, .name, .index.name dataframe ：.columns, .index, .values series: # 一组数组（列表或元组），series除了一组数据外还包括一组索引（即只有行索引），索引可自行定义也可利用Series(),自动生成索引;\ndataframe: # 是表格型数据，既有行索引又有列索引，每列数据可以为不同类型数据（数值、字符串、布尔型值），可利用DataFrame（其他数据，dataframe属性)指定dataframe的属性创建dataframe。\n实例 # series # #创建series import pandas as pd obj_list=[1,2,3,4] obj_tuple=(4,5,6,7) obj_dict={'a':[1,2],'b':[2,3],'c':[3,4],'d':[4,5]} obj_series_list=pd.Series(obj_list)#通过列表创建series obj_series_tuple=pd.Series(obj_tuple,index=list('abcd')) #通过元组创建series obj_series_dict=pd.Series(obj_dict)#通过字典创建series #定义属性 obj_series_list.index.name='zimu' obj_series_list.name='data' print \u0026quot;#通过列表创建series\u0026quot; print obj_series_list print \u0026quot;#通过元组创建series\u0026quot; print obj_series_tuple print \u0026quot;#通过字典创建series\u0026quot; print obj_series_dict #显示series类型及属性 print type(obj_series_list),obj_series_list.dtype print obj_series_list.index,obj_series_list.index.name print obj_series_list.values,obj_series_list.name #通过列表创建series\nzimu\n0 1\n1 2\n2 3\n3 4\nName: data, dtype: int64\n#通过元组创建series\na 4 b 5 c 6 d 7 dtype: int32 #通过字典创建series\na [1, 2] b [2, 3] c [3, 4] d [4, 5] dtype: object \u0026lt;class 'pandas.core.series.Series'\u0026gt; int64 RangeIndex(start=0, stop=4, step=1, name=u'zimu') zimu [1 2 3 4] data dataframe # #创建dataframe import pandas as pd import numpy as np obj_dict={'a':[1,2],'b':[2,3],'c':[3,4],'d':[4,5]} obj_array=np.array([[1,2,3,4],[3,4,5,6]]) obj_series_1=pd.Series([11,12,13,14]) obj_series_2=pd.Series([21,22,23,24]) obj_dataframe_dict=pd.DataFrame(obj_dict) #通过字典创建dataframe obj_dataframe_array=pd.DataFrame(obj_array,index=['one','two']) #通过矩阵创建dataframe obj_dataframe_series=pd.DataFrame([obj_series_1,obj_series_2]) #通过series创建dataframe obj_dataframe_dataframe=pd.DataFrame(obj_dataframe_series,index= [0,1,'one'],columns=[0,1,2,'a']) #通过其他dataframe创建dataframe print \u0026quot;#通过字典创建dataframe\u0026quot; print obj_dataframe_dict print \u0026quot;#通过矩阵创建dataframe\u0026quot; print obj_dataframe_array print \u0026quot;#通过series创建dataframe\u0026quot; print obj_dataframe_series print \u0026quot;#通过其他dataframe创建dataframe\u0026quot; print obj_dataframe_dataframe #dataframe属性 print obj_dataframe_dataframe.dtypes print obj_dataframe_dataframe.values print obj_dataframe_dataframe.columns print obj_dataframe_dataframe.index 输出结果为： #通过字典创建dataframe a b c d 0 1 2 3 4 1 2 3 4 5 #通过矩阵创建dataframe 0 1 2 3 one 1 2 3 4 two 3 4 5 6 #通过series创建dataframe 0 1 2 3 0 11 12 13 14 1 21 22 23 24 #通过其他dataframe创建dataframe 0 1 2 a 0 11.0 12.0 13.0 NaN 1 21.0 22.0 23.0 NaN one NaN NaN NaN NaN 0 float64 1 float64 2 float64 a float64 dtype: object [[ 11. 12. 13. nan] [ 21. 22. 23. nan] [ nan nan nan nan]] Index([0, 1, 2, u\u0026rsquo;a\u0026rsquo;], dtype=\u0026lsquo;object\u0026rsquo;) Index([0, 1, u\u0026rsquo;one\u0026rsquo;], dtype=\u0026lsquo;object\u0026rsquo;) 取数据的话，便是obj_dataframe_dict['a'][0]取出数值即为1\n自命名创建方式 # df4 = pd.DataFrame(np.random.randn(6, 4), index=[u'第二', 4, 3, 2, 1, 0], columns=[u'第一',5,4,1]) #行为： 第一， 5， 4， 1 #列为：第二 -0.091305 ... # 4 ... # 3 # 2 # 1 # 0 ... 查看 # .dtypes 查看各行数据格式 .head() 查看前几行（默认5） .tail() 查看后几行 .index 查看数据框引索 .columns 查看列名 .values 数据值 .T 转置 .sort 排序 .sort(columns = '***')根据***列数据进行排序 取数据方法见上 # zip 和 数组变字典 # a = [1,2,3] b = [4,5,6] c = [4,5,6,7,8] zipped = zip(a,b) [(1, 4), (2, 5), (3, 6)]\nzip(a,c) [(1, 4), (2, 5), (3, 6)]\nzip(*zipped) [(1, 2, 3), (4, 5, 6)]\nzip 也可以二维矩阵变换（矩阵的行列互换） 因为其作用为按序号重组数组。（其英语翻译为拉链……）\n数组变字典~： # dic(zip(a, b)) # a中值为key b中值为values 字典操作 # dict= sorted(dic.items(), key=lambda d:d[0]) # 将字典按照键值升序排列 # d： 无所谓的参数 # d[0]：0为升序，1为降序 # 如果是字符型，那么‘1’‘10’‘12’… 才是‘2’’20‘，因为Python的比较是按照 # 按序提取第一个字符进行比较。所以要排序，还是得用int # 排序之后被转换为list类型。 for i in orderIDic: spamwriter.writerow(orderIDic[i]) # 变为 for i in orderIDic: spamwriter.writerow(i[1]) namedtuple # import collections person = collections.namedtuple('P', 'name age gender') # P: 类名 后面空格隔开的为变量名称 bob = person(name = 'B', age = 30, gender = 'male') jane = Person(name = 'J', age = 29, gender = 'female') for people in [bob, jane]: print (\u0026quot;%s is %d years old %s\u0026quot; % people) 元组的命名—— 命名之后可以由bob.name 来调用 （看了那个Python面向对象进阶， 老多__hahah__()函数之后，所以这明显是当成基本类的变量在用了。 emm 这么么说也不贴切 😔 果然理解程度还是跟不上的… emm 现在需要跟进的不是怎么用Python了，而是python的用法了，走起~ 继续写future笔记去了—— 这个得看的明白点儿😄）\nCSV # 读取 # import csv reader = csv.reader(open('test.csv', 'rb')) for item in reader: print item 官方是这么教你的 # #我记得我写过一次，怎么不见了… import csv with open('names.csv') as csvfile: reader = csv.DictReader(csvfilr) for row in reader: print (row['first_name'], row['last_name']) 写入 # import csv writer = csv.writer(open('test2.csv', 'wb')) writer.writerow(['col1', 'col2', 'col3']) data = [range(3) for i in range(3)] for item in data: writer.writerow(item) 官方教你这么写 # import csv with open('names.csv') as csvfile: fieldnames = ['first_name', 'last_name'] writer = csv.DictWriter(csvfile, fieldnames = fieldnames) writer.writeheader() writer.writerow('first_name' : 'Naled', 'last_name' : 'Beans') 须注意之处：writer.writerow()方法中的参数是list类型，如果你想在A1列写入\u0026rsquo;hello\u0026rsquo;，则必须是writer.writerow(\u0026lsquo;hello\u0026rsquo;)，不然\u0026rsquo;hello\u0026rsquo;会被看成是个list从而被分写入5列。写入CSV时，CSV文件的创建必须加上\u0026rsquo;b\u0026rsquo;参数，即csv.writer(open(\u0026rsquo;test.csv\u0026rsquo;, \u0026lsquo;wb\u0026rsquo;))，不然会出现隔行的现象。网上搜到的解释是：python正常写入文件的时候，每行的结束默认添加\u0026rsquo;\\n’，即0x0D，而writerow命令的结束会再增加一个0x0D0A，因此对于windows系统来说，就是两行，而采用’b\u0026rsquo;参数，用二进制进行文件写入，系统默认是不添加0x0D的。\n关闭 # csvfile.close() 值得注意的是上面的文档是覆盖型创建，即，写数据只能在关闭文档之前完成，之后再打开文件，再写就会覆盖掉之前（清空再写） 下面的txt mode = 'a' 就属于添加型写入了，再关闭之后再打开会在最后一条开始继续添加。然后将csv中的\u0026rsquo;w\u0026rsquo;替换成‘a’就行了。记得带上\u0026rsquo;b\u0026rsquo;要不会出现数据隔行…隔行显示\n官方还叫你这么写嘞 # with open('na1me.csv', 'ab') as csvfile: spamwriter = csv.writer(csvfile, delimiter = ',') spamwriter.writerow(['adasd', 'w.c.w', 'lol']) txt保存 # # 基本与CSV一致，emm其实都是保存为文档，就只有个后缀区别… def text_save(content,filename,mode='a'): # Try to save a list variable in txt file. file = open(filename,mode) file.write(str(content)+'\\n') file.close() text_save(np.mean(self.trueRange[start: ]), 'atr.txt') 关于保存路径呢，windows 下必须?用 ‘.\\.\\..’没错，当前路径（相对路径）和绝对路径都是这样用的\nmode b代表二进制模式打开，而a就有用了，表示有此文件就打开，没的话就创建。\njson # 和上述txt文件保存差不过，嗯应该说完全一样。因为我是用的是`json.dumps` dumps、loads # 这两个语句前者是将字典转化为str格式，后者是将str转换为字典。所以保 存到文件也不过是 字典 -\u0026gt; str -\u0026gt;(用`write`写入)-\u0026gt; 本地文件， 反之。 与之相对比的是`dump`和`load`这个是直接保存至文件，但`s`多好用 需注意的是`dumps`有`indent`参数可用来指明转换为`str`之后的缩进参 数。一般`4`（所以说这里说的是空格数？）。 哦，`loads`直接加载文件也 行，不用读出来`str`再去转换 Shelve # 对象的持久化存储—— 目的：Shelve模块为任意能够pickle的Python对象实现持久化存储，并提供一个类似字典的 接口。 # 列表List # 需提前定义，不能像变量一样随用随写…\n以下来自于 Python 列表(List)操作方法详解\n列表操作包含以下函数: # cmp(list1, list2) # 比较两个列表的元素 len(list) # 列表元素个数 max(list) # 返回列表元素最大值 min(list) # 返回列表元素最小值 list(seq) # 将元组转换为列表 列表操作包含以下方法: # list.append(obj) # 在列表末尾添加新的对象 list.count(obj) # 统计某个元素在列表中出现的次数 list.extend(seq) # 在列表末尾一次性 # 追加另一个序列中的多个值（用新列表扩展原来的列表） list.index(obj) # 从列表中找出某个值第一个匹配项的索引位置 list.insert(index, obj) # 将对象插入列表 list.pop(obj=list[-1]) #移除列表中的一个元素（默认最后一个元素） #，并且返回该元素的值 list.remove(obj) # 移除列表中某个值的第一个匹配项 list.reverse() # 反向列表中元素 list.sort([func]) # 对原列表进行排序 字符串连接 # 来自http://www.cnblogs.com/chenjingyi/p/5741901.html\n方法一 # website = 'python' + 'tab' + '.com' 方法二 # listStr = ['python', 'tab', '.com'] website = ''.join(listStr) 方法三 # website = '%s%s%s' % ('python', 'tab', '.com') 结论： 连接个数少使用一，个数多使用二。 推荐，使用三 ~ ，~\n手动编译Py文件 # import compileall compileall.compile_dir(目录) 时间 # datetime # from datetime import datetime a = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0) a.year a.hour #int 型变量 2017\n0\n获取当前本机电脑💻时间，replace为自定义某个数值。单独调用某个信息如a.year、a.hour\ndatetime 类型变量可直接相减获得间隔日 # a = datetime.datetime.now() # datetime.datetime(2017, 10, 18, 8, 52, 27, 5000) b = datetime(2005, 2, 6) # datetime.datetime(2005, 2, 6, 0, 0) c = a - b # datetime.timedelta(4637, 31947, 5000) c.days # int 型 4637\ntimedelta # timedelta为datetime类型相减而来（datetime不能相加…），然后嘞，datetime.timedelta(1,35340)这是它的样子，前是天数，后是秒数。也就是说所有相减就是告诉你相距多少天零多少秒，都是标准单位（误）。要取出可 .days 和 `seconds``\n格式化输出当前时间 # import time print time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) 2017-08-21 10:54:31\ntime # import time time.time() # 返回当前时间的时间戳（1970纪元后经过的浮点秒数） # 返回值为float 可直接拿来运算，还是很舒服的。 线程 threading # 用于实现定时器 # import threading def hel(): print \u0026quot;so you sucsessful to kill 5 seconde\u0026quot; time = threading.Timer(5, hel) time.start() so you sucsessful to kill 5 seconde 在命令行中按下回车后消失，很有意思，并且当第二调用时time.start()时就会——\nRuntimeError: threads can only be started once\n循环调用 # 以上的不能循环调用的话就没啥价值了，所以下面有个妖艳用法为：\ndef fun(): print \u0026quot;So jian\u0026quot; global timer timer = threading.Timer(5.5, fun) timer.start() timer = threading.Timer(1, fun) timer.start() # 通过自调自的方法循环创建时间线程，另外，timer.cancel()可停止定时器工作。 # 值得注意的是，上面不循环调用的 在执行完函数之后依然会持续运行 # 所以得记得关闭。 比方说这个妖艳……呃 本来打算在调用函数里写上cancel但是…依然之后不能再次start()\n线程池 # 自实现或者使用threadpool.ThreadPool:\nimport time import threadpool def sayhello(str): print \u0026#34;Hello \u0026#34;,str time.sleep(2) name_list =[\u0026#39;dd\u0026#39;,\u0026#39;aa\u0026#39;,\u0026#39;bb\u0026#39;,\u0026#39;cc\u0026#39;] start_time = time.time() pool = threadpool.ThreadPool(10) requests = threadpool.makeRequests(sayhello, name_list) for req in requests: pool.putRequest(req) pool.wait() print \u0026#39;%d second\u0026#39;% (time.time()-start_time) Math 库 # import math 数值取整 # ceil、floor 还有一个不是此库中的round 找来翻译就是 ： 小区、地板、回合………… 好吧，是（抹灰泥装镶板、最低的，最小的、周围，围绕）\n# 使用方法为： math.ceil(3.12) math.floor(3.24) round(3.51) round(3.10999999999, 10) #取值时的参考步长，好像（😭）是10就是最大步长了，再大没意义 # 手动赋值超过9位也就是10位小数的时候在PyCharm里直接赋值调试就自己约了， # 而一般产生精度漂移都是十几位小数开外的。emm 就这么表达了，看得懂 4.0\n3.0\n4.0\n3.11\n令程序有序执行的方法 # 对象（伪类）间变量传递 # Like This：\nclass A(object): \u0026quot;\u0026quot;\u0026quot;docstring for A\u0026quot;\u0026quot;\u0026quot; def __init__(self, name): super(A, self).__init__() self.name = name self.a = 0 def da(self): print self.name print self.a a = A('I am A') a.da() class B(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(B, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() b = B(a) b.dada() class C(object): \u0026quot;\u0026quot;\u0026quot;docstring for B\u0026quot;\u0026quot;\u0026quot; def __init__(self, aclass): super(C, self).__init__() self.aclass = aclass self.aclass.a += 1 def dada(self): self.aclass.da() c = C(a) c.dada() I am A\n0\nI am A\n1\nI am A\n2\nB与C分别在去改变读取在A中定义的数值。 嗯，没错，这么看的画确实时Python基础……所以没有这个基础的我看起来前期还挺费劲。当然，理解很好理解，就是在实现方法上不知原理的话就很难过。最主要的是，知道了原理在自己编写的时候可以的心用手，信手拈来。嗯~ o(￣▽￣)o就是这么写意和惬意。在VN.PY中有记录，不过还是拿过来吧，毕竟python用法\n字典中建立函数映射，方便调用~ # def add(x, y): return x + y def sub(x, y): return x - y a = {'add':add, 'sub':sub} a a['add'](1, 2) a['sub'](1, 2) {\u0026lsquo;add\u0026rsquo;: \u0026lt;function add at 0x02D162B0\u0026gt;, \u0026lsquo;sub\u0026rsquo;: \u0026lt;function sub at 0x02D16530\u0026gt;}\n3\n-1\ncollections 模块 # namedtuple # 给元组元素命名（貌似写过这个笔记欸，不过现在才发现这几个都是在一个模块下的） deque # #双端队列 快速插入 以及取出 l.insert(0, v) l.pop(0) l.popleft() l.appendleft() # 数据量大时，速度优于原生list a Game: # import sys import time from collections import deque fancy_loading = deque('\u0026gt;--------------------') while True: print '\\r%s' % ''.join(fancy_loading), fancy_loading.rotate(1) sys.stdout.flush() time.sleep(0.08) Result: # 一个无尽循环的跑马灯 Counter # # 计数器 from collections import Counter s = '''A Counter is a dict subclass for counting hashable objects. It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value including zero or negative counts. The Counter class is similar to bags or multisets in other languages.'''.lower() c = Counter(s) print c.most_common(5) [(\u0026rsquo; \u0026lsquo;, 54), (\u0026rsquo;e\u0026rsquo;, 32), (\u0026rsquo;s\u0026rsquo;, 25), (\u0026lsquo;a\u0026rsquo;, 24), (\u0026rsquo;t\u0026rsquo;, 24)]\nOrderDict # # 有序字典：记录了数据存入时的先后顺序 # 不过发现一个骚操作： defaultdict # # 默认字典： 当key不存在时，返回此结果 线程 # 创建线程： 使用Threading模块创建，从threading.Thread继承，然后重写__init__ 和run 方法 import threading import time exitFlag = 0 class myThread (threading.Thread): #继承父类threading.Thread def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 print \u0026#34;Starting \u0026#34; + self.name 写到这儿 print \u0026#34;Exiting \u0026#34; + self.name thread1 = myThread(1, \u0026#34;Thread - 1\u0026#34; , 1) thread1 = myThread(2, \u0026#34;Thread - 2\u0026#34; , 2) # 开启 thread1.start() thread2.start() 线程同步 # 不同线程对某个数据同时修改就很刺激，所以需要同步。（当然也可以选择不） 其实也简单，如下：\nimport threading threadingLock = threading.Lock() # 从这儿领一把锁 # 然后在 run()函数中，“写到这儿——也就是工作函数之前，写上 threadingLock.acquire() # 随后在工作函数之后 # threadingLock.release() 然后拿到小锁子的函数就能运行，运行完了把小锁子释放掉。为啥不是钥匙🔑……好吧。我就称呼它我就称呼它梭子吧——\n队列 # 线程优先级队列 Queue.qsize()\t返回队列的里站了几个 Queue.empty() 如果队列为空，返回True,反之False Queue.full() 如果队列满了，返回True,反之False Queue.full 与 maxsize 大小对应 Queue.get([block[, timeout]]) 获取队列,timeout`等待时间 Queue.get_nowait() 相当 Queue.get(False) Queue.put(item) 写入队列，timeout 等待时间 Queue.put_nowait(item) 相当 Queue.put(item, False) Queue.task_done() 在完成一项工作之后， Queue.task_done() 函数向任务已经完成的队列发送一个信号 Queue.join() 实际上意味着等到队列为空，再执行别的操作 来段儿示例：来自这儿\n#!/usr/bin/python # -*- coding: UTF-8 -*- import Queue import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print \u0026#34;Starting \u0026#34; + self.name process_data(self.name, self.q) print \u0026#34;Exiting \u0026#34; + self.name def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print \u0026#34;%s processing %s\u0026#34; % (threadName, data) else: queueLock.release() time.sleep(1) threadList = [\u0026#34;Thread-1\u0026#34;, \u0026#34;Thread-2\u0026#34;, \u0026#34;Thread-3\u0026#34;] nameList = [\u0026#34;One\u0026#34;, \u0026#34;Two\u0026#34;, \u0026#34;Three\u0026#34;, \u0026#34;Four\u0026#34;, \u0026#34;Five\u0026#34;] queueLock = threading.Lock() workQueue = Queue.Queue(10) threads = [] threadID = 1 # 创建新线程 for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1 # 填充队列 queueLock.acquire() for word in nameList: workQueue.put(word) queueLock.release() # 等待队列清空 while not workQueue.empty(): pass # 通知线程是时候退出 exitFlag = 1 # 等待所有线程完成 for t in threads: t.join() print \u0026#34;Exiting Main Thread\u0026#34; Starting Thread-1\nStarting Thread-2\nStarting Thread-3\nThread-1 processing One\nThread-2 processing Two\nThread-3 processing Three\nThread-1 processing Four\nThread-2 processing Five\nExiting Thread-3\nExiting Thread-1\nExiting Thread-2\nExiting Main Thread\n呃， 以上就是我现知道的终极用法，当然其基础于：\nworkQueue = Queue.Queue(10) # 创建+设定队列长度（emm 小心卡死就是了） # 只要满了再往里塞绝对死，无意外……(lll￢ω￢) workQueue.put(word) # 往里塞。 基础就是塞个数字，高级就是塞个线程 workQueue.get() # 顺序往外取 # 括号里里面可以写进参数，然而，依然按照顺序往外取，插队办理啥的不存在 # 另外，队列空的话取依然会死…… 一些方法 # q = queue.Queue(maxsize=0) q.qsize() #查看队列大小 q.empty() #判断队列是否为空 q.full() #如果maxsize设置了大小(eg:2)，如果q.put()了2个元素，则返回真，反之，则为假 q.get_nowait() # 如果队列中没有元素了，只用q.get() （当然，可以设置`q.get(block=False）`）会使程序卡住，用q.get_nowait()则会报错而不卡住 q.put_nowait() # 如果maxsize设置了大小，用q.put()超过范围则会卡住（当然 # 可以设置属性q.put(block=False)）。用q.put_nowait()则会报错而不卡住 老夫的Demo # 消费生产者关系\nimport threading import queue import threadpool import time pool = threadpool.ThreadPool(2) que = queue.Queue() dataList = [1,2,3,4,5,6,7,8,9,0] dataList1 = [1,2,3,\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] dataList2 = [4,5,6] dataList3 = [7,8,9,0] printLock = threading.Lock() workList = [dataList1, dataList2, dataList3] def worker(): ## 消费者 #printLock.acquire() aaa = que.get() print(aaa) for i in aaa: print (i) #printLock.release() time.sleep(5) def geter(task): ## 生产者 print(\u0026#34;emm, put in_:\u0026#34;, task) time.sleep(1) que.put(task) a = threading.Thread(target=worker) a.start() for i in workList: geter(i) 进程 # import multiprocessing import time def worker_1(interval, lock, low): print (\u0026#34;worker_1\u0026#34;) print (time.time()) lock.acquire() time.sleep(0.1) print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print(low) print (\u0026#34;end worker_1\u0026#34;) lock.release() def worker_2(interval, lock): print (\u0026#34;worker_2\u0026#34;) print (time.time()) lock.acquire() print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print (\u0026#34;end worker_2\u0026#34;) lock.release() def worker_3(interval, lock): print (\u0026#34;worker_3\u0026#34;) print (time.time()) lock.acquire() print(\u0026#34;I got the lock\u0026#34;) time.sleep(interval) print (\u0026#34;end worker_3\u0026#34;) lock.release() if __name__ == \u0026#34;__main__\u0026#34;: printLock = multiprocessing.Lock() # 🔒 来自关爱的小锁子 p1 = multiprocessing.Process(target = worker_1, args = (2, printLock, [\u0026#34;asd\u0026#34;, {\u0026#39;s\u0026#39;:1}, [1,2,3]])).start() p2 = multiprocessing.Process(target = worker_2, args = (3, printLock)).start() p3 = multiprocessing.Process(target = worker_3, args = (4, printLock)).start() w = {\u0026#39;a\u0026#39;:p1, \u0026#39;b\u0026#39;:p2, \u0026#39;c\u0026#39;:p3} # 创建三个进程去运行这三个函数 #p1.start() #p2.start() #p3.start() #for i in w: # w[i].start() # 启动进程 print(\u0026#34;The number of CPU is:\u0026#34; + str(multiprocessing.cpu_count())) for p in multiprocessing.active_children(): print(\u0026#34;child p.name:\u0026#34; + p.name + \u0026#34;\\tp.id\u0026#34; + str(p.pid)) print (\u0026#34;Main All Done\u0026#34;) # dt 2018年5月18日11点22分 worker_1 1526613489.1864893 worker_2 1526613489.1932006 The number of CPU is:4 child p.name:Process-3 p.id208 child p.name:Process-1 p.id206 child p.name:Process-2 p.id207 Main All Done worker_3 1526613489.1968668 I got the lock [\u0026lsquo;asd\u0026rsquo;, {\u0026rsquo;s\u0026rsquo;: 1}, [1, 2, 3]] end worker_1 I got the lock\nend worker_2 I got the lock end worker_3\n插一句话 线程和进程的关系，貌似与电脑双系统和系统再开虚拟机的关系emm 对于资源利用的角度上。\n没有传参的进程 # import multiprocessing def sayHello(): print(\u0026#39;hello~ I can see you\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: p1 = multiprocessing.Process(target=sayHello) p2 = multiprocessing.Process(target=sayHello) p3 = multiprocessing.Process(target=sayHello) p1.start() p2.start() p3.start() 如果只是单纯运行，这样就可以了，之所以做这个测试是因为我忌惮于那个args的传参，毕竟()里面若有元素存在就必须要有逗号… 看来没有传参的话就不需要了 一个参数a的时候: (a, )emmm🤔\n将进程定义为类 # import multiprocessing import time class ClockProcess(multiprocessing.Process): def __init__(self, interval): multiprocessing.Process.__init__(self) self.interval = interval def run(self): n = 5 while n \u0026gt; 0: print(\u0026quot;the time is {0}\u0026quot;.format(time.ctime())) time.sleep(self.interval) n -= 1 if __name__ == '__main__': p = ClockProcess(3) p.start() 以上，p.start()被调用时，自动调用run() 另外时间戳都是瞎戳的，所以… emm 这都一年之前的东西了，现在才想起来戳时间有点儿纪念意义(⊙﹏⊙) 2018年5月18日\n属性 # daemon ：是否伴随主程序结束而结束 Lock: 锁：（如下， 防止访问共享资源时冲突，如以上打印时间时出现的不连续打印😰） def worker(lock, var): try: *** finally: lock.release() lock = multiprocessing.Lock() var = '我是变量' p = multiptocessing.Process(target = worker, args = (lock, var)) 警个告 # 创建进程分支的函数选择只能隶属于__main__下或者是隶属与创建进程的函数级别相同的级别，例如今天在main下一个函数中选择目标函数为此函数的函数就不可以… 如下：\ndef a(): def c(para): pass *(target=b, args=(1,)) 🌹 *(target=c, args=(1,)) ❌ def b(para): pass emm，上述表述的很明确，但是昨天又重新犯了这个问题… 进程的执行者放到了类中的某个函数，然后又提出到__main__ 中函数，所以都不能执行，最终放到`main``外，与它同级，也就是def 前无空格。 才能“受命”。\n通过队列来存储不同进程产生的结果 # {来自}(https://blog.csdn.net/u014556057/article/details/66974452)\n# -*- coding:utf-8 -*- from multiprocessing import Process, Queue, Lock L = [1, 2, 3] def add(q, lock, a, b): lock.acquire() # 加锁避免写入时出现不可预知的错误 L1 = range(a, b) lock.release() q.put(L1) print L1 if __name__ == \u0026#39;__main__\u0026#39;: q = Queue() lock = Lock() p1 = Process(target=add, args=(q, lock, 20, 30)) p2 = Process(target=add, args=(q, lock, 30, 40)) p1.start() p2.start() p1.join() p2.join() L += q.get() + q.get() print L [20, 21, 22, 23, 24, 25, 26, 27, 28, 29] [30, 31, 32, 33, 34, 35, 36, 37, 38, 39] [1, 2, 3, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n再加一个协程 # 基础实现： # # yield def creatAor(): mylist = range(3) for i in mylist: yield i*i mygenerator = creatAor() # 生成一个生成器 print (mygenerator) for i in mygenerator: print (i) \u0026lt;generator object creatAor at 0x7f54ed368f10\u0026gt; 0 1 4\n当调用函数时，其返回并不立马执行（显示）——emm 经过十几分钟😰的观察👀说那么玄乎，.其实就是在函数执行过程中，在yield处把后面紧接的东西记录下来，之后最后生成一个可迭代的对象。 所以网上说时生成器也不可厚非，但表达真的是……不过貌似.不仅仅是记录后面紧跟的东西…\n$ vim def creatAor(): mylist = range(3) print(\u0026#34;so jia nei?\u0026#34;) for i in mylist: print(\u0026#34;pre a hou ga\u0026#34;) yield i*i print (\u0026#34;nihoua\u0026#34;) print (\u0026#34;2333333\u0026#34;) mygenerator = creatAor() print (mygenerator) for i in mygenerator: print (i) \u0026lt;generator object creatAor at 0x7fe2585a8f10\u0026gt; so jia nei? pre a hou ga 0 nihoua pre a hou ga 1 nihoua pre a hou ga 4 nihoua 2333333\n所以看这苗头像是重新执行了一次函数，但是将后面紧跟的东西也进行了记录\n应用到协程中，便是：\nimport time def consumer(): r = \u0026#39;\u0026#39; while True: n = yield r if not n: return print(\u0026#39;[CONSUMER] Consuming %s....\u0026#39; % n) time.sleep(1) r = \u0026#39;200 OK\u0026#39; def produce(c): c.next() n = 0 while n \u0026lt; 5: n = n + 1 print(\u0026#39;[PRODUCER] Producing %s...\u0026#39; % n) r = c.send(n) print(\u0026#39;[PRODUCER] Consumer return: %s\\n\u0026#39; % r) c.close() if __name__==\u0026#39;__main__\u0026#39;: c = consumer() produce(c) for i in c: print(i) [PRODUCER] Producing 1\u0026hellip; [CONSUMER] Consuming 1\u0026hellip;. [PRODUCER] Consumer return: 200 OK\n[PRODUCER] Producing 2\u0026hellip; [CONSUMER] Consuming 2\u0026hellip;. [PRODUCER] Consumer return: 200 OK\n[PRODUCER] Producing 3\u0026hellip; [CONSUMER] Consuming 3\u0026hellip;. [PRODUCER] Consumer return: 200 OK \u0026hellip; \u0026hellip;\n那么，是什么道理呢？\nsend next 方法的背后今生 # def my(): value = yield 1 value = yield value print(\u0026#39;finally: \u0026#39;, value) ge = my() print(ge.next()) print(ge.send(2)) print(ge.send(3)) 1 2 (\u0026lsquo;finally: \u0026lsquo;, 3) Traceback (most recent call last): File \u0026ldquo;yield_emm3.py\u0026rdquo;, line 8, in print(ge.send(3)) StopIteration\n可知： 当next时，yield挂起，但将之后的1返回。而后send激活了之前挂起赋值动作，但此时yield 1被替换为send来的2所以value被置为2. 再第三次调用，完成赋值动作之后，由于只被挂起两次动作，而这里调取了三次，所以报错 停止递归 。若直接递归则得到1 和 None.\n所以 next与send都是用来激活挂起动作而使用的，但send好在可以与之交互。 在send``之前需先next否则提示can\u0026rsquo;t send * to a just-started generator`(⊙﹏⊙) 我上面阐述的挂起，激活，是不是出现了什么偏差…\n2018年5月18日16点30分\n较完善方案： # # 1 import gevent def f(n): for i in range(n): print gevent.getcurrent(), i g2 = gevent.spawn(f, 5) g3 = gevent.spawn(f, 5) g1.join() g3.join() # 2 import gevent from gevent import monkey; monkey.patch_all() import urllib2 def f(url): print \u0026#39;GET: %s\u0026#39; % url resp = urllib2.urlopen(url) data = resp.read() print \u0026#39;[%d] bytes received from %s\\n\u0026#39; %(len(data), url) gevent.joinall([ gevent.spawn(f, \u0026#39;http://www.cnblogs.com/kaituorensheng/\u0026#39;), gevent.spawn(f, \u0026#39;https://www.python.org/\u0026#39;), gevent.spawn(f, \u0026#39;https://www.baidu.com\u0026#39;), ]) # 3 from gevent import monkey monkey.patch_all() import gevent from gevent import Greenlet class Task(Greenlet): def __init__(self, name): Greenlet.__init__(self) self.name = name def _run(self): print \u0026#34;Task %s: some task...\u0026#34; % self.name t1 = Task(\u0026#34;task1\u0026#34;) t2 = Task(\u0026#34;task2\u0026#34;) t1.start() t2.start() # here we are waiting all tasks gevent.joinall([t1,t2]) 和线程 进程 差不多一个用法，只不过没锁，也不需要锁。\nfutures # futures.ThreadPoolExecutor # with futures.ThreadPoolExecutor(16) as executor: executor.map(run, urls) # 这里是个爬虫，urls就是一个前方run函数的输入变量 父类中的变量与类中变量 # 在使用self.a 的时候——呃其实是实例化之后a.a时，会只在父类中寻找相关变量，而解决办法居然是将super(A, self).__init__(CtaEngine, setting)移动到变量定义之后，所以谁说这玩意放前面和放后面没有区别的！（欸?😘 这个之后有过说明，不过忘记写在哪儿了，再说一下，就是super\u0026hellip;.表示父类的初始化动作，__init__因为这个函数名子父相同不会重写，会合并。）\n列表的增删添 # append # 在最后添加一元素 extend # c.extend(a) 将列表a中元素加到c中去。可自加 + # 连接两方数组元素 c = a + c 然而创建新对象，耗内存… 所以没啥 用\ndel # 删除对应下标元素 del c[0] 删除c列表第一位元素 pop # c.pop() 删除最后一位元素 remove # 删除指定值元素，有相同值时只会删除第一位 [ : ] # 使用切片进行删除 insert # c.insert(0, 1)将1插入到c的最前方，可插列表，插入还是列表 一个函数的有效方式只在循环中执行一次 - 代码日志 # 这是原链接 emm 代码反正照着输入是不会有结果的，但感觉挺有戏先保留，以后技术提升再来看\n自己的方法 # 自己的方法很简单，很暴力，就是用字典啊—— 当执行过一次之后直接把调用关系扭到别的地方，反正只要是知道结果的判断都可以用字典来代替么。\n函数调用函数 and 语法糖 @ # import time def timehel(hell): def wrapper(): start = time.clock() hell() end =time.clock() print 'used:', end - start return wrapper @timehel def foo(): print \u0026lsquo;a ho ga\u0026rsquo;\na ho ga\nused: 0.000489465229975\n其上@timehel 和 foo = timehel(foo)等价（感谢被遗忘的博客）… 就是把下方函数当成输入，然后执行通俗来翻译就是：\n@：呼叫timehel 来执行下面这孙子。 这里是官方教你怎么用： https://wiki.python.org/moin/PythonDecoratorLibrary\n其中 函数中定义函数就类似于“父子关系”，也或者叫另辟空间。每次执行父函数时，子函数会有也尽在此时会有被执行的机会，会不会被执行，就看其在其父亲面前的表现了（他爸有没有叫他（有没有调用…））。\n变量作用域 # 因为从这个@ 这儿学到的，所以：\ndef hel(x): def inner(): print x return inner p1 = hel(1) p1 = hel(1) p1() 1\np2() 2\n闭包——如果没有inner这东西，下面绝不会输出东西，反而会报错。 直接p1,p2又不会再输出任何东西，只有在定义时会运行一次。 对比于def hel(x): print x 其中内层原因 先不深究，就脑补成外层需运行时才能去找那些变量，而其中的函数会主动去外围找所需的变量。\n应用案例 # import time def coseTime(func): print func def inner(*args, **kwargs): print args, kwargs start = time.clock() func(*args, **kwargs) end = time.clock() print args, kwargs print ('Running time: %s Seconds' % (end-start)) return inner @coseTime def hel(x): print ('hello~') hel(12) \u0026lt;function hel at 0x02BC5070\u0026gt; (12,) {} hello~ (12,) {} Running time: 0.000446197317167 Seconds\n用来无视变量来记录 函数运行所需时间的——同时输出其在运行时接入的变量\nfunctools # 就姑且放这儿吧，毕竟也算是为了有序执行而接触到的\npartial # import functools def add(a, b): print a, b return a, b addplus = functools.partial(add, 3) addplus(7) 3 7\naddplus(add, b = 6) addplus(7) 7 6\n这函数作用是 提前给定函数一个变量值…The functools module is for higher-order functions: functions that act on or return other functions. In general, any callable object can be treated as a function for the purposes of this module.\n我的接触场景是在PyQt 中信号槽循环连接时，用了partial在connect之后.connect(partial(self.start, i))去唯一化相同功能的复用。不过我之前也应该写过类似的，那时我找的解决办法时在连接调用时传参(在Python GUI里面应该会写有吧，假如两三个月前我没脑子短期性失忆的话😭)。emm那个传参是利用Qt机制 不知道孰优孰劣😄\n运气好，直接翻到： ——那里的应用场景是在鼠标点击按钮捕获点击事件click时传递的参数~ lambda # 使用方法为：\nfunc = lambda x:x*x # :前x表示函数输入，:后为返回值，x*x是这个函数收到输入后所执行的动作 w = lambda x:func(x) 网络编程 # socket # import socket # 服务端 s = socket.socket() host = socket.gethostname() port = 12345 s.bind((host, port)) s.listen(5) while True: c, addr = s.accept() print \u0026quot;link address is\u0026quot;, addr c.send('welcome here') c.close() # 客户端 s = socket.socket() host = socket.gethostname() port = 12345 s.connect((host, port)) # 此时服务端便弹出 link address is：('192.168.*.*', 64*5) print s.recv(1024) # 客户端显示welcome here select : 与Socket配合的跨平台的异步io模型 # import select import socket import Queue\n#create a socket server = socket.socket(socket.AF_INET,socket.SOCK_STREAM) server.setblocking(False) #set option reused server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR , 1)\nserver_address= (\u0026lsquo;192.168.1.102\u0026rsquo;,10001) server.bind(server_address)\nserver.listen(10)\n#sockets from which we except to read inputs = [server]\n#sockets from which we expect to write outputs = []\n#Outgoing message queues (socket:Queue) message_queues = {}\n#A optional parameter for select is TIMEOUT timeout = 20\nwhile inputs: print \u0026ldquo;waiting for next event\u0026rdquo; readable , writable , exceptional = select.select(inputs, outputs, inputs, timeout)\n# When timeout reached , select return three empty lists if not (readable or writable or exceptional) : print \u0026quot;Time out ! \u0026quot; break; for s in readable : if s is server: # A \u0026quot;readable\u0026quot; socket is ready to accept a connection connection, client_address = s.accept() print \u0026quot; connection from \u0026quot;, client_address connection.setblocking(0) inputs.append(connection) message_queues[connection] = Queue.Queue() else: data = s.recv(1024) if data : print \u0026quot; received \u0026quot; , data , \u0026quot;from \u0026quot;,s.getpeername() message_queues[s].put(data) # Add output channel for response if s not in outputs: outputs.append(s) else: #Interpret empty result as closed connection print \u0026quot; closing\u0026quot;, client_address if s in outputs : outputs.remove(s) inputs.remove(s) s.close() #remove message queue del message_queues[s] for s in writable: try: next_msg = message_queues[s].get_nowait() except Queue.Empty: print \u0026quot; \u0026quot; , s.getpeername() , 'queue empty' outputs.remove(s) else: print \u0026quot; sending \u0026quot; , next_msg , \u0026quot; to \u0026quot;, s.getpeername() s.send(next_msg) for s in exceptional: print \u0026quot; exception condition on \u0026quot;, s.getpeername() #stop listening for input on the connection inputs.remove(s) if s in outputs: outputs.remove(s) s.close() #Remove message queue del message_queues[s] 糖拌咸鱼 - 记录学习的点点滴滴~\n简单来说一下select的作用： 返回值：三个列表 select方法用来监视文件描述符(当文件描述符条件不满足时，select会阻塞)，当某个文件描述符状态改变后，会返回三个列表 1、当参数1 序列中的fd满足“可读”条件时，则获取发生变化的fd并添加到fd_r_list中 2、当参数2 序列中含有fd时，则将该序列中所有的fd添加到 fd_w_list中 3、当参数3 序列中的fd发生错误时，则将该发生错误的fd添加到 fd_e_list中 4、当超时时间为空，则select会一直阻塞，直到监听的句柄发生变化 当超时时间 ＝ n(正整数)时，那么如果监听的句柄均无任何变化，则select会阻塞n秒，之后返回三个空列表，如果监听的句柄有变化，则直接执行。 epoll很好的改进了select 具体请看(深入理解python中的select模块)[http://blog.csdn.net/songfreeman/article/details/51179213]\n引用模块 # action.py中引用model.py为例\n同一文件夹下 # from model import * # or import model 其下级文件\u0026quot;here\u0026quot;下 # # 在model.py 文件中创建__init__.py空文件 from here import model # or form here.model import * 在上级文件下 # import sys sys.path.append(\u0026quot;..\u0026quot;) # 添加上级文件 路径 # import model 在上级文件的下级文件中（也就是在隔壁“wang”文件中） # # 需要创建__init__.py空文件 # 添加上级文件路径 import wang.model 解决编码问题 # import sys reload(sys) sys.setdefaultencoding('utf8') # 这段直接塞它嘴里 输出提示打印乱码 # #coding: utf-8 n=raw_input(unicode('请输入文字','utf-8').encode('gbk')) print n 内存异常占用 # import sys v = 1 sys.getsizeof(v) # 可以读出 此变量emm 或者说 对象的内存占用大小 异常 # plan1 ： # try: #正常的操作 except: #发生异常，执行这块代码 else: #如果没有异常执行这块代码(在执行完try下函数没有异常发生) 列表的坑 # 当a 为一个列表 a = [1, 2, 3] b = a c = a d = a b.append(4)\n这时，abcd四个列表都变成[1, 2, 3, 4]，emm… 所以直接以后不要把一个列表赋值给两个变量…除非不涉及修改，慎重慎重。。不过python中列表有copy一说，不过还没试过\n@staticmethod # 定义类中的的这个方法为静态方法，同理的还有`@classmethod`类方法。 常见异常 # 1.AssertionError：当assert断言条件为假的时候抛出的异常 2.AttributeError：当访问的对象属性不存在的时候抛出的异常 3.IndexError：超出对象索引的范围时抛出的异常 4.KeyError：在字典中查找一个不存在的key抛出的异常 5.NameError：访问一个不存在的变量时抛出的异常 6.OSError：操作系统产生的异常 7.SyntaxError：语法错误时会抛出此异常 8.TypeError：类型错误，通常是不通类型之间的操作会出现此异常 9.ZeroDivisionError：进行数学运算时除数为0时会出现此异常·· 事件模式中，事件篡改事故 # 在循环创建事件时，将event put到队列中，此时，被处理一半，因为不在一个线程所以下一个循环来临就将event的内容进行了修改。 杜绝此方法除了添加锁，只好将事件copy之后再传入时间引擎。如此便可暂防止事件处理一半被修改的事情发生。\n代码块注释 # Surrounding Blocks of Code with Language Constructs\nVisualStudio模式： # #region Description(说明) print \u0026quot;code here\u0026quot; #endregion NetBeans模式： # // \u0026lt;editor-fold desc=\u0026quot;Description\u0026quot;\u0026gt; code here // \u0026lt;/editor-fold\u0026gt; 类 # 以后详谈，本着一切皆对象的原则，所以对于类的了解决定了Python的认知，先记一个 def __init__(self): super(Proformance, self).__init__() #这个super表示了继承类和被继承类的 __init__调用时序，其它重名函数是覆盖，这个…… 数据类 # 用一个类来表示一个数据类型（这几天想着这个表示不同数据类型的组合方法恰类似于C中的结构体，然后Python中的数组元素存储各种东西什么类啊、数组套数组啊，字典存储啊，恰巧与C中的指针指向指针……emm ）如：\nclass A(object): def __init__(self): self.a = 'a' self.b = 'b' A().__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;}\n但是A().__dict__['a'] = 'It is a' 虽然不会报错，但之后再次调用A().__dict__显示结果还是一样，但：\na = A() a.__dict__['a'] = 'It is a' a.__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;It is a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;}\n这样我就用过一次，在不确定数据类会有几个元素甚至不知道会是什么名称的时候来创建的，毕竟：(这样的方式可以随便添加嘛)\na.__dict__['w'] = 'It is www' a.__dict__ {\u0026lsquo;a\u0026rsquo;: \u0026lsquo;It is a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;: \u0026lsquo;b\u0026rsquo;, \u0026lsquo;w\u0026rsquo;: \u0026lsquo;It is www\u0026rsquo;\n若出现docx模块pyInstaller打包问题 # 大概的解决步骤是这样的： 找到python-docx包安装路径下的一个名为default.docx的文件，我是通过everything这个强大的搜索工具全局搜索找到这个文件的，它在我本地所在的路径是：E:\\code\\env.env\\Lib\\site-packages\\docx\\templates 把找到的default.docx文件复制到我的py脚本文件所在的目录下。 修改脚本中创建Document对象的方式： 从原来的创建方式： document = Document() 修改为： import os document = Document(docx=os.path.join(os.getcwd(), \u0026lsquo;default.docx\u0026rsquo;)) 再次用pyinstaller工具打包脚本为exe文件 把default.docx文件复制到与生成的exe文件相同的路径下，再次运行exe文件，顺利运行通过，没有再出现之前的报错，问题得到解决。 作者：(m2fox)[https://www.jianshu.com/p/94ac13f6633e] 來源：简书\n拼接List字符串 # 将list中的元素拼接起来，并使用,隔开可这么来：\nimport itertools list = ['123', '567'] xlist = \u0026quot;,\u0026quot;.join(list) or ylist = \u0026quot;,\u0026quot;.join(*list) s = .join(itertools.chain(kwargs.keys())) 区别在于x为一个元素添加一个,，y为把列表中的素也拆分之后再添加\nSimpleHTTPServer # 小型的局域网嘛☺，很常用，不过在Python3中有了变化…\n$ Python2 python -m SimpleHTTPServer --- $ Python3 python -m http.server 顺带一提：-m是可以在外执行内库的操作，🦑大概是这个意思吧—— 用pdb的时候也是这么用的…\n老夫的月份生成 # # -*- coding:utf-8 -*- import datetime import copy def splitMonth(start, end): start = str2Date(start) end = str2Date(end) _delta = end - start datelist = [] if _delta.days \u0026gt; 10: # 拆分 # 按*月*拆分（10日间隔） n = 0 _start = copy.copy(start) while _delta.days \u0026gt; 0: n += 1 if _start.day \u0026lt; 10: _end = datetime.date(_start.year, _start.month, 10) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) break elif _start.day \u0026lt; 20: _end = datetime.date(_start.year, _start.month, 20) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) break else: _end = datetime.date(_start.year, _start.month, _start.day) + datetime.timedelta(15) _end = datetime.date(_end.year, _end.month, 1) - datetime.timedelta(1) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append(date2str(_start), date2str(end)) break _delta = end - _start + datetime.timedelta(1) return datelist else: return [(date2str(start), date2str(end))] def splitMouthBySE_N(start, end, n): start = str2Date(start) end = str2Date(end) _delta = end - start datelist = [] if _delta.days \u0026gt; n: # 拆分 # 按*月*拆分（10日间隔） _start = copy.copy(start) while _delta.days \u0026gt; 0: _loop = 0 for _n in range(int(30/n)): _loop = _loop + n if _start.day \u0026lt; _loop: if _start.month == 2 and _loop \u0026gt; 28: if _start.year%4: _end = datetime.date(_start.year, _start.month, 28) else: _end = datetime.date(_start.year, _start.month, 29) else: _end = datetime.date(_start.year, _start.month, _loop) if end \u0026gt; _end: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) _delta = datetime.timedelta(0) break _end = datetime.date(_start.year, _start.month, _start.day) + datetime.timedelta(15) else: continue else: _end = datetime.date(_end.year, _end.month, 1) - datetime.timedelta(1) if end \u0026gt; _end: if _start \u0026gt; _end: _delta = end - _start + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(_end))) _start = _end + datetime.timedelta(1) else: datelist.append((date2str(_start), date2str(end))) _delta = datetime.timedelta(0) break _delta = end - _start + datetime.timedelta(1) return datelist else: return [(date2str(start), date2str(end))] def gropdate(datelist, itemNum=0, gropNum=0): #将传入datelist[(str(start1), str(end1)), (str(start2), str(end2))...] -\u0026gt; 传入为月碎片 # 打按月对月碎片进行打组。 # 传入参数 itemNum: 一个组含几个月, gropNum: 将这些碎片打为几组 _dic = collections.OrderedDict() for i in datelist: # 按月分组 keyName = i[0].split(\u0026#39;-\u0026#39;)[1] if keyName not in _dic: _dic[keyName] = [] _dic[keyName].append(i) monthList = [] groups = [] groupListTemp = [] groupList = [] for i in _dic.keys(): # 得到月份列表 monthList.append(i) #[1,2,3...,7,8,9] monthNum = len(monthList) if gropNum: itemNum = round(float(monthNum)/gropNum) itemNum = int(itemNum) if itemNum: slipNum = int(monthNum/itemNum) start = 0 end = int(itemNum) for mon in range(slipNum): groups.append(monthList[int(start):int(end)]) start = copy.copy(end) end = end + itemNum if monthNum%itemNum: groups.append(monthList[start:monthNum]) # 非整除补足 for i in groups: for ii in i: groupListTemp.append(_dic[ii]) groupList.append(groupListTemp) groupListTemp = [] return groupList else: return None # region 日期`date`格式与`str`转换处理 def date2str(_date): # datetime.date 转换为 str (有为了适配原程序的补零操作…) if _date.month \u0026lt; 10: strDate = str(_date.year) + \u0026#39;-\u0026#39; + \u0026#39;0\u0026#39;+str(_date.month) + \u0026#39;-\u0026#39; + str(_date.day) else: strDate = str(_date.year) + \u0026#39;-\u0026#39; + str(_date.month) + \u0026#39;-\u0026#39; + str(_date.day) if _date.day \u0026lt; 10: strDate = strDate[:-1] + \u0026#39;0\u0026#39;+str(_date.day) return strDate def str2Date(_str): # str 转换为 datetime.date y, m, d = _str.split(\u0026#39;-\u0026#39;) return datetime.date(int(y), int(m), int(d)) # endregion if __name__ == \u0026#39;__main__\u0026#39;: print(splitMouthBySE_N(\u0026#39;2016-01-02\u0026#39;, \u0026#39;2018-03-01\u0026#39;, 5)) Python3.6之后的奇淫技巧 # 可使用下划线将长数字隔开，便于阅读 10000=10_000 字符串操作除了 %和format之外还有f操作 $ % s = \u0026#34;%s is %d\u0026#34; % (\u0026#39;two\u0026#39;, 2) $ format s = \u0026#34;{fruit} is {color}\u0026#34;.format(fruit=\u0026#39;apple\u0026#39;, color=\u0026#39;red\u0026#39;) $ f name = \u0026#39;Bob\u0026#39; f\u0026#39;Hello, {name}!\u0026#39; ### 甚至 a = 5 b = 10 f\u0026#39;Five plus ten is {a + b} and not {2 * (a + b)}.\u0026#39; #### 精度 PI = 3.141592653 f\u0026#34;Pi is {PI:.2f}\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Pi is 3.14\u0026#39; \u0026gt;\u0026gt;\u0026gt; error = 50159747054 ##### 以16进制格式化 f\u0026#39;Programmer Error: {error:#x}\u0026#39; \u0026gt;\u0026gt;\u0026gt;\u0026#39;Programmer Error: 0xbadc0ffee\u0026#39; ##### 以二进制格式化 f\u0026#39;Programmer Error: {error:#b}\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026#39;Programmer Error: 0b101110101101110000001111111111101110\u0026#39; 3.变量注释 def my_add(a: int, b: int) -\u0026gt; int: \\n return 0 仅仅用来注释，其实传参出参并不受控制…\n魔法方法 # 假设定义类 EmmNe, EmmNe拥有self.aaa与self.aaadict、列表self.aaalist 且__init__允许两个传参\n__len__:\ndef __len__(self): return len(self.aaa) # 则在外`len`此实例化对象时，会返回这个结果 __getitem__:\ndef __getitem__(self, key) return self.aaadict[key] en = EmmNe(1, 2) print(en[`]) \u0026gt; 2 #就像上面那样。 不过还有下面的用法 def __getitem__(self, index): retrun self.aaalist[index] w = Emm(1,2) for i in w: print (i) # 则输出列表中内容 __setitem__:\ndef __setitem__(self, key, value) return self.aaadict[key] = value # 拥有此方法，则在外可将实例对象当作字典操作: enp[\u0026#39;a\u0026#39;] = \u0026#39;asd\u0026#39; # 就像这样 collectionss # 总结一句话： collections出品， 必属精品。 马上能想到的 有序字典，还有那啥都是出自此个模块之下。 今天用的 计数也是出自此处 反正之后 这个里面能实现的功能，那就放弃手写吧————😓 from collections import Counter\nFunction Annotations # Annotations are stored in the annotations attribute of the function as a dictionary and have no effect on any other part of the function. Parameter annotations are defined by a colon after the parameter name, followed by an expression evaluating to the value of the annotation. Return annotations are defined by a literal -\u0026gt;, followed by an expression, between the parameter list and the colon denoting the end of the def statement. The following example has a positional argument, a keyword argument, and the return value annotated:\n\u0026gt;\u0026gt;\u0026gt; def f(ham: str, eggs: str = \u0026#39;eggs\u0026#39;) -\u0026gt; str: print(\u0026#34;Annotations:\u0026#34;, f.__annotations__) print(\u0026#34;Arguments:\u0026#34;, ham, eggs) return ham + \u0026#39; and \u0026#39; + eggs f(\u0026#39;spam\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Annotations: {\u0026#39;ham\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;, \u0026#39;return\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;, \u0026#39;eggs\u0026#39;: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;} \u0026gt;\u0026gt;\u0026gt; Arguments: spam eggs \u0026gt;\u0026gt;\u0026gt; \u0026#39;spam and eggs\u0026#39; Logger # 模块名： logging 上手容易，功能丰富，性能肯定也好过自己✍ 另外，懒———\nimport sys import logging import logging_error logger1 = logging.getLogger(\u0026#39;loger1\u0026#39;) logger2 = logging.getLogger(\u0026#39;loger2\u0026#39;) #实例化两个logger,默认名称为：`root` \u0026#34;\u0026#34;\u0026#34; 我居然以为root是程序执行处的名字，以为放到函数中就会显示函数名。emm 所以才有了下面多层函数嵌套…，以及调用外部`import` \u0026#34;\u0026#34;\u0026#34; formatter = logging.Formatter(\u0026#39;[%(name)s]%(asctime)s %(levelname)-8s: %(message)s\u0026#39;) #定义日志格式： \u0026#34;\u0026#34;\u0026#34; %(name)s Logger的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名| %(funcName)s 调用日志输出函数的函数名| %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用UNIX标准的表示时间的浮点数表示| %(relativeCreated)d 输出日志信息时的，自Logger创建以来的毫秒数| %(asctime)s 字符串形式的当前时间。默认格式是“2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程ID。可能没有 %(message)s 用户输出的消息 \u0026#34;\u0026#34;\u0026#34; fileHandler = logging.FileHandler(\u0026#39;loger.log\u0026#39;) fileHandler.setFormatter(formatter) consoleHandler = logging.StreamHandler(sys.stdout) consoleHandler.formatter = formatter #配置文件、终端日志处理器。可以使用不同格式，来区分处理 logger1.addHandler(fileHandler) logger2.addHandler(fileHandler) logger1.addHandler(consoleHandler) logger2.addHandler(consoleHandler) #为日志机添加处理器 logger1.setLevel(logging.INFO) #logger2.setLevel() #设置各日志机打印等级 logger1.debug(\u0026#39;debugO\u0026#39;) logger1.info(\u0026#39;info\u0026#39;) logger2.info(\u0026#39;info\u0026#39;) logger1.error(\u0026#39;error\u0026#39;) def warn_msg(): logger1.warn(\u0026#39;warn msg\u0026#39;) warn_msg2() def warn_msg2(): logger2.warn(u\u0026#39;warn 信息\u0026#39;) logging_error.error_demo() warn_msg() 当然，logger还有别的调用方法，不过这应该就够了， 具体要怎么实现，就去找官方文档了。 预防针： 多种配置方法、日志重复输出:见此\nlambda函数 # 排序 # aaa \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 1}, {\u0026#39;time\u0026#39;: 3}, {\u0026#39;time\u0026#39;: 2}] sorted(aaa, key = lambda x: x[\u0026#34;time\u0026#34;]) \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 1}, {\u0026#39;time\u0026#39;: 2}, {\u0026#39;time\u0026#39;: 3}] sorted(aaa, key = lambda x: x[\u0026#34;time\u0026#34;], reverse=True) \u0026gt;\u0026gt;\u0026gt; [{\u0026#39;time\u0026#39;: 3}, {\u0026#39;time\u0026#39;: 2}, {\u0026#39;time\u0026#39;: 1}] Mock # 使用: unittest\nmock.patch.object: Mock # 一个类, 后接方法 mock.patch: Mock # 一个方法, 按路径 @mock.patch(\u0026#34;databases.wx_service.get_user_base_info\u0026#34;) @mock.patch.object(wx_service.WeChat_OAP, \u0026#34;send_template_msg\u0026#34;) def test_create_weawarning(self, mock_send_template_msg, mock_get_user_base_info): # 装饰器生效从内到外, 传入参数顺序, 从左到右 pass mock_send_template_msg.return_value = \u0026#39;\u0026#39;/{}/[]/() 皆可 设定mock返回值 mock_get_user_base_info.side_effect = [\u0026#39;\u0026#39;/{}/[]/(), \u0026#39;\u0026#39;/{}/[]/()] 设定每次调用mock函数依次返回返回值 "},{"id":72,"href":"/docs/programmer/gui/notespython/","title":"图形化界面 （Python Gui）","section":"Gui","content":"author:Ian\nPython GUI 💽 # pynput # 在 pynput 模块中，Win键被称为“特殊键”（Special keys），需要使用特殊的名称来表示。\n以下是可以使用的特殊键名称列表：\nhttps://pynput.readthedocs.io/en/latest/keyboard.html?highlight=%3Ccmd%3E#controlling-the-keyboard 因此，如果你想要在热键设置中使用 Win键+空格 这个热键，可以将它们分别替换为 cmd 和 space，如下所示：\nfrom pynput import keyboard def on_activate(): print(\u0026#39;Hotkey activated\u0026#39;) def on_exit(): print(\u0026#39;Hotkey exited\u0026#39;) return False with keyboard.GlobalHotKeys({\u0026#39;\u0026lt;cmd\u0026gt;+\u0026lt;space\u0026gt;\u0026#39;: on_activate}) as h: h.join(on_exit)``` 在这个例子中，我们使用 \u0026lt;cmd\u0026gt;+\u0026lt;space\u0026gt; 来表示 Win键+空格 热键，因为在Mac中，Command键（cmd）可以起到类似于Win键的作用。 ## PyQt ![qt](https://tse4-mm.cn.bing.net/th/id/OIP.J4_Nqrcc0x7slHHUFwKLSQHaI6?pid=ImgDet\u0026amp;rs=1 \u0026#34;tmp\u0026#34;) 官方说明文档：\u0026lt;http://pyqt.sourceforge.net/Docs/PyQt4/index.html\u0026gt; 照例，先贴网址： \u0026lt;http://www.qaulau.com/books/PyQt4_Tutorial/index.html\u0026gt; ## 画界面 #PyQt4使用designer.exe import os for root, dirs, files in os.walk(\u0026#39;.\u0026#39;): for file in files: if file.endswith(\u0026#39;.ui\u0026#39;): os.system(\u0026#39;pyuic4 -o ui_%s.py %s\u0026#39; % (file.rsplit(\u0026#39;.\u0026#39;, 1)[0], file)) elif file.endswith(\u0026#39;.qrc\u0026#39;): os.system(\u0026#39;pyrcc4 -o %s_rc.py %s\u0026#39; % (file.rsplit(\u0026#39;.\u0026#39;, 1)[0], file)) # 注：在Win中调用pyrcc4 可能无法识别该命令，即使添加到环境变量也不行，而是 #pyrcc.exe才能调用简直…… #### 窗口设置 resize(8, 8) setWindowTitle(u\u0026#39;标题\u0026#39;) #### 获取图标 def getIcon(filename): \u0026#34;\u0026#34;\u0026#34; 获取图标 \u0026#34;\u0026#34;\u0026#34; fileInfo = Qt.QFileInfo(filename) fileIcon = Qt.QFileIconProvider() icon = QtGui.QIcon(fileIcon.icon(fileInfo)) return icon 使用时： self.setWindowIcon(getIcon(\u0026#39;../hi/app.ico\u0026#39;)) --- ##### Dock widgetTestM, dockTestM = self.createDock(AllMarketMonitor, vtText.“dock标题”, QtCore.Qt.RightDockWidgetArea) # 方向有： `RightDockWidgetArea`,`BottomDockWidgetArea`,`LeftDockWidgetArea` # 创建dock窗口 # 可利用 self.tabifyDockWidget(dockMarketM, dockAllDataM) 来合并同一个方向上的dock # 此下还没看… dockTradeM.raise_() dockPositionM.raise_() # 连接组件之间的信号 widgetPositionM.itemDoubleClicked.connect(widgetTradingW.closePosition) # 保存默认设置 self.saveWindowSettings(\u0026#39;default\u0026#39;) 其实现函数为： \u0026#34;\u0026#34;\u0026#34;创建停靠组件\u0026#34;\u0026#34;\u0026#34; def createDock(self, widgetClass, widgetName, widgetArea): widget = widgetClass(self.mainEngine, self.eventEngine) dock = QtGui.QDockWidget(widgetName) dock.setWidget(widget) dock.setObjectName(widgetName) dock.setFeatures(dock.DockWidgetFloatable|dock.DockWidgetMovable) self.addDockWidget(widgetArea, dock) return widget, dock \u0026gt; 再本质一点的东西为： widget1 = Ha(self) dock = QtGui.QDockWidget(\u0026#39;haha\u0026#39;) dock.setObjectName(\u0026#39;ha1\u0026#39;) dock.setWidget(widget1) dock.setFeatures(dock.DockWidgetFloatable | dock.DockWidgetMovable) self.addDockWidget(QtCore.Qt.BottomDockWidgetArea, dock) #### 动作 exit = QtGui.QAction(QtGui.QIcon(\u0026#39;hello.ico\u0026#39;), \u0026#39;exit\u0026#39;, self) exit.setShortcut(\u0026#39;Ctrl+Q\u0026#39;) exit.setStatusTip(\u0026#39;Exit application\u0026#39;) # 图标、文字、快捷键、提示信息 menubar = self.menuBar() file = menubar.addMenu(\u0026#39;\u0026amp;File\u0026#39;) file.addAction(exit) # 创建目录和工具栏，将动作添加进去。工具栏同理 ### 定位布局 #### 绝对定位 label1 = QtGui.QLabel(u\u0026#39;绝对定位\u0026#39;, self) label1.move(15, 60) # 创建、移动到显示位置 #### 框布局 及 布局元素平均分布 okButton = QtGui.QPushButton(\u0026#34;OK\u0026#34;) cancelButton = QtGui.QPushButton(\u0026#34;Cancel\u0026#34;) # 创建按钮 hbox = QtGui.QHBoxLayout() hbox.addStretch(1) hbox.addWidget(okButton) # 增加组件 hbox.addWidget(cancelButton) # 创建水平栏 hbox.addStretch() # 平均分布 vbox = QtGui.QVBoxLayout() vbox.addStretch(1) # 创建竖列 vbox.addLayout(hbox) # 将水平栏插入竖列 self.setLayout(vbox) # 显示最终竖列 注意一下add时选择对类型就好了。 ### QTableWidget \u0026lt;p\u0026gt;\u0026lt;textarea cols=\u0026#34;50\u0026#34; rows=\u0026#34;15\u0026#34; name=\u0026#34;code\u0026#34; class=\u0026#34;python\u0026#34;\u0026gt;#!/usr/bin/env python #coding=utf-8 from PyQt4.QtGui import * from PyQt4.QtCore import * class MyDialog(QDialog): def __init__(self, parent=None): super(MyDialog, self).__init__(parent) self.MyTable = QTableWidget(4,3) self.MyTable.setHorizontalHeaderLabels([\u0026#39;姓名\u0026#39;,\u0026#39;身高\u0026#39;,\u0026#39;体重\u0026#39;]) newItem = QTableWidgetItem(\u0026amp;quot;松鼠\u0026amp;quot;) self.MyTable.setItem(0, 0, newItem) newItem = QTableWidgetItem(\u0026amp;quot;10cm\u0026amp;quot;) self.MyTable.setItem(0, 1, newItem) newItem = QTableWidgetItem(\u0026amp;quot;60g\u0026amp;quot;) self.MyTable.setItem(0, 2, newItem) layout = QHBoxLayout() layout.addWidget(self.MyTable) self.setLayout(layout) if __name__ == \u0026#39;__main__\u0026#39;: import sys app = QApplication(sys.argv) myWindow = MyDialog() myWindow.show() sys.exit(app.exec_()) \u0026lt;/textarea\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026amp;nbsp;\u0026lt;/p\u0026gt; 其中： \u0026lt;p\u0026gt;self.MyTable = QTableWidget(4,3)\u0026amp;nbsp; 构造了一个QTableWidget的对象，并且设置为4行，3列\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;self.MyTable.setHorizontalHeaderLabels([\u0026#39;姓名\u0026#39;,\u0026#39;身高\u0026#39;,\u0026#39;体重\u0026#39;]) 则设置表格的表头\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;newItem = QTableWidgetItem(\u0026amp;quot;松鼠\u0026amp;quot;)\u0026amp;nbsp;\u0026amp;nbsp; 则是生成了一个QTableWidgetItem的对象，并让其名为\u0026amp;ldquo;松鼠\u0026amp;rdquo;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;self.MyTable.setItem(0, 0, newItem)\u0026amp;nbsp;\u0026amp;nbsp;\u0026amp;nbsp; 将刚才生成的Item加载到第0行、0列处 \u0026lt;p\u0026gt;\u0026amp;nbsp;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;这样一个简单的QTableWidget就构造完成了。\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;http://hi.csdn.net/attachment/201103/1/0_1298961912c0mN.gif\u0026#34; alt=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;/p\u0026gt; 感谢[来源](view-source:blog.csdn.net/vah101/article/details/6215066) ### 以上。 之后的设置字体，底色，之类用的的时候再说。 其中： ##### 合并单元格效果的实现： self.MyTable.setSpan(0, 0, 3, 1) # 其参数为： 要改变单元格的 1行数 2列数 要合并的 3行数 4列数 ##### 表格表头的显示与隐藏 self.MyTable.verticalHeader().setVisible(False) self.MyTable.horizontalHeader().setVisible(False) # 默认显示 且标号为： 1，2，3… #### 空位填补 .addStretch() # 不过比较鸡肋，还是下面的调整窗口显示比例比较好玩 ##### 调整各部分显示比例 QVBoxLayout* layout = new QVBoxLayout; QPushButton* btn = new QPushButton; QTableWidget* tableWidget = new QTableWidget; QHBoxLayout* h_layout = new QHBoxLayout; layout.addWidget(btn); layout.addWidget(tableWidget); layout.addLayout(h_layout) layout-\u0026gt;setStretchFactor(btn, 1); layout-\u0026gt;setStretchFactor(tableWidget, 2); layout-\u0026gt;setStretchFactor(h_layout, 2); 上面是C++ 所以下面的是俺的Python： hbox1[i].addWidget(self.buttonBox[i]) hbox1[i].addWidget(self.paramMonitor[i]) hbox1[i].addWidget(self.varMonitor[i]) # 设置显示比例 hbox1[i].setStretchFactor(self.buttonBox[i], 3) hbox1[i].setStretchFactor(self.paramMonitor[i], 3) hbox1[i].setStretchFactor(self.varMonitor[i], 4) ### 列表内添加按钮 \u0026lt;p\u0026gt;1、定义添加按钮的方法\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;cnblogs_code\u0026#34;\u0026gt; \u0026lt;pre\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 列表内添加按钮\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; buttonForRow(self,id): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 3\u0026lt;/span\u0026gt; widget=\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;QWidget() \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 4\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 修改\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 5\u0026lt;/span\u0026gt; updateBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;修改\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 6\u0026lt;/span\u0026gt; updateBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 7\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : NavajoWhite; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 8\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt; 9\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;10\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;11\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;12\u0026lt;/span\u0026gt; updateBtn.clicked.connect(\u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;:self.updateTable(id)) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;13\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;14\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 查看\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;15\u0026lt;/span\u0026gt; viewBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;查看\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;16\u0026lt;/span\u0026gt; viewBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;17\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : DarkSeaGreen; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;18\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;19\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;20\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;21\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;22\u0026lt;/span\u0026gt; viewBtn.clicked.connect(\u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;: self.viewTable(id)) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;23\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;24\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 删除\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;25\u0026lt;/span\u0026gt; deleteBtn = QPushButton(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;删除\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;26\u0026lt;/span\u0026gt; deleteBtn.setStyleSheet(\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; text-align : center; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;27\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; background-color : LightCoral; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;28\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; height : 30px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;29\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; border-style: outset; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;30\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt; font : 13px; \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #800000\u0026#34;\u0026gt;\u0026#39;\u0026#39;\u0026#39;\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;31\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;32\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;33\u0026lt;/span\u0026gt; hLayout =\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; QHBoxLayout() \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;34\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(updateBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;35\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(viewBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;36\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; hLayout.addWidget(deleteBtn) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;37\u0026lt;/span\u0026gt; hLayout.setContentsMargins(5,2,5,2\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;38\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; widget.setLayout(hLayout) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;39\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;return\u0026lt;/span\u0026gt; widget\u0026lt;/pre\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p\u0026gt;2、在向tableWidget里添加数据时插入即可\u0026lt;/p\u0026gt; \u0026lt;div class=\u0026#34;cnblogs_code\u0026#34;\u0026gt; \u0026lt;pre\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; row_number, row_data \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; enumerate(rsdata): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; self.ui.tableWidget.insertRow(row_number) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;3\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt; range(len(row_data)+1\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;4\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; i\u0026amp;lt;\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;len(row_data): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;5\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt; self.ui.tableWidget.setItem(row_number, i, QtWidgets.QTableWidgetItem(str(row_data[i]))) \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;6\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 添加按钮\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;7\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #0000ff\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; i==\u0026lt;span style=\u0026#34;color: #000000\u0026#34;\u0026gt;len(row_data): \u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;8\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt;#\u0026lt;/span\u0026gt;\u0026lt;span style=\u0026#34;color: #008000\u0026#34;\u0026gt; 传入当前id\u0026lt;/span\u0026gt; \u0026lt;span style=\u0026#34;color: #008080\u0026#34;\u0026gt;9\u0026lt;/span\u0026gt; self.ui.tableWidget.setCellWidget(row_number, i,self.buttonForRow(str(row_data[0])))\u0026lt;/pre\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;p\u0026gt;效果图\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;img src=\u0026#34;http://images2017.cnblogs.com/blog/896442/201709/896442-20170907222902741-300228307.png\u0026#34; alt=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; 就像以上显示的那样[来源](https://www.cnblogs.com/yuanlipu/p/7492260.html) #### 值得注意的是，再排布的时候必须只有一个表格对其进行放置（也就是说指挥它去哪儿的只能有一个人），之前我为了测试，两个hbox 对其进行排版，简直…… labelSymbol = QtGui.QLabel(self.CtaEngine.strategyTickDict[self.name]) buttonInit[i] = QtGui.QPushButton(u\u0026#39;初始化\u0026#39;) buttonStart[i] = QtGui.QPushButton(u\u0026#39;启动\u0026#39;) buttonStop[i] = QtGui.QPushButton(u\u0026#39;停止\u0026#39;) buttonUpdate[i] = QtGui.QPushButton(u\u0026#39;更新参数\u0026#39;) buttonSave[i] = QtGui.QPushButton(u\u0026#39;保存参数\u0026#39;) buttonInit[i].clicked.connect(partial(self.init, i)) buttonStart[i].clicked.connect(partial(self.start, i)) buttonStop[i].clicked.connect(partial(self.stop, i)) buttonUpdate[i].clicked.connect(partial(self.updateParams,i)) buttonSave[i].clicked.connect(partial(self.saveParams, i)) hbox1[i] = QtGui.QHBoxLayout() ##参数设置显示 hbox2[i] = QtGui.QHBoxLayout() #hbox1[i].addWidget(labelSymbol) #hbox1[i].addWidget(buttonInit[i]) #hbox1[i].addWidget(buttonStart[i]) #hbox1[i].addWidget(buttonStop[i]) #hbox1[i].addWidget(buttonUpdate[i]) #hbox1[i].addWidget(buttonSave[i]) self.buttonBox[i].setCellWidget(0, 0, buttonInit[i]) self.buttonBox[i].setCellWidget(0, 1, buttonStart[i]) self.buttonBox[i].setCellWidget(0, 2, buttonStop[i]) --- --- --- #### 组件之间连接信号 # classA(QtGui.QTableWidget): # pass classA.itemDoubleClicked.connect(classB.actionFunction) # 这样单纯调用还是可以的，但是数据传输… 就得继续研究一下了。 ##### 关闭事件退出提示 def closeEvent(self, event): reply = QtGui.QMessageBox.question(self, \u0026#39;Message\u0026#39;,\u0026#34;Are you sure to quit?\u0026#34;, QtGui.QMessageBox.Yes, QtGui.QMessageBox.No) if reply == QtGui.QMessageBox.Yes: event.accept() else: event.ignore() 函数放置位置就是主窗口类下就好。 ### QTableWidget 清除数据 def updateData(self, data): #（缩进没问题吧…🙏） \u0026#34;\u0026#34;\u0026#34;将数据更新到表格中\u0026#34;\u0026#34;\u0026#34; if self.name == u\u0026#39;RiskAlarmWidget\u0026#39;: pass if self.updateBeginAction: data = self.updateBeginAction(data) if not data: return if self.updateAction: self.updateAction(data) else: if isinstance(data, unicode) and self.dataKey: # 删除模式 key = data if key in self.dataDict: d = self.dataDict[key] row = d[self.headerList[0]].row() self.removeRow(row) del self.dataDict[key] else: # 如果设置了dataKey，则采用存量更新模式 if self.InsertMode: # 如果允许了排序功能，则插入数据前必须关闭，否则插入新的数据会变乱 if self._sorting: self.setSortingEnabled(False) newRow = 0 if self.InsertTopRow else self.rowCount() self.insertRow(newRow) for n, header in enumerate(self.headerList): content = self.getContents(data, header) cellType = self.headerDict[header][\u0026#39;cellType\u0026#39;] cell = cellType(content) if self.font: cell.setFont(self.font) if self._saveData: cell.data = data self.setItem(newRow, n, cell) # 重新打开排序 if self._sorting: self.setSortingEnabled(True) else: key = data.__getattribute__(self.dataKey) if key in self.dataDict: # 已存在数据字典中，则更新相关单元格 d = self.dataDict[key] for header in self.headerList: content = self.getContents(data, header) cell = d[header] cell.setContent(content) if self._saveData: # 如果设置了保存数据对象，则进行对象保存 cell.data = data else: # 如果允许了排序功能，则插入数据前必须关闭， #否则插入新的数据会变乱 if self._sorting: self.setSortingEnabled(False) # 不存在数据字典中，插入新行，创建此行单元格 newRow = 0 if self.InsertTopRow else self.rowCount() self.insertRow(newRow) d = {} for n, header in enumerate(self.headerList): content = self.getContents(data, header) cellType = self.headerDict[header][\u0026#39;cellType\u0026#39;] cell = cellType(content) if self.font: cell.setFont(self.font) # 如果设置了特殊字体，则进行单元格设置 if self._saveData: # 如果设置了保存数据对象，则进行对象保存 cell.data = data self.setItem(newRow, n, cell) d[header] = cell self.dataDict[key] = d # 重新打开排序 if self._sorting: self.setSortingEnabled(True) if self.updateAfterAction: self.updateAfterAction(data) 插入后数据需要清理只需`.clearContentsText()`，这样是清理数据但保留表格，方便更新内容。`.clear()`则清理数据以及表格方便\u0026lt;font color=75362109\u0026gt;重新\u0026lt;/font\u0026gt;填入新的内容 --- #### 调用Windows程序 import win32api path = \u0026#39;D:/.../dockerTrader/gateway/ctpGateway/CTP_connect.json\u0026#39; win32api.ShellExecute(0, \u0026#39;open\u0026#39;, \u0026#39;notepad.exe\u0026#39;, path, \u0026#39;\u0026#39;, 1) # 使用记事本打开此文件 --- #### Json with open(\u0026#39;D:/.../dockerTrader/gateway/ctpGateway/CTP_connect.json\u0026#39;, \u0026#39;r\u0026#39;) as f: setting = json.load(f) self.userID = str(setting[\u0026#39;userID\u0026#39;]) self.password = str(setting[\u0026#39;password\u0026#39;]) --- --- ### 信号槽（传输额外参数） 一般来说，比如一个按钮吧。 在链接点击信号与槽时`buttonInit[i].clicked.connect(partial(self.init, i))`就完事了。然而，当循环创建按钮，对应同样的槽函数，只是需要执行的变量有区别时，就需要传输额外的参数。 这时，方法有二： 环境： python2.7.8 pyqt 4.11.1 ### 一： 使用lambda表达式 \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtCore \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtGui \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-class\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;MyForm\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(QMainWindow)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;__init__\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, parent=None)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; super(MyForm, self).__init__(parent) button1 = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button 1\u0026#39;\u0026lt;/span\u0026gt;) button2 = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button 1\u0026#39;\u0026lt;/span\u0026gt;) button1.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_button(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt;)) button2.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_button(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt;)) layout = QHBoxLayout() layout.addWidget(button1) layout.addWidget(button2) main_frame = QWidget() main_frame.setLayout(layout) self.setCentralWidget(main_frame) \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;on_button\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, n)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; print(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;Button {0} clicked\u0026#39;\u0026lt;/span\u0026gt;.format(n)) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#34;__main__\u0026#34;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; sys app = QApplication(sys.argv) form = MyForm() form.show() app.exec_() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; \u0026lt;p\u0026gt;解释一下，on_button是怎样处理从两个按钮传来的信号。我们使用lambda传递按钮数字给槽，也可以传递任何其他东西—甚至是按钮组件本身（假如，槽打算把传递信号的按钮修改为不可用）\u0026lt;/p\u0026gt; ### 二： 使用functools里的partial函数 \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;button1.clicked.connect(partial(self.on_button, \u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;1\u0026lt;/span\u0026gt;)) button2.clicked.connect(partial(self.on_button, \u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;2\u0026lt;/span\u0026gt;)) \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; \u0026lt;p\u0026gt;《Rapid GUI Program with Python and QT》 P143例子。\u0026lt;/p\u0026gt; \u0026lt;pre class=\u0026#34;prettyprint\u0026#34;\u0026gt;\u0026lt;code class=\u0026#34;language-python hljs \u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtCore \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtGui \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;from\u0026lt;/span\u0026gt; functools \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; partial \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;import\u0026lt;/span\u0026gt; sys \u0026lt;span class=\u0026#34;hljs-class\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;Bu1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(QWidget)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;__init__\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, parent=None)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; super(Bu1, self).__init__(parent) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#水平盒式布局 \u0026lt;/span\u0026gt; layout = QHBoxLayout() \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#显示 \u0026lt;/span\u0026gt; self.lbl = QLabel(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;no button is pressed\u0026#39;\u0026lt;/span\u0026gt;) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#循环5个按钮 \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;in\u0026lt;/span\u0026gt; range(\u0026lt;span class=\u0026#34;hljs-number\u0026#34;\u0026gt;5\u0026lt;/span\u0026gt;): but = QPushButton(str(i)) layout.addWidget(but) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#信号和槽连接 \u0026lt;/span\u0026gt; but.clicked.connect(self.cliked) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用封装，lambda \u0026lt;/span\u0026gt; but = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;5\u0026#39;\u0026lt;/span\u0026gt;) layout.addWidget(but) but.clicked.connect(\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;lambda\u0026lt;/span\u0026gt;: self.on_click(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;5\u0026#39;\u0026lt;/span\u0026gt;)) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用个who变量，结果不正常，显示 False is pressed \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#but.clicked.connect(lambda who=\u0026#34;5\u0026#34;: self.on_click(who)) \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#使用封装，partial函数 \u0026lt;/span\u0026gt; but = QPushButton(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;6\u0026#39;\u0026lt;/span\u0026gt;) layout.addWidget(but) but.clicked.connect(partial(self.on_click, \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;6\u0026#39;\u0026lt;/span\u0026gt;)) layout.addWidget(self.lbl) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#设置布局 \u0026lt;/span\u0026gt; self.setLayout(layout) \u0026lt;span class=\u0026#34;hljs-comment\u0026#34;\u0026gt;#传递额外参数 \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;cliked\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; bu = self.sender() \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; isinstance(bu, QPushButton): self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;%s is pressed\u0026#39;\u0026lt;/span\u0026gt; % bu.text()) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;else\u0026lt;/span\u0026gt;: self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;no effect\u0026#39;\u0026lt;/span\u0026gt;) \u0026lt;span class=\u0026#34;hljs-function\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;hljs-title\u0026#34;\u0026gt;on_click\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026#34;hljs-params\u0026#34;\u0026gt;(self, n)\u0026lt;/span\u0026gt;:\u0026lt;/span\u0026gt; self.lbl.setText(\u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;%s is pressed\u0026#39;\u0026lt;/span\u0026gt; % n) \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026#34;hljs-string\u0026#34;\u0026gt;\u0026#39;__main__\u0026#39;\u0026lt;/span\u0026gt;: app = QApplication(sys.argv) bu =Bu1() bu.show() app.exec_() \u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt; 三：感谢[来源](http://blog.csdn.net/fengyu09/article/details/39498777) --- ### ## PyQt + echarts图表 echarts绘制图标会在本地保存一个`html`文件，所以使用`PyQt`将之作为一个网页页面加载即可： from PyQt4.QtWebKit import * from PyQt4.QtGui import * from PyQt4.QtCore import * from pyecharts import Kline, Page def creat_charts(): page = Page() chart_init = { \u0026#34;width\u0026#34;: 1600, \u0026#34;height\u0026#34;: 900, } chart = Kline(\u0026#34;K 线图\u0026#34;, **chart_init) chart.add(\u0026#34;日K\u0026#34;, [\u0026#34;2017/7/{}\u0026#34;.format(i + 1) for i in range(31)], v1) page.add(chart) return page creat_charts()_render() # 生成`render.html`文件 self.view = QWebView() self.create_charts().render() url = QUrl(\u0026#34;render.html\u0026#34;) # 需要加载`QUrl`使用字符串转化 self.view.load(url) ## addWidget 在窗口布局的时候这玩意至关重要，因为要先创建一个框架，再往里面塞东西。而塞的方法就是`addWidget`。所以简单记录一下小年这一天经常用到的环套： hbox = QtGui.QHBoxLayout() vbox = QtGui.QVBoxLayout() 可以通过`addWidget`来塞入`QtGui.QWidget`, `QtGui.QGroupBox`, `QtGui.QTableWidget` ,`QScrollArea`等 还可以`addWidget`诸如`QtGui.QPushButton`, `QtGui.QLabel`, `QtGui.QComboBox`, `QtGui.QLineEdit`等小部件 `hbox`和`vbox`可以通过`addLayout`互相添加（这两个是 框架，即页面上的“骨头”。来摆设“肌肉”-\u0026gt;“Widget”、\u0026#34;Box\u0026#34;等的） 当然最后要显示谁，需要`self.setLayout(hbox)` 而支持`setLayout`少不了有 `QWidget`,`QScrollArea`, 所以它们好像能够无限互相套下去… ### 小部件的方法 其实哪些方法也不用记…打开`QtDesigner`直接搜索拖拽，然后看右边的清单就行了，但这几个还是记录下来吧，在网上找太累了~ `QtGui.QComboBox`: `addItems`, \u0026#39;\u0026#39;\u0026#39;addItem`, `currentText` `QtGui.QSpinBox`: `setValue`, ### QString2String def QString2PyString(self, qStr): #QString，如果内容是中文，则直接使用会有问题，要转换成 python #string return unicode(qStr.toUtf8(), \u0026#39;utf-8\u0026#39;, \u0026#39;ignore\u0026#39;) ## QLineEdit 之所以放这么后面是因为我觉得这东西没什么好说的，也就是一个输入框嘛，但因为出现在后面所以说是现在发现了其中有趣的东西。那就是最近在做输入密码的时候想要限制，但在程序中去判断显然并不是什么有意思的事情。然后想起来输入的时候可以直接限制住啊。于是采用了`textChanged`去`connect`一个函数，来动态监测输入。但在调试中打开错了窗口所以以为没有用就找了其他的方法。那就是在初始化的时候直接卡死，结果没有找到设置长度的.set***但找到了现用的`setValidator`其配合正则表达式的食用方法如下： import re a = QtCore.QRegExp(\u0026#34;[A-Za-z]{0,5}[1-9][0-9]{0,5}\u0026#34;) a = QtCore.QRegExp(\u0026#34;[a-zA-Z0-9]{0,12}$\u0026#34;) self.txtPasswd.setValidator(QtGui.QRegExpValidator(a)) # emm,很显然，把a替换成limitRule就要顺眼一些了。 不过\u0026lt;font color=#ff3bffl9\u0026gt;值得注意的是：\u0026lt;/font\u0026gt;如果用`setText`将其它字符写进这个编辑小框框中的话，那么这个框框的规则就会被打破然后随便写。但要是`setText`的内容没有超出所规定的形式之外的话，那么规则照旧，依然执行。 # PyQtGraph: [Link](http://www.pyqtgraph.org/) import pyqtgraph.examples pyqtgraph.examples.run() "},{"id":73,"href":"/docs/programmer/langs/notesjava/","title":"愉快的Java(happy to learn the fuck java)","section":"Langs","content":"author: Ian\nhappy to the fuck java 😅 # \u0026lt;微人事\u0026gt; 笔记 -\u0026gt; ψ(._. )\u0026gt; # 先贴官方文档 哦 还有官方项目地址\n爪哇方法定义: # 修饰符 返回值类型 方法名(参数类型 参数名){ 方法体; return 返回值; } # 示个例 public boolean NiHou(int num){ int a = num; return turn; } // `boolean` 处 可为 public Collection\u0026lt;? extends GrantedAuthority\u0026gt; getAuthorities(){ List\u0026lt;GrantedAuthority\u0026gt; authorities = new ArrayList\u0026lt;\u0026gt;(); return authorities; } // 表泛型中可以是的`GrantedAuthority`所有子类 爪哇抽象方法(即Python父类中直接pass的函数…) # abstract\n包含抽象方法必须得是抽象类 任何子类必须重写父类抽象方法，或者声明自身为抽象类 public abstract class Employee { private String name; private int number; public abstract double computePay(); //其余 } 爪哇接口 # interface, implements\n[可见度] interface 接口名称 [extends 其他的类名] { // 声明变量 // 抽象方法 } # 示个例 /* 文件名 : NameOfInterface.java */ public interface NameOfInterface { //任何类型 final, static 字段 //抽象方法 } Interface关键字用来声明一个接口。 爪哇抽象类 # abstract classextends\n不能直接实例化 只能被继承后实例 public abstract class Employee { private String name; private String address; private int number; public Employee(String name, String address, int number) { System.out.println(\u0026#34;Constructing an Employee\u0026#34;); this.name = name; this.address = address; this.number = number; } //…… 等方法 public int getNumber() { return number; } } /* 文件名 : Salary.java */ // 用于继承上述东西 public class Salary extends Employee { private double salary; //Annual salary public Salary(String name, String address, int number, double salary) { super(name, address, number); setSalary(salary); } public void mailCheck() { System.out.println(\u0026#34;Within mailCheck of Salary class \u0026#34;); System.out.println(\u0026#34;Mailing check to \u0026#34; + getName() + \u0026#34; with salary \u0026#34; + salary); } public double getSalary() { return salary; } public void setSalary(double newSalary) { if(newSalary \u0026gt;= 0.0) { salary = newSalary; } } public double computePay() { System.out.println(\u0026#34;Computing salary pay for \u0026#34; + getName()); return salary/52; } } /* 文件名 : AbstractDemo.java */ // 用于实现继承类 public class AbstractDemo { public static void main(String [] args) { Salary s = new Salary(\u0026#34;Mohd Mohtashim\u0026#34;, \u0026#34;Ambehta, UP\u0026#34;, 3, 3600.00); Employee e = new Salary(\u0026#34;John Adams\u0026#34;, \u0026#34;Boston, MA\u0026#34;, 2, 2400.00); System.out.println(\u0026#34;Call mailCheck using Salary reference --\u0026#34;); s.mailCheck(); System.out.println(\u0026#34;\\n Call mailCheck using Employee reference--\u0026#34;); e.mailCheck(); } } 爪哇类 # class, extends\nMaven 项目标准目录结构 # str |\tmain |\tbin\t脚本库 |\tjava Java源代码文件 |\tresources 资源库，会自动复制到classes目录中 |\tfilters 资源过滤文件 |\tassembly 组建的描述配置（如何打包） |\tconfig 配置文件 |\twebapp web应用的目录。WEB-INF、css、js等 |\ttest |\tjava 单元测试Java源代码文件 |\tresorces 测试需要用到的资源库 |\tfilters 测试资源过滤库 |\tsite Site（一些文档） |\ttarget LICENSE.txt Project\u0026rsquo;s license README.txt Project\u0026rsquo;s readme\n工程根目录下就只有src和target两个目录 target是有存放项目构建后的文件和目录，jar包、war包、编译的class文件等。 target里的所有内容都是maven构建的时候生成的\n顶级目录工程的描述文件pom.xml\n摘自: https://blog.csdn.net/lengyue_wy/article/details/6718637\nsrc # java # Bean: 扮演应用程序素材的角色（其中放置了各种自定义类 如：Hr、Role、Employee、menu等数据类型）（作为service的模型库） common: 常用方法 （如字符串转换、邮件、几个查询） config: 看不懂的设置 controller: 动作执行，即受到什么请求执行什么动作。 但是我打了断点鲜有进来的。所以具体实现过程还是不清楚。 另外其url地址与网页真正输入地址有全拼简写的区别，哪里有指定也没找到还。（并且寥寥草草一个就处理完了，所以肯定是简写了💩） exception: 异常处理 mapper: 虽不觉然明厉的东西集合_20180525_其中定义了诸多做实事的接口，在.java文件中画饼，在.xml中实现，另外昨天在查资料时，还了解到有人要将.java与.xml分开来存放，解决方法是将.xml放在resources文件夹中，仿照在java文件夹中的路径，依瓢葫芦画😄的建立相同路径，如此一来在coding阶段看起来是分开的，但在building阶段编译器就是看作在同一目录下了——由此引发了虽然拆开了他们的人，却没有拆散他们的心的哲学论题😰(作为service的方法库) service: 动作逻辑服务，和controller中类似，不过详细不少（作为）\nresources # ftl: emm…… static: 静态资源 js: emm… application.properties: 各项配置 mybatis-config.xml: MySQL数据库配置\nMybatis # 头 # \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;/configuration\u0026gt; configuration中的配置信息 # 详解： https://blog.csdn.net/yqynsmile/article/details/52807815\n// 别名，假名，代称 \u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias alias=\u0026#34;Student\u0026#34; type=\u0026#34;com.mybatis3.domain.Student\u0026#34; /\u0026gt; \u0026lt;/typeAliases\u0026gt; // 声明环境变量 \u0026lt;environments default=\u0026#34;development\u0026#34;\u0026gt; \u0026lt;environment id=\u0026#34;development\u0026#34;\u0026gt; /* 声明数据源，数据源的类型有NOPOOLED ，POOLED ，还有JIDN. 在数据量少的话用ONPOOLED，测试和开发过程一般用POOLED，实际运行使用JIDN */ \u0026lt;dataSource type=\u0026#34;POOLED\u0026#34;\u0026gt; // \u0026lt;mappers\u0026gt;：声明我们定义的一个个Mapper类，或者说是关联 \u0026lt;mapper resource=\u0026#34;com/mybatis3/mappers/StudentMapper.xml\u0026#34; /\u0026gt; // \u0026lt;property\u0026gt;：jdbc连接的一些属性 \u0026lt;property name=\u0026#34;driver\u0026#34; value=\u0026#34;com.mysql.jdbc.Driver\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;url\u0026#34; value=\u0026#34;jdbc:mysql://localhost:3306/test\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;root\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;admin\u0026#34; /\u0026gt; /* 这些东西貌似也可以写在其他地方：application中 \u0026lt;property name=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;value\u0026gt;jdbc:mysql://localhost:3306/springmybaitis?useUnicode=true\u0026amp;amp;characterEncoding=UTF-8\u0026lt;/value\u0026gt; \u0026lt;!--springmybaitis是我的数据库 --\u0026gt; \u0026lt;/property\u0026gt; 或 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/vhr?useUnicode=true\u0026amp;characterEncoding=UTF-8 两种写法而已 */ // \u0026lt;mapper\u0026gt;：声明Mapper的路径 // 默认setting配置 \u0026lt;setting name=\u0026#34;cacheEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt;//是否使用缓存 \u0026lt;setting name=\u0026#34;lazyLoadingEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt;//是否是懒记载 \u0026lt;setting name=\u0026#34;multipleResultSetsEnabled\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;useColumnLabel\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;useGeneratedKeys\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;autoMappingBehavior\u0026#34; value=\u0026#34;PARTIAL\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;defaultExecutorType\u0026#34; value=\u0026#34;SIMPLE\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;defaultStatementTimeout\u0026#34; value=\u0026#34;25000\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;safeRowBoundsEnabled\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;localCacheScope\u0026#34; value=\u0026#34;SESSION\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;jdbcTypeForNull\u0026#34; value=\u0026#34;OTHER\u0026#34; /\u0026gt; \u0026lt;setting name=\u0026#34;lazyLoadTriggerMethods\u0026#34; value=\u0026#34;equals,clone,hashCode ,toString\u0026#34; /\u0026gt; 还有 \u0026lt;Settings\u0026gt;:声明一些全局变量、\u0026lt;typeHandlers\u0026gt;: 自定义我们的传入参数类型处理器、\u0026lt;properties\u0026gt;: 声明属性文件的key和value，但使用.properties文件将会被覆盖。\n注: 在要使用指定日志工具时，需要在\u0026lt;Settings\u0026gt;里指定\u0026lt;setting name=\u0026quot;logImpl\u0026quot; value=\u0026quot;LOG4J\u0026quot;/\u0026gt;\nequals 与 == # equals 对比两者是否类型一致，内容一致 ==\t则会由于 不同对象而False\nString str1=new String(\u0026#34;hello\u0026#34;); String str2=new String(\u0026#34;hello\u0026#34;); str1==str2 输出：false,因为不同对象 int1.equals(int2) 输出：TRUE // 无论 整形 or 字符串等 爪洼调用Python # 爪哇语有个通用调用方式，就是通过Runtime，也就是通过命令行执行，然后通过BufferedReader捕获命令行（内存）中的信息。但数据传输只能通过字符串，另外，python回传数据也只能通过print来回传，所以……基本没啥用.\n"},{"id":74,"href":"/docs/programmer/base/noteoffmtdata/","title":"数据格式笔记","section":"Base","content":" 算法图解 # 在线书: https://www.hello-algo.com\n单向链表实现和反转 # # 单向链表实现和反转 \u0026#34;\u0026#34;\u0026#34; # 当前值, 下一个值 # 循环 # 将当前值赋值为下一个的值, 下一个节点值为当前节点值 # 当前节点next赋 \u0026#34;\u0026#34;\u0026#34; class A: def __init__(self, v): self.v = v self.next = None class LA: def __init__(self): self.head = None def add(self, v): node = A(v) node.next = self.head self.head = node def print(self): cur = self.head while cur and cur.v != None: print(f\u0026#34;linkdata node v: {cur.v}\u0026#34;) cur = cur.next def revert(self, node: A=None, head=None): if not head: cache = self.head.next else: cache = node.next if cache: pass # print(f\u0026#34;cache: {cache.v}\u0026#34;) else: self.head = node self.head.next = head return if head == None: node = self.head node.next = None self.revert(cache, node) else: node.next = head self.revert(cache, node) if __name__ == \u0026#34;__main__\u0026#34;: # 1234 # 234 ldata = LA() for i in (1, 2, 3, 4): ldata.add(i) ldata.print() print(\u0026#34;---\u0026#34;*10) ldata.revert() ldata.print() \u0026#34;\u0026#34;\u0026#34; \u0026gt;\u0026gt;\u0026gt;运行输出: linkdata node v: 4 linkdata node v: 3 linkdata node v: 2 linkdata node v: 1 ------------------------------ linkdata node v: 1 linkdata node v: 2 linkdata node v: 3 linkdata node v: 4 \u0026#34;\u0026#34;\u0026#34; 其他 # "},{"id":75,"href":"/docs/programmer/ml/noteofmachinelearning/","title":"机器学习库","section":"Ml","content":" Python 机器学习库 👽 # Plotly # 与matplotlib 都是绘图工具，不过效果炫一些，我也没画过，所以只放链接，不放实例了 Plotly Python Library : https://plot.ly/python/\nmatplotlib # import matplotlib.pyplot as plt 参数等太多，链接最可靠 # pyplot参数\n还是粘一些常用的： marker 属性（下面写在分号里呦） o . v ^ \u0026lt; \u0026gt; 1 2 3 4 8 s p * h H + x D d | _ 之类\n画出一些“花儿”\n绘图 # plt.plot(x, y) # 在y之后可添加参数，例如常用的label = ‘IamLabel’之类 # 线的样式、颜色 ：b: blue g: green r: red c: cyan m: magenta y: yellow k: black w: white '-' : solid , '--' : dashed, '-.' : dashdot ':' : dotted ' '', ' ' ': None # 粗细 lw=3 更改数字 # 数值折点显示样式 marker = ‘o’ plot.show() 绘制图表 # 1 # plt.figure(1) 绘图 plt.figure(2) 绘图 2（未测试） # plt.figure(1) # 创建图表1 plt.figure(2) # 创建图表2 hi1 = plt.subplot(211) # 在图表2中创建子图1 hi2 = plt.subplot(212) # 在图表2中创建子图2 一表多图 # pCapital = plt.subplot(4, 1, 1) pCapital.set_ylabel(\u0026quot;capital\u0026quot;) pCapital.plot(d['capitalList'], color='r', lw=0.8) plt.show() 标注点 # eg1 # for w, m in enumerate(self.lowestPrice): if w % 120*10 == 0: plt.plot([w, w], [m, self.highestPrice[w]], linestyle = '--') #plt.scatter(self.dealPoints,color = 'c') for i in self.dealPoints: plt.scatter([i[0]], [i[1]], color = 'c') for ii in self.ydealPoints: plt.scatter([ii[0]], [ii[1]], color = 'm') plt.title('Tick \u0026amp; TradePoint') plt.legend() plt.show() plt.legend() # show() 之前不加这句是不会显示出标注的呦\neg2(还不晓得咋回事儿) # import numpy as np t = 2 * np.pi / 3 plt.plot([t, t], [0, np.cos(t)], color=\u0026#39;blue\u0026#39;, linewidth=2.5, linestyle=\u0026#34;--\u0026#34;) plt.scatter([t, ], [np.cos(t), ], 50, color=\u0026#39;blue\u0026#39;) plt.annotate(r\u0026#39;$sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$\u0026#39;, xy=(t, np.sin(t)), xycoords=\u0026#39;data\u0026#39;, xytext=(+10, +30), textcoords=\u0026#39;offset points\u0026#39;, fontsize=16, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, connectionstyle=\u0026#34;arc3,rad=.2\u0026#34;)) plt.plot([t, t],[0, np.sin(t)], color=\u0026#39;red\u0026#39;, linewidth=2.5, linestyle=\u0026#34;--\u0026#34;) plt.scatter([t, ],[np.sin(t), ], 50, color=\u0026#39;red\u0026#39;) plt.annotate(r\u0026#39;$cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$\u0026#39;, xy=(t, np.cos(t)), xycoords=\u0026#39;data\u0026#39;, xytext=(-90, -50), textcoords=\u0026#39;offset points\u0026#39;, fontsize=16, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, connectionstyle=\u0026#34;arc3,rad=.2\u0026#34;)) 坐标标签显示方案 # plt.setp(plt.gca().get_xticklabels(), rotation=20, horizontalalignment=\u0026#39;right\u0026#39;) # 貌似除了角度和right，没有了修改内容 来画一个动态图吧（感觉没啥作用所以就小标题了） # import matplotlib.pyplot as plt from matplotlib.patches import Circle import numpy as np import math plt.close() #clf() # 清图 cla() # 清坐标轴 close() # 关窗口 fig=plt.figure() ax=fig.add_subplot(1,1,1) ax.axis(\u0026#34;equal\u0026#34;) #设置图像显示的时候XY轴比例 plt.grid(True) #添加网格 plt.ion() #interactive mode on打开交互模式 而不是plt.show() IniObsX=0000 IniObsY=4000 IniObsAngle=135 IniObsSpeed=10*math.sqrt(2) #米/秒 print(\u0026#39;开始仿真\u0026#39;) try: for t in range(180): #障碍物船只轨迹 obsX=IniObsX+IniObsSpeed*math.sin(IniObsAngle/180*math.pi)*t obsY=IniObsY+IniObsSpeed*math.cos(IniObsAngle/180*math.pi)*t ax.scatter(obsX,obsY,c=\u0026#39;b\u0026#39;,marker=\u0026#39;.\u0026#39;) #散点图 #ax.lines.pop(1) 删除轨迹 #下面的图,两船的距离 plt.pause(0.1) except Exception as err: print(err) pandas # DataFrame # import pandas as pd import numpy as np a = {\u0026#39;a\u0026#39;:[\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;], \u0026#39;b\u0026#39;:[1,2,3], \u0026#39;c\u0026#39;:[\u0026#39;lo\u0026#39;, \u0026#39;hel\u0026#39;, \u0026#39;hi\u0026#39;], \u0026#39;d\u0026#39;:[7,8,9]} df = pd.DataFrame(a) # 字典转换为dataFrame（每一个Key 和 Value构成一列，key为列标） df = df.set_index(\u0026#39;a\u0026#39;) # 将‘a‘列设置为行标 sr = pd.Series(a) sr2 = df[\u0026#39;b\u0026#39;] df[[\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;]].to_records()[1][\u0026#39;b\u0026#39;] df[[\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;]] columns index # 列，参数(行) 取用方法 # dfValue.loc[indexKey][colKey] 一个将DataFrame字符串化之后重新解析的程序😓 # def parseSTR(self, _str, indexKey, colKey, setIndexNum=0, setColNum=0): \u0026#34;\u0026#34;\u0026#34; 通过setIndexNum来确定第几列数据为行标题， setColNum确定使用第几行数据作为列标题 返回通过indexKey行标题 与 colKey列标题 确定的结果 \u0026#34;\u0026#34;\u0026#34; rows = _str.split(\u0026#39;\\n\u0026#39;) columns = rows[0].split(\u0026#39;,\u0026#39;)[1:] tempRow = [] index = [] for row in rows[1:]: if len(row): index.append(row.split(\u0026#39;,\u0026#39;)[setIndexNum]) tempRow.append(row.split(\u0026#39;,\u0026#39;)[1:]) dfValue = pd.DataFrame(tempRow, index=index, columns=columns) try: return dfValue.loc[indexKey][colKey] except: print u\u0026#39;【error:】信息不全\u0026#39; return None Emm,有点儿… 嗯… 嗯…\nnumpy # random # random.seed(int类型) # 理解可以为设定开始随机的开始，也就是说每次设定之后再开始取值就会得到相同的随机数() 即 np.random.seed(1)\nnp.random.random(1)\nnp.random.seed(1) np.random.random(1) array([ 0.417022])\narray([ 0.417022])\n标准差 # a = np.arange(10) np.std(a) a.std() 样本标准差 # a.std(ddof = 1) np.std(a, ddof = 1) 以上 a.std 只有当a为\u0026lt;type \u0026rsquo;numpy.ndarray\u0026rsquo;\u0026gt; 即用numpy生成的矩阵，array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])才可有，如果是python的列表list 则只能用np.std 来算\nscikit-learn # OpenCV # Insatll # caffe：\nsudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler sudo apt-get install --no-install-recommends libboost-all-dev sudo apt-get install libatlas-base-dev sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev PIL # his = im.histogram() values = {}\nfor i in range(256): values[i] = his[i]\nfor j,k in sorted(values.items(),key=lambda x:x[1],reverse = True)[:10]: print j,k\n爬虫 # 先链接 为实例视频教程，貌似不错，还没看。\n问题 # 虽然, 以前已经积累了一些东西, 知道\nheaders cookie 啥的, 但今天突然碰到了这个报错: Caused by SSLError(SSLError(\u0026ldquo;bad handshake: Error([(\u0026lsquo;SSL routines\u0026rsquo;, \u0026rsquo;tls_process_server_certificate\u0026rsquo;, \u0026lsquo;certificate verify failed\u0026rsquo;)])\n没见过, 之后碰到其余, 统一汇总在此.\nSSLError HTTPS # 有人指点到: 因用https的缘故, 其中报 verify failed 所以可以通过\nrequests.get(url, verify=False) 将verify关闭可通过.\nSelenium # 从网页粘来的，下方有作者以及来源链接，格式就保留原有不改了… # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.taobao.com/')\n显示等待10s # wait = WebDriverWait(browser, 10)\n等待直到元素加载出 # input = wait.until(EC.presence_of_element_located((By.ID, \u0026lsquo;q\u0026rsquo;)))\n等待直到元素可点击 # button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \u0026lsquo;.btn-search\u0026rsquo;))) print(input, button) from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.common.keys import Keys from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait\n创建一个浏览器对象 # browser = webdriver.Chrome() try: # 开启一个浏览器并访问https://www.baidu.com browser.get(\u0026lsquo;https://www.baidu.com\u0026rsquo;) # 在打开的网页响应中根据id查找元素 获取到查询框 input = browser.find_element_by_id(\u0026lsquo;kw\u0026rsquo;) # 向查询框中输入Python input.send_keys(\u0026lsquo;Python\u0026rsquo;) # 模拟回车 input.send_keys(Keys.ENTER) # 显示等待， 等待10秒 wait = WebDriverWait(browser, 10) # 显式等待指定某个条件，然后设置最长等待时间。如果在这个时间还没有找到元素，那么便会抛出异常 wait.until(EC.presence_of_element_located((By.ID,\u0026lsquo;content_left\u0026rsquo;))) # 输出当前的url print(browser.current_url) # 输出Cookies print(browser.get_cookies()) # 输出页面响应内容 print(browser.page_source) finally: pass # 关闭浏览器 browser.close() 2、Selenium声明浏览器对象from selenium import webdriver\nbrowser = webdriver.Chrome() browser = webdriver.Firefox() browser = webdriver.Edge() browser = webdriver.PhantomJS() browser = webdriver.Safari() 3、查找元素3.1、查找单个元素from selenium import webdriver\n申明一个浏览器对象 # browser = webdriver.Chrome()\n使用浏览器访问淘宝 # browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;)\n在响应结果中通过id查找元素 # input_first = browser.find_element_by_id(\u0026lsquo;q\u0026rsquo;)\n在响应结果中通过css选择器查找元素 # input_second = browser.find_element_by_css_selector(\u0026rsquo;#q\u0026rsquo;)\n在响应结果中通过xpath查找元素 # input_third = browser.find_element_by_xpath(\u0026rsquo;//*[@id=\u0026ldquo;q\u0026rdquo;]\u0026rsquo;) print(input_first) print(input_second) print(input_third) browser.close() find_element_by_name 通过name查找find_element_by_xpath 通过xpath查找find_element_by_link_text 通过链接查找find_element_by_partial_link_text 通过部分链接查找find_element_by_tag_name 通过标签名称查找find_element_by_class_name 通过类名查找find_element_by_css_selector 通过css选择武器查找from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome()\n使用浏览器访问淘宝 # browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;)\n第二种方式，通过使用By.xxx指定查找方式 # input = browser.find_element(By.ID,\u0026lsquo;q\u0026rsquo;) print(input) browser.close() 3.2、多个元素from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome()\n使用浏览器访问淘宝 # browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;)\n根据选择查找多个元素 # input_first = browser.find_elements_by_css_selector(\u0026rsquo;.service-bd li\u0026rsquo;) input_second = browser.find_elements(By.CSS_SELECTOR,\u0026rsquo;.service-bd li\u0026rsquo;) print(input_first) print(input_second) browser.close() find_elements_by_namefind_elements_by_xpathfind_elements_by_link_textfind_elements_by_partial_link_textfind_elements_by_tag_namefind_elements_by_class_namefind_elements_by_css_selector4、元素交互操作对获取的元素调用交互方法 import time from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome()\n使用浏览器访问淘宝 # browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;)\n根据ID查找元素 # input_search = browser.find_element(By.ID,\u0026lsquo;q\u0026rsquo;)\n模拟输入PSV到输入框 # input_search.send_keys(\u0026lsquo;PSV\u0026rsquo;) time.sleep(2)\n清空输入 # input_search.clear() input_search.send_keys(\u0026lsquo;3DS\u0026rsquo;) button = browser.find_element(By.CLASS_NAME,\u0026lsquo;btn-search\u0026rsquo;)\n模拟点击 # button.click() 更多的操作 http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement5、交互动作from selenium import webdriver from selenium.webdriver import ActionChains\nbrowser = webdriver.Chrome() url = \u0026lsquo;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable' browser.get(url)\n切换id为iframeResult的frame # browser.switch_to.frame(\u0026lsquo;iframeResult\u0026rsquo;) source = browser.find_element_by_css_selector(\u0026rsquo;#draggable\u0026rsquo;) target = browser.find_element_by_css_selector(\u0026rsquo;#droppable\u0026rsquo;) actions = ActionChains(browser) actions.drag_and_drop(source, target) actions.perform() 更多操作http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains6、执行JavaScriptfrom selenium import webdriver\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore')\n执行JavaScript脚本 # browser.execute_script(\u0026lsquo;window.scrollTo(0, document.body.scrollHeight)\u0026rsquo;) browser.execute_script(\u0026lsquo;alert(\u0026ldquo;To Bottom\u0026rdquo;)\u0026rsquo;) 7、获取元素信息7.1、获取属性from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') logo = browser.find_element(By.ID,\u0026lsquo;zh-top-link-logo\u0026rsquo;)\n获取属性 # print(logo.get_attribute(\u0026lsquo;class\u0026rsquo;)) print(logo) browser.close() 7.2、获取文本值from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') submit = browser.find_element(By.ID,\u0026lsquo;zu-top-add-question\u0026rsquo;)\n获取文本值 # print(submit.text) print(submit) browser.close() 7.3、获取ID、位置、标签名、大小from selenium import webdriver from selenium.webdriver.common.by import By\n申明一个浏览器对象 # browser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore') submit = browser.find_element(By.ID,\u0026lsquo;zu-top-add-question\u0026rsquo;)\n获取id 0.04584255991652042-1 # print(submit.id)\n获取位置 {\u0026lsquo;y\u0026rsquo;: 7, \u0026lsquo;x\u0026rsquo;: 675} # print(submit.location)\n获取标签名称 button # print(submit.tag_name)\n获取大小 {\u0026lsquo;width\u0026rsquo;: 66, \u0026lsquo;height\u0026rsquo;: 32} # print(submit.size) browser.close() 8、Framefrom selenium import webdriver from selenium.common.exceptions import NoSuchElementException\nbrowser = webdriver.Chrome() url = \u0026lsquo;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable' browser.get(url)\n将操作的响应数据换成iframeResult # browser.switch_to.frame(\u0026lsquo;iframeResult\u0026rsquo;) source = browser.find_element_by_css_selector(\u0026rsquo;#draggable\u0026rsquo;) print(source) try: logo = browser.find_element_by_class_name(\u0026rsquo;logo\u0026rsquo;) except NoSuchElementException: print(\u0026lsquo;NO LOGO\u0026rsquo;)\n切换成父元素 # browser.switch_to.parent_frame() logo = browser.find_element_by_class_name(\u0026rsquo;logo\u0026rsquo;) print(logo) print(logo.text) 9、等待9.1、隐式等待当使用了隐式等待执行测试的时候，如果 WebDriver没有在 DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常, 换句话说，当查找元素或元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0from selenium import webdriver\nbrowser = webdriver.Chrome()\n等待10秒 # browser.implicitly_wait(10) browser.get(\u0026lsquo;https://www.zhihu.com/explore') input = browser.find_element_by_class_name(\u0026lsquo;zu-top-add-question\u0026rsquo;) print(input) 9.2、显示等待显式等待指定某个条件，然后设置最长等待时间。如果在这个时间还没有找到元素，那么便会抛出异常了。 from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.taobao.com/')\n显示等待10s # wait = WebDriverWait(browser, 10)\n等待直到元素加载出 # input = wait.until(EC.presence_of_element_located((By.ID, \u0026lsquo;q\u0026rsquo;)))\n等待直到元素可点击 # button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \u0026lsquo;.btn-search\u0026rsquo;))) print(input, button) title_is 标题是某内容title_contains 标题包含某内容presence_of_element_located 元素加载出，传入定位元组，如(By.ID, \u0026lsquo;p\u0026rsquo;)visibility_of_element_located 元素可见，传入定位元组visibility_of 可见，传入元素对象presence_of_all_elements_located 所有元素加载出text_to_be_present_in_element 某个元素文本包含某文字text_to_be_present_in_element_value 某个元素值包含某文字frame_to_be_available_and_switch_to_it frame加载并切换invisibility_of_element_located 元素不可见element_to_be_clickable 元素可点击staleness_of 判断一个元素是否仍在DOM，可判断页面是否已经刷新element_to_be_selected 元素可选择，传元素对象element_located_to_be_selected 元素可选择，传入定位元组element_selection_state_to_be 传入元素对象以及状态，相等返回True，否则返回Falseelement_located_selection_state_to_be 传入定位元组以及状态，相等返回True，否则返回Falsealert_is_present 是否出现Alert更多操作http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions10、前进后退import time from selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.baidu.com/') browser.get(\u0026lsquo;https://www.taobao.com/') browser.get(\u0026lsquo;https://www.python.org/') browser.back() time.sleep(1) browser.forward() browser.close() 11、Cookiesfrom selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.zhihu.com/explore')\n获得cookies # print(browser.get_cookies())\n添加cookie # browser.add_cookie({\u0026rsquo;name\u0026rsquo;: \u0026rsquo;name\u0026rsquo;, \u0026lsquo;domain\u0026rsquo;: \u0026lsquo;www.zhihu.com\u0026rsquo;, \u0026lsquo;value\u0026rsquo;: \u0026lsquo;germey\u0026rsquo;}) print(browser.get_cookies())\n删除所有cookies # browser.delete_all_cookies() print(browser.get_cookies()) 12、选项卡管理import time from selenium import webdriver\nbrowser = webdriver.Chrome() browser.get(\u0026lsquo;https://www.baidu.com\u0026rsquo;)\n打开一个选项卡 # browser.execute_script(\u0026lsquo;window.open()\u0026rsquo;) print(browser.window_handles)\n选择第二个选项卡 # browser.switch_to_window(browser.window_handles[1]) browser.get(\u0026lsquo;https://www.taobao.com\u0026rsquo;) time.sleep(1) browser.switch_to_window(browser.window_handles[0]) browser.get(\u0026lsquo;https://python.org\u0026rsquo;) 13、异常处理from selenium import webdriver from selenium.common.exceptions import TimeoutException, NoSuchElementException\nbrowser = webdriver.Chrome() try: browser.get(\u0026lsquo;https://www.baidu.com\u0026rsquo;) except TimeoutException: print(\u0026lsquo;Time Out\u0026rsquo;) try: browser.find_element_by_id(\u0026lsquo;hello\u0026rsquo;) except NoSuchElementException: print(\u0026lsquo;No Element\u0026rsquo;) finally: browser.close() 作者：蒋蜀黍 Python爱好者社区专栏作者 授权原创发布，请勿转载，谢谢。出处：Selenium 库学习笔记\nTensorFlow # Variable # 必须用到: ```init = tf.initialize_all_variables() #初始化全部变量\n随后即可: ```sess.run(init)\nTensorflow 笔记 # 這是在對照官網學習時的前期入門筆記，其實和官網基本沒有區別，好吧，真的沒有區別。因爲官網真的寫的太好了。 至於我爲什麼要寫出來，是因爲我之前寫在了紙上，對於邏輯的把握很給力，所以在寫一邊。\n不過TensorFlow 變動真的很大，版本更迭也很快，所以，下方只是理清邏輯，具體的東西還是去官網比較好。只不過我這兒網謎之很難等上去…\n總而言之一句話，先搭好架子再選擇填充材料。就是它的核心邏輯了。而改進也是在架子基礎上去優化優化器。嗯…現在理解就是這樣。\n1 # 导入 # import tensorflow as tf 步骤：①构建计算图 ②运行计算图\n2 # Build a simple computational Graph # node1 = tf.contant(3.0, dtype = tf.float32) node2 = tf.contant(4.0) #also tf.float32 impicitly print (node1, node2) 输出为： # Tensor (\u0026quot;Cast: 0\u0026quot;, shape = (), dtype = float) Tensor (\u0026quot;Cast_1: 0\u0026quot;, shape = (), dtype = float) 打印并不输出值3.0，4.0，而在评估时分别产生3.0和4.0节点。欲实际评估节点，We must run the computational graph within a session. A seesion encapsulation the control and state of the tensorflow runtime.\n3 # Creates a session object , 然后调用run方法运行足够的computational graph to envlute node1 and node2 # sess = tf.Session() print (sess.run([node1, node2])) 输出为： # [3.0, 4.0] #可见预期值 4 # We can build more complicated computations by combining Tensor nodes with operations # node3 = tf.add(node1, node2) print (\u0026quot;node3: \u0026quot;, node3) print (\u0026quot;sess.run(node3):\u0026quot;, sess.run(node3)) 输出为： # node3: Tensor(\u0026quot;Add:0\u0026quot;, shape = (1,dtype = float32)) sess.run(node3): 7.0 5 # 更进一步的，A graph can be parameterized. To accept external input , 称为placeholders # a = tf.placeholder(tf.float32) b = tf.placeholder(tf.float32) adder_note = a + b #provide a shortcut for tf.add(a, b) and can with multiple input by using print (sess.run(add_note, {a:3, b:4.5})) print (sess.run(add_note, {a:[1, 3], b:[2, 4]})) 输出为： # 7.5 [3. 7.] 5.1 # more complex by adding anther aperation. for example: # add_and_triple = adder_note * 3 print (sess.run(add_and_triple, {a:3, b:4.5})) 输出为： # 22.5 In TensorBoard(Tensorflow圖形化界面): 图片.jpg 是下面a+b```` 然后连接到adder_node ,随后再连接到y(add_and_triple)```\n5.2 # That a model that can take arbitary inputs:To mode the modeel trainable,need to modify the graph to get new a outputs with the some input : Variables allow us: # w = tf.Variables([ .3], dtype = tf.float32) b = tf.Variables([ - .3], dtype = tf.float32) x = tf.placeholder(tf.float32) linear_model = w * x + b #线性模型 6 # 使用tf.constant :调用、初始化常数 用tf.Vaiables :變量不被初始化，調用欲初始化所有變量，必須calll a special operation: # init = tf.global_variables_initializer() sess.run(init) 7 # x is a placeholder, we can evaluate lnear_model for several values of x simultaneausly as follow: # print (sess.run(linear_model, {x:[1,2,3,4]})) 輸出爲： # [0. 0.30000001 0.60000002 0.90000004] 8 # 有以上結果並不知好壞，因此編寫損失函數： # y = tf.placeholder(tf.float32) squared_deltas = tf.square(linear_model - y) #平方（下方差和） loss = tf.reduce_sum(squred_deltas) #差和（上方平方） print (sess.run)loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]}) 輸出爲： # 23.66 #損失值：差平方和 8.1 # We could improve this manually W,b to perfact values of -1 and 1. A variable is initializef to the value provided to tf.Variable but can be charged using operation like tf.assign # W = -1 and b = 1 are optimal parameters:(最優參數) # fixW = tf.assign(W, [-1. ]) fixb = tf.assign(b,[1. ]) sess.run(fixW, fixb) print(sess.run(loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]})) 輸出爲： # 0, 0 # The final print shows the loss now is zero ! 9 # 模型保存与加载： # 保存： # saver = tf.train.Saver() # 生成saver with tf.Session() as sess: sess.run(tf.global_variables_initializer()) # 先对模型初始化 # 然后将数据丢入模型进行训练blablabla # 训练完以后，使用saver.save 来保存 saver.save(sess, \u0026quot;save_path/file_name\u0026quot;) #file_name如果不存在的话，会自动创建 加载： # saver = tf.train.Saver() with tf.Session() as sess: #参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的值给覆盖 sess.run(tf.global_variables_initializer()) saver.restore(sess, \u0026quot;save_path/file_name\u0026quot;) #会将已经保存的变量值resotre到 变量中。 10 # 图形化操作： # \u0026gt;http://blog.csdn.net/u014595019/article/details/53912710 这篇写的还不错，等之后用过之后再写。\nVariable # 必须用到: ```init = tf.initialize_all_variables()\t#初始化全部变量\n随后即可: ```sess.run(init)\nTensorflow 笔记 # 這是在對照官網學習時的前期入門筆記，其實和官網基本沒有區別，好吧，真的沒有區別。因爲官網真的寫的太好了。 至於我爲什麼要寫出來，是因爲我之前寫在了紙上，對於邏輯的把握很給力，所以在寫一邊。\n不過TensorFlow 變動真的很大，版本更迭也很快，所以，下方只是理清邏輯，具體的東西還是去官網比較好。只不過我這兒網謎之很難等上去…\n總而言之一句話，先搭好架子再選擇填充材料。就是它的核心邏輯了。而改進也是在架子基礎上去優化優化器。嗯…現在理解就是這樣。\n1 # 导入 # import tensorflow as tf 步骤：①构建计算图\t②运行计算图\n2 # Build a simple computational Graph # node1 = tf.contant(3.0, dtype = tf.float32) node2 = tf.contant(4.0)\t#also tf.float32 impicitly print (node1, node2) 输出为： # Tensor (\u0026quot;Cast: 0\u0026quot;, shape = (), dtype = float) Tensor (\u0026quot;Cast_1: 0\u0026quot;, shape = (), dtype = float) 打印并不输出值3.0，4.0，而在评估时分别产生3.0和4.0节点。欲实际评估节点，We must run the computational graph within a session. A seesion encapsulation the control and state of the tensorflow runtime.\n3 # Creates a session object , 然后调用run方法运行足够的computational graph to envlute node1 and node2 # sess = tf.Session() print (sess.run([node1, node2])) 输出为： # [3.0, 4.0]\t#可见预期值 4 # We can build more complicated computations by combining Tensor nodes with operations # node3 = tf.add(node1, node2) print (\u0026quot;node3: \u0026quot;, node3) print (\u0026quot;sess.run(node3):\u0026quot;, sess.run(node3)) 输出为： # node3: Tensor(\u0026quot;Add:0\u0026quot;, shape = (1,dtype = float32)) sess.run(node3): 7.0 5 # 更进一步的，A graph can be parameterized. To accept external input , 称为placeholders # a = tf.placeholder(tf.float32) b = tf.placeholder(tf.float32) adder_note = a + b\t#provide a shortcut for tf.add(a, b) and can with multiple input by using print (sess.run(add_note, {a:3, b:4.5})) print (sess.run(add_note, {a:[1, 3], b:[2, 4]})) 输出为： # 7.5 [3. 7.] 5.1 # more complex by adding anther aperation. for example: # add_and_triple = adder_note * 3 print (sess.run(add_and_triple, {a:3, b:4.5})) 输出为： # 22.5 In TensorBoard(Tensorflow圖形化界面): 图片.jpg\t是下面a+b```` 然后连接到adder_node ,随后再连接到y(add_and_triple)```\n5.2 # That a model that can take arbitary inputs:To mode the modeel trainable,need to modify the graph to get new a outputs with the some input : Variables allow us: # w = tf.Variables([ .3], dtype = tf.float32) b = tf.Variables([ - .3], dtype = tf.float32) x = tf.placeholder(tf.float32) linear_model = w * x + b\t#线性模型 6 # 使用tf.constant :调用、初始化常数 用tf.Vaiables :變量不被初始化，調用欲初始化所有變量，必須calll a special operation: # init = tf.global_variables_initializer() sess.run(init) 7 # x is a placeholder, we can evaluate lnear_model for several values of x simultaneausly as follow: # print (sess.run(linear_model, {x:[1,2,3,4]})) 輸出爲： # [0. 0.30000001 0.60000002 0.90000004] 8 # 有以上結果並不知好壞，因此編寫損失函數： # y = tf.placeholder(tf.float32) squared_deltas = tf.square(linear_model - y)\t#平方（下方差和） loss = tf.reduce_sum(squred_deltas)\t#差和（上方平方） print (sess.run)loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]}) 輸出爲： # 23.66\t#損失值：差平方和 8.1 # We could improve this manually W,b to perfact values of -1 and 1. A variable is initializef to the value provided to tf.Variable but can be charged using operation like tf.assign # W = -1 and b = 1 are optimal parameters:(最優參數) # fixW = tf.assign(W, [-1. ]) fixb = tf.assign(b,[1. ]) sess.run(fixW, fixb) print(sess.run(loss, {x:[1, 2, 3, 4], y:[0, -1, -2, -3]})) 輸出爲： # 0, 0 # The final print shows the loss now is zero ! 9 # 模型保存与加载： # 保存： # saver = tf.train.Saver()\t# 生成saver with tf.Session() as sess: sess.run(tf.global_variables_initializer())\t# 先对模型初始化 # 然后将数据丢入模型进行训练blablabla # 训练完以后，使用saver.save 来保存 saver.save(sess, \u0026quot;save_path/file_name\u0026quot;)\t#file_name如果不存在的话，会自动创建 加载： # saver = tf.train.Saver() with tf.Session() as sess:\t#参数可以进行初始化，也可不进行初始化。即使初始化了，初始化的值也会被restore的值给覆盖 sess.run(tf.global_variables_initializer()) saver.restore(sess, \u0026quot;save_path/file_name\u0026quot;)\t#会将已经保存的变量值resotre到 变量中。 10 # 图形化操作： # \u0026lt;http://blog.csdn.net/u014595019/article/details/53912710\u0026gt; 这篇写的还不错，等之后用过之后再写。\n"},{"id":76,"href":"/docs/programmer/tipsofproblems/","title":"解决问题","section":"程序员笔记","content":"\n各种一键问题解决方案 # Windows下Git问题 # Linux没啥问题,但在Win下报checkout失败,路径问题 git config core.protectNTFS false docker - supervisord 禁用日志文件或使用 logfile=/dev/stdout # from: https://www.coder.work/article/100835 标签 docker supervisord\n[supervisord] nodaemon=true logfile=/dev/stdout pidfile=/var/run/supervisord.pid childlogdir=/var/log/supervisor 当我这样做时，这个主管会崩溃，因为它无法在/dev/stdout 中寻找\n如何禁用 supervisord 在我的 docker 容器中创建任何日志文件？\n最佳答案\n对于主主管，nodaemon 将导致日志转到 stdout\n[supervisord] nodaemon=true logfile=/dev/null logfile_maxbytes=0 然后将每个托管进程的日志发送到标准输出文件描述符/dev/fd/1\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 redirect_stderr=true 或者，如果您希望将 stderr 保留在不同的流上:\n[program:x] command=echo test stdout_logfile=/dev/fd/1 stdout_logfile_maxbytes=0 stderr_logfile=/dev/fd/2 stderr_logfile_maxbytes=0 关于docker - supervisord 禁用日志文件或使用 logfile=/dev/stdout，我们在Stack Overflow上找到一个类似的问题： https://stackoverflow.com/questions/45645758/\ndocker中执行sed报Device or resource busy错误的处理原因及方式 转载 # kuSorZ 博主文章分类：Linux 文章标签: docker | sed 文章分类: Docker 原文出处： https://www.cnblogs.com/xuxinkun/p/7116737.html错误现象\n在docker容器中想要修改/etc/resolv.conf中的namesever，使用sed命令进行执行时遇到错误：\n/ # sed -i \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf sed: can\u0026rsquo;t move \u0026lsquo;/etc/resolv.conf73UqmG\u0026rsquo; to \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n但是可以通过vi/vim直接修改这个文件/etc/resolv.conf这个文件的内容。 问题原因\nsed命令的实质并不是修改文件，而是产生一个新的文件替换原有的文件。这里我们做了一个实验。\n我先创建了一个test.txt的文件，文件内容是123。然后我使用sed命令对文件内容进行了替换。再次查看test.txt。\n/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 265 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:28:35.000000000Modify: 2017-07-04 06:28:17.000000000Change: 2017-07-04 06:29:03.000000000/ # cat test.txt 123/ # sed -i \u0026rsquo;s/123/321/g\u0026rsquo; test.txt/ # stat test.txt File: test.txt Size: 4 Blocks: 8 IO Block: 4096 regular fileDevice: fd28h/64808d Inode: 266 Links: 1Access: (0644/-rw-r\u0026ndash;r\u0026ndash;) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2017-07-04 06:29:31.000000000Modify: 2017-07-04 06:29:31.000000000Change: 2017-07-04 06:29:31.000000000/ # cat test.txt321\n可以看到文件内容被正确修改了，但是同时，文件的inode也修改了。说明了实质上是新生成的文件替换了原有的文件。但是vim/vi是在原文件基础上修改的，所以inode没有变化。\n在docker中，/etc/resolv.conf是通过挂载入容器的。所以当你想去删除这个挂载文件，也就是挂载点时，自然就会报Device or resource busy。\n这个跟是不是特权privilege没有关系。即使是privilege的容器，也会有这个问题。 / # rm /etc/resolv.conf rm: can\u0026rsquo;t remove \u0026lsquo;/etc/resolv.conf\u0026rsquo;: Device or resource busy\n其实不仅仅/etc/resolv.conf，还有/etc/hostname，/etc/hosts等文件都是通过挂载方式挂载到容器中来的。所以想要用sed对他们进行修改，都会遇到这样的问题。我们可以通过df -h查看容器内的挂载情况。\n/ # df -h Filesystem Size Used Available Use% Mounted on/dev/mapper/docker-253:2-807144231-37acfcd86387ddcbc52ef8dac69d919283fc5d9d8ab5f55fd23d1c782e3b1c70 10.0G 33.8M 10.0G 0% /tmpfs 15.4G 0 15.4G 0% /devtmpfs 15.4G 0 15.4G 0% /sys/fs/cgroup/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /run/secrets/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /dev/termination-log/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/resolv.conf/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostname/dev/mapper/centos-home 212.1G 181.8G 30.3G 86% /etc/hostsshm 64.0M 0 64.0M 0% /dev/shmtmpfs 15.4G 0 15.4G 0% /proc/kcoretmpfs 15.4G 0 15.4G 0% /proc/timer_stats\n如何解决\n使用vi固然可以，但是对于批量操作就不是很合适了。可以通过sed和echo的组合命令echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf 即可实现替换。\n/ # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.1options ndots:5/ # echo \u0026ldquo;$(sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf)\u0026rdquo; \u0026gt; /etc/resolv.conf / # cat /etc/resolv.conf search default.svc.games.local svc.games.local games.localnameserver 192.168.1.254options ndots:5\n这里如果使用sed \u0026rsquo;s/192.168.1.1/192.168.1.254/g\u0026rsquo; /etc/resolv.conf \u0026gt; /etc/resolv.conf是无效的。最终会导致/etc/resolv.conf内容为空。\n示例 # Dockerfile # CMD mkdir -p /var/log/scancenter \\ \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \\ \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini --log-master k8s yaml # spec: containers: - command: - /bin/sh - -c - mkdir -p /var/log/scancenter \u0026amp;\u0026amp; echo -e \u0026#34;10.120.16.12\\tapi.s.com\\n10.5.25.5\\tpp.api.com\u0026#34; \u0026gt;\u0026gt; /etc/hosts \u0026amp;\u0026amp; echo \u0026#34;$(sed \u0026#39;s/^-e //g\u0026#39; /etc/hosts)\u0026#34; \u0026gt; /etc/hosts \u0026amp;\u0026amp; sed \u0026#39;s/INFO\\|ERROR/DEBUG/g\u0026#39; -i scancenter/logging.cfg \u0026amp;\u0026amp; uwsgi /opt/disk2/var/www/scancenter/3rd/conf/uwsgi-docker/uwsgi.ini env: - name: POD_IP_ADDRESS valueFrom: fieldRef: apiVersion: v1 fieldPath: status.podIP "}]