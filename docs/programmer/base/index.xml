<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ian's Blog</title><link>http://example.org/docs/programmer/base/</link><description>Recent content on Ian's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 07 Sep 2023 20:58:56 +0000</lastBuildDate><atom:link href="http://example.org/docs/programmer/base/index.xml" rel="self" type="application/rss+xml"/><item><title>k8s技术分享</title><link>http://example.org/docs/programmer/base/k8s-%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/</link><pubDate>Thu, 07 Sep 2023 20:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/base/k8s-%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/</guid><description>k8s技术分享 # 工作负载资源 # 一、pod # 1. 概要 # 可创建管理、最小的可部署计算单元，是可以在主机上运行的容器的集合 我们的服务都在其中运行。如我们的服务是nginx，则最内层是我们的服务 nginx，运行在 container 容器当中。container (容器) 的本质是进程，而 pod 是管理这一组进程的资源 所以pod可视为一个极为轻量化、没插网线的电脑，如果所需任务无需交互，那么用pod就很合适。例如给它挂载一个文件来训练模型、生成报表，可以根据场景使用 Job 或者 CronJob 或者其它 图示关系如下 # ![[k8s-pod-insert.png]]
2. pod网络 # 当然，pod 可以管理多个 container，又因为container (容器) 的本质是进程，如果有本地网络通信需求(使用 localhost 或者 Socket 文件进行本地通信)，在这些场景中使用 pod 管理多个 container 就非常的推荐。
如下图展示了Pod网络所依赖的3个网络设备
1. eth0是节点主机上的网卡，支持该节点流量出入的设备、也是支持集群节点间IP寻址和互通的设备；
2. docker0是一个虚拟网桥，可以简单理解为一个虚拟交换机，支持该节点上的Pod之间进行IP寻址和互通的设备；
3. veth0则是Pod1的虚拟网卡，支持该Pod内容器互通和对外访问的虚拟设备；
4. docker0网桥和veth0网卡，都是linux支持和创建的虚拟网络设备；
5. pause属于特殊容器，其运行的唯一目的是为Pod建立共享的veth0网络接口
![[k8s-nginx-pod.png]]
二、deployment、StatefulSet # 1. 概要 # Deployment 使得 Pod 和 ReplicaSet 能够进行声明式更新
StatefulSet 表示一组具有一致身份的 Pod：
1. 身份定义为：</description></item><item><title>k8s网络配置说明</title><link>http://example.org/docs/programmer/base/k8s-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</link><pubDate>Thu, 07 Sep 2023 20:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/base/k8s-%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E/</guid><description> k8s 网络介绍 # Ingress 定义路由，本质只是配置文件，需要Ingress Controller读取执行 当集群中存在多个Controller时，就需要使用Ingress Class来区分对应的是哪个</description></item><item><title>k8s学习-常用命令和配置文件</title><link>http://example.org/docs/programmer/base/k8s%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/</link><pubDate>Mon, 27 Mar 2023 10:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/base/k8s%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/</guid><description>k8s学习 # 常用命令 # kubectl apply -f rcm_log_monut_k8s_pod.yaml kubectl get pod -A kubectl get pod -all-namespaces kubectl get node kubectl get deploy 持久卷 - PersistentVolume kubectl get persistentvolume kubectl describe persistentvolume example-pv kubectl **delete** persistentvolume example-pv 从kubectl cp -n &amp;lt;命名空间&amp;gt; -c :xxx.json xxx.json configmap / secret 存储文件内容 # sftpkey 为名称
新建 # kubectl create secret generic sftpkey --from-file=/etc/id_rsa # kubectl create -n {NAMESPACE} secret generic sftpkey --from-file=/etc/id_rsa 删除 # kubectl delete secret sftpkey</description></item><item><title>PyPi</title><link>http://example.org/docs/programmer/base/pypi/</link><pubDate>Thu, 31 Mar 2022 15:15:14 +0000</pubDate><guid>http://example.org/docs/programmer/base/pypi/</guid><description>示例项目 # py-muti-scrcpy
配置文件 # pyproject
工具介绍 # poetry
增加安装包 # 直接修改pyproject.toml文件并不能生效, 因为还依赖于poetry.lock
可使用poetry add {xxx}进行添加
注意事项 # 需要链接外网 # HTTPSConnectionPool(host=&amp;#39;files.pythonhosted.org&amp;#39;, port=443): Max retries exceeded with url: /packages/17/61/32c3ab8951142e061587d957226b5683d1387fb22d95b4f69186d92616d1/typing_extensions-4.0.0-py3-none-any.whl (Caused by ProxyError(&amp;#39;Cannot connect to proxy.&amp;#39;, ConnectionResetError(54, &amp;#39;Connection reset by peer&amp;#39;))) HTTPSConnectionPool(host=&amp;#39;pypi.org&amp;#39;, port=443): Max retries exceeded with url: /pypi/colorama/0.4.4/json (Caused by ProxyError(&amp;#39;Cannot connect to proxy.&amp;#39;, ConnectionResetError(54, &amp;#39;Connection reset by peer&amp;#39;))) 需要安装ssl # SSLError HTTPSConnectionPool(host=&amp;#39;pypi.org&amp;#39;, port=443): Max retries exceeded with url: /pypi/importlib-metadata/4.2.0/json (Caused by SSLError(SSLEOFError(8, &amp;#39;EOF occurred in violation of protocol (_ssl.</description></item><item><title>Nginx高可用</title><link>http://example.org/docs/programmer/base/tipsofweb/</link><pubDate>Sun, 09 May 2021 09:56:41 +0000</pubDate><guid>http://example.org/docs/programmer/base/tipsofweb/</guid><description>Keepalived+Nginx实现高可用 # Nginx 关键字 # IO多路复用epoll(IO复用) 轻量,插件: Nginx仅保留了HTTP CPU亲和: 每个worker进程固定在一个CPU Nginx配置 # 代理 # 动静分离 # 动态页面和静态页面交给不同的服务器来解析
负载均衡 # upstream balanceServer { server 10.1.22.33:12345; server 10.1.22.34:12345; server 10.1.22.35:12345; } server { server_name fe.server.com; listen 80; location /api { proxy_pass http://balanceServer; } } 机制 # 默认: 轮询, 单机卡顿, 影响分配在这台服务器下的用户 默认: 权重轮询, 宕机Nginx会自动剔除出队列, ip_hash-来源IP分配分配给同个服务器 fair: 根据相应时间均衡分配, 默认不支持. 需安装upstream_fair, url_hash类ip_hash同样需要安装Nginx的hash软件包. Keepalived 配置 # 粘贴自: 这里
概览 # VIP IP 主机名 Nginx端口 默认主从 192.</description></item><item><title>各个软件换源</title><link>http://example.org/docs/programmer/base/for_china/</link><pubDate>Thu, 22 Apr 2021 17:04:15 +0000</pubDate><guid>http://example.org/docs/programmer/base/for_china/</guid><description>在国内用原源都会很慢, 所以总结一下各个软件(?吧)换源方法.
Qt # 使用Maintain管理kit时，可以在Settings中设置Repositories，设置地址可从Qt Downloads页面查询.
apt # 可解决版本升级时的问题,即使用了国内源,最后一个文件不知道为什么还是从国外拉取&amp;hellip;
# sudo touch /etc/apt/apt.conf sudo vim /etc/apt/apt.conf -&amp;gt; Acquire::http::Proxy &amp;ldquo;http://127.0.0.1:8001&amp;rdquo;;
FreeBSD # mkdir -p /usr/local/etc/pkg/repos vim /usr/local/etc/pkg/repos/bjtu.conf
bjtu: { url: &amp;#34;pkg+http://mirror.bjtu.edu.cn/reverse/freebsd-pkg/${ABI}/quarterly&amp;#34;, mirror_type: &amp;#34;srv&amp;#34;, signature_type: &amp;#34;none&amp;#34;, fingerprints: &amp;#34;/usr/share/keys/pkg&amp;#34;, enabled: yes } FreeBSD: { enabled: no } pkg update
Qt # 源 # 中国科学技术大学：http://mirrors.ustc.edu.cn/qtproject/ 清华大学：https://mirrors.tuna.tsinghua.edu.cn/qt/ 北京理工大学：http://mirror.bit.edu.cn/qtproject/ 中国互联网络信息中心：https://mirrors.cnnic.cn/qt/ Python Pip # pip install --index https://pypi.mirrors.ustc.edu.cn/simple/ dlib(numpy等包名) 源 # 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.</description></item><item><title>tips Of Debuggers</title><link>http://example.org/docs/programmer/base/tipsofdebugers/</link><pubDate>Thu, 10 Jan 2019 12:21:12 +0000</pubDate><guid>http://example.org/docs/programmer/base/tipsofdebugers/</guid><description>Clang &amp;amp;&amp;amp; lldb # 听说clang+lldb &amp;gt;= gcc + gdb, 所以一试:
lldb基本命令 # 与GDB相同
break (b) - 设置断点，也就是程序暂停的地方 run (r) - 启动目标程序，如果遇到断点则暂停 step (s) - 进入下一条指令中的函数内部 backtrace (bt) - 显示当前的有效函数 frame (f) - 默认显示当前栈的内容，可以通过 frame arg 进入特定的 frame（用作输出本地变量） next (n) - 运行当前箭头指向行 continue (c) - 继续运行程序直到遇到断点。 clang hello.c -g -o hello lldb hello # lldb b main run n p str 还有颜色 😂 可视效果确实提高了不少 而且这四个工具可以混用,也蛮好.
GDB # First and foremost, you will need to compile your program with the flag &amp;ldquo;-g&amp;rdquo; (for debug) to run it via GDB.</description></item><item><title>Django的建站的(｡･･)ﾉﾞ</title><link>http://example.org/docs/programmer/base/notesdjango/</link><pubDate>Thu, 07 Jun 2018 16:30:18 +0000</pubDate><guid>http://example.org/docs/programmer/base/notesdjango/</guid><description>author: Ian
Django 的一些东西 # 一些问题 # 使用字体 zh-cn时如果报错: # OSError: No translation files found for default language zh-cn.
LANGUAGE_CODE = &amp;#39;zh-Hans&amp;#39; TIME_ZONE = &amp;#39;Asia/Shanghai&amp;#39; # zh-Hans是简体中文 zh-Hant是繁体中文 # 如果数据库有UTC的时间，那么可以设置： # USE_TZ = True 改为 USE_TZ = False 时区问题 # python3.8/site-packages/django/db/models/fields/init.py:1416: RuntimeWarning: DateTimeField {DATABASEMODEL}.update_time received a naive datetime (2023-09-14 21:55:56) while time zone support is active. warnings.warn(&amp;ldquo;DateTimeField %s received a naive datetime (%s)&amp;rdquo;
这个警告是由于在使用带有时区支持的DateTimeField字段时，传入了一个没有时区信息的datetime对象。要修复这个警告，你可以将传入DateTimeField字段的datetime对象转换为带有时区信息的datetime对象。
有两种方法可以解决这个问题：
使用带有时区信息的datetime对象：确保在创建datetime对象时，使用正确的时区信息。你可以使用pytz库来设置时区信息，例如： from datetime import datetime import pytz # 创建带有时区信息的datetime对象 naive_datetime = datetime(2023, 9, 14, 21, 55, 56) timezone = pytz.</description></item><item><title>tip Of vim</title><link>http://example.org/docs/programmer/base/tipsofvim/</link><pubDate>Tue, 15 May 2018 09:56:41 +0000</pubDate><guid>http://example.org/docs/programmer/base/tipsofvim/</guid><description>Vim 使用 # 除去“简便生活”里的几条配置，在纠结是否添加到别的地方，果然还是单独给vim一个使用手册比较好……
注释 # # 注释 1， 12s/^/#/g --- # 取消注释 1， 12s/^#//g 其实 是vim中的 :s替换命令… 下方解释
或者，使用列编辑的模式:
v、选择区域、ctrl q置行首、I插入#、Esc应用到全列 ctrl v、I、#、Esc 因为有的ctrl q或者ctrl v 不能用…… 取消，即使用上述方法选中行首，删除第一个字节即可了 替换 # :s/oldWords/newWords/g g : 代表当前光标所在行。
由此可知: # ^表行首标识符。 /^/表示行首的空字符。 而取消注释中的/^#/即表示行首的#，被//空字符所替换。
查找高亮 # set hlsearch set nohlsearch 分屏 # 实现 # 在外部使用-o or -O参数 内部split or vsplit 操作 # 移动光标 Ctrl + w hjkl 移动分区Ctrl + w HJKL 统一高度Ctrl + w = 改变高度Ctrl + w +- more and less # 阅读器~~~ 因为经常读大文件发现了这两个的无敌好处——快。</description></item><item><title>编辑器使用</title><link>http://example.org/docs/programmer/base/editer/</link><pubDate>Sat, 29 Oct 2016 16:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/base/editer/</guid><description>Jupyter-Note # 局域网访问 # 方法1: 使用jupyter notebook --generate-config生成配置文件 修改配置文件中c.NotebookApp.allow_root(因为安卓用的Termux跑的,所以伪root),c.NotebookApp.ip这样就能通过局域网和Token访问了 如果想要使用密码(长期使用局域网的话),可以使用from notebook.auth import passwd;passwd()生成加密密码,配置到c.NotebookApp.password 方法2: 如果只是临时的,那传入运行命令肯定最好了,如下可以使用如下格式: jupyter-notebook --allow-root --ip=0.0.0.0 自动补全 # 安装插件: pip install jupyter_contrib_nbextensions -i https://pypi.tuna.tsinghua.edu.cn/simple(此命令包含代理) 到Nbextensions中将Disable改为Enable 开始 Vim # vim 查看日志中文乱码(2021) # .bash_profile # export LC_ALL=en_US.utf-8 .vimrc # set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936 set termencoding=utf-8 set encoding=utf-8 双管齐下, 一个解决系统配置, 一个解决vim配置
中文乱码问题(2018) # 在.bash_profile中增加
export LANG=zh_CN.utf8 export LC_ALL=zh_CN.utf8 即可增加中文支持。 不过，还是
export LANG=en_US.utf8 export LC_ALL=en_US.utf8 比较香，因为中文字体很难看… ^_^: 2019年5月5日19点46分
vscode vs code # venv # Python # Command Palette.</description></item><item><title>Linux</title><link>http://example.org/docs/programmer/base/noteoflinux/</link><pubDate>Fri, 08 Apr 2016 16:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/base/noteoflinux/</guid><description>Ubuntu22.04 依赖项整理 # vbox: libqt5opengl5 kate: konsole Qt5.12.12: mesa-common-dev, libgl1-mesa-dev OpenCV4.6.0: libgtk2.0-dev, pkg-config, libcanberra-gtk-module 如果没有安装这俩依赖不会影响编译，但是编译后会有功能损失，补充安装后不会修复； 如果想修复，只能安装后再编译一次； dpkg .deb # Install # sudo dpkg -i file.deb
c l r P L s # -c列出内容 -l提取包信息 -r移除一个已安装的包 -P完全清除一个已安装包 -L列出安装所有文件清单 -s显示已安装包信息 WSL # wsl问题 因为后面不太喜欢这种东西了,还是上了物理机. 所以就不粘贴过来了.
sudo apt upgrade # E: Sub-process /usr/bin/dpkg returned an error code (1)
解决 # sudu下
备份/var/lib/dpkg/info 新建/var/lib/dpkg/info 重新执行更新 合并/var/lib/dpkg/info 和 备份文件 完 说明 # 非原理性解决方案, 若解决不了, 另寻他法或者需要直击灵魂.</description></item><item><title/><link>http://example.org/docs/programmer/base/argo-workflow%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/argo-workflow%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/</guid><description>Github: https://github.com/argoproj
一、简介 # Argo Workflow 是一个开源的、基于 Kubernetes 的工作流引擎，用于编排和运行容器化应用的工作流程。它使用 YAML 文件来定义工作流、依赖关系和参数。
工作流中可以包含多个步骤，每个步骤可以是一个容器、一个脚本或一个自定义的操作。工作流中的步骤可以串行执行、并行执行或根据条件进行分支。
Argo Workflow 还支持任务的重试、跳过、并行执行和失败处理等功能。它提供了丰富的工作流控制和监控功能，可以查看工作流的状态、日志和执行历史，并支持自定义的事件触发和通知机制。 目前Argo项目中有如下几个子项目：
argoproj Common project repo for all Argo Projects gitops-engine Public Democratizing GitOps argo-workflows Workflow engine for Kubernetes argo-cd Declarative continuous deployment for Kubernetes. argo-events Event-driven automation framework argo-rollouts Progressive Delivery for Kubernetes cd和rollouts一个是持续交付工具，一个是渐进式发布工具，与原子能力关系不大。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。都与本次原子能力相关。
这样，就可以设计出一个由新建扫描任务事件触发，实例化经过编排可实现扫描全流程的方案。
流程如下：![[book_architecture/content/docs/programmer/base/argo_events_workfows.png]]
sensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排 # name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = &amp;ldquo;heads&amp;rdquo; if random.</description></item><item><title/><link>http://example.org/docs/programmer/base/argo-%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/argo-%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/</guid><description>Github: https://github.com/argoproj
一、简介 # 目前Argo项目中有如下几个子项目：
argoproj Common project repo for all Argo Projects
gitops-engine Public Democratizing GitOps
argo-workflows Workflow engine for Kubernetes
argo-cd Declarative continuous deployment for Kubernetes.
argo-events Event-driven automation framework
argo-rollouts Progressive Delivery for Kubernetes
cd和rollouts一个是持续交付工具，一个是渐进式发布工具，与原子能力关系不大。 workflows和events一个是基于容器的任务编排工具，一个是事件驱动框架。都与本次原子能力相关。
这样，就可以设计出一个由新建扫描任务事件触发，实例化经过编排可实现扫描全流程的方案。
流程如下：![[book_architecture/content/docs/programmer/base/argo_events_workfows.png]]
sensor作用 # 使事件转发和处理松耦合 Trigger事件的参数化，比如根据事件内容动态生成 二、Argo Workflow编排 # name: flip-coin script: image: python:alpine3.6 command: [python] source: | import random result = &amp;ldquo;heads&amp;rdquo; if random.randint(0,1) == 0 else &amp;ldquo;tails&amp;rdquo; print(result)
name: heads container: image: alpine:3.</description></item><item><title/><link>http://example.org/docs/programmer/base/kafka-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/kafka-%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</guid><description>常用命令 # 创建topic # sh kafka-console-producer.sh --create --topic scanner_device_log --bootstrap-server localhost:9092 --partitions 0 --replication-factor 1 发送接收测试 # sh kafka-console-producer.sh --broker-list localhost:9092 --topic test sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test 单机部署 # 本文链接🔗 Kafka是一个开源的分布式消息引擎/消息中间件，同时Kafka也是一个流处理平台。Kakfa支持以发布/订阅的方式在应用间传递消息，同时并基于消息功能添加了Kafka Connect、Kafka Streams以支持连接其他系统的数据(Elasticsearch、Hadoop等) Kafka在生产环境下使用通常是集群化部署的，同时也要依赖ZooKeeper集群，这对开发测试环境来说比较重，不过我们可以通过Docker便捷Kafka单机的方式，节省部署时间以及机器资源
1、本文主要内容 # 通过Docker手动部署ZooKeeper&amp;amp;Kafka 通过Docker Compose快捷部署ZooKeeper&amp;amp;Kafka Kafka发送、接收消息测试 2、本文环境信息 # 工具 说明 适配 Docker Docker CE 23.0.5 Docker CE Docker Desktop 4.19.0 4.0.x ZooKeeper zookeeper:3.8（Docker Image ） zookeeper:3.x（Docker Image ） Kafka wurstmeister/kafka:2.13-2.8.1（Docker Image） wurstmeister/kafka:2.x（Docker Image） 二、手动部署Kafka # 1、拉取镜像 # 先通过docker pull 命令把镜像拉取下来，方便后续操作</description></item><item><title/><link>http://example.org/docs/programmer/base/pytest-%E6%B5%8B%E8%AF%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/pytest-%E6%B5%8B%E8%AF%95/</guid><description>[TOC]
命令 # Django 整合进 pytest测试 # pip install pytest-django pytest -s -vv .\tests\test_step2.py --rootdir X:\Code\workflows\ --ds project.settings rootdir 指定项目根目录 ds 指向django setting.py 文件 一、为什么需要pytest # helps you write better programs
提高阅读理解代码效率 提高debug效率 提高开发效率 保证交付代码质量 简单例子 # 入门例子:
了解使用test文件命名格式: test_前缀 了解断言assert 了解测试输出 # content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5 输出
$ pytest =========================== test session starts ============================ platform linux -- Python 3.</description></item><item><title/><link>http://example.org/docs/programmer/base/sonar-%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E6%A3%80%E6%9F%A5/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/sonar-%E4%BB%A3%E7%A0%81%E9%9D%99%E6%80%81%E6%A3%80%E6%9F%A5/</guid><description>平台地址 需要自建
在平台新建项目，新建token后可以自动生成扫描命令(拉代码, cd进去后在项目代码/路径下执行)：
sonar-scanner \ -Dsonar.projectKey=scancenter \ -Dsonar.sources=. \ -Dsonar.host.url=https://sonar-xa.inone.nsfocus.com \ -Dsonar.login=3e569f7abcfd8a64067d790f038c57a6a6b73207 如果使用的是他人的token，需要给授权。</description></item><item><title/><link>http://example.org/docs/programmer/base/%E5%B0%8F%E5%91%BD%E4%BB%A4/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/%E5%B0%8F%E5%91%BD%E4%BB%A4/</guid><description>title: 小命令 date: 2023-09-24 23:03:41 categories: [小命令] tags: [小命令]
小命令 # 1. 递归删除某些文件 # 如以.py.bak 为结尾的文件: find . -name &amp;quot;*.py.bak&amp;quot; -exec rm {} \;
2. 批量杀死进程 # - pkill -f uwsgi
- ps aux | grep 关键字 | awk &amp;lsquo;{print $2}&amp;rsquo; | xargs kill
批量删除pod - xargs 的使用 # kubectl get pod -n argo | grep workflow-template | awk &amp;#39;{print $1}&amp;#39; | xargs kubectl -n argo delete pod 3. MySQL NOW # 指定东八：update scanner_device set update_time = CONVERT_TZ(NOW(), @@session.</description></item><item><title>Dgraph</title><link>http://example.org/docs/programmer/base/tip_dgraph/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/tip_dgraph/</guid><description>
问题 # 在新手村的时候使用dgraph/standalone 但此时(2021-12-8 18:30:23)文档使用的版本为dgraph/standalone:v21.03.2但是这个版本的Ratel UI不工作&amp;hellip;. 导致hello 不了 world很是难受
结果换了dgraph/standalone:v20.11.3好了诶.
sudo docker run --rm -it -p &amp;#34;8080:8080&amp;#34; -p &amp;#34;9080:9080&amp;#34; -p &amp;#34;8000:8000&amp;#34; -v ~/dgraph:/dgraph &amp;#34;dgraph/standalone:v20.11.3&amp;#34; http://127.0.0.1:8000</description></item><item><title>数据格式笔记</title><link>http://example.org/docs/programmer/base/noteoffmtdata/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/base/noteoffmtdata/</guid><description>算法图解 # 在线书: https://www.hello-algo.com
单向链表实现和反转 # # 单向链表实现和反转 &amp;#34;&amp;#34;&amp;#34; # 当前值, 下一个值 # 循环 # 将当前值赋值为下一个的值, 下一个节点值为当前节点值 # 当前节点next赋 &amp;#34;&amp;#34;&amp;#34; class A: def __init__(self, v): self.v = v self.next = None class LA: def __init__(self): self.head = None def add(self, v): node = A(v) node.next = self.head self.head = node def print(self): cur = self.head while cur and cur.v != None: print(f&amp;#34;linkdata node v: {cur.v}&amp;#34;) cur = cur.next def revert(self, node: A=None, head=None): if not head: cache = self.</description></item></channel></rss>