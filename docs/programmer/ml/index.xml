<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习 on Ian's Blog</title><link>http://example.org/docs/programmer/ml/</link><description>Recent content in 机器学习 on Ian's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 26 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://example.org/docs/programmer/ml/index.xml" rel="self" type="application/rss+xml"/><item><title>AI画图</title><link>http://example.org/docs/programmer/ml/stable-diffusion/</link><pubDate>Mon, 18 Mar 2024 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/stable-diffusion/</guid><description>起手式 # 正 # best quality, (mature:1.3),perfect face, beautiful face,western, sharp focus, solo,beautiful woman,sexy,shiny skin,Navy blouse, beige shorts, soft light,cinematic lighting, sunny, dusk, outdoor,depth of field,shidudou,red_dress, 反 # (worst quality, low quality:2), NSFW, monochrome, zombie, overexposure, watermark, text, bad anatomy, bad hand,((extra hands)),extra fingers, too many fingers, fused fingers, bad arm, distorted arm, extra arms, fused arms, extra legs, missing leg,disembodied leg,extra nipples, detached arm, liquid hand, inverted hand, disembodied limb, oversized head, extra body, extra navel, (hair between eyes),sketch, duplicate, ugly, huge eyes, text, logo, worst face, (bad and mutated hands:1.</description></item><item><title>图片背景消除</title><link>http://example.org/docs/programmer/ml/%E5%9B%BE%E7%89%87%E8%83%8C%E6%99%AF%E6%B6%88%E9%99%A4/</link><pubDate>Tue, 26 Nov 2024 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/%E5%9B%BE%E7%89%87%E8%83%8C%E6%99%AF%E6%B6%88%E9%99%A4/</guid><description>一、工具 rembg # https://github.com/danielgatis/rembg
rembg i -m birefnet-massive 20241126-140049.jpg 49-max.png 默认使用u2net模型， 使用-m 可以指定模型运行
二、模型 # Model Name Download Link Source Link Description 描述 u2net Download Source A pre-trained model for general use cases. 用于通用用途的预训练模型。 u2netp Download Source A lightweight version of u2net model. u2net模型的轻量版。 u2net_human_seg Download Source A pre-trained model for human segmentation. 用于人类分割的预训练模型。 u2net_cloth_seg Download Source A pre-trained model for clothes parsing. 用于服装解析的预训练模型（上衣、下衣、全身）。 silueta Download Source A reduced size version of u2net (43MB).</description></item><item><title>机器人行为自动编排和任务</title><link>http://example.org/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%A1%8C%E4%B8%BA%E8%87%AA%E5%8A%A8%E7%BC%96%E6%8E%92%E5%92%8C%E4%BB%BB%E5%8A%A1/</link><pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%A1%8C%E4%B8%BA%E8%87%AA%E5%8A%A8%E7%BC%96%E6%8E%92%E5%92%8C%E4%BB%BB%E5%8A%A1/</guid><description>一、分层 # 人机交互型的从人到机器逐层看是
接受端： 语音识别 &amp;amp; 图像识别 &amp;amp; 压力感知 语义理解： 语言大模型/语义提取模型， 前者专业，后者专精 状态感知：图像识别 &amp;amp; 其他传感器 行为编排： 语言大模型/图数据编排/行为树 动作执行 二、最小系统流程 # 使用者发出命令，接收端接受进行语义理解，获知使用者目的 -&amp;gt; 参数一 当获知目的之后，先对当前状态进行分析（所处环境和当前执行任务状态） -&amp;gt; 参数二 将获取到的两参数都传于任务编排模型后，基于当前状态和命令创建后续流程 最后按步骤执行任务即可 三、所需技术 # 语音识别： 本地部署模型可选用阿里Paraformer，地址：https://github.com/modelscope/FunASR/wiki/paraformer， 我这里也有个demo项目: https://github.com/IanVzs/asr 基本和wiki里示例一样 如果需要tts的话可以用: https://github.com/kuangdd/ttskit， 可以在执行动作的时候“说”出来调试用 或者调讯飞服务接口，地址：https://www.xfyun.cn/doc/asr/voicedictation/API.html#%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B 以上两个都涵盖了流式和语音文件识别两种方式，准确率都相当高可以满足几乎任何场合使用 图像识别： 目标识别可用yolo，或者用飞桨相关模型，不过这两个只能获取到二维信息，要对物体进行准确定位还需要搭配“双目深度估计算法”才可以组装出来三维信息 当然也可以用多模态大模型替换yolo，但是速度会变慢，其获取到的还是二维数据，可以对视野里的物体进行广泛的识别但是无法做到精准定位：https://community.modelscope.cn/669e26f4962e585a2565ab42.html 压力感知或其他传感器： 嵌入式内容， 具体情况具体实现 大模型prompt工程和微调： prompt可以满足大多数场景需求，可见： https://www.promptingguide.ai/zh 微调Lora技术 有需要再看，具体得根据大模型选型，去看相对应大模型的具体微调文档 汉语类的可选ChatGLM, QWen这些 Mixtral-8x7b 这种混合模型或许更适合你的使用场景 四、优化点 # 在跑通最小系统的单线程流程之后， 就可以就任务中断、处理干扰、大模型效果优化进行对点的提升。 所用方案大体上也就是：
同步改异步：将最小系统流程中的步骤由1-&amp;gt;2-&amp;gt;3-&amp;gt;4修改为互相独立的1, 2, 3, 4每个任务都基于事件变化进行触发，如拿红球，突然视野中红球全部变为绿球，因外界状态改变就应自主触发第三步编排任务对当前的抓取动作进行中断。 多任务融合： 续接1中红绿球所描述的，对抓取红球和取消抓取动作这两个任务进行融合 或者说原本视野只有一个红球，突然变成两个，就需要对抓取一个红球的任务编排和抓取两个红球的任务编排进行融合 对大语言模型进行“驯化”，固化大模型输出内容格式，链式思考提升准确度： 大语言模型经常性胡言乱语或逻辑不准，很正常，需要反复了解把控 需要对大模型动作做风控 总之，以上工作所涉领域很多，每个领域所要求都偏高，要实现只能是搭积木。这样就使得这个工作更加偏向工程一些，并不怎么偏研究类。语音识别能力现在已经相当高尽管拿来用，不用投入无用时间。 图像这块儿所投入的精力会比较多，尤其是在具体定位某个物体上。</description></item><item><title>爬虫</title><link>http://example.org/docs/programmer/ml/%E7%88%AC%E8%99%AB/</link><pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/%E7%88%AC%E8%99%AB/</guid><description>https://github.com/SeleniumHQ/seleniumhq.github.io/blob/trunk/examples/python/tests/getting_started/first_script.py#L4
Selenium # chromedriver地址 # https://googlechromelabs.github.io/chrome-for-testing/#stable
geckodriver(firefox)地址 # https://github.com/mozilla/geckodriver/releases
Firefox headlees运行需要的依赖 # apt-get install -y wget bzip2 libxtst6 libgtk-3-0 libx11-xcb-dev libdbus-glib-1-2 libxt6 libpci-dev libasound2</description></item><item><title>Paddle</title><link>http://example.org/docs/programmer/ml/paddle/</link><pubDate>Wed, 08 Jun 2022 18:58:56 +0000</pubDate><guid>http://example.org/docs/programmer/ml/paddle/</guid><description>slug: Paddle的坑 # 资源占用 # 命令示例(yml中修改了train,test样本地址,使用--gpus这里只用了一个GPU,可方便修改为多卡0,1,2,3)
python -m paddle.distributed.launch --gpus &amp;#39;1&amp;#39; tools/train.py -c configs/rec/PP-OCRv3/en_PP-OCRv3_rec.yml -o Global.pretrained_model=./pretrain_models/en_PP-OCRv3_rec_train/best_accuracy.pdparams en_PP-OCRv3_rec默认性能配置在, 单卡V100上: +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+ | 1 Tesla V100-SXM2&amp;hellip; On | 00000000:00:09.0 Off | 0 | | N/A 53C P0 223W / 300W | 23065MiB / 32510MiB | 100% Default | | | | N/A | +&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;-+
Paddle 多卡训练 # You may need to install &amp;rsquo;nccl2&amp;rsquo; from NVIDIA official website
Traceback: 这种问题可以参看Github Issues
写在坑前头 # 经测试，下面预训练模型下载地址和检测训练效果的脚本之所以报错是因为PaddleOCR项目主页的readme中链接的子readme是develop分支的。且这个分支是落后于当前release/2.5的，所以出现了以下不匹配的情况. 切换了分支之后, 匹配度还可以接受.</description></item><item><title>Tensorflow</title><link>http://example.org/docs/programmer/ml/tensorflow/</link><pubDate>Wed, 30 Mar 2022 17:23:23 +0000</pubDate><guid>http://example.org/docs/programmer/ml/tensorflow/</guid><description>
v2兼容v1 API # import tensorflow.compat.v1 as tf tf.disable_v2_behavior()</description></item><item><title>OpenCV</title><link>http://example.org/docs/programmer/ml/opencv/</link><pubDate>Thu, 22 Apr 2021 17:23:23 +0000</pubDate><guid>http://example.org/docs/programmer/ml/opencv/</guid><description>
问题(libSM.so.6 缺失) # 运行opencv的代码时，报以下错误： # Traceback (most recent call last): File &amp;#34;data_generator.py&amp;#34;, line 24, in &amp;lt;module&amp;gt; import cv2 File &amp;#34;/usr/local/lib/python3.5/dist-packages/cv2/__init__.py&amp;#34;, line 3, in &amp;lt;module&amp;gt; from .cv2 import * ImportError: libSM.so.6: cannot open shared object file: No such file or directory 解决 # 原因是缺少共享文件库，解决办法如下：
安装apt-file $ apt-get update $ apt-get install apt-file $ apt-file update
寻找依赖库 $ apt-file search libSM.so.6
libsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6 libsm6: /usr/lib/x86_64-linux-gnu/libSM.so.6.0.1
根据提示，安装合适的依赖库 $ apt-get install libsm6
其余文件缺失类似, 即可解决问题。</description></item><item><title>Demo Test项目中的一些东西</title><link>http://example.org/docs/programmer/ml/yolo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/yolo/</guid><description>yolov5 # 使用自己的素材进行目标识别训练
之前使用个位数样本识别Vmon结果败的一塌糊涂 现在用来检测卡片倒是得心应手 9个训练卡片,准确率可以到50多,自我感觉还行 使用方法: 在此</description></item><item><title>Python 图表</title><link>http://example.org/docs/programmer/ml/python-%E5%9B%BE%E8%A1%A8/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/python-%E5%9B%BE%E8%A1%A8/</guid><description>Python 图表 # 主要用: matplotlib import matplotlib.pyplot as plt
堆叠图 # summery_one_offer_dict_by_install_date, install_datas_by_install_date_dict = await rc.calculate_offer_do_status(offer_id=offer_id) # 计算需要的行数和列数（每行4个图表） num_offers = len(summery_one_offer_dict_by_install_date.keys()) num_cols = 3 num_rows = math.ceil(num_offers / num_cols) # 创建一个图形和子图数组 fig, axs = plt.subplots(num_rows, num_cols, figsize=(45, num_rows * 3)) if num_offers == 1: axs = [axs] # Flatten the axs array for easy iteration else: axs = axs.flatten() for ax, (install_date, data) in zip(axs, summery_one_offer_dict_by_install_date.items()): # 排序和处理数据 data = data.</description></item><item><title>机器学习库</title><link>http://example.org/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%BA%93%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://example.org/docs/programmer/ml/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E5%BA%93%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/</guid><description>Python 机器学习库 👽 # Plotly # 与matplotlib 都是绘图工具，不过效果炫一些，我也没画过，所以只放链接，不放实例了 Plotly Python Library : https://plot.ly/python/
matplotlib # import matplotlib.pyplot as plt 参数等太多，链接最可靠 # pyplot参数
还是粘一些常用的： marker 属性（下面写在分号里呦） o . v ^ &amp;lt; &amp;gt; 1 2 3 4 8 s p * h H + x D d | _ 之类
画出一些“花儿”
绘图 # plt.plot(x, y) # 在y之后可添加参数，例如常用的label = ‘IamLabel’之类 # 线的样式、颜色 ：b: blue g: green r: red c: cyan m: magenta y: yellow k: black w: white '-' : solid , '--' : dashed, '-.</description></item></channel></rss>